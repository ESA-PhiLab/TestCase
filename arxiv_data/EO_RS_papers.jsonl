{"entry_id": "http://arxiv.org/abs/2106.00079v2", "date": "2021-05-31", "title": "Fundamental Challenges to Remote Sensing of Exo-Earths", "authors": "Adiv Paradise, Kristen Menou, Christopher Lee, Bo Lin Fan", "abstract": "Inferring the climate and surface conditions of terrestrial exoplanets in the\nhabitable zone is a major goal for the field of exoplanet science. This pursuit\nwill require both statistical analyses of the population of habitable planets\nas well as in-depth analyses of the climates of individual planets. Given the\nclose relationship between habitability and surface liquid water, it is\nimportant to ask whether the fraction of a planet's surface where water can be\na liquid, $\\chi_\\text{hab}$, can be inferred from observations. We have\nproduced a diverse bank of 1,874 3D climate models and computed the full-phase\nreflectance and emission spectrum for each model to investigate whether surface\nclimate inference is feasible with high-quality direct imaging or secondary\neclipse spectroscopy. These models represent the outcome of approximately\n200,000 total simulated years of climate and over 50,000 CPU-hours, and the\nroughly-100 GB model bank and its associated spectra are being made\npublicly-available for community use. We find that there are correlations\nbetween spectra and $\\chi_\\text{hab}$ that will permit statistical approaches.\nHowever, spectral degeneracies in the climate observables produced by our model\nbank indicate that inference of individual climates is likely to be\nmodel-dependent, and inference will likely be impossible without exhaustive\nexplorations of the climate parameter space. The diversity of potential\nclimates on habitable planets therefore poses fundamental challenges to remote\nsensing efforts targeting exo-Earths.", "journal": "", "doi": "10.1093/mnras/stac724", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2106.00079v2"}
{"entry_id": "http://arxiv.org/abs/2209.00551v1", "date": "2022-09-01", "title": "Fast Fourier Convolution Based Remote Sensor Image Object Detection for Earth Observation", "authors": "Gu Lingyun, Eugene Popov, Dong Ge", "abstract": "Remote sensor image object detection is an important technology for Earth\nobservation, and is used in various tasks such as forest fire monitoring and\nocean monitoring. Image object detection technology, despite the significant\ndevelopments, is struggling to handle remote sensor images and small-scale\nobjects, due to the limited pixels of small objects. Numerous existing studies\nhave demonstrated that an effective way to promote small object detection is to\nintroduce the spatial context. Meanwhile, recent researches for image\nclassification have shown that spectral convolution operations can perceive\nlong-term spatial dependence more efficiently in the frequency domain than\nspatial domain. Inspired by this observation, we propose a Frequency-aware\nFeature Pyramid Framework (FFPF) for remote sensing object detection, which\nconsists of a novel Frequency-aware ResNet (F-ResNet) and a Bilateral\nSpectral-aware Feature Pyramid Network (BS-FPN). Specifically, the F-ResNet is\nproposed to perceive the spectral context information by plugging the frequency\ndomain convolution into each stage of the backbone, extracting richer features\nof small objects. To the best of our knowledge, this is the first work to\nintroduce frequency-domain convolution into remote sensing object detection\ntask. In addition, the BSFPN is designed to use a bilateral sampling strategy\nand skipping connection to better model the association of object features at\ndifferent scales, towards unleashing the potential of the spectral context\ninformation from F-ResNet. Extensive experiments are conducted for object\ndetection in the optical remote sensing image dataset (DIOR and DOTA). The\nexperimental results demonstrate the excellent performance of our method. It\nachieves an average accuracy (mAP) without any tricks.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2209.00551v1"}
{"entry_id": "http://arxiv.org/abs/1804.04138v2", "date": "2018-04-11", "title": "Earth as an Exoplanet", "authors": "Tyler D. Robinson, Christopher T. Reinhard", "abstract": "Earth is the only planet known to harbor life and, as a result, the search\nfor habitable and inhabited planets beyond the Solar System commonly focuses on\nanalogs to our planet. However, Earth's atmosphere and surface environment have\nevolved substantially in the last 4.5 billion years. A combination of in situ\ngeological and biogeochemical modeling studies of our planet have provided\nglimpses of environments that, while technically belonging to our Earth, are\nseemingly alien worlds. For modern Earth, observations from ground-based\nfacilities, satellites, and spacecraft have yielded a rich collection of data\nthat can be used to effectively view our planet within the context of exoplanet\ncharacterization. Application of planetary and exoplanetary remote sensing\ntechniques to these datasets then enables the development of approaches for\ndetecting signatures of habitability and life on other worlds. In addition, an\narray of models have been used to simulate exoplanet-like datasets for the\ndistant Earth, thereby providing insights that are often complementary to those\nfrom existing observations. Understanding the myriad ways Earth has been\nhabitable and inhabited, coupled with remote sensing approaches honed on the\ndistant Earth, provides a key guide to recognizing potentially life-bearing\nenvironments in other planetary systems.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1804.04138v2"}
{"entry_id": "http://arxiv.org/abs/2206.13188v2", "date": "2022-06-27", "title": "Self-supervised Learning in Remote Sensing: A Review", "authors": "Yi Wang, Conrad M Albrecht, Nassim Ait Ali Braham, Lichao Mou, Xiao Xiang Zhu", "abstract": "In deep learning research, self-supervised learning (SSL) has received great\nattention triggering interest within both the computer vision and remote\nsensing communities. While there has been a big success in computer vision,\nmost of the potential of SSL in the domain of earth observation remains locked.\nIn this paper, we provide an introduction to, and a review of the concepts and\nlatest developments in SSL for computer vision in the context of remote\nsensing. Further, we provide a preliminary benchmark of modern SSL algorithms\non popular remote sensing datasets, verifying the potential of SSL in remote\nsensing and providing an extended study on data augmentations. Finally, we\nidentify a list of promising directions of future research in SSL for earth\nobservation (SSL4EO) to pave the way for fruitful interaction of both domains.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2206.13188v2"}
{"entry_id": "http://arxiv.org/abs/2209.12480v1", "date": "2022-09-26", "title": "EOD: The IEEE GRSS Earth Observation Database", "authors": "Michael Schmitt, Pedram Ghamisi, Naoto Yokoya, Ronny H\u00e4nsch", "abstract": "In the era of deep learning, annotated datasets have become a crucial asset\nto the remote sensing community. In the last decade, a plethora of different\ndatasets was published, each designed for a specific data type and with a\nspecific task or application in mind. In the jungle of remote sensing datasets,\nit can be hard to keep track of what is available already. With this paper, we\nintroduce EOD - the IEEE GRSS Earth Observation Database (EOD) - an interactive\nonline platform for cataloguing different types of datasets leveraging remote\nsensing imagery.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2209.12480v1"}
{"entry_id": "http://arxiv.org/abs/2112.05455v1", "date": "2021-12-10", "title": "Quantum-enhanced passive remote sensing", "authors": "Emre K\u00f6se, Gerardo Adesso, Daniel Braun", "abstract": "We investigate theoretically the ultimate resolution that can be achieved\nwith passive remote sensing in the microwave regime used e.g.~on board of\nsatellites observing Earth, such as the Soil Moisture and Ocean Salinity (SMOS)\nmission. We give a fully quantum mechanical analysis of the problem, starting\nfrom thermal distributions of microscopic currents on the surface to be imaged\nthat lead to a mixture of coherent states of the electromagnetic field which\nare then measured with an array of receivers. We derive the optimal detection\nmodes and measurement schemes that allow one to saturate the quantum\nCram\\'er-Rao bound for the chosen parameters that determine the distribution of\nthe microscopic currents. For parameters comparable to those of SMOS, a quantum\nenhancement of the spatial resolution by more than a factor of 20 should be\npossible with a single measurement and a single detector, and a resolution down\nto the order of 1 meter and less than a 1/10 Kelvin for the theoretically\npossible maximum number of measurements.", "journal": "", "doi": "10.1103/PhysRevA.106.012601", "primary_category": "quant-ph", "categories": ["quant-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/2112.05455v1"}
{"entry_id": "http://arxiv.org/abs/1909.04381v1", "date": "2019-09-10", "title": "Pedagogical techniques of Earth remote sensing data application into modern school practice", "authors": "Ihor Kholoshyn, Iryna Varfolomyeyeva, Olena Hanchuk, Olga Bondarenko, Andrey Pikilnyak", "abstract": "The article dwells upon the Earth remote sensing data as one of the basic\ndirections of Geo-Information Science, a unique source of information on\nprocesses and phenomena occurring in almost all spheres of the Earth geographic\nshell (atmosphere, hydrosphere, lithosphere, etc.). The authors argue that the\nuse of aerospace images by means of the information and communication\ntechnologies involvement in the learning process allows not only to increase\nthe information context value of learning, but also contributes to the\nformation of students' cognitive interest in such disciplines as geography,\nbiology, history, physics, computer science, etc. It has been grounded that\nremote sensing data form students' spatial, temporal and qualitative concepts,\nsensory support for the perception, knowledge and explanation of the specifics\nof objects and phenomena of geographical reality, which, in its turn, provides\nan increase in the level of educational achievements. The techniques of\naerospace images application into the modern school practice have been analyzed\nand illustrated in the examples: from using them as visual aids, to realization\nof practical and research orientation of training on the basis of remote\nsensing data. Particular attention is paid to the practical component of the\nEarth remote sensing implementation into the modern school practice with the\nhelp of information and communication technologies.", "journal": "CEUR Workshop Proceedings 2433 (2018) 391-402", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY"], "pdf_url": "http://arxiv.org/pdf/1909.04381v1"}
{"entry_id": "http://arxiv.org/abs/1010.1171v1", "date": "2010-10-06", "title": "Polarimetric Remote Sensing of Solar System Objects", "authors": "M. I. Mishchenko, V. K. Rosenbush, N. N. Kiselev, D. F. Lupishko, V. P. Tishkovets, V. G. Kaydash, I. N. Belskaya, Y. S. Efimov, N. M. Shakhovskoy", "abstract": "This book outlines the basic physical principles and practical methods of\npolarimetric remote sensing of Solar System objects and summarizes numerous\nadvanced applications of polarimetry in geophysics and planetary astrophysics.\nIn the first chapter we present a complete and rigorous theory of\nelectromagnetic scattering by disperse media directly based on the Maxwell\nequations and describe advanced physically based modeling tools. This is\nfollowed, in Chapter 2, by a theoretical analysis of polarimetry as a\nremote-sensing tool and an outline of basic principles of polarimetric\nmeasurements and their practical implementations. In Chapters 3 and 4, we\ndescribe the results of extensive ground-based, aircraft, and spacecraft\nobservations of numerous Solar System objects (the Earth and other planets,\nplanetary satellites, Saturn's rings, asteroids, trans-Neptunian objects, and\ncomets). Theoretical analyses of these data are used to retrieve optical and\nphysical characteristics of planetary surfaces and atmospheres as well as to\nidentify a number of new phenomena and effects. This monograph is intended for\nscience professionals, educators, and graduate students specializing in remote\nsensing, astrophysics, atmospheric physics, optics of disperse and disordered\nmedia, and optical particle characterization.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.ao-ph", "physics.ins-det", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/1010.1171v1"}
{"entry_id": "http://arxiv.org/abs/2210.04936v2", "date": "2022-10-10", "title": "EarthNets: Empowering AI in Earth Observation", "authors": "Zhitong Xiong, Fahong Zhang, Yi Wang, Yilei Shi, Xiao Xiang Zhu", "abstract": "Earth observation, aiming at monitoring the state of planet Earth using\nremote sensing data, is critical for improving our daily lives and living\nenvironment. With a growing number of satellites in orbit, an increasing number\nof datasets with diverse sensors and research domains are being published to\nfacilitate the research of the remote sensing community. In this paper, we\npresent a comprehensive review of more than 400 publicly published datasets,\nincluding applications like land use/cover, change/disaster monitoring, scene\nunderstanding, agriculture, climate change, and weather forecasting. We\nsystematically analyze these Earth observation datasets with respect to five\naspects volume, bibliometric analysis, resolution distributions, research\ndomains, and the correlation between datasets. Based on the dataset attributes,\nwe propose to measure, rank, and select datasets to build a new benchmark for\nmodel evaluation. Furthermore, a new platform for Earth observation, termed\nEarthNets, is released as a means of achieving a fair and consistent evaluation\nof deep learning methods on remote sensing data. EarthNets supports standard\ndataset libraries and cutting-edge deep learning models to bridge the gap\nbetween the remote sensing and machine learning communities. Based on this\nplatform, extensive deep learning methods are evaluated on the new benchmark.\nThe insightful results are beneficial to future research. The platform and\ndataset collections are publicly available at https://earthnets.github.io/.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.04936v2"}
{"entry_id": "http://arxiv.org/abs/2007.10774v1", "date": "2020-07-21", "title": "Cloud technologies as a tool of creating Earth Remote Sensing educational resources", "authors": "Ihor Kholoshyn, Olga Bondarenko, Olena Hanchuk, Iryna Varfolomyeyeva", "abstract": "This article is dedicated to the Earth Remote Sensing (ERS), which the\nauthors believe is a great way to teach geography and allows forming an idea of\nthe actual geographic features and phenomena. One of the major problems that\nnow constrains the active introduction of remote sensing data in the\neducational process is the low availability of training aerospace pictures,\nwhich meet didactic requirements. The article analyzes the main sources of ERS\nas a basis for educational resources formation with aerospace images: paper,\nvarious individual sources (personal stations receiving satellite information,\ndrones, balloons, kites and balls) and Internet sources (mainstream sites,\nsites of scientific-technical organizations and distributors, interactive\nInternet geoservices, cloud platforms of geospatial analysis). The authors\npoint out that their geospatial analysis platforms (Google Earth Engine, Land\nViewer, EOS Platform, etc.), due to their unique features, are the basis for\nthe creation of information thematic databases of ERS. The article presents an\nexample of such a database, covering more than 800 aerospace images and dynamic\nmodels, which are combined according to such didactic principles as high\ninformation load and clarity.", "journal": "CEUR Workshop Proceedings 2643 (2020) 474-486", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY"], "pdf_url": "http://arxiv.org/pdf/2007.10774v1"}
{"entry_id": "http://arxiv.org/abs/2206.11892v2", "date": "2022-06-23", "title": "DDPM-CD: Remote Sensing Change Detection using Denoising Diffusion Probabilistic Models", "authors": "Wele Gedara Chaminda Bandara, Nithin Gopalakrishnan Nair, Vishal M. Patel", "abstract": "Human civilization has an increasingly powerful influence on the earth\nsystem, and earth observations are an invaluable tool for assessing and\nmitigating the negative impacts. To this end, observing precisely defined\nchanges on Earth's surface is essential, and we propose an effective way to\nachieve this goal. Notably, our change detection (CD)/ segmentation method\nproposes a novel way to incorporate the millions of off-the-shelf, unlabeled,\nremote sensing images available through different earth observation programs\ninto the training process through denoising diffusion probabilistic models. We\nfirst leverage the information from these off-the-shelf, uncurated, and\nunlabeled remote sensing images by using a pre-trained denoising diffusion\nprobabilistic model and then employ the multi-scale feature representations\nfrom the diffusion model decoder to train a lightweight CD classifier to detect\nprecise changes. The experiments performed on four publically available CD\ndatasets show that the proposed approach achieves remarkably better results\nthan the state-of-the-art methods in F1, IoU, and overall accuracy. Code and\npre-trained models are available at: https://github.com/wgcban/ddpm-cd", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2206.11892v2"}
{"entry_id": "http://arxiv.org/abs/2302.00912v3", "date": "2023-02-02", "title": "Advances and Challenges in Multimodal Remote Sensing Image Registration", "authors": "Bai Zhu, Liang Zhou, Simiao Pu, Jianwei Fan, Yuanxin Ye", "abstract": "Over the past few decades, with the rapid development of global aerospace and\naerial remote sensing technology, the types of sensors have evolved from the\ntraditional monomodal sensors (e.g., optical sensors) to the new generation of\nmultimodal sensors [e.g., multispectral, hyperspectral, light detection and\nranging (LiDAR) and synthetic aperture radar (SAR) sensors]. These advanced\ndevices can dynamically provide various and abundant multimodal remote sensing\nimages with different spatial, temporal, and spectral resolutions according to\ndifferent application requirements. Since then, it is of great scientific\nsignificance to carry out the research of multimodal remote sensing image\nregistration, which is a crucial step for integrating the complementary\ninformation among multimodal data and making comprehensive observations and\nanalysis of the Earths surface. In this work, we will present our own\ncontributions to the field of multimodal image registration, summarize the\nadvantages and limitations of existing multimodal image registration methods,\nand then discuss the remaining challenges and make a forward-looking prospect\nfor the future development of the field.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2302.00912v3"}
{"entry_id": "http://arxiv.org/abs/1010.2281v2", "date": "2010-10-12", "title": "GNSS Reflectometry and Remote Sensing: New Objectives and Results", "authors": "Shuanggen Jin, Attila Komjathy", "abstract": "The Global Navigation Satellite System (GNSS) has been a very powerful and\nimportant contributor to all scientific questions related to precise\npositioning on Earth's surface, particularly as a mature technique in geodesy\nand geosciences. With the development of GNSS as a satellite microwave (L-band)\ntechnique, more and wider applications and new potentials are explored and\nutilized. The versatile and available GNSS signals can image the Earth's\nsurface environments as a new, highly precise, continuous, all-weather and\nnear-real-time remote sensing tool. The refracted signals from GNSS Radio\nOccultation satellites together with ground GNSS observations can provide the\nhigh-resolution tropospheric water vapor, temperature and pressure, tropopause\nparameters and ionospheric total electron content (TEC) and electron density\nprofile as well. The GNSS reflected signals from the ocean and land surface\ncould determine the ocean height, wind speed and wind direction of ocean\nsurface, soil moisture, ice and snow thickness. In this paper, GNSS remote\nsensing applications in the atmosphere, oceans, land and hydrology are\npresented as well as new objectives and results discussed.", "journal": "Adv. Space Res., 46(2), 111-117 (2010)", "doi": "10.1016/j.asr.2010.01.014", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1010.2281v2"}
{"entry_id": "http://arxiv.org/abs/2103.05969v1", "date": "2021-03-10", "title": "Self-supervised Change Detection in Multi-view Remote Sensing Images", "authors": "Yuxing Chen, Lorenzo Bruzzone", "abstract": "The vast amount of unlabeled multi-temporal and multi-sensor remote sensing\ndata acquired by the many Earth Observation satellites present a challenge for\nchange detection. Recently, many generative model-based methods have been\nproposed for remote sensing image change detection on such unlabeled data.\nHowever, the high diversities in the learned features weaken the discrimination\nof the relevant change indicators in unsupervised change detection tasks.\nMoreover, these methods lack research on massive archived images. In this work,\na self-supervised change detection approach based on an unlabeled multi-view\nsetting is proposed to overcome this limitation. This is achieved by the use of\na multi-view contrastive loss and an implicit contrastive strategy in the\nfeature alignment between multi-view images. In this approach, a pseudo-Siamese\nnetwork is trained to regress the output between its two branches pre-trained\nin a contrastive way on a large dataset of multi-temporal homogeneous or\nheterogeneous image patches. Finally, the feature distance between the outputs\nof the two branches is used to define a change measure, which can be analyzed\nby thresholding to get the final binary change map. Experiments are carried out\non five homogeneous and heterogeneous remote sensing image datasets. The\nproposed SSL approach is compared with other supervised and unsupervised\nstate-of-the-art change detection methods. Results demonstrate both\nimprovements over state-of-the-art unsupervised methods and that the proposed\nSSL approach narrows the gap between unsupervised and supervised change\ndetection.", "journal": "", "doi": "10.1109/TGRS.2021.3089453", "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2103.05969v1"}
{"entry_id": "http://arxiv.org/abs/2007.06277v1", "date": "2020-07-13", "title": "OpenStreetMap: Challenges and Opportunities in Machine Learning and Remote Sensing", "authors": "John Vargas, Shivangi Srivastava, Devis Tuia, Alexandre Falcao", "abstract": "OpenStreetMap (OSM) is a community-based, freely available, editable map\nservice that was created as an alternative to authoritative ones. Given that it\nis edited mainly by volunteers with different mapping skills, the completeness\nand quality of its annotations are heterogeneous across different geographical\nlocations. Despite that, OSM has been widely used in several applications in\n{Geosciences}, Earth Observation and environmental sciences. In this work, we\npresent a review of recent methods based on machine learning to improve and use\nOSM data. Such methods aim either 1) at improving the coverage and quality of\nOSM layers, typically using GIS and remote sensing technologies, or 2) at using\nthe existing OSM layers to train models based on image data to serve\napplications like navigation or {land use} classification. We believe that OSM\n(as well as other sources of open land maps) can change the way we interpret\nremote sensing data and that the synergy with machine learning can scale\nparticipatory map making and its quality to the level needed to serve global\nand up-to-date land mapping.", "journal": "", "doi": "10.1109/MGRS.2020.2994107", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2007.06277v1"}
{"entry_id": "http://arxiv.org/abs/2209.13369v1", "date": "2022-09-27", "title": "OBBStacking: An Ensemble Method for Remote Sensing Object Detection", "authors": "Haoning Lin, Changhao Sun, Yunpeng Liu", "abstract": "Ensemble methods are a reliable way to combine several models to achieve\nsuperior performance. However, research on the application of ensemble methods\nin the remote sensing object detection scenario is mostly overlooked. Two\nproblems arise. First, one unique characteristic of remote sensing object\ndetection is the Oriented Bounding Boxes (OBB) of the objects and the fusion of\nmultiple OBBs requires further research attention. Second, the widely used deep\nlearning object detectors provide a score for each detected object as an\nindicator of confidence, but how to use these indicators effectively in an\nensemble method remains a problem. Trying to address these problems, this paper\nproposes OBBStacking, an ensemble method that is compatible with OBBs and\ncombines the detection results in a learned fashion. This ensemble method helps\ntake 1st place in the Challenge Track \\textit{Fine-grained Object Recognition\nin High-Resolution Optical Images}, which was featured in \\textit{2021 Gaofen\nChallenge on Automated High-Resolution Earth Observation Image Interpretation}.\nThe experiments on DOTA dataset and FAIR1M dataset demonstrate the improved\nperformance of OBBStacking and the features of OBBStacking are analyzed.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2209.13369v1"}
{"entry_id": "http://arxiv.org/abs/1805.10997v1", "date": "2018-05-28", "title": "Adversarial Examples in Remote Sensing", "authors": "Wojciech Czaja, Neil Fendley, Michael Pekala, Christopher Ratto, I-Jeng Wang", "abstract": "This paper considers attacks against machine learning algorithms used in\nremote sensing applications, a domain that presents a suite of challenges that\nare not fully addressed by current research focused on natural image data such\nas ImageNet. In particular, we present a new study of adversarial examples in\nthe context of satellite image classification problems. Using a recently\ncurated data set and associated classifier, we provide a preliminary analysis\nof adversarial examples in settings where the targeted classifier is permitted\nmultiple observations of the same location over time. While our experiments to\ndate are purely digital, our problem setup explicitly incorporates a number of\npractical considerations that a real-world attacker would need to take into\naccount when mounting a physical attack. We hope this work provides a useful\nstarting point for future studies of potential vulnerabilities in this setting.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1805.10997v1"}
{"entry_id": "http://arxiv.org/abs/1811.02471v2", "date": "2018-10-28", "title": "Convolutional LSTMs for Cloud-Robust Segmentation of Remote Sensing Imagery", "authors": "Marc Ru\u00dfwurm, Marco K\u00f6rner", "abstract": "Clouds frequently cover the Earth's surface and pose an omnipresent challenge\nto optical Earth observation methods. The vast majority of remote sensing\napproaches either selectively choose single cloud-free observations or employ a\npre-classification strategy to identify and mask cloudy pixels. We follow a\ndifferent strategy and treat cloud coverage as noise that is inherent to the\nobserved satellite data. In prior work, we directly employed a straightforward\n\\emph{convolutional long short-term memory} network for vegetation\nclassification without explicit cloud filtering and achieved state-of-the-art\nclassification accuracies. In this work, we investigate this cloud-robustness\nfurther by visualizing internal cell activations and performing an ablation\nexperiment on datasets of different cloud coverage. In the visualizations of\nnetwork states, we identified some cells in which modulation and input gates\nclosed on cloudy pixels. This indicates that the network has internalized a\ncloud-filtering mechanism without being specifically trained on cloud labels.\nOverall, our results question the necessity of sophisticated pre-processing\npipelines for multi-temporal deep learning approaches.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1811.02471v2"}
{"entry_id": "http://arxiv.org/abs/2107.02701v1", "date": "2021-07-06", "title": "Spatiotemporal Fusion in Remote Sensing", "authors": "Hessah Albanwan, Rongjun Qin", "abstract": "Remote sensing images and techniques are powerful tools to investigate earth\nsurface. Data quality is the key to enhance remote sensing applications and\nobtaining a clear and noise-free set of data is very difficult in most\nsituations due to the varying acquisition (e.g., atmosphere and season),\nsensor, and platform (e.g., satellite angles and sensor characteristics)\nconditions. With the increasing development of satellites, nowadays Terabytes\nof remote sensing images can be acquired every day. Therefore, information and\ndata fusion can be particularly important in the remote sensing community. The\nfusion integrates data from various sources acquired asynchronously for\ninformation extraction, analysis, and quality improvement. In this chapter, we\naim to discuss the theory of spatiotemporal fusion by investigating previous\nworks, in addition to describing the basic concepts and some of its\napplications by summarizing our prior and ongoing works.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2107.02701v1"}
{"entry_id": "http://arxiv.org/abs/1401.2871v1", "date": "2014-01-13", "title": "Tensor Representation and Manifold Learning Methods for Remote Sensing Images", "authors": "Lefei Zhang", "abstract": "One of the main purposes of earth observation is to extract interested\ninformation and knowledge from remote sensing (RS) images with high efficiency\nand accuracy. However, with the development of RS technologies, RS system\nprovide images with higher spatial and temporal resolution and more spectral\nchannels than before, and it is inefficient and almost impossible to manually\ninterpret these images. Thus, it is of great interests to explore automatic and\nintelligent algorithms to quickly process such massive RS data with high\naccuracy. This thesis targets to develop some efficient information extraction\nalgorithms for RS images, by relying on the advanced technologies in machine\nlearning. More precisely, we adopt the manifold learning algorithms as the\nmainline and unify the regularization theory, tensor-based method, sparse\nlearning and transfer learning into the same framework. The main contributions\nof this thesis are as follows.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "68"], "pdf_url": "http://arxiv.org/pdf/1401.2871v1"}
{"entry_id": "http://arxiv.org/abs/1209.0671v1", "date": "2012-09-04", "title": "Remote Sensing of Chiral Signatures on Mars", "authors": "William Sparks, James H. Hough, Thomas A. Germer, Frank Robb, Ludmilla Kolokolova", "abstract": "We describe circular polarization as a remote sensing diagnostic of chiral\nsignatures which may be applied to Mars. The remarkable phenomenon of\nhomochirality provides a unique biosignature which can be amenable to remote\nsensing through circular polarization spectroscopy. The natural tendency of\nmicrobes to congregate in close knit communities would be beneficial for such a\nsurvey. Observations of selected areas of the Mars surface could reveal chiral\nsignatures and hence explore the possibility of extant or preserved biological\nmaterial. We describe a new instrumental technique that may enable observations\nof this form.", "journal": "", "doi": "10.1016/j.pss.2012.08.010", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1209.0671v1"}
{"entry_id": "http://arxiv.org/abs/1703.00694v1", "date": "2017-03-02", "title": "On flare-CME characteristics from Sun to Earth combining remote-sensing image data with in-situ measurements supported by modeling", "authors": "M. Temmer, J. K. Thalmann, K. Dissauer, A. M. Veronig, J. Tschernitz, J. Hinterreiter, L. Rodriguez", "abstract": "We analyze the well observed flare-CME event from October 1, 2011\n(SOL2011-10-01T09:18) covering the complete chain of action - from Sun to Earth\n- for a better understanding of the dynamic evolution of the CME and its\nembedded magnetic field. We study the solar surface and atmosphere associated\nwith the flare-CME from SDO and ground-based instruments, and also track the\nCME signature off-limb from combined EUV and white-light data with STEREO. By\napplying 3D reconstruction techniques (GCS, total mass) to stereoscopic\nSTEREO-SoHO coronagraph data, we track the temporal and spatial evolution of\nthe CME in interplanetary space and derive its geometry and 3D-mass. We combine\nthe GCS and Lundquist model results to derive the axial flux and helicity of\nthe MC from in-situ measurements (Wind). This is compared to nonlinear\nforce-free (NLFF) model results as well as to the reconnected magnetic flux\nderived from the flare ribbons (flare reconnection flux) and the magnetic flux\nencompassed by the associated dimming (dimming flux). We find that magnetic\nreconnection processes were already ongoing before the start of the impulsive\nflare phase, adding magnetic flux to the flux rope before its final eruption.\nThe dimming flux increases by more than 25% after the end of the flare,\nindicating that magnetic flux is still added to the flux rope after eruption.\nHence, the derived flare reconnection flux is most probably a lower limit for\nestimating the magnetic flux within the flux rope. We find that the magnetic\nhelicity and axial magnetic flux are reduced in interplanetary space by ~50%\nand 75%, respectively, possibly indicating to an erosion process. A mass\nincrease of 10% for the CME is observed over the distance range from ~4-20 Rs.\nThe temporal evolution of the CME associated core dimming regions supports the\nscenario that fast outflows might supply additional mass to the rear part of\nthe CME.", "journal": "", "doi": "10.1007/s11207-017-1112-5", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1703.00694v1"}
{"entry_id": "http://arxiv.org/abs/1903.02702v2", "date": "2019-03-07", "title": "Robust Semantic Segmentation By Dense Fusion Network On Blurred VHR Remote Sensing Images", "authors": "Yi Peng, Shihao Sun, Zheng Wang, Yining Pan, Ruirui Li", "abstract": "Robust semantic segmentation of VHR remote sensing images from UAV sensors is\ncritical for earth observation, land use, land cover or mapping applications.\nSeveral factors such as shadows, weather disruption and camera shakes making\nthis problem highly challenging, especially only using RGB images. In this\npaper, we propose the use of multi-modality data including NIR, RGB and DSM to\nincrease robustness of segmentation in blurred or partially damaged VHR remote\nsensing images. By proposing a cascaded dense encoder-decoder network and the\nSELayer based fusion and assembling techniques, the proposed RobustDenseNet\nachieves steady performance when the image quality is decreasing, compared with\nthe state-of-the-art semantic segmentation model.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1903.02702v2"}
{"entry_id": "http://arxiv.org/abs/2012.06377v1", "date": "2020-12-07", "title": "Nonlinear Distribution Regression for Remote Sensing Applications", "authors": "Jose E. Adsuara, Adri\u00e1n P\u00e9rez-Suay, Jordi Mu\u00f1oz-Mar\u00ed, Anna Mateo-Sanchis, Maria Piles, Gustau Camps-Valls", "abstract": "In many remote sensing applications one wants to estimate variables or\nparameters of interest from observations. When the target variable is available\nat a resolution that matches the remote sensing observations, standard\nalgorithms such as neural networks, random forests or Gaussian processes are\nreadily available to relate the two. However, we often encounter situations\nwhere the target variable is only available at the group level, i.e.\ncollectively associated to a number of remotely sensed observations. This\nproblem setting is known in statistics and machine learning as {\\em multiple\ninstance learning} or {\\em distribution regression}. This paper introduces a\nnonlinear (kernel-based) method for distribution regression that solves the\nprevious problems without making any assumption on the statistics of the\ngrouped data. The presented formulation considers distribution embeddings in\nreproducing kernel Hilbert spaces, and performs standard least squares\nregression with the empirical means therein. A flexible version to deal with\nmultisource data of different dimensionality and sample sizes is also presented\nand evaluated. It allows working with the native spatial resolution of each\nsensor, avoiding the need of match-up procedures. Noting the large\ncomputational cost of the approach, we introduce an efficient version via\nrandom Fourier features to cope with millions of points and groups.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/2012.06377v1"}
{"entry_id": "http://arxiv.org/abs/2202.03998v1", "date": "2022-02-08", "title": "Design of optimal low-thrust manoeuvres for remote sensing multi-satellite formation flying in low Earth orbit", "authors": "Francesca Scala, Gabriella Gaias, Camilla Colombo, Manuel Mart\u00ecn-Neira", "abstract": "This paper presents a strategy for optimal manoeuvre design of\nmulti-satellite formation flying in low Earth orbit environment, with the aim\nof providing a tool for mission operation design. The proposed methodology for\nformation flying manoeuvres foresees a continuous low-thrust control profile,\nto enable the operational phases. The design is performed starting from the\ndynamic representation described in the relative orbital elements, including\nthe main orbital perturbations effects. It also exploits an interface with the\nclassical radial-transversal-normal description to include the maximum delta-v\nlimitation and the safety condition requirements. The methodology is applied to\na remote sensing mission study, Formation Flying L-band Aperture Synthesis, for\nland and ocean application, such as a potential high-resolution Soil Moisture\nand Ocean Salinity (SMOS) follow-on mission, as part of a European Space Agency\nmission concept study. Moreover, the results are applicable to a wide range of\nlow Earth orbit missions, exploiting a distributed system, and in particular to\nFormation Flying L-band Aperture Synthesis (FFLAS) as a follow-on concept to\nSMOS.", "journal": "Advances in Space Research Advances in Space research, Volume 68,\n  Issue 11, 1 December 2021, Pages 4359-4378", "doi": "10.1016/j.asr.2021.09.030", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP", "math.DS", "math.OC"], "pdf_url": "http://arxiv.org/pdf/2202.03998v1"}
{"entry_id": "http://arxiv.org/abs/0908.4074v1", "date": "2009-08-27", "title": "Retrieval of Remote Sensing Images Using Colour and Texture Attribute", "authors": "Priti Maheswary, Namita Srivastava", "abstract": "Grouping images into semantically meaningful categories using low-level\nvisual feature is a challenging and important problem in content-based image\nretrieval. The groupings can be used to build effective indices for an image\ndatabase. Digital image analysis techniques are being used widely in remote\nsensing assuming that each terrain surface category is characterized with\nspectral signature observed by remote sensors. Even with the remote sensing\nimages of IRS data, integration of spatial information is expected to assist\nand to improve the image analysis of remote sensing data. In this paper we\npresent a satellite image retrieval based on a mixture of old fashioned ideas\nand state of the art learning tools. We have developed a methodology to\nclassify remote sensing images using HSV color features and Haar wavelet\ntexture features and then grouping them on the basis of particular threshold\nvalue. The experimental results indicate that the use of color and texture\nfeature extraction is very useful for image retrieval.", "journal": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 4, No. 1 & No. 2, August 2009, USA", "doi": null, "primary_category": "cs.IR", "categories": ["cs.IR", "cs.MM"], "pdf_url": "http://arxiv.org/pdf/0908.4074v1"}
{"entry_id": "http://arxiv.org/abs/2104.05107v1", "date": "2021-04-11", "title": "Towards a Collective Agenda on AI for Earth Science Data Analysis", "authors": "Devis Tuia, Ribana Roscher, Jan Dirk Wegner, Nathan Jacobs, Xiao Xiang Zhu, Gustau Camps-Valls", "abstract": "In the last years we have witnessed the fields of geosciences and remote\nsensing and artificial intelligence to become closer. Thanks to both the\nmassive availability of observational data, improved simulations, and\nalgorithmic advances, these disciplines have found common objectives and\nchallenges to advance the modeling and understanding of the Earth system.\nDespite such great opportunities, we also observed a worrying tendency to\nremain in disciplinary comfort zones applying recent advances from artificial\nintelligence on well resolved remote sensing problems. Here we take a position\non research directions where we think the interface between these fields will\nhave the most impact and become potential game changers. In our declared agenda\nfor AI on Earth sciences, we aim to inspire researchers, especially the younger\ngenerations, to tackle these challenges for a real advance of remote sensing\nand the geosciences.", "journal": "", "doi": "10.1109/MGRS.2020.3043504", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/2104.05107v1"}
{"entry_id": "http://arxiv.org/abs/2012.05150v1", "date": "2020-12-07", "title": "Causal Inference in Geoscience and Remote Sensing from Observational Data", "authors": "Adri\u00e1n P\u00e9rez-Suay, Gustau Camps-Valls", "abstract": "Establishing causal relations between random variables from observational\ndata is perhaps the most important challenge in today's \\blue{science}. In\nremote sensing and geosciences this is of special relevance to better\nunderstand the Earth's system and the complex interactions between the\ngoverning processes. In this paper, we focus on observational causal inference,\nthus we try to estimate the correct direction of causation using a finite set\nof empirical data. In addition, we focus on the more complex bivariate scenario\nthat requires strong assumptions and no conditional independence tests can be\nused. In particular, we explore the framework of (non-deterministic) additive\nnoise models, which relies on the principle of independence between the cause\nand the generating mechanism. A practical algorithmic instantiation of such\nprinciple only requires 1) two regression models in the forward and backward\ndirections, and 2) the estimation of {\\em statistical independence} between the\nobtained residuals and the observations. The direction leading to more\nindependent residuals is decided to be the cause. We instead propose a\ncriterion that uses the {\\em sensitivity} (derivative) of the dependence\nestimator, the sensitivity criterion allows to identify samples most affecting\nthe dependence measure, and hence the criterion is robust to spurious\ndetections. We illustrate performance in a collection of 28 geoscience causal\ninference problems, in a database of radiative transfer models simulations and\nmachine learning emulators in vegetation parameter modeling involving 182\nproblems, and in assessing the impact of different regression models in a\ncarbon cycle problem. The criterion achieves state-of-the-art detection rates\nin all cases, it is generally robust to noise sources and distortions.", "journal": "", "doi": null, "primary_category": "stat.ME", "categories": ["stat.ME", "cs.LG", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/2012.05150v1"}
{"entry_id": "http://arxiv.org/abs/2108.11827v1", "date": "2021-08-26", "title": "Remote Phase Sensing by Coherent Single Photon Addition", "authors": "Nicola Biagi, Saverio Francesconi, Manuel Gessner, Marco Bellini, Alessandro Zavatta", "abstract": "We propose a remote phase sensing scheme inspired by the high sensitivity of\nthe entanglement produced by coherent multimode photon addition on the phase\nset in the remote heralding apparatus. By exploring the case of delocalized\nphoton addition over two modes containing identical coherent states, we derive\nthe optimal observable to perform remote phase estimation from heralded\nquadrature measurements. The technique is experimentally tested with\ncalibration measurements and then used for estimating a remote phase with a\nsensitivity that is found to scale with the intensity of the (local) coherent\nstates, which never interacted with the sample.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2108.11827v1"}
{"entry_id": "http://arxiv.org/abs/2012.04222v1", "date": "2020-12-08", "title": "Scale Aware Adaptation for Land-Cover Classification in Remote Sensing Imagery", "authors": "Xueqing Deng, Yi Zhu, Yuxin Tian, Shawn Newsam", "abstract": "Land-cover classification using remote sensing imagery is an important Earth\nobservation task. Recently, land cover classification has benefited from the\ndevelopment of fully connected neural networks for semantic segmentation. The\nbenchmark datasets available for training deep segmentation models in remote\nsensing imagery tend to be small, however, often consisting of only a handful\nof images from a single location with a single scale. This limits the models'\nability to generalize to other datasets. Domain adaptation has been proposed to\nimprove the models' generalization but we find these approaches are not\neffective for dealing with the scale variation commonly found between remote\nsensing image collections. We therefore propose a scale aware adversarial\nlearning framework to perform joint cross-location and cross-scale land-cover\nclassification. The framework has a dual discriminator architecture with a\nstandard feature discriminator as well as a novel scale discriminator. We also\nintroduce a scale attention module which produces scale-enhanced features.\nExperimental results show that the proposed framework outperforms\nstate-of-the-art domain adaptation methods by a large margin.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2012.04222v1"}
{"entry_id": "http://arxiv.org/abs/1910.14567v1", "date": "2019-10-31", "title": "Conditional Denoising of Remote Sensing Imagery Using Cycle-Consistent Deep Generative Models", "authors": "Michael Zotov, Jevgenij Gamper", "abstract": "The potential of using remote sensing imagery for environmental modelling and\nfor providing real time support to humanitarian operations such as hurricane\nrelief efforts is well established. These applications are substantially\naffected by missing data due to non-structural noise such as clouds, shadows\nand other atmospheric effects. In this work we probe the potential of applying\na cycle-consistent latent variable deep generative model (DGM) for denoising\ncloudy Sentinel-2 observations conditioned on the information in cloud\npenetrating bands. We adapt the recently proposed Fr\\'{e}chet Distance metric\nto remote sensing images for evaluating performance of the generator,\ndemonstrate the potential of DGMs for conditional denoising, and discuss future\ndirections as well as the limitations of DGMs in Earth science and humanitarian\napplications.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1910.14567v1"}
{"entry_id": "http://arxiv.org/abs/1711.07629v2", "date": "2017-11-21", "title": "On statistical approaches to generate Level 3 products from satellite remote sensing retrievals", "authors": "Andrew Zammit-Mangion, Noel Cressie, Clint Shumack", "abstract": "Satellite remote sensing of trace gases such as carbon dioxide (CO$_2$) has\nincreased our ability to observe and understand Earth's climate. However, these\nremote sensing data, specifically~Level 2 retrievals, tend to be irregular in\nspace and time, and hence, spatio-temporal prediction is required to infer\nvalues at any location and time point. Such inferences are not only required to\nanswer important questions about our climate, but they are also needed for\nvalidating the satellite instrument, since Level 2 retrievals are generally not\nco-located with ground-based remote sensing instruments. Here, we discuss\nstatistical approaches to construct Level 3 products from Level 2 retrievals,\nplacing particular emphasis on the strengths and potential pitfalls when using\nstatistical prediction in this context. Following this discussion, we use a\nspatio-temporal statistical modelling framework known as fixed rank kriging\n(FRK) to obtain global predictions and prediction standard errors of\ncolumn-averaged carbon dioxide based on Version 7r and Version 8r retrievals\nfrom the Orbiting Carbon Observatory-2 (OCO-2) satellite. The FRK predictions\nallow us to validate statistically the Level 2 retrievals globally even though\nthe data are at locations and at time points that do not coincide with\nvalidation data. Importantly, the validation takes into account the prediction\nuncertainty, which is dependent both on the temporally-varying density of\nobservations around the ground-based measurement sites and on the\nspatio-temporal high-frequency components of the trace gas field that are not\nexplicitly modelled. Here, for validation of remotely-sensed CO$_2$ data, we\nuse observations from the Total Carbon Column Observing Network. We demonstrate\nthat the resulting FRK product based on Version 8r compares better with TCCON\ndata than that based on Version 7r.", "journal": "Zammit-Mangion, A.; Cressie, N.; Shumack, C. On Statistical\n  Approaches to Generate Level 3 Products from Satellite Remote Sensing\n  Retrievals. Remote Sens. 2018, 10, 155", "doi": "10.3390/rs10010155", "primary_category": "stat.AP", "categories": ["stat.AP"], "pdf_url": "http://arxiv.org/pdf/1711.07629v2"}
{"entry_id": "http://arxiv.org/abs/1707.02023v1", "date": "2017-07-07", "title": "A flux calibration method for remote sensing satellites using stars", "authors": "Chun Xu", "abstract": "Star surveys and model analyses show that many stars have absolute stable\nfluxes as good as 3% in 0.3-35{\\mu}m wavebands and about 1% in the visible\nwavebands. The relative flux calibrations between stars are better than 0.2%.\nSome stars have extremely stable fluxes and can be used as long term flux\ncalibration sources. Stellar brightness is several orders of magnitude lower\nthan most ground objects while the stars do not usually appear in remote\nsensing cameras, which makes the stars inappropriate for being calibration\nsources. The calibration method using stars discussed in this paper is through\na mini-camera attached to remote sensing satellite. The mini-camera works at\nsimilar wavebands as the remote sensing cameras and it can observe the stars\nand the ground objects alternatively. High signal-to-noise ratio is achieved\nfor the relatively faint stars through longer exposure time. Simultaneous\nprecise cross-calibration is obtained as the mini-camera and remote sensing\ncameras look at the ground objects at the same time. The fluxes from the stars\nused as calibration standards are transferred to the remote sensing cameras\nthrough this procedure. Analysis shows that a 2% accurate calibration is\npossible.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1707.02023v1"}
{"entry_id": "http://arxiv.org/abs/2006.13806v2", "date": "2020-06-24", "title": "X-ModalNet: A Semi-Supervised Deep Cross-Modal Network for Classification of Remote Sensing Data", "authors": "Danfeng Hong, Naoto Yokoya, Gui-Song Xia, Jocelyn Chanussot, Xiao Xiang Zhu", "abstract": "This paper addresses the problem of semi-supervised transfer learning with\nlimited cross-modality data in remote sensing. A large amount of multi-modal\nearth observation images, such as multispectral imagery (MSI) or synthetic\naperture radar (SAR) data, are openly available on a global scale, enabling\nparsing global urban scenes through remote sensing imagery. However, their\nability in identifying materials (pixel-wise classification) remains limited,\ndue to the noisy collection environment and poor discriminative information as\nwell as limited number of well-annotated training images. To this end, we\npropose a novel cross-modal deep-learning framework, called X-ModalNet, with\nthree well-designed modules: self-adversarial module, interactive learning\nmodule, and label propagation module, by learning to transfer more\ndiscriminative information from a small-scale hyperspectral image (HSI) into\nthe classification task using a large-scale MSI or SAR data. Significantly,\nX-ModalNet generalizes well, owing to propagating labels on an updatable graph\nconstructed by high-level features on the top of the network, yielding\nsemi-supervised cross-modality learning. We evaluate X-ModalNet on two\nmulti-modal remote sensing datasets (HSI-MSI and HSI-SAR) and achieve a\nsignificant improvement in comparison with several state-of-the-art methods.", "journal": "ISPRS Journal of Photogrammetry and Remote Sensing,2020,167:12-23", "doi": "10.1016/j.isprsjprs.2020.06.014", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2006.13806v2"}
{"entry_id": "http://arxiv.org/abs/2005.01094v2", "date": "2020-05-03", "title": "Remote Sensing Image Scene Classification Meets Deep Learning: Challenges, Methods, Benchmarks, and Opportunities", "authors": "Gong Cheng, Xingxing Xie, Junwei Han, Lei Guo, Gui-Song Xia", "abstract": "Remote sensing image scene classification, which aims at labeling remote\nsensing images with a set of semantic categories based on their contents, has\nbroad applications in a range of fields. Propelled by the powerful feature\nlearning capabilities of deep neural networks, remote sensing image scene\nclassification driven by deep learning has drawn remarkable attention and\nachieved significant breakthroughs. However, to the best of our knowledge, a\ncomprehensive review of recent achievements regarding deep learning for scene\nclassification of remote sensing images is still lacking. Considering the rapid\nevolution of this field, this paper provides a systematic survey of deep\nlearning methods for remote sensing image scene classification by covering more\nthan 160 papers. To be specific, we discuss the main challenges of remote\nsensing image scene classification and survey (1) Autoencoder-based remote\nsensing image scene classification methods, (2) Convolutional Neural\nNetwork-based remote sensing image scene classification methods, and (3)\nGenerative Adversarial Network-based remote sensing image scene classification\nmethods. In addition, we introduce the benchmarks used for remote sensing image\nscene classification and summarize the performance of more than two dozen of\nrepresentative algorithms on three commonly-used benchmark data sets. Finally,\nwe discuss the promising opportunities for further research.", "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and\n  Remote Sensing, 13: 3735-3756, 2020", "doi": "10.1109/JSTARS.2020.3005403", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2005.01094v2"}
{"entry_id": "http://arxiv.org/abs/1907.07823v1", "date": "2019-07-18", "title": "Remote sensing of angular scattering effect of aerosols in a North American megacity", "authors": "Zhao-Cheng Zeng, Feng Xu, Vijay Natraj, Thomas J. Pongetti, Run-Lie Shia, Qiong Zhang, Stanley P. Sander, Yuk L. Yung", "abstract": "The angle-dependent scattering effect of aerosols in the atmosphere can be\nused to infer their compositions, which in turn is important to understand\ntheir impacts of human health and Earth climate. The aerosol phase function,\nwhich characterizes the angular signature of scattering, has been continuously\nmonitored from ground-based and space-borne observations. However, the range of\nscattering angles these instruments can sample is very limited. There is a\ndearth of research on the remote sensing of aerosol angular scattering effect\nat a city scale that analyzes diurnal variability and includes a wide range of\nscattering angles. Here, we quantify the aerosol angular scattering effect\nusing measurements from a mountain-top remote sensing instrument: the\nCalifornia Laboratory for Atmospheric Remote Sensing Fourier Transform\nSpectrometer (CLARS-FTS). CLARS-FTS is located on top of the Mt. Wilson (1.67km\nabove sea level) overlooking the Los Angeles (LA) megacity and receives\nreflected sunlight from targeted surface reflection points. The observational\ngeometries of CLARS-FTS provide a wide range of scattering angles, from about\n20 degrees (forward) to about 140 degrees (backward). The O2 ratio, which is\nthe ratio of retrieved O2 Slant Column Density (SCD) to geometric O2 SCD,\nquantifies the aerosol transmission with a value of 1.0 represent aerosol-free\nand with a value closer to 0.0 represents stronger aerosol loadings. The\naerosol transmission quantified by the O2 ratio from CLARS measurements\nprovides an effective indicator of the aerosol scattering effect.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1907.07823v1"}
{"entry_id": "http://arxiv.org/abs/2103.05302v1", "date": "2021-03-09", "title": "Semantics-Consistent Representation Learning for Remote Sensing Image-Voice Retrieval", "authors": "Hailong Ning, Bin Zhao, Yuan Yuan", "abstract": "With the development of earth observation technology, massive amounts of\nremote sensing (RS) images are acquired. To find useful information from these\nimages, cross-modal RS image-voice retrieval provides a new insight. This paper\naims to study the task of RS image-voice retrieval so as to search effective\ninformation from massive amounts of RS data. Existing methods for RS\nimage-voice retrieval rely primarily on the pairwise relationship to narrow the\nheterogeneous semantic gap between images and voices. However, apart from the\npairwise relationship included in the datasets, the intra-modality and\nnon-paired inter-modality relationships should also be taken into account\nsimultaneously, since the semantic consistency among non-paired representations\nplays an important role in the RS image-voice retrieval task. Inspired by this,\na semantics-consistent representation learning (SCRL) method is proposed for RS\nimage-voice retrieval. The main novelty is that the proposed method takes the\npairwise, intra-modality, and non-paired inter-modality relationships into\naccount simultaneously, thereby improving the semantic consistency of the\nlearned representations for the RS image-voice retrieval. The proposed SCRL\nmethod consists of two main steps: 1) semantics encoding and 2)\nsemantics-consistent representation learning. Firstly, an image encoding\nnetwork is adopted to extract high-level image features with a transfer\nlearning strategy, and a voice encoding network with dilated convolution is\ndevised to obtain high-level voice features. Secondly, a consistent\nrepresentation space is conducted by modeling the three kinds of relationships\nto narrow the heterogeneous semantic gap and learn semantics-consistent\nrepresentations across two modalities. Extensive experimental results on three\nchallenging RS image-voice datasets show the effectiveness of the proposed\nmethod.", "journal": "", "doi": "10.1109/TGRS.2021.3060705", "primary_category": "cs.MM", "categories": ["cs.MM"], "pdf_url": "http://arxiv.org/pdf/2103.05302v1"}
{"entry_id": "http://arxiv.org/abs/1206.4290v1", "date": "2012-06-19", "title": "Investigation of the Forces that Govern the Three-Dimensional Propagation and Expansion of Coronal Mass Ejections from Sun to Earth", "authors": "Robin C. Colaninno", "abstract": "In this study, we analyze nine CMEs from the Sun to Earth as observed in both\nthe remote sensing and in situ data sets. To date, this is the largest study of\nEarth impacting CMEs using the multi-view point remote sensing and in situ\ndata. However, the remote sensing and in situ data of the same CME cannot be\ndirectly compared. Thus, we use several models to parameterize the two data\nsets. With the model results, we are able to compare the arrival time, Earth\nimpact speed, internal magnetic field, size and orientation as derived from the\nremote sensing and in situ methods. From the derived kinematics, we compare the\npredicted arrival times and impact velocities with the in situ data. We find\nthat even with nearly continuous observations and the best available model of\nthe CME structure, there is still a significant error in the predicted values.\nWe estimate the various forces acting on the CME as predicted by three\ntheoretical models of CME propagation and expansion and compare these results\nwith the observational results. We find that the flux rope model of Chen (1989)\nprovides the best agreement with the observations. With the flux rope model, we\nare able to predict the internal magnetic field of the CME near Earth from the\nremote sensing data to an order of magnitude. Finally, we compare the size and\norientation of the CMEs as predicted from the remote sensing and in situ data.\nWe find very little agreement between the values derived from the two data\nsets.", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1206.4290v1"}
{"entry_id": "http://arxiv.org/abs/1802.04686v1", "date": "2018-02-09", "title": "Remote sensing of geomagnetic fields and atomic collisions in the mesosphere", "authors": "Felipe Pedreros Bustos, Domenico Bonaccini Calia, Dmitry Budker, Mauro Centrone, Joschua Hellemeier, Paul Hickson, Ronald Holzl\u00f6hner, Simon Rochester", "abstract": "Magnetic-field sensing has contributed to the formulation of the\nplate-tectonics theory, the discovery and mapping of underground structures on\nEarth, and the study of magnetism in other planets. Filling the gap between\nspace-based and near-Earth observation, we demonstrate a novel method for\nremote measurement of the geomagnetic field at an altitude of 85-100 km. The\nmethod consists of optical pumping of atomic sodium in the upper mesosphere\nwith an intensity-modulated laser beam, and simultaneous ground-based\nobservation of the resultant magneto-optical resonance when driving the\natomic-sodium spins at the Larmor precession frequency. The experiment was\ncarried out at the Roque de Los Muchachos Observatory in La Palma (Canary\nIslands) where we validated this technique and remotely measured the Larmor\nprecession frequency of sodium as 260.4(1) kHz, corresponding to a mesospheric\nmagnetic field of 0.3720(1) G. We demonstrate a magnetometry accuracy level of\n0.28 mG/$\\sqrt{\\text{Hz}}$ in good atmospheric conditions. In addition, these\nobservations allow us to characterize various atomic-collision processes in the\nmesosphere. Remote detection of mesospheric magnetic fields has potential\napplications such as mapping of large-scale magnetic structures in the\nlithosphere and the study of electric-current fluctuations in the ionosphere.", "journal": "", "doi": "10.1038/s41467-018-06396-7", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph", "astro-ph.IM", "physics.atom-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/1802.04686v1"}
{"entry_id": "http://arxiv.org/abs/2010.00332v1", "date": "2020-09-30", "title": "Training general representations for remote sensing using in-domain knowledge", "authors": "Maxim Neumann, Andr\u00e9 Susano Pinto, Xiaohua Zhai, Neil Houlsby", "abstract": "Automatically finding good and general remote sensing representations allows\nto perform transfer learning on a wide range of applications - improving the\naccuracy and reducing the required number of training samples. This paper\ninvestigates development of generic remote sensing representations, and\nexplores which characteristics are important for a dataset to be a good source\nfor representation learning. For this analysis, five diverse remote sensing\ndatasets are selected and used for both, disjoint upstream representation\nlearning and downstream model training and evaluation. A common evaluation\nprotocol is used to establish baselines for these datasets that achieve\nstate-of-the-art performance. As the results indicate, especially with a low\nnumber of available training samples a significant performance enhancement can\nbe observed when including additionally in-domain data in comparison to\ntraining models from scratch or fine-tuning only on ImageNet (up to 11% and\n40%, respectively, at 100 training samples). All datasets and pretrained\nrepresentation models are published online.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2010.00332v1"}
{"entry_id": "http://arxiv.org/abs/1801.08706v1", "date": "2018-01-26", "title": "Cloud Detection From RGB Color Remote Sensing Images With Deep Pyramid Networks", "authors": "Savas Ozkan, Mehmet Efendioglu, Caner Demirpolat", "abstract": "Cloud detection from remotely observed data is a critical pre-processing step\nfor various remote sensing applications. In particular, this problem becomes\neven harder for RGB color images, since there is no distinct spectral pattern\nfor clouds, which is directly separable from the Earth surface. In this paper,\nwe adapt a deep pyramid network (DPN) to tackle this problem. For this purpose,\nthe network is enhanced with a pre-trained parameter model at the encoder\nlayer. Moreover, the method is able to obtain accurate pixel-level segmentation\nand classification results from a set of noisy labeled RGB color images. In\norder to demonstrate the superiority of the method, we collect and label data\nwith the corresponding cloud/non-cloudy masks acquired from low-orbit Gokturk-2\nand RASAT satellites. The experimental results validates that the proposed\nmethod outperforms several baselines even for hard cases (e.g. snowy mountains)\nthat are perceptually difficult to distinguish by human eyes.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1801.08706v1"}
{"entry_id": "http://arxiv.org/abs/2107.00557v3", "date": "2021-07-01", "title": "Image Restoration for Remote Sensing: Overview and Toolbox", "authors": "Benhood Rasti, Yi Chang, Emanuele Dalsasso, Lo\u00efc Denis, Pedram Ghamisi", "abstract": "Remote sensing provides valuable information about objects or areas from a\ndistance in either active (e.g., RADAR and LiDAR) or passive (e.g.,\nmultispectral and hyperspectral) modes. The quality of data acquired by\nremotely sensed imaging sensors (both active and passive) is often degraded by\na variety of noise types and artifacts. Image restoration, which is a vibrant\nfield of research in the remote sensing community, is the task of recovering\nthe true unknown image from the degraded observed image. Each imaging sensor\ninduces unique noise types and artifacts into the observed image. This fact has\nled to the expansion of restoration techniques in different paths according to\neach sensor type. This review paper brings together the advances of image\nrestoration techniques with particular focuses on synthetic aperture radar and\nhyperspectral images as the most active sub-fields of image restoration in the\nremote sensing community. We, therefore, provide a comprehensive,\ndiscipline-specific starting point for researchers at different levels (i.e.,\nstudents, researchers, and senior researchers) willing to investigate the\nvibrant topic of data restoration by supplying sufficient detail and\nreferences. Additionally, this review paper accompanies a toolbox to provide a\nplatform to encourage interested students and researchers in the field to\nfurther explore the restoration techniques and fast-forward the community. The\ntoolboxes are provided in https://github.com/ImageRestorationToolbox.", "journal": "", "doi": "10.1109/MGRS.2021.3121761", "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2107.00557v3"}
{"entry_id": "http://arxiv.org/abs/2112.02447v2", "date": "2021-12-04", "title": "Next Day Wildfire Spread: A Machine Learning Data Set to Predict Wildfire Spreading from Remote-Sensing Data", "authors": "Fantine Huot, R. Lily Hu, Nita Goyal, Tharun Sankar, Matthias Ihme, Yi-Fan Chen", "abstract": "Predicting wildfire spread is critical for land management and disaster\npreparedness. To this end, we present `Next Day Wildfire Spread,' a curated,\nlarge-scale, multivariate data set of historical wildfires aggregating nearly a\ndecade of remote-sensing data across the United States. In contrast to existing\nfire data sets based on Earth observation satellites, our data set combines 2D\nfire data with multiple explanatory variables (e.g., topography, vegetation,\nweather, drought index, population density) aligned over 2D regions, providing\na feature-rich data set for machine learning. To demonstrate the usefulness of\nthis data set, we implement a neural network that takes advantage of the\nspatial information of this data to predict wildfire spread. We compare the\nperformance of the neural network with other machine learning models: logistic\nregression and random forest. This data set can be used as a benchmark for\ndeveloping wildfire propagation models based on remote sensing data for a lead\ntime of one day.", "journal": "", "doi": "10.1109/TGRS.2022.3192974", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2112.02447v2"}
{"entry_id": "http://arxiv.org/abs/1812.05581v1", "date": "2018-12-13", "title": "Benchmark Dataset for Automatic Damaged Building Detection from Post-Hurricane Remotely Sensed Imagery", "authors": "Sean Andrew Chen, Andrew Escay, Christopher Haberland, Tessa Schneider, Valentina Staneva, Youngjun Choe", "abstract": "Rapid damage assessment is of crucial importance to emergency responders\nduring hurricane events, however, the evaluation process is often slow,\nlabor-intensive, costly, and error-prone. New advances in computer vision and\nremote sensing open possibilities to observe the Earth at a different scale.\nHowever, substantial pre-processing work is still required in order to apply\nstate-of-the-art methodology for emergency response. To enable the comparison\nof methods for automatic detection of damaged buildings from post-hurricane\nremote sensing imagery taken from both airborne and satellite sensors, this\npaper presents the development of benchmark datasets from publicly available\ndata. The major contributions of this work include (1) a scalable framework for\ncreating benchmark datasets of hurricane-damaged buildings and (2) public\nsharing of the resulting benchmark datasets for Greater Houston area after\nHurricane Harvey in 2017. The proposed approach can be used to build other\nhurricane-damaged building datasets on which researchers can train and test\nobject detection models to automatically identify damaged buildings.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1812.05581v1"}
{"entry_id": "http://arxiv.org/abs/1311.3283v1", "date": "2013-11-13", "title": "Remote sensor response study in the regime of the microwave radiation-induced magnetoresistance oscillations", "authors": "Tianyu Ye, Ramesh Mani, Werner Wegscheider", "abstract": "A concurrent remote sensing and magneto-transport study of the microwave\nexcited two dimensional electron system (2DES) at liquid Helium temperatures\nhas been carried out using a carbon detector to remotely sense the microwave\nactivity of the 2D electron system in the GaAs/AlGaAs heterostructure during\nconventional magnetotransport measurements. Various correlations are observed\nand reported between the oscillatory magnetotransport and the remotely sensed\nreflection. In addition, the oscillatory remotely sensed signal is shown to\nexhibit a power law type variation in its amplitude, similar to the\nradiation-induced magnetoresistance oscillations.", "journal": "Appl. Phys. Lett. 103, 192106 (2013)", "doi": "10.1063/1.4829441", "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/1311.3283v1"}
{"entry_id": "http://arxiv.org/abs/1806.04331v1", "date": "2018-06-12", "title": "Automatic Ship Detection of Remote Sensing Images from Google Earth in Complex Scenes Based on Multi-Scale Rotation Dense Feature Pyramid Networks", "authors": "Xue Yang, Hao Sun, Kun Fu, Jirui Yang, Xian Sun, Menglong Yan, Zhi Guo", "abstract": "Ship detection has been playing a significant role in the field of remote\nsensing for a long time but it is still full of challenges. The main\nlimitations of traditional ship detection methods usually lie in the complexity\nof application scenarios, the difficulty of intensive object detection and the\nredundancy of detection region. In order to solve such problems above, we\npropose a framework called Rotation Dense Feature Pyramid Networks (R-DFPN)\nwhich can effectively detect ship in different scenes including ocean and port.\nSpecifically, we put forward the Dense Feature Pyramid Network (DFPN), which is\naimed at solving the problem resulted from the narrow width of the ship.\nCompared with previous multi-scale detectors such as Feature Pyramid Network\n(FPN), DFPN builds the high-level semantic feature-maps for all scales by means\nof dense connections, through which enhances the feature propagation and\nencourages the feature reuse. Additionally, in the case of ship rotation and\ndense arrangement, we design a rotation anchor strategy to predict the minimum\ncircumscribed rectangle of the object so as to reduce the redundant detection\nregion and improve the recall. Furthermore, we also propose multi-scale ROI\nAlign for the purpose of maintaining the completeness of semantic and spatial\ninformation. Experiments based on remote sensing images from Google Earth for\nship detection show that our detection method based on R-DFPN representation\nhas a state-of-the-art performance.", "journal": "Remote Sens. 2018, 10, 132", "doi": "10.3390/rs10010132", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1806.04331v1"}
{"entry_id": "http://arxiv.org/abs/1705.05689v1", "date": "2017-05-16", "title": "Remote sensing of cloud base charge", "authors": "R Giles Harrison, Keri Nicoll, Karen Aplin", "abstract": "Layer clouds are abundant in the Earth's atmosphere. Such clouds do not\nbecome sufficiently strongly charged to generate lightning, but they show weak\ncharging along the upper and lower cloud boundaries where there is a\nconductivity transition. Cloud edge charging has recently been observed using\nballoon-carried electrometers. Measurement of cloud boundary charging without\nballoons is shown to be possible here for low altitude (<1km) charged cloud\nbases, through combining their effect on the surface electric field with laser\ntime of flight cloud base height measurements, and the application of simple\nelectrostatic models.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1705.05689v1"}
{"entry_id": "http://arxiv.org/abs/1909.00133v2", "date": "2019-08-31", "title": "Object Detection in Optical Remote Sensing Images: A Survey and A New Benchmark", "authors": "Ke Li, Gang Wan, Gong Cheng, Liqiu Meng, Junwei Han", "abstract": "Substantial efforts have been devoted more recently to presenting various\nmethods for object detection in optical remote sensing images. However, the\ncurrent survey of datasets and deep learning based methods for object detection\nin optical remote sensing images is not adequate. Moreover, most of the\nexisting datasets have some shortcomings, for example, the numbers of images\nand object categories are small scale, and the image diversity and variations\nare insufficient. These limitations greatly affect the development of deep\nlearning based object detection methods. In the paper, we provide a\ncomprehensive review of the recent deep learning based object detection\nprogress in both the computer vision and earth observation communities. Then,\nwe propose a large-scale, publicly available benchmark for object DetectIon in\nOptical Remote sensing images, which we name as DIOR. The dataset contains\n23463 images and 192472 instances, covering 20 object classes. The proposed\nDIOR dataset 1) is large-scale on the object categories, on the object instance\nnumber, and on the total image number; 2) has a large range of object size\nvariations, not only in terms of spatial resolutions, but also in the aspect of\ninter- and intra-class size variability across objects; 3) holds big variations\nas the images are obtained with different imaging conditions, weathers,\nseasons, and image quality; and 4) has high inter-class similarity and\nintra-class diversity. The proposed benchmark can help the researchers to\ndevelop and validate their data-driven methods. Finally, we evaluate several\nstate-of-the-art approaches on our DIOR dataset to establish a baseline for\nfuture research.", "journal": "ISPRS Journal of Photogrammetry and Remote Sensing, 159: 296-307,\n  2020", "doi": "10.1016/j.isprsjprs.2019.11.023", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1909.00133v2"}
{"entry_id": "http://arxiv.org/abs/1609.06846v1", "date": "2016-09-22", "title": "Semantic Segmentation of Earth Observation Data Using Multimodal and Multi-scale Deep Networks", "authors": "Nicolas Audebert, Bertrand Le Saux, S\u00e9bastien Lef\u00e8vre", "abstract": "This work investigates the use of deep fully convolutional neural networks\n(DFCNN) for pixel-wise scene labeling of Earth Observation images. Especially,\nwe train a variant of the SegNet architecture on remote sensing data over an\nurban area and study different strategies for performing accurate semantic\nsegmentation. Our contributions are the following: 1) we transfer efficiently a\nDFCNN from generic everyday images to remote sensing images; 2) we introduce a\nmulti-kernel convolutional layer for fast aggregation of predictions at\nmultiple scales; 3) we perform data fusion from heterogeneous sensors (optical\nand laser) using residual correction. Our framework improves state-of-the-art\naccuracy on the ISPRS Vaihingen 2D Semantic Labeling dataset.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.NE"], "pdf_url": "http://arxiv.org/pdf/1609.06846v1"}
{"entry_id": "http://arxiv.org/abs/2007.01238v1", "date": "2020-07-02", "title": "A Perspective on Gaussian Processes for Earth Observation", "authors": "Gustau Camps-Valls, Dino Sejdinovic, Jakob Runge, Markus Reichstein", "abstract": "Earth observation (EO) by airborne and satellite remote sensing and in-situ\nobservations play a fundamental role in monitoring our planet. In the last\ndecade, machine learning and Gaussian processes (GPs) in particular has\nattained outstanding results in the estimation of bio-geo-physical variables\nfrom the acquired images at local and global scales in a time-resolved manner.\nGPs provide not only accurate estimates but also principled uncertainty\nestimates for the predictions, can easily accommodate multimodal data coming\nfrom different sensors and from multitemporal acquisitions, allow the\nintroduction of physical knowledge, and a formal treatment of uncertainty\nquantification and error propagation. Despite great advances in forward and\ninverse modelling, GP models still have to face important challenges that are\nrevised in this perspective paper. GP models should evolve towards data-driven\nphysics-aware models that respect signal characteristics, be consistent with\nelementary laws of physics, and move from pure regression to observational\ncausal inference.", "journal": "National Science Review, Volume 6, Issue 4, July 2019, Pages\n  616-618", "doi": "10.1093/nsr/nwz028", "primary_category": "cs.LG", "categories": ["cs.LG", "stat.AP", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2007.01238v1"}
{"entry_id": "http://arxiv.org/abs/2002.04539v1", "date": "2020-01-27", "title": "Nonlinear PCA for Spatio-Temporal Analysis of Earth Observation Data", "authors": "Diego Bueso, Maria Piles, Gustau Camps-Valls", "abstract": "Remote sensing observations, products and simulations are fundamental sources\nof information to monitor our planet and its climate variability. Uncovering\nthe main modes of spatial and temporal variability in Earth data is essential\nto analyze and understand the underlying physical dynamics and processes\ndriving the Earth System. Dimensionality reduction methods can work with\nspatio-temporal datasets and decompose the information efficiently. Principal\nComponent Analysis (PCA), also known as Empirical Orthogonal Functions (EOF) in\ngeophysics, has been traditionally used to analyze climatic data. However, when\nnonlinear feature relations are present, PCA/EOF fails. In this work, we\npropose a nonlinear PCA method to deal with spatio-temporal Earth System data.\nThe proposed method, called Rotated Complex Kernel PCA (ROCK-PCA for short),\nworks in reproducing kernel Hilbert spaces to account for nonlinear processes,\noperates in the complex kernel domain to account for both space and time\nfeatures, and adds an extra rotation for improved flexibility. The result is an\nexplicitly resolved spatio-temporal decomposition of the Earth data cube. The\nmethod is unsupervised and computationally very efficient.We illustrate its\nability to uncover spatio-temporal patterns using synthetic experiments and\nreal data. Results of the decomposition of three essential climate variables\nare shown: satellite-based global Gross Primary Productivity (GPP) and Soil\nMoisture (SM), and reanalysis Sea Surface Temperature (SST) data. The ROCK-PCA\nmethod allows identifying their annual and seasonal oscillations, as well as\ntheir non-seasonal trends and spatial variability patterns.", "journal": "", "doi": "10.1109/TGRS.2020.2969813", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph", "physics.comp-ph", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2002.04539v1"}
{"entry_id": "http://arxiv.org/abs/2204.08454v3", "date": "2022-04-18", "title": "Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images", "authors": "Wele Gedara Chaminda Bandara, Vishal M. Patel", "abstract": "Remote-sensing (RS) Change Detection (CD) aims to detect \"changes of\ninterest\" from co-registered bi-temporal images. The performance of existing\ndeep supervised CD methods is attributed to the large amounts of annotated data\nused to train the networks. However, annotating large amounts of remote sensing\nimages is labor-intensive and expensive, particularly with bi-temporal images,\nas it requires pixel-wise comparisons by a human expert. On the other hand, we\noften have access to unlimited unlabeled multi-temporal RS imagery thanks to\never-increasing earth observation programs. In this paper, we propose a simple\nyet effective way to leverage the information from unlabeled bi-temporal images\nto improve the performance of CD approaches. More specifically, we propose a\nsemi-supervised CD model in which we formulate an unsupervised CD loss in\naddition to the supervised Cross-Entropy (CE) loss by constraining the output\nchange probability map of a given unlabeled bi-temporal image pair to be\nconsistent under the small random perturbations applied on the deep feature\ndifference map that is obtained by subtracting their latent feature\nrepresentations. Experiments conducted on two publicly available CD datasets\nshow that the proposed semi-supervised CD method can reach closer to the\nperformance of supervised CD even with access to as little as 10% of the\nannotated training data. Code available at https://github.com/wgcban/SemiCD", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2204.08454v3"}
{"entry_id": "http://arxiv.org/abs/1803.05482v1", "date": "2018-03-14", "title": "Targeted change detection in remote sensing images", "authors": "Vladimir Ignatiev, Alexey Trekin, Viktor Lobachev, Georgy Potapov, Evgeny Burnaev", "abstract": "Recent developments in the remote sensing systems and image processing made\nit possible to propose a new method of the object classification and detection\nof the specific changes in the series of satellite Earth images (so called\ntargeted change detection). In this paper we propose a formal problem statement\nthat allows to use effectively the deep learning approach to analyze\ntime-dependent series of remote sensing images. We also introduce a new\nframework for the development of deep learning models for targeted change\ndetection and demonstrate some cases of business applications it can be used\nfor.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.CE", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1803.05482v1"}
{"entry_id": "http://arxiv.org/abs/2101.10861v2", "date": "2021-01-22", "title": "A Review on Deep Learning in UAV Remote Sensing", "authors": "Lucas Prado Osco, Jos\u00e9 Marcato Junior, Ana Paula Marques Ramos, L\u00facio Andr\u00e9 de Castro Jorge, Sarah Narges Fatholahi, Jonathan de Andrade Silva, Edson Takashi Matsubara, Hemerson Pistori, Wesley Nunes Gon\u00e7alves, Jonathan Li", "abstract": "Deep Neural Networks (DNNs) learn representation from data with an impressive\ncapability, and brought important breakthroughs for processing images,\ntime-series, natural language, audio, video, and many others. In the remote\nsensing field, surveys and literature revisions specifically involving DNNs\nalgorithms' applications have been conducted in an attempt to summarize the\namount of information produced in its subfields. Recently, Unmanned Aerial\nVehicles (UAV) based applications have dominated aerial sensing research.\nHowever, a literature revision that combines both \"deep learning\" and \"UAV\nremote sensing\" thematics has not yet been conducted. The motivation for our\nwork was to present a comprehensive review of the fundamentals of Deep Learning\n(DL) applied in UAV-based imagery. We focused mainly on describing\nclassification and regression techniques used in recent applications with\nUAV-acquired data. For that, a total of 232 papers published in international\nscientific journal databases was examined. We gathered the published material\nand evaluated their characteristics regarding application, sensor, and\ntechnique used. We relate how DL presents promising results and has the\npotential for processing tasks associated with UAV-based image data. Lastly, we\nproject future perspectives, commentating on prominent DL paths to be explored\nin the UAV remote sensing field. Our revision consists of a friendly-approach\nto introduce, commentate, and summarize the state-of-the-art in UAV-based image\napplications with DNNs algorithms in diverse subfields of remote sensing,\ngrouping it in the environmental, urban, and agricultural contexts.", "journal": "International Journal of Applied Earth Observation and\n  Geoinformation, 2022", "doi": "10.1016/j.jag.2021.102456", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2101.10861v2"}
{"entry_id": "http://arxiv.org/abs/2111.07042v1", "date": "2021-11-13", "title": "Agile Satellite Planning for Multi-Payload Observations for Earth Science", "authors": "Rich Levinson, Sreeja Nag, Vinay Ravindra", "abstract": "We present planning challenges, methods and preliminary results for a new\nmodel-based paradigm for earth observing systems in adaptive remote sensing.\nOur heuristically guided constraint optimization planner produces coordinated\nplans for multiple satellites, each with multiple instruments (payloads). The\nsatellites are agile, meaning they can quickly maneuver to change viewing\nangles in response to rapidly changing phenomena. The planner operates in a\nclosed-loop context, updating the plan as it receives regular sensor data and\nupdated predictions. We describe the planner's search space and search\nprocedure, and present preliminary experiment results. Contributions include\ninitial identification of the planner's search space, constraints, heuristics,\nand performance metrics applied to a soil moisture monitoring scenario using\nspaceborne radars.", "journal": "International Workshop on Planning & Scheduling for Space (IWPSS)\n  2021", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf_url": "http://arxiv.org/pdf/2111.07042v1"}
{"entry_id": "http://arxiv.org/abs/1903.09469v1", "date": "2019-03-22", "title": "Aggregated Deep Local Features for Remote Sensing Image Retrieval", "authors": "Raffaele Imbriaco, Clint Sebastian, Egor Bondarev, Peter H. N. de With", "abstract": "Remote Sensing Image Retrieval remains a challenging topic due to the special\nnature of Remote Sensing Imagery. Such images contain various different\nsemantic objects, which clearly complicates the retrieval task. In this paper,\nwe present an image retrieval pipeline that uses attentive, local convolutional\nfeatures and aggregates them using the Vector of Locally Aggregated Descriptors\n(VLAD) to produce a global descriptor. We study various system parameters such\nas the multiplicative and additive attention mechanisms and descriptor\ndimensionality. We propose a query expansion method that requires no external\ninputs. Experiments demonstrate that even without training, the local\nconvolutional features and global representation outperform other systems.\nAfter system tuning, we can achieve state-of-the-art or competitive results.\nFurthermore, we observe that our query expansion method increases overall\nsystem performance by about 3%, using only the top-three retrieved images.\nFinally, we show how dimensionality reduction produces compact descriptors with\nincreased retrieval performance and fast retrieval computation times, e.g. 50%\nfaster than the current systems.", "journal": "Remote Sensing, 2019", "doi": "10.3390/rs11050493", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1903.09469v1"}
{"entry_id": "http://arxiv.org/abs/2109.09484v2", "date": "2021-09-20", "title": "On Circuit-based Hybrid Quantum Neural Networks for Remote Sensing Imagery Classification", "authors": "Alessandro Sebastianelli, Daniela A. Zaidenberg, Dario Spiller, Bertrand Le Saux, Silvia Liberata Ullo", "abstract": "This article aims to investigate how circuit-based hybrid Quantum\nConvolutional Neural Networks (QCNNs) can be successfully employed as image\nclassifiers in the context of remote sensing. The hybrid QCNNs enrich the\nclassical architecture of CNNs by introducing a quantum layer within a standard\nneural network. The novel QCNN proposed in this work is applied to the Land Use\nand Land Cover (LULC) classification, chosen as an Earth Observation (EO) use\ncase, and tested on the EuroSAT dataset used as reference benchmark. The\nresults of the multiclass classification prove the effectiveness of the\npresented approach, by demonstrating that the QCNN performances are higher than\nthe classical counterparts. Moreover, investigation of various quantum circuits\nshows that the ones exploiting quantum entanglement achieve the best\nclassification scores. This study underlines the potentialities of applying\nquantum computing to an EO case study and provides the theoretical and\nexperimental background for futures investigations.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.ET", "quant-ph"], "pdf_url": "http://arxiv.org/pdf/2109.09484v2"}
{"entry_id": "http://arxiv.org/abs/2301.01200v1", "date": "2022-12-20", "title": "Common Practices and Taxonomy in Deep Multi-view Fusion for Remote Sensing Applications", "authors": "Francisco Mena, Diego Arenas, Marlon Nuske, Andreas Dengel", "abstract": "The advances in remote sensing technologies have boosted applications for\nEarth observation. These technologies provide multiple observations or views\nwith different levels of information. They might contain static or temporary\nviews with different levels of resolution, in addition to having different\ntypes and amounts of noise due to sensor calibration or deterioration. A great\nvariety of deep learning models have been applied to fuse the information from\nthese multiple views, known as deep multi-view or multi-modal fusion learning.\nHowever, the approaches in the literature vary greatly since different\nterminology is used to refer to similar concepts or different illustrations are\ngiven to similar techniques. This article gathers works on multi-view fusion\nfor Earth observation by focusing on the common practices and approaches used\nin the literature. We summarize and structure insights from several different\npublications concentrating on unifying points and ideas. In this manuscript, we\nprovide a harmonized terminology while at the same time mentioning the various\nalternative terms that are used in literature. The topics covered by the works\nreviewed focus on supervised learning with the use of neural network models. We\nhope this review, with a long list of recent references, can support future\nresearch and lead to a unified advance in the area.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2301.01200v1"}
{"entry_id": "http://arxiv.org/abs/1403.5473v1", "date": "2014-03-11", "title": "Image Fusion Techniques in Remote Sensing", "authors": "Reham Gharbia, Ahmad Taher Azar, Ali El Baz, Aboul Ella Hassanien", "abstract": "Remote sensing image fusion is an effective way to use a large volume of data\nfrom multisensor images. Most earth satellites such as SPOT, Landsat 7, IKONOS\nand QuickBird provide both panchromatic (Pan) images at a higher spatial\nresolution and multispectral (MS) images at a lower spatial resolution and many\nremote sensing applications require both high spatial and high spectral\nresolutions, especially for GIS based applications. An effective image fusion\ntechnique can produce such remotely sensed images. Image fusion is the\ncombination of two or more different images to form a new image by using a\ncertain algorithm to obtain more and better information about an object or a\nstudy area than. The image fusion is performed at three different processing\nlevels which are pixel level, feature level and decision level according to the\nstage at which the fusion takes place. There are many image fusion methods that\ncan be used to produce high resolution multispectral images from a high\nresolution pan image and low resolution multispectral images. This paper\nexplores the major remote sensing data fusion techniques at pixel level and\nreviews the concept, principals, limitations and advantages for each technique.\nThis paper focused on traditional techniques like intensity hue-saturation-\n(HIS), Brovey, principal component analysis (PCA) and Wavelet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1403.5473v1"}
{"entry_id": "http://arxiv.org/abs/1901.07574v1", "date": "2019-01-22", "title": "Photonic Newton's Cradle for Remote Energy Transport", "authors": "Zhen Feng, Zhen-Wei Gao, Lian-Ao Wu, Hao Tang, Ke Sun, Cheng-Qiu Hu, Yao Wang, Zhan-Ming Li, Xiao-Wei Wang, Yuan Chen, En-Ze Zhang, Zhi-Qiang Jiao, Xiao-Yun Xu, Jun Gao, Ai-Lin Yang, Xian-Min Jin", "abstract": "Energy transport is of central importance in understanding a wide variety of\ntransitions of physical states in nature. Recently, the coherence and noise\nhave been identified for their existence and key roles in energy transport\nprocesses, for instance, in a photosynthesis complex, DNA, and odor sensing\netc, of which one may have to reveal the inner mechanics in the quantum regime.\nHere we present an analog of Newton's cradle by manipulating a\nboundary-controlled chain on a photonic chip. Long-range interactions can be\nmediated by a long chain composed of 21 strongly coupled sites, where\nsingle-photon excitations are transferred between two remote sites via\nsimultaneous control of inter-site weak and strong couplings. We observe a high\nretrieval efficiency in both uniform and defect-doped chain structures. Our\nresults may offer a flexible approach to Hamiltonian engineering beyond\ngeometric limitation, enabling the design and construction of quantum\nsimulators on demand.", "journal": "Phys. Rev. Applied 11, 044009 (2019)", "doi": "10.1103/PhysRevApplied.11.044009", "primary_category": "quant-ph", "categories": ["quant-ph", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/1901.07574v1"}
{"entry_id": "http://arxiv.org/abs/2103.16607v2", "date": "2021-03-30", "title": "Seasonal Contrast: Unsupervised Pre-Training from Uncurated Remote Sensing Data", "authors": "Oscar Ma\u00f1as, Alexandre Lacoste, Xavier Giro-i-Nieto, David Vazquez, Pau Rodriguez", "abstract": "Remote sensing and automatic earth monitoring are key to solve global-scale\nchallenges such as disaster prevention, land use monitoring, or tackling\nclimate change. Although there exist vast amounts of remote sensing data, most\nof it remains unlabeled and thus inaccessible for supervised learning\nalgorithms. Transfer learning approaches can reduce the data requirements of\ndeep learning algorithms. However, most of these methods are pre-trained on\nImageNet and their generalization to remote sensing imagery is not guaranteed\ndue to the domain gap. In this work, we propose Seasonal Contrast (SeCo), an\neffective pipeline to leverage unlabeled data for in-domain pre-training of\nremote sensing representations. The SeCo pipeline is composed of two parts.\nFirst, a principled procedure to gather large-scale, unlabeled and uncurated\nremote sensing datasets containing images from multiple Earth locations at\ndifferent timestamps. Second, a self-supervised algorithm that takes advantage\nof time and position invariance to learn transferable representations for\nremote sensing applications. We empirically show that models trained with SeCo\nachieve better performance than their ImageNet pre-trained counterparts and\nstate-of-the-art self-supervised learning methods on multiple downstream tasks.\nThe datasets and models in SeCo will be made public to facilitate transfer\nlearning and enable rapid progress in remote sensing applications.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2103.16607v2"}
{"entry_id": "http://arxiv.org/abs/2212.09360v1", "date": "2022-12-19", "title": "AI Security for Geoscience and Remote Sensing: Challenges and Future Trends", "authors": "Yonghao Xu, Tao Bai, Weikang Yu, Shizhen Chang, Peter M. Atkinson, Pedram Ghamisi", "abstract": "Recent advances in artificial intelligence (AI) have significantly\nintensified research in the geoscience and remote sensing (RS) field. AI\nalgorithms, especially deep learning-based ones, have been developed and\napplied widely to RS data analysis. The successful application of AI covers\nalmost all aspects of Earth observation (EO) missions, from low-level vision\ntasks like super-resolution, denoising, and inpainting, to high-level vision\ntasks like scene classification, object detection, and semantic segmentation.\nWhile AI techniques enable researchers to observe and understand the Earth more\naccurately, the vulnerability and uncertainty of AI models deserve further\nattention, considering that many geoscience and RS tasks are highly\nsafety-critical. This paper reviews the current development of AI security in\nthe geoscience and RS field, covering the following five important aspects:\nadversarial attack, backdoor attack, federated learning, uncertainty, and\nexplainability. Moreover, the potential opportunities and trends are discussed\nto provide insights for future research. To the best of the authors' knowledge,\nthis paper is the first attempt to provide a systematic review of AI\nsecurity-related research in the geoscience and RS community. Available code\nand datasets are also listed in the paper to move this vibrant field of\nresearch forward.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2212.09360v1"}
{"entry_id": "http://arxiv.org/abs/2102.07940v1", "date": "2021-02-16", "title": "Attitude Trajectory Optimization for Agile Satellites in Autonomous Remote Sensing Constellation", "authors": "Emmanuel Sin, Sreeja Nag, Vinay Ravindra, Alan Li, Murat Arcak", "abstract": "Agile attitude maneuvering maximizes the utility of remote sensing satellite\nconstellations. By taking into account a satellite's physical properties and\nits actuator specifications, we may leverage the full performance potential of\nthe attitude control system to conduct agile remote sensing beyond conventional\nslew-and-stabilize maneuvers. Employing a constellation of agile satellites,\ncoordinated by an autonomous and responsive scheduler, can significantly\nincrease overall response rate, revisit time and global coverage for the\nmission. In this paper, we use recent advances in sequential convex programming\nbased trajectory optimization to enable rapid-target acquisition, pointing and\ntracking capabilities for a scheduler-based constellation. We present two\nproblem formulations. The Minimum-Time Slew Optimal Control Problem determines\nthe minimum time, required energy, and optimal trajectory to slew between any\ntwo orientations given nonlinear quaternion kinematics, gyrostat and actuator\ndynamics, and state/input constraints. By gridding the space of 3D rotations\nand efficiently solving this problem on the grid, we produce lookup tables or\nparametric fits off-line that can then be used on-line by a scheduler to\ncompute accurate estimates of minimum-time and maneuver energy for real-time\nconstellation scheduling. The Minimum-Effort Multi-Target Pointing Optimal\nControl Problem is used on-line by each satellite to produce continuous\nattitude-state and control-input trajectories that realize a given schedule\nwhile minimizing attitude error and control effort. The optimal trajectory may\nthen be achieved by a low-level tracking controller. We demonstrate our\napproach with an example of a reference satellite in Sun-synchronous orbit\npassing over globally-distributed, Earth-observation targets.", "journal": "", "doi": null, "primary_category": "eess.SY", "categories": ["eess.SY", "cs.SY"], "pdf_url": "http://arxiv.org/pdf/2102.07940v1"}
{"entry_id": "http://arxiv.org/abs/2207.07534v1", "date": "2022-07-15", "title": "Multispacecraft Remote Sensing and In Situ Observations of the 2020 November 29 Coronal Mass Ejection and Associated Shock: From Solar Source to Heliospheric Impacts", "authors": "Chong Chen, Ying D. Liu, Bei Zhu", "abstract": "We investigate the source eruption, propagation and expansion\ncharacteristics, and heliospheric impacts of the 2020 November 29 coronal mass\nejection (CME) and associated shock, using remote sensing and in situ\nobservations from multiple spacecraft. A potential--field source--surface model\nis employed to examine the coronal magnetic fields surrounding the source\nregion. The CME and associated shock are tracked from the early stage to the\nouter corona using extreme ultraviolet and white light observations. Forward\nmodels are applied to determine the structures and kinematics of the CME and\nthe shock near the Sun. The shock shows an ellipsoidal structure, expands in\nall directions, and encloses the whole Sun as viewed from both SOHO and STEREO\nA, which results from the large expansion of the CME flux rope and its fast\nacceleration. The structure and potential impacts of the shock are mainly\ndetermined by its radial and lateral expansions. The CME and shock arrive at\nParker Solar Probe and STEREO A. Only based on the remote sensing observations,\nit is difficult to predict whether and when the CME/shock would arrive at the\nEarth. Combining Wind in situ measurements and WSA-ENLIL simulation results, we\nconfirm that the far flank of the CME (or the CME leg) arrives at the Earth\nwith no shock signature. These results highlight the importance of multipoint\nremote sensing and in situ observations for determining the heliospheric\nimpacts of CMEs.", "journal": "", "doi": "10.3847/1538-4357/ac7ff6", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2207.07534v1"}
{"entry_id": "http://arxiv.org/abs/2101.03523v3", "date": "2021-01-10", "title": "Quantifying COVID-19 enforced global changes in atmospheric pollutants using cloud computing based remote sensing", "authors": "Manmeet Singh, Bhupendra Bahadur Singh, Raunaq Singh, Badimela Upendra, Rupinder Kaur, Sukhpal Singh Gill, Mriganka Sekhar Biswas", "abstract": "Global lockdowns in response to the COVID-19 pandemic have led to changes in\nthe anthropogenic activities resulting in perceivable air quality improvements.\nAlthough several recent studies have analyzed these changes over different\nregions of the globe, these analyses have been constrained due to the usage of\nstation-based data which is mostly limited upto the metropolitan cities. Also,\nthe quantifiable changes have been reported only for the developed and\ndeveloping regions leaving the poor economies (e.g. Africa) due to the shortage\nof in-situ data. Using a comprehensive set of high spatiotemporal resolution\nsatellites and merged products of air pollutants, we analyze the air quality\nacross the globe and quantify the improvement resulting from the suppressed\nanthropogenic activity during the lockdowns. In particular, we focus on\nmegacities, capitals and cities with high standards of living to make the\nquantitative assessment. Our results offer valuable insights into the spatial\ndistribution of changes in the air pollutants due to COVID-19 enforced\nlockdowns. Statistically significant reductions are observed over megacities\nwith mean reduction by 19.74%, 7.38% and 49.9% in nitrogen dioxide (NO2),\naerosol optical depth (AOD) and PM 2.5 concentrations. Google Earth Engine\nempowered cloud computing based remote sensing is used and the results provide\na testbed for climate sensitivity experiments and validation of\nchemistry-climate models. Additionally, Google Earth Engine based apps have\nbeen developed to visualize the changes in a real-time fashion.", "journal": "22(100489) (2021), 13", "doi": "10.1016/j.rsase.2021.100489", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2101.03523v3"}
{"entry_id": "http://arxiv.org/abs/1903.09842v1", "date": "2019-03-23", "title": "Remote-sensing Characterisation of Major Solar System Bodies with the Twinkle Space Telescope", "authors": "Billy Edwards, Giorgio Savini, Giovanna Tinetti, Marcell Tessenyi, Claudio Arena, Sean Lindsay, Neil Bowles", "abstract": "Remote-sensing observations of Solar System objects with a space telescope\noffer a key method of understanding celestial bodies and contributing to\nplanetary formation and evolution theories. The capabilities of Twinkle, a\nspace telescope in a low Earth orbit with a 0.45m mirror, to acquire\nspectroscopic data of Solar System targets in the visible and infrared are\nassessed. Twinkle is a general observatory that provides on demand observations\nof a wide variety of targets within wavelength ranges that are currently not\naccessible using other space telescopes or that are accessible only to\noversubscribed observatories in the short-term future. We determine the periods\nfor which numerous Solar System objects could be observed and find that Solar\nSystem objects are regularly observable. The photon flux of major bodies is\ndetermined for comparison to the sensitivity and saturation limits of Twinkle's\ninstrumentation and we find that the satellite's capability varies across the\nthree spectral bands (0.4-1, 1.3-2.42, and 2.42-4.5{\\mu}m). We find that for a\nnumber of targets, including the outer planets, their large moons, and bright\nasteroids, the model created predicts that with short exposure times,\nhigh-resolution spectra (R~250, {\\lambda} < 2.42{\\mu}m; R~60, {\\lambda} >\n2.42{\\mu}m) could be obtained with signal-to-noise ratio (SNR) of >100 with\nexposure times of <300s.", "journal": "J. Astron. Telesc. Instrum. Syst. 5(1), 014006 (2019)", "doi": "10.1117/1.JATIS.5.1.014006", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1903.09842v1"}
{"entry_id": "http://arxiv.org/abs/2012.05795v1", "date": "2020-12-07", "title": "Machine Learning Information Fusion in Earth Observation: A Comprehensive Review of Methods, Applications and Data Sources", "authors": "S. Salcedo-Sanz, P. Ghamisi, M. Piles, M. Werner, L. Cuadra, A. Moreno-Mart\u00ednez, E. Izquierdo-Verdiguier, J. Mu\u00f1oz-Mar\u00ed, Amirhosein Mosavi, G. Camps-Valls", "abstract": "This paper reviews the most important information fusion data-driven\nalgorithms based on Machine Learning (ML) techniques for problems in Earth\nobservation. Nowadays we observe and model the Earth with a wealth of\nobservations, from a plethora of different sensors, measuring states, fluxes,\nprocesses and variables, at unprecedented spatial and temporal resolutions.\nEarth observation is well equipped with remote sensing systems, mounted on\nsatellites and airborne platforms, but it also involves in-situ observations,\nnumerical models and social media data streams, among other data sources.\nData-driven approaches, and ML techniques in particular, are the natural choice\nto extract significant information from this data deluge. This paper produces a\nthorough review of the latest work on information fusion for Earth observation,\nwith a practical intention, not only focusing on describing the most relevant\nprevious works in the field, but also the most important Earth observation\napplications where ML information fusion has obtained significant results. We\nalso review some of the most currently used data sets, models and sources for\nEarth observation problems, describing their importance and how to obtain the\ndata when needed. Finally, we illustrate the application of ML data fusion with\na representative set of case studies, as well as we discuss and outlook the\nnear future of the field.", "journal": "Information Fusion, Volume 63, November 2020, Pages 256-272", "doi": "10.1016/j.inffus.2020.07.004", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2012.05795v1"}
{"entry_id": "http://arxiv.org/abs/2212.02265v1", "date": "2022-12-05", "title": "MapInWild: A Remote Sensing Dataset to Address the Question What Makes Nature Wild", "authors": "Burak Ekim, Timo T. Stomberg, Ribana Roscher, Michael Schmitt", "abstract": "Antrophonegic pressure (i.e. human influence) on the environment is one of\nthe largest causes of the loss of biological diversity. Wilderness areas, in\ncontrast, are home to undisturbed ecological processes. However, there is no\nbiophysical definition of the term wilderness. Instead, wilderness is more of a\nphilosophical or cultural concept and thus cannot be easily delineated or\ncategorized in a technical manner. With this paper, (i) we introduce the task\nof wilderness mapping by means of machine learning applied to satellite imagery\n(ii) and publish MapInWild, a large-scale benchmark dataset curated for that\ntask. MapInWild is a multi-modal dataset and comprises various geodata acquired\nand formed from a diverse set of Earth observation sensors. The dataset\nconsists of 8144 images with a shape of 1920 x 1920 pixels and is approximately\n350 GB in size. The images are weakly annotated with three classes derived from\nthe World Database of Protected Areas - Strict Nature Reserves, Wilderness\nAreas, and National Parks. With the dataset, which shall serve as a testbed for\ndevelopments in fields such as explainable machine learning and environmental\nremote sensing, we hope to contribute to a deepening of our understanding of\nthe question \"What makes nature wild?\".", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2212.02265v1"}
{"entry_id": "http://arxiv.org/abs/2210.06090v2", "date": "2022-10-12", "title": "Can We \"Sense\" the Call of The Ocean? Current Advances in Remote Sensing Computational Imaging for Marine Debris Monitoring", "authors": "Oktay Karaku\u015f", "abstract": "Especially due to the unconscious use of petroleum products, the ocean faces\na potential danger: $\\textit{plastic pollution}$. Plastic pollutes not only the\nocean but also directly the air and foods whilst endangering the ocean\nwild-life due to the ingestion and entanglements. Especially, during the last\ndecade, public initiatives and academic institutions have spent an enormous\ntime on finding possible solutions to marine plastic pollution. Remote sensing\nimagery sits in a crucial place for these efforts since it provides highly\ninformative earth observation products. Despite this, detection, and monitoring\nof the marine environment in the context of plastic pollution is still in its\nearly stages and the current technology offers possible important development\nfor the computational efforts. This paper contributes to the literature with a\nthorough and rich review and aims to highlight notable literature milestones in\nmarine debris monitoring applications by promoting the computational imaging\nmethodology behind these approaches.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2210.06090v2"}
{"entry_id": "http://arxiv.org/abs/2301.01557v1", "date": "2023-01-04", "title": "Super-Resolution Imaging with Multiparameter Quantum Metrology in Passive Remote Sensing", "authors": "Emre K\u00f6se, Daniel Braun", "abstract": "We study super-resolution imaging theoretically using a distant n-mode\ninterferometer in the microwave regime for passive remote sensing, used e.g.,\nfor satellites like the \"soil moisture and ocean salinity (SMOS)\" mission to\nobserve the surface of the Earth. We give a complete quantum mechanical\nanalysis of multiparameter estimation of the temperatures on the source plane.\nWe find the optimal detection modes by combining incoming modes with an\noptimized unitary that enables the most informative measurement based on photon\ncounting in the detection modes and saturates the quantum Cram\\'er-Rao bound\nfrom the symmetric logarithmic derivative for the parameter set of\ntemperatures. In our numerical analysis, we achieved a quantum-enhanced\nsuper-resolution by reconstructing an image using the maximum likelihood\nestimator with a pixel size of 3 km, which is ten times smaller than the\nspatial resolution of SMOS with comparable parameters. Further, we find the\noptimized unitary for uniform temperature distribution on the source plane,\nwith the temperatures corresponding to the average temperatures of the image.\nEven though the corresponding unitary was not optimized for the specific image,\nit still gives a super-resolution compared to local measurement scenarios for\nthe theoretically possible maximum number of measurements.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph", "physics.ins-det", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/2301.01557v1"}
{"entry_id": "http://arxiv.org/abs/2012.07986v1", "date": "2020-12-07", "title": "Physics-Aware Gaussian Processes in Remote Sensing", "authors": "Gustau Camps-Valls, Luca Martino, Daniel H. Svendsen, Manuel Campos-Taberner, Jordi Mu\u00f1oz-Mar\u00ed, Valero Laparra, David Luengo, Francisco Javier Garc\u00eda-Haro", "abstract": "Earth observation from satellite sensory data poses challenging problems,\nwhere machine learning is currently a key player. In recent years, Gaussian\nProcess (GP) regression has excelled in biophysical parameter estimation tasks\nfrom airborne and satellite observations. GP regression is based on solid\nBayesian statistics and generally yields efficient and accurate parameter\nestimates. However, GPs are typically used for inverse modeling based on\nconcurrent observations and in situ measurements only. Very often a forward\nmodel encoding the well-understood physical relations between the state vector\nand the radiance observations is available though and could be useful to\nimprove predictions and understanding. In this work, we review three GP models\nthat respect and learn the physics of the underlying processes in the context\nof both forward and inverse modeling. After reviewing the traditional\napplication of GPs for parameter retrieval, we introduce a Joint GP (JGP) model\nthat combines in situ measurements and simulated data in a single GP model.\nThen, we present a latent force model (LFM) for GP modeling that encodes\nordinary differential equations to blend data-driven modeling and physical\nconstraints of the system governing equations. The LFM performs multi-output\nregression, adapts to the signal characteristics, is able to cope with missing\ndata in the time series, and provides explicit latent functions that allow\nsystem analysis and evaluation. Finally, we present an Automatic Gaussian\nProcess Emulator (AGAPE) that approximates the forward physical model using\nconcepts from Bayesian optimization and at the same time builds an optimally\ncompact look-up-table for inversion. We give empirical evidence of the\nperformance of these models through illustrative examples of vegetation\nmonitoring and atmospheric modeling.", "journal": "Applied Soft Computing Volume 68, July 2018, Pages 69-82", "doi": "10.1016/j.asoc.2018.03.021", "primary_category": "eess.SP", "categories": ["eess.SP", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/2012.07986v1"}
{"entry_id": "http://arxiv.org/abs/2207.05807v1", "date": "2022-07-12", "title": "Dam reservoir extraction from remote sensing imagery using tailored metric learning strategies", "authors": "Arnout van Soesbergen, Zedong Chu, Miaojing Shi, Mark Mulligan", "abstract": "Dam reservoirs play an important role in meeting sustainable development\ngoals and global climate targets. However, particularly for small dam\nreservoirs, there is a lack of consistent data on their geographical location.\nTo address this data gap, a promising approach is to perform automated dam\nreservoir extraction based on globally available remote sensing imagery. It can\nbe considered as a fine-grained task of water body extraction, which involves\nextracting water areas in images and then separating dam reservoirs from\nnatural water bodies. We propose a novel deep neural network (DNN) based\npipeline that decomposes dam reservoir extraction into water body segmentation\nand dam reservoir recognition. Water bodies are firstly separated from\nbackground lands in a segmentation model and each individual water body is then\npredicted as either dam reservoir or natural water body in a classification\nmodel. For the former step, point-level metric learning with triplets across\nimages is injected into the segmentation model to address contour ambiguities\nbetween water areas and land regions. For the latter step, prior-guided metric\nlearning with triplets from clusters is injected into the classification model\nto optimize the image embedding space in a fine-grained level based on\nreservoir clusters. To facilitate future research, we establish a benchmark\ndataset with earth imagery data and human labelled reservoirs from river basins\nin West Africa and India. Extensive experiments were conducted on this\nbenchmark in the water body segmentation task, dam reservoir recognition task,\nand the joint dam reservoir extraction task. Superior performance has been\nobserved in the respective tasks when comparing our method with state of the\nart approaches.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2207.05807v1"}
{"entry_id": "http://arxiv.org/abs/2104.07778v1", "date": "2021-04-15", "title": "Recent Advances in Domain Adaptation for the Classification of Remote Sensing Data", "authors": "Devis Tuia, Claudio Persello, Lorenzo Bruzzone", "abstract": "The success of supervised classification of remotely sensed images acquired\nover large geographical areas or at short time intervals strongly depends on\nthe representativity of the samples used to train the classification algorithm\nand to define the model. When training samples are collected from an image (or\na spatial region) different from the one used for mapping, spectral shifts\nbetween the two distributions are likely to make the model fail. Such shifts\nare generally due to differences in acquisition and atmospheric conditions or\nto changes in the nature of the object observed. In order to design\nclassification methods that are robust to data-set shifts, recent remote\nsensing literature has considered solutions based on domain adaptation (DA)\napproaches. Inspired by machine learning literature, several DA methods have\nbeen proposed to solve specific problems in remote sensing data classification.\nThis paper provides a critical review of the recent advances in DA for remote\nsensing and presents an overview of methods divided into four categories: i)\ninvariant feature selection; ii) representation matching; iii) adaptation of\nclassifiers and iv) selective sampling. We provide an overview of recent\nmethodologies, as well as examples of application of the considered techniques\nto real remote sensing images characterized by very high spatial and spectral\nresolution. Finally, we propose guidelines to the selection of the method to\nuse in real application scenarios.", "journal": "IEEE Geoscience and Remote Sensing Magazine, 4(2): 41-57, 2016", "doi": "10.1109/MGRS.2016.2548504", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2104.07778v1"}
{"entry_id": "http://arxiv.org/abs/2011.09766v1", "date": "2020-11-19", "title": "Foreground-Aware Relation Network for Geospatial Object Segmentation in High Spatial Resolution Remote Sensing Imagery", "authors": "Zhuo Zheng, Yanfei Zhong, Junjue Wang, Ailong Ma", "abstract": "Geospatial object segmentation, as a particular semantic segmentation task,\nalways faces with larger-scale variation, larger intra-class variance of\nbackground, and foreground-background imbalance in the high spatial resolution\n(HSR) remote sensing imagery. However, general semantic segmentation methods\nmainly focus on scale variation in the natural scene, with inadequate\nconsideration of the other two problems that usually happen in the large area\nearth observation scene. In this paper, we argue that the problems lie on the\nlack of foreground modeling and propose a foreground-aware relation network\n(FarSeg) from the perspectives of relation-based and optimization-based\nforeground modeling, to alleviate the above two problems. From perspective of\nrelation, FarSeg enhances the discrimination of foreground features via\nforeground-correlated contexts associated by learning foreground-scene\nrelation. Meanwhile, from perspective of optimization, a foreground-aware\noptimization is proposed to focus on foreground examples and hard examples of\nbackground during training for a balanced optimization. The experimental\nresults obtained using a large scale dataset suggest that the proposed method\nis superior to the state-of-the-art general semantic segmentation methods and\nachieves a better trade-off between speed and accuracy. Code has been made\navailable at: \\url{https://github.com/Z-Zheng/FarSeg}.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2011.09766v1"}
{"entry_id": "http://arxiv.org/abs/1501.05286v1", "date": "2015-01-17", "title": "Distributed mining of large scale remote sensing image archives on public computing infrastructures", "authors": "Luigi Mascolo, Marco Quartulli, Pietro Guccione, Giovanni Nico, Igor G. Olaizola", "abstract": "Earth Observation (EO) mining aims at supporting efficient access and\nexploration of petabyte-scale space- and airborne remote sensing archives that\nare currently expanding at rates of terabytes per day. A significant challenge\nis performing the analysis required by envisaged applications --- like for\ninstance process mapping for environmental risk management --- in reasonable\ntime. In this work, we address the problem of content-based image retrieval via\nexample-based queries from EO data archives. In particular, we focus on the\nanalysis of polarimetric SAR data, for which target decomposition theorems have\nproved fundamental in discovering patterns in data and characterize the ground\nscattering properties. To this end, we propose an interactive region-oriented\ncontent-based image mining system in which 1) unsupervised ingestion processes\nare distributed onto virtual machines in elastic, on-demand computing\ninfrastructures 2) archive-scale content hierarchical indexing is implemented\nin terms of a \"big data\" analytics cluster-computing framework 3) query\nprocessing amounts to traversing the generated binary tree index, computing\ndistances that correspond to descriptor-based similarity measures between image\ngroups and a query image tile. We describe in depth both the strategies and the\nactual implementations for the ingestion and indexing components, and verify\nthe approach by experiments carried out on the NASA/JPL UAVSAR full\npolarimetric data archive. We report the results of the tests performed on\ncomputer clusters by using a public Infrastructure-as-a-Service and evaluating\nthe impact of cluster configuration on system performance. Results are\npromising for data mapping and information retrieval applications.", "journal": "", "doi": null, "primary_category": "cs.DC", "categories": ["cs.DC"], "pdf_url": "http://arxiv.org/pdf/1501.05286v1"}
{"entry_id": "http://arxiv.org/abs/2001.04650v1", "date": "2020-01-14", "title": "Deep learning-based air temperature mapping by fusing remote sensing, station, simulation and socioeconomic data", "authors": "Huanfeng Shen, Yun Jiang, Tongwen Li, Qing Cheng, Chao Zeng, Liangpei Zhang", "abstract": "Air temperature (Ta) is an essential climatological component that controls\nand influences various earth surface processes. In this study, we make the\nfirst attempt to employ deep learning for Ta mapping mainly based on space\nremote sensing and ground station observations. Considering that Ta varies\ngreatly in space and time and is sensitive to many factors, assimilation data\nand socioeconomic data are also included for a multi-source data fusion based\nestimation. Specifically, a 5-layers structured deep belief network (DBN) is\nemployed to better capture the complicated and non-linear relationships between\nTa and different predictor variables. Layer-wise pre-training process for\nessential features extraction and fine-tuning process for weight parameters\noptimization ensure the robust prediction of Ta spatio-temporal distribution.\nThe DBN model was implemented for 0.01{\\deg} daily maximum Ta mapping across\nChina. The ten-fold cross-validation results indicate that the DBN model\nachieves promising results with the RMSE of 1.996{\\deg}C, MAE of 1.539{\\deg}C,\nand R of 0.986 at the national scale. Compared with multiple linear regression\n(MLR), back-propagation neural network (BPNN) and random forest (RF) method,\nthe DBN model reduces the MAE values by 1.340{\\deg}C, 0.387{\\deg}C and\n0.222{\\deg}C, respectively. Further analysis on spatial distribution and\ntemporal tendency of prediction errors both validate the great potentials of\nDBN in Ta estimation.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2001.04650v1"}
{"entry_id": "http://arxiv.org/abs/2205.11319v2", "date": "2022-05-23", "title": "Continual Barlow Twins: continual self-supervised learning for remote sensing semantic segmentation", "authors": "Valerio Marsocci, Simone Scardapane", "abstract": "In the field of Earth Observation (EO), Continual Learning (CL) algorithms\nhave been proposed to deal with large datasets by decomposing them into several\nsubsets and processing them incrementally. The majority of these algorithms\nassume that data is (a) coming from a single source, and (b) fully labeled.\nReal-world EO datasets are instead characterized by a large heterogeneity\n(e.g., coming from aerial, satellite, or drone scenarios), and for the most\npart they are unlabeled, meaning they can be fully exploited only through the\nemerging Self-Supervised Learning (SSL) paradigm. For these reasons, in this\npaper we propose a new algorithm for merging SSL and CL for remote sensing\napplications, that we call Continual Barlow Twins (CBT). It combines the\nadvantages of one of the simplest self-supervision techniques, i.e., Barlow\nTwins, with the Elastic Weight Consolidation method to avoid catastrophic\nforgetting. In addition, for the first time we evaluate SSL methods on a highly\nheterogeneous EO dataset, showing the effectiveness of these strategies on a\nnovel combination of three almost non-overlapping domains datasets (airborne\nPotsdam dataset, satellite US3D dataset, and drone UAVid dataset), on a crucial\ndownstream task in EO, i.e., semantic segmentation. Encouraging results show\nthe superiority of SSL in this setting, and the effectiveness of creating an\nincremental effective pretrained feature extractor, based on ResNet50, without\nthe need of relying on the complete availability of all the data, with a\nvaluable saving of time and resources.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2205.11319v2"}
{"entry_id": "http://arxiv.org/abs/2012.03630v1", "date": "2020-12-07", "title": "Randomized kernels for large scale Earth observation applications", "authors": "Adri\u00e1n P\u00e9rez-Suay, Julia Amor\u00f3s-L\u00f3pez, Luis G\u00f3mez-Chova, Valero Laparra, Jordi Mu\u00f1oz-Mar\u00ed, Gustau Camps-Valls", "abstract": "Dealing with land cover classification of the new image sources has also\nturned to be a complex problem requiring large amount of memory and processing\ntime. In order to cope with these problems, statistical learning has greatly\nhelped in the last years to develop statistical retrieval and classification\nmodels that can ingest large amounts of Earth observation data. Kernel methods\nconstitute a family of powerful machine learning algorithms, which have found\nwide use in remote sensing and geosciences. However, kernel methods are still\nnot widely adopted because of the high computational cost when dealing with\nlarge scale problems, such as the inversion of radiative transfer models or the\nclassification of high spatial-spectral-temporal resolution data. This paper\nintroduces an efficient kernel method for fast statistical retrieval of\nbio-geo-physical parameters and image classification problems. The method\nallows to approximate a kernel matrix with a set of projections on random bases\nsampled from the Fourier domain. The method is simple, computationally very\nefficient in both memory and processing costs, and easily parallelizable. We\nshow that kernel regression and classification is now possible for datasets\nwith millions of examples and high dimensionality. Examples on atmospheric\nparameter retrieval from hyperspectral infrared sounders like IASI/Metop; large\nscale emulation and inversion of the familiar PROSAIL radiative transfer model\non Sentinel-2 data; and the identification of clouds over landmarks in time\nseries of MSG/Seviri images show the efficiency and effectiveness of the\nproposed technique.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2012.03630v1"}
{"entry_id": "http://arxiv.org/abs/1809.01652v1", "date": "2018-09-04", "title": "Current potentials and challenges using Sentinel-1 for broadacre field remote sensing", "authors": "Martin Peter Christiansen, Morten Stigaard Laursen, Birgitte Feld Mikkelsen, Nima Teimouri, Rasmus Nyholm J\u00f8rgensen, Claus Aage Gr\u00f8n S\u00f8rensen", "abstract": "ESA operates the Sentinel-1 satellites, which provides Synthetic Aperture\nRadar (SAR) data of Earth. Recorded Sentinel-1 data have shown a potential for\nremotely observing and monitoring local conditions on broad acre fields. Remote\nsensing using Sentinel-1 have the potential to provide daily updates on the\ncurrent conditions in the individual fields and at the same time give an\noverview of the agricultural areas in the region. Research depends on the\nability of independent validation of the presented results. In the case of the\nSentinel-1 satellites, every researcher has access to the same base dataset,\nand therefore independent validation is possible. Well documented research\nperformed with Sentinel-1 allow other research the ability to redo the\nexperiments and either validate or falsify presented findings. Based on current\nstate-of-art research we have chosen to provide a service for researchers in\nthe agricultural domain. The service allows researchers the ability to monitor\nlocal conditions by using the Sentinel-1 information combined with a priori\nknowledge from broad acre fields. Correlating processed Sentinel-1 to the\nactual conditions is still a task the individual researchers must perform to\nbenefit from the service. In this paper, we presented our methodology in\ntranslating sentinel-1 data to a level that is more accessible to researchers\nin the agricultural field. The goal here was to make the data more easily\navailable, so the primary focus can be on correlating and comparing to\nmeasurements collected in the broadacre fields. We illustrate the value of the\nservice with three examples of the possible application areas. The presented\napplication examples are all based on Denmark, where we have processed all\nsentinel-1 scan from since 2016.", "journal": "EurAgEng 2018", "doi": null, "primary_category": "cs.OH", "categories": ["cs.OH"], "pdf_url": "http://arxiv.org/pdf/1809.01652v1"}
{"entry_id": "http://arxiv.org/abs/1212.3242v1", "date": "2012-12-11", "title": "Polarization Invariants and Retrieval of Surface Parameters Using Polarization Measurements in Remote Sensing Applications", "authors": "Yu. K. Shestopaloff", "abstract": "Using polarization measurements in remote sensing and optical studies allows\nretrieving more information. We consider relationship between the reflection\ncoefficients of plane and rough surfaces for linearly polarized waves. Certain\npolarization properties of reflected waves and polarization invariants, in\nparticular at incident angle of forty five degrees, allow finding amplitude and\nphase characteristics of reflected waves. Based on this study, we introduce\nmethods for finding dielectric permittivity, temperature and geometrical\ncharacteristics of observed surfaces. Experimental results prove that these\nmethods can be used for different practical purposes in technological and\nremote sensing applications, in a broad range of electromagnetic spectrum.", "journal": "Applied Optics, 2011, V. 50, Iss. 36, p. 6606-6616", "doi": "10.1364/AO.50.006606", "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/1212.3242v1"}
{"entry_id": "http://arxiv.org/abs/2210.04770v1", "date": "2022-10-10", "title": "Infrared Remote Sensing Using Low Noise Avalanche Photodiode Detector", "authors": "Joice Mathew, James Gilbert, Robert Sharp, Alexey Grigoriev, Nicolas Cardena, Marta Yebra", "abstract": "For a remote sensing optical payload to achieve a Ground Sampling Distance of\n~ 10-30 m, a critical problem is platform-induced motion blur. While forward\nmotion compensation can reduce this transit speed, it comes at the expense of a\nmore challenging satellite attitude control system and induces a variable\nobservation/illumination angle. This relative motion can be frozen out by\nsimply reading the sensor system at a frame rate that matches the ground\nresolution element's pixel crossing time. To achieve high resolution using this\nTime-Delay Integration (TDI)-like approach requires high speed and hence near\n\"zero\" readout noise detector arrays to avoid swamping the observed signal.\nThis requires associated control electronics for fast frame readout and direct\ninterface with smart- Artificial Intelligence (AI) onboard processing. With\nthis technique, the platform freezes out its movement concerning the ground,\nreducing the demands placed on the attitude control systems, which can\notherwise be difficult to implement on a small satellite platform. Here we\nreport the Australian National University's OzFuel mission which applies this\ntechnical solution to deliver high ground resolution via high frame rate\nimaging. OzFuel is built around the Leonardo SAPHIRA Mercury Cadmium Telluride\nlinear mode electron avalanche photodiode (LMeAPD) detector and the in-house\ndeveloped Rosella electronics control system. The mission will deliver an\nintegrated sensor system in a suite of Short-Wave Infrared (SWIR) passbands\ndedicated to monitoring the flammability of Eucalypt trees. The OzFuel mission\nconcept focuses on the application of SWIR remote sensing data to deliver a\nstrategic evaluation of fuel loads and moisture content in the bushfire-prone\nAustralian environment.", "journal": "", "doi": null, "primary_category": "physics.ins-det", "categories": ["physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/2210.04770v1"}
{"entry_id": "http://arxiv.org/abs/1708.01420v1", "date": "2017-08-04", "title": "On the Selective and Invariant Representation of DCNN for High-Resolution Remote Sensing Image Recognition", "authors": "Jie Chen, Chao Yuan, Min Deng, Chao Tao, Jian Peng, Haifeng Li", "abstract": "Human vision possesses strong invariance in image recognition. The cognitive\ncapability of deep convolutional neural network (DCNN) is close to the human\nvisual level because of hierarchical coding directly from raw image. Owing to\nits superiority in feature representation, DCNN has exhibited remarkable\nperformance in scene recognition of high-resolution remote sensing (HRRS)\nimages and classification of hyper-spectral remote sensing images. In-depth\ninvestigation is still essential for understanding why DCNN can accurately\nidentify diverse ground objects via its effective feature representation. Thus,\nwe train the deep neural network called AlexNet on our large scale remote\nsensing image recognition benchmark. At the neuron level in each convolution\nlayer, we analyze the general properties of DCNN in HRRS image recognition by\nuse of a framework of visual stimulation-characteristic response combined with\nfeature coding-classification decoding. Specifically, we use histogram\nstatistics, representational dissimilarity matrix, and class activation mapping\nto observe the selective and invariance representations of DCNN in HRRS image\nrecognition. We argue that selective and invariance representations play\nimportant roles in remote sensing images tasks, such as classification,\ndetection, and segment. Also selective and invariance representations are\nsignificant to design new DCNN liked models for analyzing and understanding\nremote sensing images.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1708.01420v1"}
{"entry_id": "http://arxiv.org/abs/2211.07044v1", "date": "2022-11-13", "title": "SSL4EO-S12: A Large-Scale Multi-Modal, Multi-Temporal Dataset for Self-Supervised Learning in Earth Observation", "authors": "Yi Wang, Nassim Ait Ali Braham, Zhitong Xiong, Chenying Liu, Conrad M Albrecht, Xiao Xiang Zhu", "abstract": "Self-supervised pre-training bears potential to generate expressive\nrepresentations without human annotation. Most pre-training in Earth\nobservation (EO) are based on ImageNet or medium-size, labeled remote sensing\n(RS) datasets. We share an unlabeled RS dataset SSL4EO-S12 (Self-Supervised\nLearning for Earth Observation - Sentinel-1/2) to assemble a large-scale,\nglobal, multimodal, and multi-seasonal corpus of satellite imagery from the ESA\nSentinel-1 \\& -2 satellite missions. For EO applications we demonstrate\nSSL4EO-S12 to succeed in self-supervised pre-training for a set of methods:\nMoCo-v2, DINO, MAE, and data2vec. Resulting models yield downstream performance\nclose to, or surpassing accuracy measures of supervised learning. In addition,\npre-training on SSL4EO-S12 excels compared to existing datasets. We make openly\navailable the dataset, related source code, and pre-trained models at\nhttps://github.com/zhu-xlab/SSL4EO-S12.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2211.07044v1"}
{"entry_id": "http://arxiv.org/abs/2205.06407v1", "date": "2022-05-13", "title": "Tensor Decompositions for Hyperspectral Data Processing in Remote Sensing: A Comprehensive Review", "authors": "Minghua Wang, Danfeng Hong, Zhu Han, Jiaxin Li, Jing Yao, Lianru Gao, Bing Zhang, Jocelyn Chanussot", "abstract": "Owing to the rapid development of sensor technology, hyperspectral (HS)\nremote sensing (RS) imaging has provided a significant amount of spatial and\nspectral information for the observation and analysis of the Earth's surface at\na distance of data acquisition devices, such as aircraft, spacecraft, and\nsatellite. The recent advancement and even revolution of the HS RS technique\noffer opportunities to realize the full potential of various applications,\nwhile confronting new challenges for efficiently processing and analyzing the\nenormous HS acquisition data. Due to the maintenance of the 3-D HS inherent\nstructure, tensor decomposition has aroused widespread concern and research in\nHS data processing tasks over the past decades. In this article, we aim at\npresenting a comprehensive overview of tensor decomposition, specifically\ncontextualizing the five broad topics in HS data processing, and they are HS\nrestoration, compressed sensing, anomaly detection, super-resolution, and\nspectral unmixing. For each topic, we elaborate on the remarkable achievements\nof tensor decomposition models for HS RS with a pivotal description of the\nexisting methodologies and a representative exhibition on the experimental\nresults. As a result, the remaining challenges of the follow-up research\ndirections are outlined and discussed from the perspective of the real HS RS\npractices and tensor decomposition merged with advanced priors and even with\ndeep neural networks. This article summarizes different tensor\ndecomposition-based HS data processing methods and categorizes them into\ndifferent classes from simple adoptions to complex combinations with other\npriors for the algorithm beginners. We also expect this survey can provide new\ninvestigations and development trends for the experienced researchers who\nunderstand tensor decomposition and HS RS to some extent.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2205.06407v1"}
{"entry_id": "http://arxiv.org/abs/2205.01380v1", "date": "2022-05-03", "title": "Deep Learning in Multimodal Remote Sensing Data Fusion: A Comprehensive Review", "authors": "Jiaxin Li, Danfeng Hong, Lianru Gao, Jing Yao, Ke Zheng, Bing Zhang, Jocelyn Chanussot", "abstract": "With the extremely rapid advances in remote sensing (RS) technology, a great\nquantity of Earth observation (EO) data featuring considerable and complicated\nheterogeneity is readily available nowadays, which renders researchers an\nopportunity to tackle current geoscience applications in a fresh way. With the\njoint utilization of EO data, much research on multimodal RS data fusion has\nmade tremendous progress in recent years, yet these developed traditional\nalgorithms inevitably meet the performance bottleneck due to the lack of the\nability to comprehensively analyse and interpret these strongly heterogeneous\ndata. Hence, this non-negligible limitation further arouses an intense demand\nfor an alternative tool with powerful processing competence. Deep learning\n(DL), as a cutting-edge technology, has witnessed remarkable breakthroughs in\nnumerous computer vision tasks owing to its impressive ability in data\nrepresentation and reconstruction. Naturally, it has been successfully applied\nto the field of multimodal RS data fusion, yielding great improvement compared\nwith traditional methods. This survey aims to present a systematic overview in\nDL-based multimodal RS data fusion. More specifically, some essential knowledge\nabout this topic is first given. Subsequently, a literature survey is conducted\nto analyse the trends of this field. Some prevalent sub-fields in the\nmultimodal RS data fusion are then reviewed in terms of the to-be-fused data\nmodalities, i.e., spatiospectral, spatiotemporal, light detection and\nranging-optical, synthetic aperture radar-optical, and RS-Geospatial Big Data\nfusion. Furthermore, We collect and summarize some valuable resources for the\nsake of the development in multimodal RS data fusion. Finally, the remaining\nchallenges and potential future directions are highlighted.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/2205.01380v1"}
{"entry_id": "http://arxiv.org/abs/2205.08908v1", "date": "2022-05-18", "title": "Remote Sensing Novel View Synthesis with Implicit Multiplane Representations", "authors": "Yongchang Wu, Zhengxia Zou, Zhenwei Shi", "abstract": "Novel view synthesis of remote sensing scenes is of great significance for\nscene visualization, human-computer interaction, and various downstream\napplications. Despite the recent advances in computer graphics and\nphotogrammetry technology, generating novel views is still challenging\nparticularly for remote sensing images due to its high complexity, view\nsparsity and limited view-perspective variations. In this paper, we propose a\nnovel remote sensing view synthesis method by leveraging the recent advances in\nimplicit neural representations. Considering the overhead and far depth imaging\nof remote sensing images, we represent the 3D space by combining implicit\nmultiplane images (MPI) representation and deep neural networks. The 3D scene\nis reconstructed under a self-supervised optimization paradigm through a\ndifferentiable multiplane renderer with multi-view input constraints. Images\nfrom any novel views thus can be freely rendered on the basis of the\nreconstructed model. As a by-product, the depth maps corresponding to the given\nviewpoint can be generated along with the rendering output. We refer to our\nmethod as Implicit Multiplane Images (ImMPI). To further improve the view\nsynthesis under sparse-view inputs, we explore the learning-based\ninitialization of remote sensing 3D scenes and proposed a neural network based\nPrior extractor to accelerate the optimization process. In addition, we propose\na new dataset for remote sensing novel view synthesis with multi-view\nreal-world google earth images. Extensive experiments demonstrate the\nsuperiority of the ImMPI over previous state-of-the-art methods in terms of\nreconstruction accuracy, visual fidelity, and time efficiency. Ablation\nexperiments also suggest the effectiveness of our methodology design. Our\ndataset and code can be found at https://github.com/wyc-Chang/ImMPI", "journal": "", "doi": "10.1109/TGRS.2022.3197409", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2205.08908v1"}
{"entry_id": "http://arxiv.org/abs/1403.2586v1", "date": "2014-03-11", "title": "Remote sensing of clouds and aerosols with cosmic rays", "authors": "A. Neronov, D. Malyshev, A. Dmytriiev", "abstract": "Remote sensing of atmosphere is conventionally done via a study of extinction\n/ scattering of light from natural (Sun, Moon) or artificial (laser) sources.\nCherenkov emission from extensive air showers generated by cosmic rays provides\none more natural light source distributed throughout the atmosphere. We show\nthat Cherenkov light carries information on three-dimensional distribution of\nclouds and aerosols in the atmosphere and on the size distribution and\nscattering phase function of cloud/aerosol particles. Therefore, it could be\nused for the atmospheric sounding. The new atmospheric sounding method could be\nimplemented via an adjustment of technique of imaging Cherenkov telescopes. The\natmospheric sounding data collected in this way could be used both for\natmospheric science and for the improvement of the quality of astronomical\ngamma-ray observations.", "journal": "", "doi": "10.1016/j.astropartphys.2014.03.005", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.HE", "physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1403.2586v1"}
{"entry_id": "http://arxiv.org/abs/2202.05988v1", "date": "2022-02-12", "title": "RSINet: Inpainting Remotely Sensed Images Using Triple GAN Framework", "authors": "Advait Kumar, Dipesh Tamboli, Shivam Pande, Biplab Banerjee", "abstract": "We tackle the problem of image inpainting in the remote sensing domain.\nRemote sensing images possess high resolution and geographical variations, that\nrender the conventional inpainting methods less effective. This further entails\nthe requirement of models with high complexity to sufficiently capture the\nspectral, spatial and textural nuances within an image, emerging from its high\nspatial variability. To this end, we propose a novel inpainting method that\nindividually focuses on each aspect of an image such as edges, colour and\ntexture using a task specific GAN. Moreover, each individual GAN also\nincorporates the attention mechanism that explicitly extracts the spectral and\nspatial features. To ensure consistent gradient flow, the model uses residual\nlearning paradigm, thus simultaneously working with high and low level\nfeatures. We evaluate our model, alongwith previous state of the art models, on\nthe two well known remote sensing datasets, Open Cities AI and Earth on Canvas,\nand achieve competitive performance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2202.05988v1"}
{"entry_id": "http://arxiv.org/abs/2108.01290v1", "date": "2021-08-03", "title": "Linking Sap Flow Measurements with Earth Observations", "authors": "Enrico Tomelleri, Giustino Tonon", "abstract": "While single-tree transpiration is challenging to compare with earth\nobservation, canopy scale data are suitable for this purpose. To test the\npotentialities of the second approach, we equipped the trees at two measurement\nsites with sap flow sensors in spruce forests. The sites have contrasting\ntopography. The measurement period covered the months between June 2020 and\nJanuary 2021. To link plot scale transpiration with earth observations, we\nutilized Sentinel-2 and local meteorological data. Within a machine learning\nframework, we have tested the suitability of earth observations for modelling\ncanopy transpiration. The R2 of the cross-validated trained models at the\nmeasurement sites was between 0.57 and 0.80. These results demonstrate the\nrelevance of Sentinel-2 data for the data-driven upscaling of ecosystem fluxes\nfrom plot scale sap flow data. If applied to a broader network of sites and\nclimatic conditions, such an approach could offer unprecedented possibilities\nfor investigating our forests' resilience and resistance capacity to an\nintensified hydrological cycle in the contest of a changing climate.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP", "cs.LG", "physics.data-an"], "pdf_url": "http://arxiv.org/pdf/2108.01290v1"}
{"entry_id": "http://arxiv.org/abs/2004.03830v1", "date": "2020-04-08", "title": "Change Detection in Heterogeneous Optical and SAR Remote Sensing Images via Deep Homogeneous Feature Fusion", "authors": "Xiao Jiang, Gang Li, Yu Liu, Xiao-Ping Zhang, You He", "abstract": "Change detection in heterogeneous remote sensing images is crucial for\ndisaster damage assessment. Recent methods use homogenous transformation, which\ntransforms the heterogeneous optical and SAR remote sensing images into the\nsame feature space, to achieve change detection. Such transformations mainly\noperate on the low-level feature space and may corrupt the semantic content,\ndeteriorating the performance of change detection. To solve this problem, this\npaper presents a new homogeneous transformation model termed deep homogeneous\nfeature fusion (DHFF) based on image style transfer (IST). Unlike the existing\nmethods, the DHFF method segregates the semantic content and the style features\nin the heterogeneous images to perform homogeneous transformation. The\nseparation of the semantic content and the style in homogeneous transformation\nprevents the corruption of image semantic content, especially in the regions of\nchange. In this way, the detection performance is improved with accurate\nhomogeneous transformation. Furthermore, we present a new iterative IST (IIST)\nstrategy, where the cost function in each IST iteration measures and thus\nmaximizes the feature homogeneity in additional new feature subspaces for\nchange detection. After that, change detection is accomplished accurately on\nthe original and the transformed images that are in the same feature space.\nReal remote sensing images acquired by SAR and optical satellites are utilized\nto evaluate the performance of the proposed method. The experiments demonstrate\nthat the proposed DHFF method achieves significant improvement for change\ndetection in heterogeneous optical and SAR remote sensing images, in terms of\nboth accuracy rate and Kappa index.", "journal": "", "doi": "10.1109/JSTARS.2020.2983993", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2004.03830v1"}
{"entry_id": "http://arxiv.org/abs/1610.02566v1", "date": "2016-10-08", "title": "Performance Bounds for Remote Estimation under Energy Harvesting Constraints", "authors": "Ayca Ozcelikkale, Tomas McKelvey, Mats Viberg", "abstract": "Remote estimation with an energy harvesting sensor with a limited data and\nenergy buffer is considered. The sensor node observes an unknown Gaussian field\nand communicates its observations to a remote fusion center using the energy it\nharvested. The fusion center employs minimum mean-square error (MMSE)\nestimation to reconstruct the unknown field. The distortion minimization\nproblem under the online scheme, where the sensor has access to only the\nstatistical information for the future energy packets is considered. We provide\nperformance bounds on the achievable distortion under a slotted block\ntransmission scheme, where at each transmission time slot, the data and the\nenergy buffer are completely emptied. Our bounds provide insights to the\ntrade-offs between the buffer sizes, the statistical properties of the energy\nharvesting process and the achievable distortion. In particular, these\ntrade-offs illustrate the insensitivity of the performance to the buffer sizes\nfor signals with low degree of freedom and suggest performance improvements\nwith increasing buffer size for signals with relatively higher degree of\nfreedom. Depending only on the mean, variance and finite support of the energy\narrival process, these results provide practical insights for the battery and\nbuffer sizes for deployment in future energy harvesting wireless sensing\nsystems.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1610.02566v1"}
{"entry_id": "http://arxiv.org/abs/2208.08494v1", "date": "2022-08-17", "title": "Bayesian Latent Variable Co-kriging Model in Remote Sensing for Observations with Quality Flagged", "authors": "Bledar A. Konomi, Emily L. Kang, Ayat Almomani, Jonathan Hobbs", "abstract": "Remote sensing data products often include quality flags that inform users\nwhether the associated observations are of good, acceptable or unreliable\nqualities. However, such information on data fidelity is not considered in\nremote sensing data analyses. Motivated by observations from the Atmospheric\nInfrared Sounder (AIRS) instrument on board NASA's Aqua satellite, we propose a\nlatent variable co-kriging model with separable Gaussian processes to analyze\nlarge quality-flagged remote sensing data sets together with their associated\nquality information. We augment the posterior distribution by an imputation\nmechanism to decompose large covariance matrices into separate computationally\nefficient components taking advantage of their input structure. Within the\naugmented posterior, we develop a Markov chain Monte Carlo (MCMC) procedure\nthat mostly consists of direct simulations from conditional distributions. In\naddition, we propose a computationally efficient recursive prediction\nprocedure. We apply the proposed method to air temperature data from the AIRS\ninstrument. We show that incorporating quality flag information in our proposed\nmodel substantially improves the prediction performance compared to models that\ndo not account for quality flags.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP"], "pdf_url": "http://arxiv.org/pdf/2208.08494v1"}
{"entry_id": "http://arxiv.org/abs/1805.02590v1", "date": "2018-05-04", "title": "Modeling Dengue Vector Population Using Remotely Sensed Data and Machine Learning", "authors": "J. M. Scavuzzo, F. Trucco, M. Espinosa, C. B. Tauro, M. Abril, C. M. Scavuzzo, A. C. Frery", "abstract": "Mosquitoes are vectors of many human diseases. In particular, Aedes \\ae gypti\n(Linnaeus) is the main vector for Chikungunya, Dengue, and Zika viruses in\nLatin America and it represents a global threat. Public health policies that\naim at combating this vector require dependable and timely information, which\nis usually expensive to obtain with field campaigns. For this reason, several\nefforts have been done to use remote sensing due to its reduced cost. The\npresent work includes the temporal modeling of the oviposition activity\n(measured weekly on 50 ovitraps in a north Argentinean city) of Aedes \\ae gypti\n(Linnaeus), based on time series of data extracted from operational earth\nobservation satellite images. We use are NDVI, NDWI, LST night, LST day and\nTRMM-GPM rain from 2012 to 2016 as predictive variables. In contrast to\nprevious works which use linear models, we employ Machine Learning techniques\nusing completely accessible open source toolkits. These models have the\nadvantages of being non-parametric and capable of describing nonlinear\nrelationships between variables. Specifically, in addition to two linear\napproaches, we assess a Support Vector Machine, an Artificial Neural Networks,\na K-nearest neighbors and a Decision Tree Regressor. Considerations are made on\nparameter tuning and the validation and training approach. The results are\ncompared to linear models used in previous works with similar data sets for\ngenerating temporal predictive models. These new tools perform better than\nlinear approaches, in particular Nearest Neighbor Regression (KNNR) performs\nthe best. These results provide better alternatives to be implemented\noperatively on the Argentine geospatial Risk system that is running since 2012.", "journal": "", "doi": null, "primary_category": "stat.ML", "categories": ["stat.ML", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1805.02590v1"}
{"entry_id": "http://arxiv.org/abs/2007.16078v2", "date": "2020-07-31", "title": "LOUPE: Observing Earth from the Moon to prepare for detecting life on Earth-like exoplanets", "authors": "Dora Klind\u017ei\u0107, Daphne M. Stam, Frans Snik, H. Jens Hoeijmakers, Michelle Willebrands, Theodora Karalidi, Vidhya Pallichadath, Chris N. van Dijk, Marco Esposito", "abstract": "LOUPE, the Lunar Observatory for Unresolved Polarimetry of the Earth, is a\nsmall, robust spectro-polarimeter with a mission to observe the Earth as an\nexoplanet. Detecting Earth-like planets in stellar habitable zones is one of\nthe key challenges of modern exoplanetary science. Characterising such planets\nand searching for traces of life requires the direct detection of their\nsignals. LOUPE provides unique spectral flux and polarisation data of sunlight\nreflected by the Earth, the only planet known to harbor life. This data will be\nused to test numerical codes to predict signals of Earth-like exoplanets, to\ntest algorithms that retrieve planet properties, and to fine-tune the design\nand observational strategies of future space observatories. From the Moon,\nLOUPE will continuously see the entire Earth, enabling it to monitor the signal\nchanges due to the planet's daily rotation, weather patterns, and seasons,\nacross all phase angles. Here, we present both the science case and the\ntechnology behind LOUPE's instrumental and mission design.", "journal": "", "doi": "10.1098/rsta.2019.0577", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2007.16078v2"}
{"entry_id": "http://arxiv.org/abs/1905.00492v1", "date": "2019-04-15", "title": "Wildfire Monitoring in Remote Areas using Autonomous Unmanned Aerial Vehicles", "authors": "Fatemeh Afghah, Abolfazl Razi, Jacob Chakareski, Jonathan Ashdown", "abstract": "In this paper, we propose a drone-based wildfire monitoring system for remote\nand hard-to-reach areas. This system utilizes autonomous unmanned aerial\nvehicles (UAVs) with the main advantage of providing on-demand monitoring\nservice faster than the current approaches of using satellite images, manned\naircraft and remotely controlled drones. Furthermore, using autonomous drones\nfacilitates minimizing human intervention in risky wildfire zones. In\nparticular, to develop a fully autonomous system, we propose a distributed\nleader-follower coalition formation model to cluster a set of drones into\nmultiple coalitions that collectively cover the designated monitoring field.\nThe coalition leader is a drone %with longer communication range that employs\nobserver drones potentially with different sensing and imaging %actuation\ncapabilities to hover in circular paths and collect imagery information from\nthe impacted areas. The objectives of the proposed system include i) to cover\nthe entire fire zone with a minimum number of drones, and ii) to minimize the\nenergy consumption and latency of the available drones to fly to the fire zone.\nSimulation results confirm that the performance of the proposed system --\nwithout the need for inter-coalition communications -- approaches that of a\ncentrally-optimized system.", "journal": "", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/1905.00492v1"}
{"entry_id": "http://arxiv.org/abs/2209.10102v1", "date": "2022-09-15", "title": "Multi-time Predictions of Wildfire Grid Map using Remote Sensing Local Data", "authors": "Hyung-Jin Yoon, Petros Voulgaris", "abstract": "Due to recent climate changes, we have seen more frequent and severe\nwildfires in the United States. Predicting wildfires is critical for natural\ndisaster prevention and mitigation. Advances in technologies in data processing\nand communication enabled us to access remote sensing data. With the remote\nsensing data, valuable spatiotemporal statistical models can be created and\nused for resource management practices. This paper proposes a distributed\nlearning framework that shares local data collected in ten locations in the\nwestern USA throughout the local agents. The local agents aim to predict\nwildfire grid maps one, two, three, and four weeks in advance while online\nprocessing the remote sensing data stream. The proposed model has distinct\nfeatures that address the characteristic need in prediction evaluations,\nincluding dynamic online estimation and time-series modeling. Local fire event\ntriggers are not isolated between locations, and there are confounding factors\nwhen local data is analyzed due to incomplete state observations. Compared to\nexisting approaches that do not account for incomplete state observation within\nwildfire time-series data, on average, we can achieve higher prediction\nperformance.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf_url": "http://arxiv.org/pdf/2209.10102v1"}
{"entry_id": "http://arxiv.org/abs/2109.06558v1", "date": "2021-09-14", "title": "Solar Flare Effects on the Earth's Lower Ionosphere", "authors": "Laura A. Hayes, Oscar S. D. O'Hara, Sophie A. Murray, Peter T. Gallagher", "abstract": "Solar flares significantly impact the conditions of the Earth's ionosphere.\nIn particular, the sudden increase in X-ray flux during a flare penetrates down\nto the lowest-lying D-region and dominates ionization at these altitudes\n(60-100 km). Measurements of very low frequency (VLF: 3-30kHz) radio waves that\nreflect at D-region altitudes provide a unique remote-sensing probe to\ninvestigate the D-region response to solar flare emissions. Here, using a\ncombination of VLF amplitude measurements at 24kHz together with X-ray\nobservations from the Geostationary Operational Environment Satellite (GOES)\nX-ray sensor, we present a large-scale statistical study of 334 solar flare\nevents and their impacts on the D-region over the past solar cycle. Focusing on\nboth GOES broadband X-ray channels, we investigate how the flare peak fluxes\nand position on the solar disk dictate an ionospheric response and extend this\nto investigate the characteristic time delay between incident X-ray flux and\nthe D-region response. We show that the VLF amplitude linearly correlates with\nboth the 1-8 A and 0.5-4 A channels, with correlation coefficients of 0.80 and\n0.79, respectively. Unlike higher altitude ionospheric regions for which the\nlocation of the flare on the solar disk affects the ionospheric response, we\nfind that the D-region response to solar flares does not depend on the flare\nlocation. By comparing the time delays between the peak X-ray fluxes in both\nGOES channels and VLF amplitudes, we find that there is an important difference\nbetween the D-region response and the X-ray spectral band. We also demonstrate\nfor several flare events that show a negative time delay, the peak VLF\namplitude matches with the impulsive 25-50 keV hard X-ray fluxes measured by\nthe Ramaty High Energy Solar Spectroscopic Imager (RHESSI).", "journal": "", "doi": "10.1007/s11207-021-01898-y", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2109.06558v1"}
{"entry_id": "http://arxiv.org/abs/1610.02670v1", "date": "2016-10-09", "title": "Transmission Strategies for Remote Estimation with an Energy Harvesting Sensor", "authors": "Ayca Ozcelikkale, Tomas McKelvey, Mats Viberg", "abstract": "We consider the remote estimation of a time-correlated signal using an energy\nharvesting (EH) sensor. The sensor observes the unknown signal and communicates\nits observations to a remote fusion center using an amplify-and-forward\nstrategy. We consider the design of optimal power allocation strategies in\norder to minimize the mean-square error at the fusion center. Contrary to the\ntraditional approaches, the degree of correlation between the signal values\nconstitutes an important aspect of our formulation. We provide the optimal\npower allocation strategies for a number of illustrative scenarios. We show\nthat the most majorized power allocation strategy, i.e. the power allocation as\nbalanced as possible, is optimal for the cases of circularly wide-sense\nstationary (c.w.s.s.) signals with a static correlation coefficient, and\nsampled low-pass c.w.s.s. signals for a static channel. We show that the\noptimal strategy can be characterized as a water-filling type solution for\nsampled low-pass c.w.s.s. signals for a fading channel. Motivated by the\nhigh-complexity of the numerical solution of the optimization problem, we\npropose low-complexity policies for the general scenario. Numerical evaluations\nillustrate the close performance of these low-complexity policies to that of\nthe optimal policies, and demonstrate the effect of the EH constraints and the\ndegree of freedom of the signal.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1610.02670v1"}
{"entry_id": "http://arxiv.org/abs/2106.07571v1", "date": "2021-06-14", "title": "Investigating Remote-sensing Techniques to Reveal Stealth Coronal Mass Ejections", "authors": "Erika Palmerio, Nariaki V. Nitta, Tamitha Mulligan, Marilena Mierla, Jennifer O'Kane, Ian G. Richardson, Suvadip Sinha, Nandita Srivastava, Stephanie L. Yardley, Andrei N. Zhukov", "abstract": "Eruptions of coronal mass ejections (CMEs) from the Sun are usually\nassociated with a number of signatures that can be identified in solar disc\nimagery. However, there are cases in which a CME that is well observed in\ncoronagraph data is missing a clear low-coronal counterpart. These events have\nreceived attention during recent years, mainly as a result of the increased\navailability of multi-point observations, and are now known as 'stealth CMEs'.\nIn this work, we analyse examples of stealth CMEs featuring various levels of\nambiguity. All the selected case studies produced a large-scale CME detected by\ncoronagraphs and were observed from at least one secondary viewpoint, enabling\na priori knowledge of their approximate source region. To each event, we apply\nseveral image processing and geometric techniques with the aim to evaluate\nwhether such methods can provide additional information compared to the study\nof \"normal\" intensity images. We are able to identify at least weak eruptive\nsignatures for all events upon careful investigation of remote-sensing data,\nnoting that differently processed images may be needed to properly interpret\nand analyse elusive observations. We also find that the effectiveness of\ngeometric techniques strongly depends on the CME propagation direction with\nrespect to the observers and the relative spacecraft separation. Being able to\nobserve and therefore forecast stealth CMEs is of great importance in the\ncontext of space weather, since such events are occasionally the solar\ncounterparts of so-called 'problem geomagnetic storms'.", "journal": "", "doi": "10.3389/fspas.2021.695966", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2106.07571v1"}
{"entry_id": "http://arxiv.org/abs/1909.13047v1", "date": "2019-09-28", "title": "Feature Fusion Detector for Semantic Cognition of Remote Sensing", "authors": "Wei Zhou, Yiying Li", "abstract": "The value of remote sensing images is of vital importance in many areas and\nneeds to be refined by some cognitive approaches. The remote sensing detection\nis an appropriate way to achieve the semantic cognition. However, such\ndetection is a challenging issue for scale diversity, diversity of views, small\nobjects, sophisticated light and shadow backgrounds. In this article, inspired\nby the state-of-the-art detection framework FPN, we propose a novel approach\nfor constructing a feature fusion module that optimizes feature context\nutilization in detection, calling our system LFFN for Layer-weakening Feature\nFusion Network. We explore the inherent relevance of different layers to the\nfinal decision, and the incentives of higher-level features to lower-level\nfeatures. More importantly, we explore the characteristics of different\nbackbone networks in the mining of basic features and the correlation\nutilization of convolutional channels, and call our upgraded version as\nadvanced LFFN. Based on experiments on the remote sensing dataset from Google\nEarth, our LFFN has proved effective and practical for the semantic cognition\nof remote sensing, achieving 89% mAP which is 4.1% higher than that of FPN.\nMoreover, in terms of the generalization performance, LFFN achieves 79.9% mAP\non VOC 2007 and achieves 73.0% mAP on VOC 2012 test, and advacned LFFN obtains\nthe mAP values of 80.7% and 74.4% on VOC 2007 and 2012 respectively,\noutperforming the comparable state-of-the-art SSD and Faster R-CNN models.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/1909.13047v1"}
{"entry_id": "http://arxiv.org/abs/1608.05536v1", "date": "2016-08-19", "title": "Measuring coronal magnetic fields with remote sensing observations of shock waves", "authors": "Alessandro Bemporad, Roberto Susino, Federica Frassati, Silvano Fineschi", "abstract": "Recent works demonstrated that remote sensing observations of shock waves\npropagating into the corona and associated with major solar eruptions can be\nused to derive the strength of coronal magnetic fields met by the shock over a\nvery large interval of heliocentric distances and latitudes. This opinion\narticle will summarize most recent results obtained on this topic and will\ndiscuss the weaknesses and strengths of these techniques to open a constructive\ndiscussion with the scientific community.", "journal": "Frontiers in Astronomy and Space Sciences, Volume 3, id.17 (2016)", "doi": "10.3389/fspas.2016.00017", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1608.05536v1"}
{"entry_id": "http://arxiv.org/abs/1712.01600v1", "date": "2017-12-05", "title": "Deep learning for semantic segmentation of remote sensing images with rich spectral content", "authors": "A Hamida, A. Beno\u00eet, P. Lambert, L Klein, C Amar, N. Audebert, S. Lef\u00e8vre", "abstract": "With the rapid development of Remote Sensing acquisition techniques, there is\na need to scale and improve processing tools to cope with the observed increase\nof both data volume and richness. Among popular techniques in remote sensing,\nDeep Learning gains increasing interest but depends on the quality of the\ntraining data. Therefore, this paper presents recent Deep Learning approaches\nfor fine or coarse land cover semantic segmentation estimation. Various 2D\narchitectures are tested and a new 3D model is introduced in order to jointly\nprocess the spatial and spectral dimensions of the data. Such a set of networks\nenables the comparison of the different spectral fusion schemes. Besides, we\nalso assess the use of a \" noisy ground truth \" (i.e. outdated and low spatial\nresolution labels) for training and testing the networks.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1712.01600v1"}
{"entry_id": "http://arxiv.org/abs/1310.3171v1", "date": "2013-10-11", "title": "Meteor Showers on Earth from Sungrazing Comets", "authors": "A. Sekhar, D. J. Asher", "abstract": "Sungrazing comets have always captured a lot of interest and curiosity among\nthe general public as well as scientists since ancient times. The perihelion\npassage of comet C/2012 S1 (ISON) at the end of this year (on 2013 November 28)\nis an eagerly awaited event. In this work, we do a mathematical study to check\nwhether meteoroids ejected from this comet during its journey around the sun\ncan produce spectacular meteor phenomena on Earth. Our calculations show that\nalthough the orbital elements of this comet are much more favourable than for\nmost sungrazers to have its descending node near the Earth's orbit, even\nejection velocities as high as 1 km/s do not induce sufficient nodal dispersion\nto bring meteoroids to Earth intersection during present times. A similar\nresult applies to Newton's comet C/1680 V1 which has surprisingly similar\norbital elements, although it is known to be a distinct comet from C/2012 S1.\nOur analysis also shows that for meteoroids ejected from all known sungrazing\ngroups during recent epochs, only the Marsden family (with required ejection\nvelocities of some hundreds of m/s) can produce meteor phenomena during present\ntimes. In a broader sense, we indicate why we do not observe visually brilliant\nmeteor showers from frequently observed sungrazers.", "journal": "", "doi": "10.1093/mnrasl/slt143", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1310.3171v1"}
{"entry_id": "http://arxiv.org/abs/1904.12255v1", "date": "2019-04-28", "title": "Non-myopic Planetary Exploration Combining In Situ and Remote Measurements", "authors": "Suhit Kodgule, Alberto Candela, David Wettergreen", "abstract": "Remote sensing can provide crucial information for planetary rovers. However,\nthey must validate these orbital observations with in situ measurements.\nTypically, this involves validating hyperspectral data using a spectrometer\non-board the field robot. In order to achieve this, the robot must visit\nsampling locations that jointly improve a model of the environment while\nsatisfying sampling constraints. However, current planners follow sub-optimal\ngreedy strategies that are not scalable to larger regions. We demonstrate how\nthe problem can be effectively defined in an MDP framework and propose a\nplanning algorithm based on Monte Carlo Tree Search, which is devoid of the\ncommon drawbacks of existing planners and also provides superior performance.\nWe evaluate our approach using hyperspectral imagery of a well-studied geologic\nsite in Cuprite, Nevada.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1904.12255v1"}
{"entry_id": "http://arxiv.org/abs/1705.06057v1", "date": "2017-05-17", "title": "Joint Learning from Earth Observation and OpenStreetMap Data to Get Faster Better Semantic Maps", "authors": "Nicolas Audebert, Bertrand Le Saux, S\u00e9bastien Lef\u00e8vre", "abstract": "In this work, we investigate the use of OpenStreetMap data for semantic\nlabeling of Earth Observation images. Deep neural networks have been used in\nthe past for remote sensing data classification from various sensors, including\nmultispectral, hyperspectral, SAR and LiDAR data. While OpenStreetMap has\nalready been used as ground truth data for training such networks, this\nabundant data source remains rarely exploited as an input information layer. In\nthis paper, we study different use cases and deep network architectures to\nleverage OpenStreetMap data for semantic labeling of aerial and satellite\nimages. Especially , we look into fusion based architectures and coarse-to-fine\nsegmentation to include the OpenStreetMap layer into multispectral-based deep\nfully convolutional networks. We illustrate how these methods can be\nsuccessfully used on two public datasets: ISPRS Potsdam and DFC2017. We show\nthat OpenStreetMap data can efficiently be integrated into the vision-based\ndeep learning models and that it significantly improves both the accuracy\nperformance and the convergence speed of the networks.", "journal": "EARTHVISION 2017 IEEE/ISPRS CVPR Workshop. Large Scale Computer\n  Vision for Remote Sensing Imagery, Jul 2017, Honolulu, United States. 2017", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.NE"], "pdf_url": "http://arxiv.org/pdf/1705.06057v1"}
{"entry_id": "http://arxiv.org/abs/1602.06611v1", "date": "2016-02-22", "title": "Remote Nanodiamond Magnetometry", "authors": "Yinlan Ruan, David A. Simpson, Jan Jeske, Heike Ebendorff-Heidepriem, Desmond W. M. Lau, Hong Ji, Brett C. Johnson, Takeshi Ohshima, Shahraam Afshar V., Lloyd Hollenberg, Andrew D. Greentree, Tanya M. Monro, Brant C. Gibson", "abstract": "Optical fibres have transformed the way people interact with the world and\nnow permeate many areas of science. Optical fibres are traditionally thought of\nas insensitive to magnetic fields, however many application areas from mining\nto biomedicine would benefit from fibre-based remote magnetometry devices. In\nthis work, we realise such a device by embedding nanoscale magnetic sensors\ninto tellurite glass fibres. Remote magnetometry is performed on magnetically\nactive defect centres in nanodiamonds embedded into the glass matrix. Standard\noptical magnetometry techniques are applied to initialize and detect local\nmagnetic field changes with a measured sensitivity of 26 micron Tesla/square\nroot(Hz). Our approach utilizes straight-forward optical excitation, simple\nfocusing elements, and low power components. We demonstrate remote magnetometry\nby direct reporting of the magnetic ground states of nitrogen-vacancy defect\ncentres in the optical fibres. In addition, we present and describe\ntheoretically an all-optical technique that is ideally suited to remote\nfibre-based sensing. The implications of our results broaden the applications\nof optical fibres, which now have the potential to underpin a new generation of\nmedical magneto-endoscopes and remote mining sensors.", "journal": "", "doi": null, "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/1602.06611v1"}
{"entry_id": "http://arxiv.org/abs/2301.04137v1", "date": "2023-01-09", "title": "A Global Radio Remote Sensing Network for Observing Space Weather Dynamics", "authors": "Ryan Volz, Philip J. Erickson, Scott E. Palo, Jorge L. Chau, Juha Vierinen, Thomas Y. Chen", "abstract": "Our current sampling of the near-Earth space environment is wholly\ninsufficient to measure the highly variable processes therein and make\npredictions on par with lower atmospheric weather. We sketch out the scientific\nrationale for a network of radio instruments delivering dense observations of\nthe near-Earth space environment and the broad steps necessary to implement\nwide-scale coverage in the next 30 years.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2301.04137v1"}
{"entry_id": "http://arxiv.org/abs/1701.02470v4", "date": "2017-01-10", "title": "Methods for Mapping Forest Disturbance and Degradation from Optical Earth Observation Data: a Review", "authors": "Manuela Hirschmugl, Heinz Gallaun, Matthias Dees, Pawan Datta, Janik Deutscher, Nikos Koutsias, Mathias Schardt", "abstract": "Purpose of review: This paper presents a review of the current state of the\nart in remote sensing based monitoring of forest disturbances and forest\ndegradation from optical Earth Observation data. Part one comprises an overview\nof currently available optical remote sensing sensors, which can be used for\nforest disturbance and degradation mapping. Part two reviews the two main\ncategories of existing approaches: classical image-to-image change detection\nand time series analysis. Recent findings: With the launch of the Sentinel-2a\nsatellite and available Landsat imagery, time series analysis has become the\nmost promising but also most demanding category of degradation mapping\napproaches. Four time series classification methods are distinguished. The\nmethods are explained and their benefits and drawbacks are discussed. A\nseparate chapter presents a number of recent forest degradation mapping studies\nfor two different ecosystems: temperate forests with a geographical focus on\nEurope and tropical forests with a geographical focus on Africa. Summary: The\nreview revealed that a wide variety of methods for the detection of forest\ndegradation is already available. Today, the main challenge is to transfer\nthese approaches to high resolution time series data from multiple sensors.\nFuture research should also focus on the classification of disturbance types\nand the development of robust up-scalable methods to enable near real time\ndisturbance mapping in support of operational reactive measures.", "journal": "Current Forestry Reports 2017", "doi": "10.1007/s40725-017-0047-2", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1701.02470v4"}
{"entry_id": "http://arxiv.org/abs/1108.5360v1", "date": "2011-08-26", "title": "Brief comment: Dicke Superradiance and Superfluorescence Find Application for Remote Sensing in Air", "authors": "D. C. Dai", "abstract": "This letter briefly introduces the concepts of Dicke superradiance (SR) and\nsuperfluorescence (SF), their difference to amplified spontaneous emission\n(ASE), and the hints for identifying them in experiment. As a typical example\nit analyzes the latest observations by Dogariu et al. (Science 331, 442, 2011),\nand clarifies that it is SR. It also highlights the revealed potential\nsignificant application of SR and SF for remote sensing in air.", "journal": "", "doi": null, "primary_category": "physics.optics", "categories": ["physics.optics", "physics.ao-ph", "physics.plasm-ph"], "pdf_url": "http://arxiv.org/pdf/1108.5360v1"}
{"entry_id": "http://arxiv.org/abs/1708.03417v1", "date": "2017-08-11", "title": "GlobeNet: Convolutional Neural Networks for Typhoon Eye Tracking from Remote Sensing Imagery", "authors": "Seungkyun Hong, Seongchan Kim, Minsu Joh, Sa-kwang Song", "abstract": "Advances in remote sensing technologies have made it possible to use\nhigh-resolution visual data for weather observation and forecasting tasks. We\npropose the use of multi-layer neural networks for understanding complex\natmospheric dynamics based on multichannel satellite images. The capability of\nour model was evaluated by using a linear regression task for single typhoon\ncoordinates prediction. A specific combination of models and different\nactivation policies enabled us to obtain an interesting prediction result in\nthe northeastern hemisphere (ENH).", "journal": "", "doi": null, "primary_category": "cs.NE", "categories": ["cs.NE", "cs.AI", "cs.CV", "I.2.6"], "pdf_url": "http://arxiv.org/pdf/1708.03417v1"}
{"entry_id": "http://arxiv.org/abs/0809.4645v1", "date": "2008-09-26", "title": "Radio Remote Sensing of the Corona and the Solar Wind", "authors": "Steven R. Spangler, Catherine A. Whiting", "abstract": "Modern radio telescopes are extremely sensitive to plasma on the line of\nsight from a radio source to the antenna. Plasmas in the corona and solar wind\nproduce measurable changes in the radio wave amplitude and phase, and the phase\ndifference between wave fields of opposite circular polarization. Such\nmeasurements can be made of radio waves from spacecraft transmitters and\nextragalactic radio sources, using radio telescopes and spacecraft tracking\nantennas. Data have been taken at frequencies from about 80 MHz to 8000 MHz.\nLower frequencies probe plasma at greater heliocentric distances. Analysis of\nthese data yields information on the plasma density, density fluctuations, and\nplasma flow speeds in the corona and solar wind, and on the magnetic field in\nthe solar corona. This paper will concentrate on the information that can be\nobtained from measurements of Faraday rotation through the corona and inner\nsolar wind. The magnitude of Faraday rotation is proportional to the line of\nsight integral of the plasma density and the line-of-sight component of the\nmagnetic field. Faraday rotation provides an almost unique means of estimating\nthe magnetic field in this part of space. This technique has contributed to\nmeasurement of the large scale coronal magnetic field, the properties of\nelectromagnetic turbulence in the corona, possible detection of electrical\ncurrents in the corona, and probing of the internal structure of coronal mass\nejections (CMEs). This paper concentrates on the search for small-scale coronal\nturbulence and remote sensing of the structure of CMEs. Future investigations\nwith the Expanded Very Large Array (EVLA) or Murchison Widefield Array (MWA)\ncould provide unique observational input on the astrophysics of CMEs.", "journal": "", "doi": "10.1017/S1743921309029834", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0809.4645v1"}
{"entry_id": "http://arxiv.org/abs/2210.10767v2", "date": "2022-10-19", "title": "CLOINet: Ocean state reconstructions through remote-sensing, in-situ sparse observations and Deep Learning", "authors": "Eugenio Cutolo, Ananda Pascual, Simon Ruiz, Nikolaos Zarokanellos, Ronan Fablet", "abstract": "Combining remote-sensing data with in-situ observations to obtain a full 3D\nreconstruction of the ocean state is challenging for classical interpolation\ntechniques. Therefore, we developed a CLuster Optimal Interpolation Neural\nNetwork (CLOINet), which leverages the well-consolidated mathematical basis of\nthe Optimal Interpolation (OI) scheme with a \"Self-Attention Mechanism\": the\nstate-of-the-art neural network technology. Our network segments the remote\nsensing images into clusters revealing non-local correlations and enhancing\nocean fine-scale reconstruction. We trained our neural network with the outputs\nof an Ocean General Circulation Model (OGCM), which also provided various test\nscenarios. In this sense, we realized Observing System Simulation Experiments\nwhere we aimed to reconstruct the deep salinity fields given the sea surface\ntemperature (SST) or the Sea Surface Height (SSH) together with sparse in-situ\nsalinity observations. As a result, we decreased the reconstruction error of\nthe $25\\%$ and resolved $50\\%$ smaller scales compared to the baseline OI.\nFurthermore, even if we trained our neural network purely with simulated data,\nwe improved by a $35\\%$ the reconstruction of a real SST field, relying on\nglider temperature observations and satellite chlorophyll concentration. We\nthus evidenced how deep-learning networks like CLOINet could be the leading\ntechnology to join the efforts of the modeling and observations community\ntoward developing an ocean digital-twin.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2210.10767v2"}
{"entry_id": "http://arxiv.org/abs/1205.2526v1", "date": "2012-05-11", "title": "Heliospheric Observations of STEREO-Directed Coronal Mass Ejections in 2008--2010: Lessons for Future Observations of Earth-Directed CMEs", "authors": "N. Lugaz, P. Kintner, C. Moestl, L. K. Jian, C. J. Davis, C. J. Farrugia", "abstract": "We present a study of coronal mass ejections (CMEs) which impacted one of the\nSTEREO spacecraft between January 2008 and early 2010. We focus our study on 20\nCMEs which were observed remotely by the Heliospheric Imagers (HIs) onboard the\nother STEREO spacecraft up to large heliocentric distances. We compare the\npredictions of the Fixed-Phi and Harmonic Mean (HM) fitting methods, which only\ndiffer by the assumed geometry of the CME. It is possible to use these\ntechniques to determine from remote-sensing observations the CME direction of\npropagation, arrival time and final speed which are compared to in situ\nmeasurements. We find evidence that for large viewing angles, the HM fitting\nmethod predicts the CME direction better. However, this may be due to the fact\nthat only wide CMEs can be successfully observed when the CME propagates more\nthan 100 deg from the observing spacecraft. Overall eight CMEs, originating\nfrom behind the limb as seen by one of the STEREO spacecraft can be tracked and\ntheir arrival time at the other STEREO spacecraft can be successfully\npredicted. This includes CMEs, such as the events on 4 December 2009 and 9\nApril 2010, which were viewed 130 deg away from their direction of propagation.\nTherefore, we predict that some Earth-directed CMEs will be observed by the HIs\nuntil early 2013, when the separation between Earth and one of the STEREO\nspacecraft will be similar to the separation of the two STEREO spacecraft in\n2009--2010.", "journal": "Solar Physics, 279, 497-515, 2012", "doi": "10.1007/10.1007/s11207-012-0007-8", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1205.2526v1"}
{"entry_id": "http://arxiv.org/abs/1911.06721v1", "date": "2019-11-15", "title": "In-domain representation learning for remote sensing", "authors": "Maxim Neumann, Andre Susano Pinto, Xiaohua Zhai, Neil Houlsby", "abstract": "Given the importance of remote sensing, surprisingly little attention has\nbeen paid to it by the representation learning community. To address it and to\nestablish baselines and a common evaluation protocol in this domain, we provide\nsimplified access to 5 diverse remote sensing datasets in a standardized form.\nSpecifically, we investigate in-domain representation learning to develop\ngeneric remote sensing representations and explore which characteristics are\nimportant for a dataset to be a good source for remote sensing representation\nlearning. The established baselines achieve state-of-the-art performance on\nthese datasets.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1911.06721v1"}
{"entry_id": "http://arxiv.org/abs/2012.12105v1", "date": "2020-12-09", "title": "Warped Gaussian Processes in Remote Sensing Parameter Estimation and Causal Inference", "authors": "Anna Mateo-Sanchis, Jordi Mu\u00f1oz-Mar\u00ed, Adri\u00e1n P\u00e9rez-Suay, Gustau Camps-Valls", "abstract": "This paper introduces warped Gaussian processes (WGP) regression in remote\nsensing applications. WGP models output observations as a parametric nonlinear\ntransformation of a GP. The parameters of such prior model are then learned via\nstandard maximum likelihood. We show the good performance of the proposed model\nfor the estimation of oceanic chlorophyll content from multispectral data,\nvegetation parameters (chlorophyll, leaf area index, and fractional vegetation\ncover) from hyperspectral data, and in the detection of the causal direction in\na collection of 28 bivariate geoscience and remote sensing causal problems. The\nmodel consistently performs better than the standard GP and the more advanced\nheteroscedastic GP model, both in terms of accuracy and more sensible\nconfidence intervals.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2012.12105v1"}
{"entry_id": "http://arxiv.org/abs/1204.6513v1", "date": "2012-04-29", "title": "Sensing remote nuclear spins", "authors": "Nan Zhao, Jan Honert, Berhard Schmid, Junichi Isoya, Mathew Markham, Daniel Twitchen, Fedor Jelezko, Ren-Bao Liu, Helmut Fedder, J\u00f6rg Wrachtrup", "abstract": "Sensing single nuclear spins is a central challenge in magnetic resonance\nbased imaging techniques. Although different methods and especially diamond\ndefect based sensing and imaging techniques in principle have shown sufficient\nsensitivity, signals from single nuclear spins are usually too weak to be\ndistinguished from background noise. Here, we present the detection and\nidentification of remote single C-13 nuclear spins embedded in nuclear spin\nbaths surrounding a single electron spins of a nitrogen-vacancy centre in\ndiamond. With dynamical decoupling control of the centre electron spin, the\nweak magnetic field ~10 nT from a single nuclear spin located ~3 nm from the\ncentre with hyperfine coupling as weak as ~500 Hz is amplified and detected.\nThe quantum nature of the coupling is confirmed and precise position and the\nvector components of the nuclear field are determined. Given the distance over\nwhich nuclear magnetic fields can be detected the technique marks a firm step\ntowards imaging, detecting and controlling nuclear spin species external to the\ndiamond sensor.", "journal": "", "doi": "10.1038/nnano.2012.152", "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall", "quant-ph"], "pdf_url": "http://arxiv.org/pdf/1204.6513v1"}
{"entry_id": "http://arxiv.org/abs/2010.01999v1", "date": "2020-10-05", "title": "A Novel Actor Dual-Critic Model for Remote Sensing Image Captioning", "authors": "Ruchika Chavhan, Biplab Banerjee, Xiao Xiang Zhu, Subhasis Chaudhuri", "abstract": "We deal with the problem of generating textual captions from optical remote\nsensing (RS) images using the notion of deep reinforcement learning. Due to the\nhigh inter-class similarity in reference sentences describing remote sensing\ndata, jointly encoding the sentences and images encourages prediction of\ncaptions that are semantically more precise than the ground truth in many\ncases. To this end, we introduce an Actor Dual-Critic training strategy where a\nsecond critic model is deployed in the form of an encoder-decoder RNN to encode\nthe latent information corresponding to the original and generated captions.\nWhile all actor-critic methods use an actor to predict sentences for an image\nand a critic to provide rewards, our proposed encoder-decoder RNN guarantees\nhigh-level comprehension of images by sentence-to-image translation. We observe\nthat the proposed model generates sentences on the test data highly similar to\nthe ground truth and is successful in generating even better captions in many\ncritical cases. Extensive experiments on the benchmark Remote Sensing Image\nCaptioning Dataset (RSICD) and the UCM-captions dataset confirm the superiority\nof the proposed approach in comparison to the previous state-of-the-art where\nwe obtain a gain of sharp increments in both the ROUGE-L and CIDEr measures.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2010.01999v1"}
{"entry_id": "http://arxiv.org/abs/2010.06476v2", "date": "2020-10-13", "title": "Gaussianizing the Earth: Multidimensional Information Measures for Earth Data Analysis", "authors": "J. Emmanuel Johnson, Valero Laparra, Maria Piles, Gustau Camps-Valls", "abstract": "Information theory is an excellent framework for analyzing Earth system data\nbecause it allows us to characterize uncertainty and redundancy, and is\nuniversally interpretable. However, accurately estimating information content\nis challenging because spatio-temporal data is high-dimensional, heterogeneous\nand has non-linear characteristics. In this paper, we apply multivariate\nGaussianization for probability density estimation which is robust to\ndimensionality, comes with statistical guarantees, and is easy to apply. In\naddition, this methodology allows us to estimate information-theoretic measures\nto characterize multivariate densities: information, entropy, total\ncorrelation, and mutual information. We demonstrate how information theory\nmeasures can be applied in various Earth system data analysis problems. First\nwe show how the method can be used to jointly Gaussianize radar backscattering\nintensities, synthesize hyperspectral data, and quantify of information content\nin aerial optical images. We also quantify the information content of several\nvariables describing the soil-vegetation status in agro-ecosystems, and\ninvestigate the temporal scales that maximize their shared information under\nextreme events such as droughts. Finally, we measure the relative information\ncontent of space and time dimensions in remote sensing products and model\nsimulations involving long records of key variables such as precipitation,\nsensible heat and evaporation. Results confirm the validity of the method, for\nwhich we anticipate a wide use and adoption. Code and demos of the implemented\nalgorithms and information-theory measures are provided.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2010.06476v2"}
{"entry_id": "http://arxiv.org/abs/2201.09613v1", "date": "2022-01-24", "title": "SEN12MS-CR-TS: A Remote Sensing Data Set for Multi-modal Multi-temporal Cloud Removal", "authors": "Patrick Ebel, Yajin Xu, Michael Schmitt, Xiaoxiang Zhu", "abstract": "About half of all optical observations collected via spaceborne satellites\nare affected by haze or clouds. Consequently, cloud coverage affects the remote\nsensing practitioner's capabilities of a continuous and seamless monitoring of\nour planet. This work addresses the challenge of optical satellite image\nreconstruction and cloud removal by proposing a novel multi-modal and\nmulti-temporal data set called SEN12MS-CR-TS. We propose two models\nhighlighting the benefits and use cases of SEN12MS-CR-TS: First, a multi-modal\nmulti-temporal 3D-Convolution Neural Network that predicts a cloud-free image\nfrom a sequence of cloudy optical and radar images. Second, a\nsequence-to-sequence translation model that predicts a cloud-free time series\nfrom a cloud-covered time series. Both approaches are evaluated experimentally,\nwith their respective models trained and tested on SEN12MS-CR-TS. The conducted\nexperiments highlight the contribution of our data set to the remote sensing\ncommunity as well as the benefits of multi-modal and multi-temporal information\nto reconstruct noisy information. Our data set is available at\nhttps://patrickTUM.github.io/cloud_removal", "journal": "IEEE Transactions on Geoscience and Remote Sensing, 2022", "doi": "10.1109/TGRS.2022.3146246", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2201.09613v1"}
{"entry_id": "http://arxiv.org/abs/1506.00768v2", "date": "2015-06-02", "title": "Soft Computing Techniques for Change Detection in remotely sensed images : A Review", "authors": "Madhu Khurana, Vikas Saxena", "abstract": "With the advent of remote sensing satellites, a huge repository of remotely\nsensed images is available. Change detection in remotely sensed images has been\nan active research area as it helps us understand the transitions that are\ntaking place on the Earths surface. This paper discusses the methods and their\nclassifications proposed by various researchers for change detection. Since use\nof soft computing based techniques are now very popular among research\ncommunity, this paper also presents a classification based on learning\ntechniques used in soft-computing methods for change detection.", "journal": "International Journal of Computer Science Issues, Volume 12, Issue\n  2, March 2015, pp 245-253", "doi": null, "primary_category": "cs.NE", "categories": ["cs.NE", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/1506.00768v2"}
{"entry_id": "http://arxiv.org/abs/2104.08134v1", "date": "2021-04-16", "title": "Integrating Domain Knowledge in Data-driven Earth Observation with Process Convolutions", "authors": "Daniel Heestermans Svendsen, Maria Piles, Jordi Mu\u00f1oz-Mar\u00ed, David Luengo, Luca Martino, Gustau Camps-Valls", "abstract": "The modelling of Earth observation data is a challenging problem, typically\napproached by either purely mechanistic or purely data-driven methods.\nMechanistic models encode the domain knowledge and physical rules governing the\nsystem. Such models, however, need the correct specification of all\ninteractions between variables in the problem and the appropriate\nparameterization is a challenge in itself. On the other hand, machine learning\napproaches are flexible data-driven tools, able to approximate arbitrarily\ncomplex functions, but lack interpretability and struggle when data is scarce\nor in extrapolation regimes. In this paper, we argue that hybrid learning\nschemes that combine both approaches can address all these issues efficiently.\nWe introduce Gaussian process (GP) convolution models for hybrid modelling in\nEarth observation (EO) problems. We specifically propose the use of a class of\nGP convolution models called latent force models (LFMs) for EO time series\nmodelling, analysis and understanding. LFMs are hybrid models that incorporate\nphysical knowledge encoded in differential equations into a multioutput GP\nmodel. LFMs can transfer information across time-series, cope with missing\nobservations, infer explicit latent functions forcing the system, and learn\nparameterizations which are very helpful for system analysis and\ninterpretability. We consider time series of soil moisture from active (ASCAT)\nand passive (SMOS, AMSR2) microwave satellites. We show how assuming a first\norder differential equation as governing equation, the model automatically\nestimates the e-folding time or decay rate related to soil moisture persistence\nand discovers latent forces related to precipitation. The proposed hybrid\nmethodology reconciles the two main approaches in remote sensing parameter\nestimation by blending statistical learning and mechanistic modeling.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp.\n  1-15, 2022, Art no. 4401715", "doi": "10.1109/TGRS.2021.3059550", "primary_category": "stat.ML", "categories": ["stat.ML", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2104.08134v1"}
{"entry_id": "http://arxiv.org/abs/1010.5125v3", "date": "2010-10-25", "title": "How to defuse Earth impact threat announcements", "authors": "Germano D'Abramo", "abstract": "Summary: In the past decade both scientists and laymen have probably heard at\nleast once through the newspapers, TV and Internet that a new asteroid has been\ndiscovered with non-zero (sometimes \"high\") probability of collision with the\nEarth in the near future. Since early 2000's, such probabilities are routinely\ncalculated by two impact monitoring systems (one in the US, the other in\nEurope) on preliminary orbits of newly discovered Near Earth Asteroids (NEAs),\nand are regularly updated whenever additional new astrometric observations for\neach threatening object become available. A typical pattern is that as the\norbit becomes more precisely determined, impact probability often increases\ninitially, but then turns around and decreases until it falls to zero, or some\nvery low number.\n  In the present study we define a probability measure which provides a simple\ntool to evaluate from the very beginning the chance that the impact probability\ncalculated by monitoring systems for a threatening object will reach unity at\nthe end of the overall process of orbit refinement. We stress that this chance\nis independent of the specific (fluctuating) value of the probability\ncalculated by the monitoring systems. In a precise sense, which should be clear\nthroughout the paper, the concrete impact probability of a newly discovered\nasteroid is not that given by the monitoring systems.", "journal": "Chance, Volume 26, Issue 2, 2013", "doi": "10.1080/09332480.2013.794610", "primary_category": "physics.space-ph", "categories": ["physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1010.5125v3"}
{"entry_id": "http://arxiv.org/abs/2102.05948v1", "date": "2021-02-11", "title": "Properties of stream interaction regions at Earth and Mars during the declining phase of SC 24", "authors": "Paul Geyer, Manuela Temmer, Jingnan Guo, Stephan G. Heinemann", "abstract": "We inspect the evolution of SIRs from Earth to Mars (distance range 1-1.5 AU)\nover the declining phase of solar cycle 24 (2014-2018). So far, studies only\nanalyzed SIRs measured at Earth and Mars at different times. We compare\nexisting catalogs for both heliospheric distances and arrive at a clean dataset\nfor the identical time range. This allows a well-sampled statistical analysis\nand for the opposition phases of the planets an in-depth analysis of SIRs as\nthey evolve with distance. We use in-situ solar wind data from OMNI and the\nMAVEN spacecraft as well as remote sensing data from SDO. A superposed epoch\nanalysis is performed for bulk speed, proton density, temperature, magnetic\nfield magnitude and total perpendicular pressure. Additionally, a study of\nevents during the two opposition phases of Earth and Mars in the years 2016 and\n2018 is conducted. SIR related coronal holes with their area as well as their\nlatitudinal and longitudinal extent are extracted and correlated to the maximum\nbulk speed and duration of the corresponding high speed solar wind streams\nfollowing the stream interaction regions. We find that while the entire solar\nwind HSS shows no expansion as it evolves from Earth to Mars, the crest of the\nHSS profile broadens by about 17%, and the magnetic field and total pressure by\nabout 45% around the stream interface. The difference between the maximum and\nminimum values in the normalized superposed profiles increases slightly or\nstagnates from 1-1.5 AU for all parameters, except for the temperature. A sharp\ndrop at zero epoch time is observed in the superposed profiles for the magnetic\nfield strength at both heliospheric distances. Maximum solar wind speed has a\nstronger dependence on the latitudinal extent of the respective coronal hole\nthan on its longitudinal extent. We arrive at an occurrence rate of fast\nforward shocks three times as high at Mars than at Earth.", "journal": "A&A 649, A80 (2021)", "doi": "10.1051/0004-6361/202040162", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2102.05948v1"}
{"entry_id": "http://arxiv.org/abs/1406.3275v1", "date": "2014-06-12", "title": "Characterization and remote sensing of biological particles using circular polarization", "authors": "Lev Nagdimunov, Ludmilla Kolokolova, Daniel Mackowski", "abstract": "Biological molecules are characterized by an intrinsic asymmetry known as\nhomochirality. The result is optical activity of biological materials and\ncircular polarization in the light scattered by microorganisms, cells of living\norganisms, as well as molecules (e.g. amino acids) of biological origin. Lab\nmeasurements (Sparks et al. 2009a, b) have found that light scattered by\ncertain biological systems, in particular photosynthetic organisms, is not only\ncircular polarized but contains a characteristic spectral trend, showing a fast\nchange and reversal of sign for circular polarization within absorption bands.\nSimilar behavior can be expected for other biological and prebiological\norganics, especially amino acids. We begin our study by reproducing the\nlaboratory measurements for photosynthetic organisms through modeling the\nbiological material as aggregated structures and using the Multiple Sphere\nT-matrix (MSTM) code for light scattering calculations. We further study how\nthe spectral effect described above depends on the porosity of the aggregates\nand the size and number of the constituent particles (monomers). We show that\nlarger aggregates are characterized by larger values of circular polarization\nand discuss how light-scattering characteristics of individual monomers and\nelectromagnetic interaction between them affect this result. We find that\ncircular polarization typically peaks at medium (40-140{\\deg}) scattering\nangles, and discuss recommendations for efficient remote observation of\ncircular polarization from (pre)biological systems.", "journal": "J. Quant. Spectrosc. Radiat. Transfer, 2013, Volume 131, pp. 59-65", "doi": "10.1016/j.jqsrt.2013.04.018", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/1406.3275v1"}
{"entry_id": "http://arxiv.org/abs/1307.2440v1", "date": "2013-07-09", "title": "Image Fusion Technologies In Commercial Remote Sensing Packages", "authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar", "abstract": "Several remote sensing software packages are used to the explicit purpose of\nanalyzing and visualizing remotely sensed data, with the developing of remote\nsensing sensor technologies from last ten years. Accord-ing to literature, the\nremote sensing is still the lack of software tools for effective information\nextraction from remote sensing data. So, this paper provides a state-of-art of\nmulti-sensor image fusion technologies as well as review on the quality\nevaluation of the single image or fused images in the commercial remote sensing\npack-ages. It also introduces program (ALwassaiProcess) developed for image\nfusion and classification.", "journal": "Journal of Global Research in Computer Science, 4 (5), May 2013,\n  44-50", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1307.2440v1"}
{"entry_id": "http://arxiv.org/abs/2209.01206v1", "date": "2022-09-02", "title": "Transformers in Remote Sensing: A Survey", "authors": "Abdulaziz Amer Aleissaee, Amandeep Kumar, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal, Gui-Song Xia, Fahad Shahbaz khan", "abstract": "Deep learning-based algorithms have seen a massive popularity in different\nareas of remote sensing image analysis over the past decade. Recently,\ntransformers-based architectures, originally introduced in natural language\nprocessing, have pervaded computer vision field where the self-attention\nmechanism has been utilized as a replacement to the popular convolution\noperator for capturing long-range dependencies. Inspired by recent advances in\ncomputer vision, remote sensing community has also witnessed an increased\nexploration of vision transformers for a diverse set of tasks. Although a\nnumber of surveys have focused on transformers in computer vision in general,\nto the best of our knowledge we are the first to present a systematic review of\nrecent advances based on transformers in remote sensing. Our survey covers more\nthan 60 recent transformers-based methods for different remote sensing problems\nin sub-areas of remote sensing: very high-resolution (VHR), hyperspectral (HSI)\nand synthetic aperture radar (SAR) imagery. We conclude the survey by\ndiscussing different challenges and open issues of transformers in remote\nsensing. Additionally, we intend to frequently update and maintain the latest\ntransformers in remote sensing papers with their respective code at:\nhttps://github.com/VIROBO-15/Transformer-in-Remote-Sensing", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2209.01206v1"}
{"entry_id": "http://arxiv.org/abs/1712.07835v1", "date": "2017-12-21", "title": "Exploring Models and Data for Remote Sensing Image Caption Generation", "authors": "Xiaoqiang Lu, Binqiang Wang, Xiangtao Zheng, Xuelong Li", "abstract": "Inspired by recent development of artificial satellite, remote sensing images\nhave attracted extensive attention. Recently, noticeable progress has been made\nin scene classification and target detection.However, it is still not clear how\nto describe the remote sensing image content with accurate and concise\nsentences. In this paper, we investigate to describe the remote sensing images\nwith accurate and flexible sentences. First, some annotated instructions are\npresented to better describe the remote sensing images considering the special\ncharacteristics of remote sensing images. Second, in order to exhaustively\nexploit the contents of remote sensing images, a large-scale aerial image data\nset is constructed for remote sensing image caption. Finally, a comprehensive\nreview is presented on the proposed data set to fully advance the task of\nremote sensing caption. Extensive experiments on the proposed data set\ndemonstrate that the content of the remote sensing image can be completely\ndescribed by generating language descriptions. The data set is available at\nhttps://github.com/201528014227051/RSICD_optimal", "journal": "", "doi": "10.1109/TGRS.2017.2776321", "primary_category": "cs.CV", "categories": ["cs.CV", "68"], "pdf_url": "http://arxiv.org/pdf/1712.07835v1"}
{"entry_id": "http://arxiv.org/abs/2207.07189v2", "date": "2022-07-14", "title": "Current Trends in Deep Learning for Earth Observation: An Open-source Benchmark Arena for Image Classification", "authors": "Ivica Dimitrovski, Ivan Kitanovski, Dragi Kocev, Nikola Simidjievski", "abstract": "We present AiTLAS: Benchmark Arena -- an open-source benchmark suite for\nevaluating state-of-the-art deep learning approaches for image classification\nin Earth Observation (EO). To this end, we present a comprehensive comparative\nanalysis of more than 500 models derived from ten different state-of-the-art\narchitectures and compare them to a variety of multi-class and multi-label\nclassification tasks from 22 datasets with different sizes and properties. In\naddition to models trained entirely on these datasets, we benchmark models\ntrained in the context of transfer learning, leveraging pre-trained model\nvariants, as it is typically performed in practice. All presented approaches\nare general and can be easily extended to many other remote sensing image\nclassification tasks not considered in this study. To ensure reproducibility\nand facilitate better usability and further developments, all of the\nexperimental resources including the trained models, model configurations, and\nprocessing details of the datasets (with their corresponding splits used for\ntraining and evaluating the models) are publicly available on the repository:\nhttps://github.com/biasvariancelabs/aitlas-arena", "journal": "", "doi": "10.1016/j.isprsjprs.2023.01.014", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2207.07189v2"}
{"entry_id": "http://arxiv.org/abs/2301.03824v1", "date": "2023-01-10", "title": "Photosynthetic Fluorescence from Earth-Like Planets around Sun-Like and Cool Stars", "authors": "Yu Komatsu, Yasunori Hori, Masayuki Kuzuhara, Makiko Kosugi, Kenji Takizawa, Norio Narita, Masashi Omiya, Eunchul Kim, Nobuhiko Kusakabe, Victoria Meadows, Motohide Tamura", "abstract": "Remote sensing of the Earth has demonstrated that photosynthesis is traceable\nas the vegetation red edge (VRE), which is the steep rise in the reflection\nspectrum of vegetation, and as solar-induced fluorescence. This study examined\nthe detectability of biological fluorescence from two types of photosynthetic\npigments, chlorophylls (Chls) and bacteriochlorophylls (BChls), on Earth-like\nplanets with oxygen-rich/poor and anoxic atmospheres around the Sun and M\ndwarfs. Atmospheric absorption, such as H2O, CH4, O2, and O3, and the VRE\nobscure the fluorescence emissions from Chls and BChls. We found that\nBChl-based fluorescence for wavelengths of 1000-1100 nm, assuming the spectrum\nof BChl b-bearing purple bacteria, could provide a suitable biosignature but\nonly in the absence of the water cloud coverage or other strong absorbers near\n1000 nm. The Chl fluorescence is weaker for several reasons, e.g., spectral\nblending with the VRE. The apparent reflectance excess is greatly increased in\nboth Chl and BChl cases around TRAPPIST-1 due to fluorescence and stellar\nabsorption lines. This could be a promising feature for detecting the\nfluorescence around ultracool red dwarfs by follow-up ground-based observations\nwith high spectral resolution; however, it requires a long time around Sun-like\nstars, even for a LUVOIR-like space mission. Moreover, the simultaneous\ndetection of fluorescence and VRE is key to identifying traces of\nphotosynthesis because absorption, reflectance, and fluorescence are physically\nconnected. For further validation of fluorescence detection, the nonlinear\nresponse of biological fluorescence as a function of light intensity could be\nconsidered.", "journal": "", "doi": "10.3847/1538-4357/aca3a5", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2301.03824v1"}
{"entry_id": "http://arxiv.org/abs/1912.05446v1", "date": "2019-12-11", "title": "Evolution of a Long-Duration Coronal Mass Ejection and its Sheath Region Between Mercury and Earth on 2013 July 9-14", "authors": "N. Lugaz, R. M. Winslow, C. J. Farrugia", "abstract": "Using in situ measurements and remote-sensing observations, we study a\ncoronal mass ejection (CME) that left the Sun on 9 July 2013 and impacted both\nMercury and Earth while the planets were in radial alignment (within\n$3^\\circ$). The CME had an initial speed as measured by coronagraphs of 580\n$\\pm$ 20 km s$^{-1}$, an inferred speed at Mercury of 580 $\\pm$ 30 km s$^{-1}$\nand a measured maximum speed at Earth of 530 km s$^{-1}$, indicating that it\ndid not decelerate substantially in the inner heliosphere. The magnetic field\nmeasurements made by MESSENGER and {\\it Wind} reveal a very similar magnetic\nejecta at both planets. We consider the CME expansion as measured by the ejecta\nduration and the decrease of the magnetic field strength between Mercury and\nEarth and the velocity profile measured {\\it in situ} by {\\it Wind}. The\nlong-duration magnetic ejecta (20 and 42 hours at Mercury and Earth,\nrespectively) is found to be associated with a relatively slowly expanding\nejecta at 1 AU, revealing that the large size of the ejecta is due to the CME\nitself or its expansion in the corona or innermost heliosphere, and not due to\na rapid expansion between Mercury at 0.45 AU and Earth at 1 AU. We also find\nevidence that the CME sheath is composed of compressed material accumulated\nbefore the shock formed, as well as more recently shocked material.", "journal": "", "doi": "10.1029/2019JA027213", "primary_category": "physics.space-ph", "categories": ["physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1912.05446v1"}
{"entry_id": "http://arxiv.org/abs/physics/0607049v1", "date": "2006-07-06", "title": "Towards Earth AntineutRino TomograpHy (EARTH)", "authors": "R. J. de Meijer, F. D. Smit, F. D. Brooks, R. W. Fearick, H. J. Woertche, F. Mantovani", "abstract": "The programme Earth AntineutRino TomograpHy (EARTH) proposes to build ten\nunderground facilities each hosting a telescope. Each telescope consists of\nmany detector modules, to map the radiogenic heat sources deep in the interior\nof the Earth by utilising direction sensitive geoneutrino detection. Recent\nhypotheses target the core-mantle boundary (CMB) as a major source of natural\nradionuclides and therefore of radiogenic heat. A typical scale of the\nprocesses that take place at the CMB is about 200km. To observe these processes\nfrom the surface requires an angular resolution of about 3 degrees. EARTH aims\nat creating a high-resolution 3D-map of the radiogenic heat sources in the\ninterior of the Earth. It will thereby contribute to a better understanding of\na number of geophysical phenomena observed at the surface of the Earth. This\ncondition requires a completely different approach from the monolithic detector\nsystems as e.g. KamLAND.\n  This paper presents, for such telescopes, the boundary conditions set by\nphysics, the estimated count rates, and the first initial results from Monte\nCarlo simulations and laboratory experiments. The Monte Carlo simulations\nindicate that the large volume telescope should consist of detector modules\neach comprising a very large number of detector units, with a cross section of\nroughly a few square centimetres. The signature of an antineutrino event will\nbe a double pulse event. One pulse arises from the slowing down of the emitted\npositron, the other from the neutron capture. In laboratory experiments small\nsized, 10B-loaded liquid scintillation detectors were investigated as\ncandidates for direction sensitive, low-energy antineutrino detection.", "journal": "", "doi": "10.1007/s11038-006-9104-8", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/physics/0607049v1"}
{"entry_id": "http://arxiv.org/abs/1907.06480v1", "date": "2019-07-15", "title": "Experimental demonstration of secure quantum remote sensing", "authors": "Peng Yin, Yuki Takeuchi, Wen-Hao Zhang, Zhen-Qiang Yin, Yuichiro Matsuzaki, Xing-Xiang Peng, Xiao-Ye Xu, Jin-Shi Xu, Jian-Shun Tang, Zong-Quan Zhou, Geng Chen, Chuan-Feng Li, Guang-Can Guo", "abstract": "Quantum metrology aims to enhance the precision of various measurement tasks\nby taking advantages of quantum properties. In many scenarios, precision is not\nthe sole target; the acquired information must be protected once it is\ngenerated in the sensing process. Considering a remote sensing scenario where a\nlocal site performs cooperative sensing with a remote site to collect private\ninformation at the remote site, the loss of sensing data inevitably causes\nprivate information to be revealed. Quantum key distribution is known to be a\nreliable solution for secure data transmission, however, it fails if an\neavesdropper accesses the sensing data generated at a remote site. In this\nstudy, we demonstrate that by sharing entanglement between local and remote\nsites, secure quantum remote sensing can be realized, and the secure level is\ncharacterized by asymmetric Fisher information gain. Concretely, only the local\nsite can acquire the estimated parameter accurately with Fisher information\napproaching 1. In contrast, the accessible Fisher information for an\neavesdropper is nearly zero even if he/she obtains the raw sensing data at the\nremote site. This achievement is primarily due to the nonlocal calibration and\nsteering of the probe state at the remote site. Our results explore one\nsignificant advantage of ``quantumness'' and extend the notion of quantum\nmetrology to the security realm.", "journal": "Phys. Rev. Applied 14, 014065 (2020)", "doi": "10.1103/PhysRevApplied.14.014065", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1907.06480v1"}
{"entry_id": "http://arxiv.org/abs/2008.05225v1", "date": "2020-08-12", "title": "A Zero-Shot Sketch-based Inter-Modal Object Retrieval Scheme for Remote Sensing Images", "authors": "Ushasi Chaudhuri, Biplab Banerjee, Avik Bhattacharya, Mihai Datcu", "abstract": "Conventional existing retrieval methods in remote sensing (RS) are often\nbased on a uni-modal data retrieval framework. In this work, we propose a novel\ninter-modal triplet-based zero-shot retrieval scheme utilizing a sketch-based\nrepresentation of RS data. The proposed scheme performs efficiently even when\nthe sketch representations are marginally prototypical of the image. We\nconducted experiments on a new bi-modal image-sketch dataset called Earth on\nCanvas (EoC) conceived during this study. We perform a thorough bench-marking\nof this dataset and demonstrate that the proposed network outperforms other\nstate-of-the-art methods for zero-shot sketch-based retrieval framework in\nremote sensing.", "journal": "", "doi": "10.1109/LGRS.2021.3056392", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.05225v1"}
{"entry_id": "http://arxiv.org/abs/1811.02793v1", "date": "2018-11-07", "title": "GeoSay: A Geometric Saliency for Extracting Buildings in Remote Sensing Images", "authors": "Gui-Song Xia, Jin Huang, Nan Xue, Qikai Lu, Xiaoxiang Zhu", "abstract": "Automatic extraction of buildings in remote sensing images is an important\nbut challenging task and finds many applications in different fields such as\nurban planning, navigation and so on. This paper addresses the problem of\nbuildings extraction in very high-spatial-resolution (VHSR) remote sensing (RS)\nimages, whose spatial resolution is often up to half meters and provides rich\ninformation about buildings. Based on the observation that buildings in VHSR-RS\nimages are always more distinguishable in geometry than in texture or spectral\ndomain, this paper proposes a geometric building index (GBI) for accurate\nbuilding extraction, by computing the geometric saliency from VHSR-RS images.\nMore precisely, given an image, the geometric saliency is derived from a\nmid-level geometric representations based on meaningful junctions that can\nlocally describe geometrical structures of images. The resulting GBI is finally\nmeasured by integrating the derived geometric saliency of buildings.\nExperiments on three public and commonly used datasets demonstrate that the\nproposed GBI achieves the state-of-the-art performance and shows impressive\ngeneralization capability. Additionally, GBI preserves both the exact position\nand accurate shape of single buildings compared to existing methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1811.02793v1"}
{"entry_id": "http://arxiv.org/abs/1810.02320v1", "date": "2018-10-04", "title": "Computer vision-based framework for extracting geological lineaments from optical remote sensing data", "authors": "Ehsan Farahbakhsh, Rohitash Chandra, Hugo K. H. Olierook, Richard Scalzo, Chris Clark, Steven M. Reddy, R. Dietmar Muller", "abstract": "The extraction of geological lineaments from digital satellite data is a\nfundamental application in remote sensing. The location of geological\nlineaments such as faults and dykes are of interest for a range of\napplications, particularly because of their association with hydrothermal\nmineralization. Although a wide range of applications have utilized computer\nvision techniques, a standard workflow for application of these techniques to\nmineral exploration is lacking. We present a framework for extracting\ngeological lineaments using computer vision techniques which is a combination\nof edge detection and line extraction algorithms for extracting geological\nlineaments using optical remote sensing data. It features ancillary computer\nvision techniques for reducing data dimensionality, removing noise and\nenhancing the expression of lineaments. We test the proposed framework on\nLandsat 8 data of a mineral-rich portion of the Gascoyne Province in Western\nAustralia using different dimension reduction techniques and convolutional\nfilters. To validate the results, the extracted lineaments are compared to our\nmanual photointerpretation and geologically mapped structures by the Geological\nSurvey of Western Australia (GSWA). The results show that the best correlation\nbetween our extracted geological lineaments and the GSWA geological lineament\nmap is achieved by applying a minimum noise fraction transformation and a\nLaplacian filter. Application of a directional filter instead shows a stronger\ncorrelation with the output of our manual photointerpretation and known sites\nof hydrothermal mineralization. Hence, our framework using either filter can be\nused for mineral prospectivity mapping in other regions where faults are\nexposed and observable in optical remote sensing data.", "journal": "", "doi": "10.1080/01431161.2019.1674462", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/1810.02320v1"}
{"entry_id": "http://arxiv.org/abs/2107.04494v1", "date": "2021-07-09", "title": "Fibre Fabry-P\u00e9rot Astrophotonic Correlation Spectroscopy for Remote Gas Identification and Radial Velocity Measurements", "authors": "Ross Cheriton, Adam Densmore, Suresh Sivanandam, Ernst De Mooij, Pavel Cheben, Dan-Xia Xu, Jens H. Schmid, Siegfried Janz", "abstract": "We present a novel remote gas detection and identification technique based on\ncorrelation spectroscopy with a piezoelectric tunable fibre-optic Fabry-P\\'erot\nfilter. We show that the spectral correlation amplitude between the filter\ntransmission window and gas absorption features is related to the gas\nabsorption optical depth, and that different gases can be distinguished from\none another using their correlation signal phase. Using an observed\ntelluric-corrected, high-resolution near-infrared spectrum of Venus, we show\nvia simulation that the Doppler shift of gases lines can be extracted from the\nphase of the lock-in signal using low-cost, compact, and lightweight\nfibre-optic components with lock-in amplification to improve the\nsignal-to-noise ratio. This correlation spectroscopy technique has applications\nin the detection and radial velocity determination of faint spectral features\nin astronomy and remote sensing. We experimentally demonstrate remote CO2\ndetection system using a lock-in amplifier, fibre-optic Fabry-P\\'erot filter,\nand single channel photodiode.", "journal": "", "doi": "10.1364/AO.430540", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "physics.app-ph", "physics.ins-det", "physics.optics", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2107.04494v1"}
{"entry_id": "http://arxiv.org/abs/2109.14532v1", "date": "2021-09-29", "title": "Multispectral CCD-in-CMOS Time Delay Integration imager for high resolution Earth observation", "authors": "Swaraj Bandhu Mahato, Steven Thijs, Jonas Bentell, Linkun Wu, Klaas Tack, Pierre Boulenc, Dorian Lasnet, Renaud Van Langendonck, Piet De Moor", "abstract": "Many future small satellite missions are aimed to provide low-cost remote\nsensing data at unprecedented revisit rates, with a ground resolution of less\nthan one meter. This requires high resolution, fast and sensitive line-scan\nimagers operating at low power consumption and ideally featuring spectral\nsensitivity. In this paper we present comprehensive characterization results of\nour 7 band Back-Side Illuminated (BSI) CCD-in-CMOS sensor with a pixel pitch of\n5.4 um. We have extensively characterized the key performance parameters of our\nCCD-in-CMOS sensor, such as quantum efficiency (QE), full well capacity (FWC),\nread noise, conversion gain, non-linearity, dark current etc. Novelty of this\ndevice is the combination of 7 TDI bands on the same imager allowing\nsimultaneous multispectral TDI capture. Glass-based broadband filters with a\ntypical band-pass width of about 100 nm have been developed and glued together\nto form a filter assembly of 6 band-pass filters and one panchromatic channel.\nMultispectral capability of this sensor is particularly interesting for Low\nEarth Observation (LEO) applications such as environmental monitoring,\nprecision agriculture, disaster detection and monitoring. To highlight its\nad-vantages for use in vegetation observation, we demonstrated a fake leaf and\na real leaf imaging using a 7 band BSI sensor with integrated filters operating\nin 7-band mode at 15 kHz.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/2109.14532v1"}
{"entry_id": "http://arxiv.org/abs/2205.01935v1", "date": "2022-05-04", "title": "Thin current sheet formation: comparison between Earth's magnetotail and coronal streamers", "authors": "Anton Artemyev, Victor Reville, Ivan Zimovets, Yukitoshi Nishimura, Marco Velli, Andrei Runov, Vassilis Angelopoulos", "abstract": "Magnetic field line reconnection is a universal plasma process responsible\nfor the magnetic field topology change and magnetic field energy dissipation\ninto charged particle heating and acceleration. In many systems, the conditions\nleading to the magnetic reconnection are determined by the pre-reconnection\nconfiguration of a thin layer with intense currents -- otherwise known as the\nthin current sheet. In this study we investigate two such systems: Earth's\nmagnetotail and helmet streamers in the solar corona. The pre-reconnection\ncurrent sheet evolution has been intensely studied in the magnetotail, where\nin-situ spacecraft observations are available; but helmet streamer current\nsheets studies are fewer, due to lack of in-situ observations -- they are\nmostly investigated with numerical simulations and information that can be\nsurmised from remote sensing instrumentation. Both systems exhibit\nqualitatively the same behavior, despite their largely different Mach numbers,\nmuch higher at the solar corona than at the magnetotail. Comparison of\nspacecraft data (from the magnetotail) with numerical simulations (for helmet\nstreamers) shows that the pre-reconnection current sheet thinning, for both\ncases, is primarily controlled by plasma pressure gradients. Scaling laws of\nthe current density, magnetic field, and pressure gradients are the same for\nboth systems. We discuss how magnetotail observations and kinetic simulations\ncan be utilized to improve our understanding and modeling of the helmet\nstreamer current sheets.", "journal": "", "doi": null, "primary_category": "physics.space-ph", "categories": ["physics.space-ph", "physics.plasm-ph"], "pdf_url": "http://arxiv.org/pdf/2205.01935v1"}
{"entry_id": "http://arxiv.org/abs/1702.01137v1", "date": "2017-02-03", "title": "False negatives for remote life detection on ocean-bearing planets: Lessons from the early Earth", "authors": "C. T. Reinhard, S. L. Olson, E. W. Schwieterman, T. W. Lyons", "abstract": "Ocean-atmosphere chemistry on Earth has undergone dramatic evolutionary\nchanges through its long history, with potentially significant ramifications\nfor the emergence and long-term stability of atmospheric biosignatures. Though\na great deal of work has centered on refining our understanding of false\npositives for remote life detection, much less attention has been paid to the\npossibility of false negatives, that is, cryptical biospheres that are\nwidespread and active on a planet's surface but are ultimately undetectable or\ndifficult to detect in the composition of a planet's atmosphere. Here, we\nsummarize recent developments from geochemical proxy records and Earth system\nmodels that provide insight into the long-term evolution of the most readily\ndetectable potential biosignature gases on Earth - oxygen (O2), ozone (O3), and\nmethane (CH4). We suggest that the canonical O2-CH4 disequilibrium biosignature\nwould perhaps have been challenging to detect remotely during Earth's ~4.5\nbillion year history and that in general atmospheric O2/O3 levels have been a\npoor proxy for the presence of Earth's biosphere for all but the last ~500\nmillion years. We further suggest that detecting atmospheric CH4 would have\nbeen problematic for most of the last ~2.5 billion years of Earth's history.\nMore broadly, we stress that internal oceanic recycling of biosignature gases\nwill often render surface biospheres on ocean-bearing silicate worlds cryptic,\nwith the implication that the planets most conducive to the development and\nmaintenance of a pervasive biosphere will often be challenging to characterize\nvia conventional atmospheric biosignatures.", "journal": "", "doi": "10.1089/ast.2016.1598", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1702.01137v1"}
{"entry_id": "http://arxiv.org/abs/2109.00400v1", "date": "2021-09-01", "title": "An Integrated Framework for the Heterogeneous Spatio-Spectral-Temporal Fusion of Remote Sensing Images", "authors": "Menghui Jiang, Huanfeng Shen, Jie Li, Liangpei Zhang", "abstract": "Image fusion technology is widely used to fuse the complementary information\nbetween multi-source remote sensing images. Inspired by the frontier of deep\nlearning, this paper first proposes a heterogeneous-integrated framework based\non a novel deep residual cycle GAN. The proposed network consists of a forward\nfusion part and a backward degeneration feedback part. The forward part\ngenerates the desired fusion result from the various observations; the backward\ndegeneration feedback part considers the imaging degradation process and\nregenerates the observations inversely from the fusion result. The proposed\nnetwork can effectively fuse not only the homogeneous but also the\nheterogeneous information. In addition, for the first time, a\nheterogeneous-integrated fusion framework is proposed to simultaneously merge\nthe complementary heterogeneous spatial, spectral and temporal information of\nmulti-source heterogeneous observations. The proposed heterogeneous-integrated\nframework also provides a uniform mode that can complete various fusion tasks,\nincluding heterogeneous spatio-spectral fusion, spatio-temporal fusion, and\nheterogeneous spatio-spectral-temporal fusion. Experiments are conducted for\ntwo challenging scenarios of land cover changes and thick cloud coverage.\nImages from many remote sensing satellites, including MODIS, Landsat-8,\nSentinel-1, and Sentinel-2, are utilized in the experiments. Both qualitative\nand quantitative evaluations confirm the effectiveness of the proposed method.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2109.00400v1"}
{"entry_id": "http://arxiv.org/abs/1809.04464v1", "date": "2018-09-11", "title": "Arbitrarily Varying Remote Sources", "authors": "Amitalok J. Budkuley, Bikash Kumar Dey, Sidharth Jaggi, Vinod M. Prabhakaran", "abstract": "We study a lossy source coding problem for an arbitrarily varying remote\nsource (AVRS) which was proposed in a prior work. An AVRS transmits symbols,\neach generated in an independent and identically distributed manner, which are\nsought to be estimated at the decoder. These symbols are remotely generated,\nand the encoder and decoder observe noise corrupted versions received through a\ntwo-output noisy channel. This channel is an arbitrarily varying channel\ncontrolled by a jamming adversary. We assume that the adversary knows the\ncoding scheme as well as the source data non-causally, and hence, can employ\nmalicious jamming strategies correlated to them. Our interest lies in studying\nthe rate distortion function for codes with a stochastic encoder, i.e, when the\nencoder can privately randomize while the decoder is deterministic. We provide\nupper and lower bounds on this rate distortion function.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1809.04464v1"}
{"entry_id": "http://arxiv.org/abs/1903.05611v1", "date": "2019-03-13", "title": "The remote detectability of Earth's biosphere through time and the importance of UV capability for characterizing habitable exoplanets", "authors": "Christopher T. Reinhard, Edward W. Schwieterman, Stephanie L. Olson, Noah J. Planavsky, Giada N. Arney, Kazumi Ozaki, Sanjoy Som, Tyler D. Robinson, Shawn D. Domagal-Goldman, Doug Lisman, Bertrand Mennesson, Victoria S. Meadows, Timothy W. Lyons", "abstract": "Thousands of planets beyond our solar system have been discovered to date,\ndozens of which are rocky in composition and are orbiting within the\ncircumstellar habitable zone of their host star. The next frontier in life\ndetection beyond our solar system will be detailed characterization of the\natmospheres of potentially habitable worlds, resulting in a pressing need to\ndevelop a comprehensive understanding of the factors controlling the emergence\nand maintenance of atmospheric biosignatures. Understanding Earth system\nevolution is central to this pursuit, and a refined understanding of Earth's\nevolution can provide substantive insight into observational and interpretive\nframeworks in exoplanet science. Using this framework, we argue here that UV\nobservations can help to effectively mitigate 'false positive' scenarios for\noxygen-based biosignatures, while 'false negative' scenarios potentially\nrepresent a significant problem for biosignature surveys lacking UV capability.\nMoving forward, we suggest that well-resolved UV observations will be critical\nfor near-term volume-limited surveys of habitable planets orbiting nearby\nSun-like stars, and will provide the potential for biosignature detection\nacross the most diverse spectrum of reducing, weakly oxygenated, and oxic\nhabitable terrestrial planets.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1903.05611v1"}
{"entry_id": "http://arxiv.org/abs/1710.03959v1", "date": "2017-10-11", "title": "Deep learning in remote sensing: a review", "authors": "Xiao Xiang Zhu, Devis Tuia, Lichao Mou, Gui-Song Xia, Liangpei Zhang, Feng Xu, Friedrich Fraundorfer", "abstract": "Standing at the paradigm shift towards data-intensive science, machine\nlearning techniques are becoming increasingly important. In particular, as a\nmajor breakthrough in the field, deep learning has proven as an extremely\npowerful tool in many fields. Shall we embrace deep learning as the key to all?\nOr, should we resist a 'black-box' solution? There are controversial opinions\nin the remote sensing community. In this article, we analyze the challenges of\nusing deep learning for remote sensing data analysis, review the recent\nadvances, and provide resources to make deep learning in remote sensing\nridiculously simple to start with. More importantly, we advocate remote sensing\nscientists to bring their expertise into deep learning, and use it as an\nimplicit general model to tackle unprecedented large-scale influential\nchallenges, such as climate change and urbanization.", "journal": "", "doi": "10.1109/MGRS.2017.2762307", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1710.03959v1"}
{"entry_id": "http://arxiv.org/abs/2301.01252v2", "date": "2022-12-17", "title": "Comparison of machine learning algorithms for merging gridded satellite and earth-observed precipitation data", "authors": "Georgia Papacharalampous, Hristos Tyralis, Anastasios Doulamis, Nikolaos Doulamis", "abstract": "Gridded satellite precipitation datasets are useful in hydrological\napplications as they cover large regions with high density. However, they are\nnot accurate in the sense that they do not agree with ground-based\nmeasurements. An established means for improving their accuracy is to correct\nthem by adopting machine learning algorithms. This correction takes the form of\na regression problem, in which the ground-based measurements have the role of\nthe dependent variable and the satellite data are the predictor variables,\ntogether with topography factors (e.g., elevation). Most studies of this kind\ninvolve a limited number of machine learning algorithms, and are conducted for\na small region and for a limited time period. Thus, the results obtained\nthrough them are of local importance and do not provide more general guidance\nand best practices. To provide results that are generalizable and to contribute\nto the delivery of best practices, we here compare eight state-of-the-art\nmachine learning algorithms in correcting satellite precipitation data for the\nentire contiguous United States and for a 15-year period. We use monthly data\nfrom the PERSIANN (Precipitation Estimation from Remotely Sensed Information\nusing Artificial Neural Networks) gridded dataset, together with monthly\nearth-observed precipitation data from the Global Historical Climatology\nNetwork monthly database, version 2 (GHCNm). The results suggest that extreme\ngradient boosting (XGBoost) and random forests are the most accurate in terms\nof the squared error scoring function. The remaining algorithms can be ordered\nas follows from the best to the worst: Bayesian regularized feed-forward neural\nnetworks, multivariate adaptive polynomial splines (poly-MARS), gradient\nboosting machines (gbm), multivariate adaptive regression splines (MARS),\nfeed-forward neural networks, linear regression.", "journal": "Water 15 (2023) 634", "doi": "10.3390/w15040634", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph", "cs.LG", "stat.AP", "stat.CO", "stat.ME"], "pdf_url": "http://arxiv.org/pdf/2301.01252v2"}
{"entry_id": "http://arxiv.org/abs/1904.04794v2", "date": "2019-04-09", "title": "CMIR-NET : A Deep Learning Based Model For Cross-Modal Retrieval In Remote Sensing", "authors": "Ushasi Chaudhuri, Biplab Banerjee, Avik Bhattacharya, Mihai Datcu", "abstract": "We address the problem of cross-modal information retrieval in the domain of\nremote sensing. In particular, we are interested in two application scenarios:\ni) cross-modal retrieval between panchromatic (PAN) and multi-spectral imagery,\nand ii) multi-label image retrieval between very high resolution (VHR) images\nand speech based label annotations. Notice that these multi-modal retrieval\nscenarios are more challenging than the traditional uni-modal retrieval\napproaches given the inherent differences in distributions between the\nmodalities. However, with the growing availability of multi-source remote\nsensing data and the scarcity of enough semantic annotations, the task of\nmulti-modal retrieval has recently become extremely important. In this regard,\nwe propose a novel deep neural network based architecture which is considered\nto learn a discriminative shared feature space for all the input modalities,\nsuitable for semantically coherent information retrieval. Extensive experiments\nare carried out on the benchmark large-scale PAN - multi-spectral DSRSID\ndataset and the multi-label UC-Merced dataset. Together with the Merced\ndataset, we generate a corpus of speech signals corresponding to the labels.\nSuperior performance with respect to the current state-of-the-art is observed\nin all the cases.", "journal": "", "doi": "10.1016/j.patrec.2020.02.006", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.IR"], "pdf_url": "http://arxiv.org/pdf/1904.04794v2"}
{"entry_id": "http://arxiv.org/abs/2111.11057v2", "date": "2021-11-22", "title": "Learning to Aggregate Multi-Scale Context for Instance Segmentation in Remote Sensing Images", "authors": "Ye Liu, Huifang Li, Chao Hu, Shuang Luo, Yan Luo, Chang Wen Chen", "abstract": "The task of instance segmentation in remote sensing images, aiming at\nperforming per-pixel labeling of objects at instance level, is of great\nimportance for various civil applications. Despite previous successes, most\nexisting instance segmentation methods designed for natural images encounter\nsharp performance degradations when they are directly applied to top-view\nremote sensing images. Through careful analysis, we observe that the challenges\nmainly come from the lack of discriminative object features due to severe scale\nvariations, low contrasts, and clustered distributions. In order to address\nthese problems, a novel context aggregation network (CATNet) is proposed to\nimprove the feature extraction process. The proposed model exploits three\nlightweight plug-and-play modules, namely dense feature pyramid network\n(DenseFPN), spatial context pyramid (SCP), and hierarchical region of interest\nextractor (HRoIE), to aggregate global visual context at feature, spatial, and\ninstance domains, respectively. DenseFPN is a multi-scale feature propagation\nmodule that establishes more flexible information flows by adopting inter-level\nresidual connections, cross-level dense connections, and feature re-weighting\nstrategy. Leveraging the attention mechanism, SCP further augments the features\nby aggregating global spatial context into local regions. For each instance,\nHRoIE adaptively generates RoI features for different downstream tasks. We\ncarry out extensive evaluations of the proposed scheme on the challenging\niSAID, DIOR, NWPU VHR-10, and HRSID datasets. The evaluation results\ndemonstrate that the proposed approach outperforms state-of-the-arts under\nsimilar computational costs. Source code and pre-trained models are available\nat https://github.com/yeliudev/CATNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2111.11057v2"}
{"entry_id": "http://arxiv.org/abs/2302.01526v1", "date": "2023-02-03", "title": "Example-Based Explainable AI and its Application for Remote Sensing Image Classification", "authors": "Shin-nosuke Ishikawa, Masato Todo, Masato Taki, Yasunobu Uchiyama, Kazunari Matsunaga, Peihsuan Lin, Taiki Ogihara, Masao Yasui", "abstract": "We present a method of explainable artificial intelligence (XAI), \"What I\nKnow (WIK)\", to provide additional information to verify the reliability of a\ndeep learning model by showing an example of an instance in a training dataset\nthat is similar to the input data to be inferred and demonstrate it in a remote\nsensing image classification task. One of the expected roles of XAI methods is\nverifying whether inferences of a trained machine learning model are valid for\nan application, and it is an important factor that what datasets are used for\ntraining the model as well as the model architecture. Our data-centric approach\ncan help determine whether the training dataset is sufficient for each\ninference by checking the selected example data. If the selected example looks\nsimilar to the input data, we can confirm that the model was not trained on a\ndataset with a feature distribution far from the feature of the input data.\nWith this method, the criteria for selecting an example are not merely data\nsimilarity with the input data but also data similarity in the context of the\nmodel task. Using a remote sensing image dataset from the Sentinel-2 satellite,\nthe concept was successfully demonstrated with reasonably selected examples.\nThis method can be applied to various machine-learning tasks, including\nclassification and regression.", "journal": "", "doi": null, "primary_category": "cs.AI", "categories": ["cs.AI", "cs.CV", "cs.LG", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2302.01526v1"}
{"entry_id": "http://arxiv.org/abs/2104.01375v2", "date": "2021-04-03", "title": "Evaluating explainable artificial intelligence methods for multi-label deep learning classification tasks in remote sensing", "authors": "Ioannis Kakogeorgiou, Konstantinos Karantzalos", "abstract": "Although deep neural networks hold the state-of-the-art in several remote\nsensing tasks, their black-box operation hinders the understanding of their\ndecisions, concealing any bias and other shortcomings in datasets and model\nperformance. To this end, we have applied explainable artificial intelligence\n(XAI) methods in remote sensing multi-label classification tasks towards\nproducing human-interpretable explanations and improve transparency. In\nparticular, we utilized and trained deep learning models with state-of-the-art\nperformance in the benchmark BigEarthNet and SEN12MS datasets. Ten XAI methods\nwere employed towards understanding and interpreting models' predictions, along\nwith quantitative metrics to assess and compare their performance. Numerous\nexperiments were performed to assess the overall performance of XAI methods for\nstraightforward prediction cases, competing multiple labels, as well as\nmisclassification cases. According to our findings, Occlusion, Grad-CAM and\nLime were the most interpretable and reliable XAI methods. However, none\ndelivers high-resolution outputs, while apart from Grad-CAM, both Lime and\nOcclusion are computationally expensive. We also highlight different aspects of\nXAI performance and elaborate with insights on black-box decisions in order to\nimprove transparency, understand their behavior and reveal, as well, datasets'\nparticularities.", "journal": "International Journal of Applied Earth Observation and\n  Geoinformation 103 (2021) 102520", "doi": "10.1016/j.jag.2021.102520", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2104.01375v2"}
{"entry_id": "http://arxiv.org/abs/0907.5062v1", "date": "2009-07-29", "title": "Heating of near-Earth objects and meteoroids due to close approaches to the Sun", "authors": "S. Marchi, M. Delbo', A. Morbidelli, P. Paolicchi, M. Lazzarin", "abstract": "It is known that near-Earth objects (NEOs) during their orbital evolution may\noften undergo close approaches to the Sun. Indeed it is estimated that up to\n~70% of them end their orbital evolution colliding with the Sun. Starting from\nthe present orbital properties, it is possible to compute the most likely past\nevolution for every NEO, and to trace its distance from the Sun. We find that a\nlarge fraction of the population may have experienced in the past frequent\nclose approaches, and thus, as a consequence, a considerable Sun-driven\nheating, not trivially correlated to the present orbits. The detailed dynamical\nbehaviour, the rotational and the thermal properties of NEOs determine the\nexact amount of the resulting heating due to the Sun. In the present paper we\ndiscuss the general features of the process, providing estimates of the surface\ntemperature reached by NEOs during their evolution. Moreover, we investigate\nthe effects of this process on meteor-size bodies, analyzing possible\ndifferences with the NEO population. We also discuss some possible effects of\nthe heating which can be observed through remote sensing by ground-based\nsurveys or space missions.", "journal": "", "doi": "10.1111/j.1365-2966.2009.15459.x", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0907.5062v1"}
{"entry_id": "http://arxiv.org/abs/1604.01816v1", "date": "2016-04-06", "title": "Solar irradiance changes and phytoplankton productivity in Earth's ocean following astrophysical ionizing radiation events", "authors": "Patrick J. Neale, Brian C. Thomas", "abstract": "Two atmospheric responses to simulated astrophysical ionizing radiation\nevents significant to life on Earth are production of odd-nitrogen species,\nespecially NO2, and subsequent depletion of stratospheric ozone. Ozone\ndepletion increases incident short-wavelength ultraviolet radiation (UVB,\n280-315 nm) and longer ( > 600 nm) wavelengths of photosynthetically available\nradiation (PAR, 400 -700 nm). On the other hand, the NO2 haze decreases\natmospheric transmission in the long-wavelength UVA (315-400 nm) and short\nwavelength PAR. Here we use the results of previous simulations of incident\nspectral irradiance following an ionizing radiation event to predict changes in\nTerran productivity focusing on photosynthesis of marine phytoplankton. The\nprediction is based on a spectral model of photosynthetic response developed\nfor the dominant genera in central regions of the ocean (Synechococcus and\nProchlorococcus), and remote-sensing based observations of spectral water\ntransparency, temperature, wind speed and mixed layer depth. Predicted\nproductivity declined after a simulated ionizing event, but the effect\nintegrated over the water column was small. For integrations taking into\naccount the full depth range of PAR transmission (down to 0.1% of utilizable\nPAR), the decrease was at most 2-3% (depending on strain), with larger effects\n(5-7%) for integrations just to the depth of the surface mixed layer. The\ndeeper integrations were most affected by the decreased utilizable PAR at depth\ndue to the NO2 haze, whereas shallower integrations were most affected by the\nincreased surface UV.", "journal": "", "doi": "10.1089/ast.2015.1360", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.HE", "physics.ao-ph", "q-bio.PE"], "pdf_url": "http://arxiv.org/pdf/1604.01816v1"}
{"entry_id": "http://arxiv.org/abs/2202.05182v1", "date": "2022-02-10", "title": "Remote Contextual Bandits", "authors": "Francesco Pase, Deniz Gunduz, Michele Zorzi", "abstract": "We consider a remote contextual multi-armed bandit (CMAB) problem, in which\nthe decision-maker observes the context and the reward, but must communicate\nthe actions to be taken by the agents over a rate-limited communication\nchannel. This can model, for example, a personalized ad placement application,\nwhere the content owner observes the individual visitors to its website, and\nhence has the context information, but must convey the ads that must be shown\nto each visitor to a separate entity that manages the marketing content. In\nthis remote CMAB (R-CMAB) problem, the constraint on the communication rate\nbetween the decision-maker and the agents imposes a trade-off between the\nnumber of bits sent per agent and the acquired average reward. We are\nparticularly interested in characterizing the rate required to achieve\nsub-linear regret. Consequently, this can be considered as a policy compression\nproblem, where the distortion metric is induced by the learning objectives. We\nfirst study the fundamental information theoretic limits of this problem by\nletting the number of agents go to infinity, and study the regret achieved when\nThompson sampling strategy is adopted. In particular, we identify two distinct\nrate regions resulting in linear and sub-linear regret behavior, respectively.\nThen, we provide upper bounds on the achievable regret when the decision-maker\ncan reliably transmit the policy without distortion.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2202.05182v1"}
{"entry_id": "http://arxiv.org/abs/1803.05179v1", "date": "2018-03-14", "title": "Transmission Spectroscopy with the ACE-FTS Infrared Spectral Atlas of Earth: A Model Validation and Feasibility Study", "authors": "Franz Schreier, Steffen St\u00e4dt, Pascal Hedelt, Mareike Godolt", "abstract": "Infrared solar occultation measurements are well established for remote\nsensing of Earth's atmosphere, and the corresponding primary transit\nspectroscopy has turned out to be valuable for characterization of extrasolar\nplanets. Our objective is an assessment of the detectability of molecular\nsignatures in Earth's transit spectra.\n  To this end, we take a limb sequence of representative cloud-free\ntransmission spectra recorded by the space-borne ACE-FTS Earth observation\nmission (Hughes et al., ACE infrared spectral atlases of the Earth's\natmosphere, JQSRT 2014) and combine these spectra to the effective height of\nthe atmosphere. These data are compared to spectra modeled with an atmospheric\nradiative transfer line-by-line infrared code to study the impact of individual\nmolecules, spectral resolution, the choice of auxiliary data, and numerical\napproximations. Moreover, the study serves as a validation of our infrared\nradiative transfer code.\n  The largest impact is due to water, carbon dioxide, ozone, methane, nitrous\noxide, nitrogen, nitric acid, oxygen, and some chlorofluorocarbons (CFC11 and\nCFC12). The effect of further molecules considered in the modeling is either\nmarginal or absent. The best matching model has a mean residuum of 0.4 km and a\nmaximum difference of 2 km to the measured effective height. For a quantitative\nestimate of visibility and detectability we consider the maximum change of the\nresidual spectrum, the relative change of the residual norm, the additional\ntransit depth, and signal-to-noise ratios for a JWST setup. In conclusion, our\nstudy provides a list of molecules that are relevant for modeling transmission\nspectra of Earth-like exoplanets and discusses the feasibility of retrieval.", "journal": "", "doi": "10.1016/j.molap.2018.02.001", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1803.05179v1"}
{"entry_id": "http://arxiv.org/abs/2104.13969v1", "date": "2021-04-26", "title": "On the Importance of 3D Surface Information for Remote Sensing Classification Tasks", "authors": "Jan Petrich, Ryan Sander, Eliza Bradley, Adam Dawood, Shawn Hough", "abstract": "There has been a surge in remote sensing machine learning applications that\noperate on data from active or passive sensors as well as multi-sensor\ncombinations (Ma et al. (2019)). Despite this surge, however, there has been\nrelatively little study on the comparative value of 3D surface information for\nmachine learning classification tasks. Adding 3D surface information to RGB\nimagery can provide crucial geometric information for semantic classes such as\nbuildings, and can thus improve out-of-sample predictive performance. In this\npaper, we examine in-sample and out-of-sample classification performance of\nFully Convolutional Neural Networks (FCNNs) and Support Vector Machines (SVMs)\ntrained with and without 3D normalized digital surface model (nDSM)\ninformation. We assess classification performance using multispectral imagery\nfrom the International Society for Photogrammetry and Remote Sensing (ISPRS) 2D\nSemantic Labeling contest and the United States Special Operations Command\n(USSOCOM) Urban 3D Challenge. We find that providing RGB classifiers with\nadditional 3D nDSM information results in little increase in in-sample\nclassification performance, suggesting that spectral information alone may be\nsufficient for the given classification tasks. However, we observe that\nproviding these RGB classifiers with additional nDSM information leads to\nsignificant gains in out-of-sample predictive performance. Specifically, we\nobserve an average improvement in out-of-sample all-class accuracy of 14.4% on\nthe ISPRS dataset and an average improvement in out-of-sample F1 score of 8.6%\non the USSOCOM dataset. In addition, the experiments establish that nDSM\ninformation is critical in machine learning and classification settings that\nface training sample scarcity.", "journal": "", "doi": "10.5334/dsj-2021-020", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2104.13969v1"}
{"entry_id": "http://arxiv.org/abs/2211.15660v1", "date": "2022-11-28", "title": "Satlas: A Large-Scale, Multi-Task Dataset for Remote Sensing Image Understanding", "authors": "Favyen Bastani, Piper Wolters, Ritwik Gupta, Joe Ferdinando, Aniruddha Kembhavi", "abstract": "Remote sensing images are useful for a wide variety of environmental and\nearth monitoring tasks, including tracking deforestation, illegal fishing,\nurban expansion, and natural disasters. The earth is extremely diverse -- the\namount of potential tasks in remote sensing images is massive, and the sizes of\nfeatures range from several kilometers to just tens of centimeters. However,\ncreating generalizable computer vision methods is a challenge in part due to\nthe lack of a large-scale dataset that captures these diverse features for many\ntasks. In this paper, we present Satlas, a remote sensing dataset and benchmark\nthat is large in both breadth, featuring all of the aforementioned applications\nand more, as well as scale, comprising 290M labels under 137 categories and\nseven label modalities. We evaluate eight baselines and a proposed method on\nSatlas, and find that there is substantial room for improvement in addressing\nresearch challenges specific to remote sensing, including processing image time\nseries that consist of images from very different types of sensors, and taking\nadvantage of long-range spatial context. We also find that pre-training on\nSatlas substantially improves performance on downstream tasks with few labeled\nexamples, increasing average accuracy by 16% over ImageNet and 5% over the next\nbest baseline.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2211.15660v1"}
{"entry_id": "http://arxiv.org/abs/2111.12126v2", "date": "2021-11-23", "title": "Panoptic Segmentation Meets Remote Sensing", "authors": "Osmar Luiz Ferreira de Carvalho, Osmar Ab\u00edlio de Carvalho J\u00fanior, Cristiano Rosa e Silva, Anesmar Olino de Albuquerque, Nickolas Castro Santana, Dibio Leandro Borges, Roberto Arnaldo Trancoso Gomes, Renato Fontes Guimar\u00e3es", "abstract": "Panoptic segmentation combines instance and semantic predictions, allowing\nthe detection of \"things\" and \"stuff\" simultaneously. Effectively approaching\npanoptic segmentation in remotely sensed data can be auspicious in many\nchallenging problems since it allows continuous mapping and specific target\ncounting. Several difficulties have prevented the growth of this task in remote\nsensing: (a) most algorithms are designed for traditional images, (b) image\nlabelling must encompass \"things\" and \"stuff\" classes, and (c) the annotation\nformat is complex. Thus, aiming to solve and increase the operability of\npanoptic segmentation in remote sensing, this study has five objectives: (1)\ncreate a novel data preparation pipeline for panoptic segmentation, (2) propose\nan annotation conversion software to generate panoptic annotations; (3) propose\na novel dataset on urban areas, (4) modify the Detectron2 for the task, and (5)\nevaluate difficulties of this task in the urban setting. We used an aerial\nimage with a 0,24-meter spatial resolution considering 14 classes. Our pipeline\nconsiders three image inputs, and the proposed software uses point shapefiles\nfor creating samples in the COCO format. Our study generated 3,400 samples with\n512x512 pixel dimensions. We used the Panoptic-FPN with two backbones\n(ResNet-50 and ResNet-101), and the model evaluation considered semantic\ninstance and panoptic metrics. We obtained 93.9, 47.7, and 64.9 for the mean\nIoU, box AP, and PQ. Our study presents the first effective pipeline for\npanoptic segmentation and an extensive database for other researchers to use\nand deal with other data or related problems requiring a thorough scene\nunderstanding.", "journal": "", "doi": "10.3390/rs14040965", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.DB", "I.4.6"], "pdf_url": "http://arxiv.org/pdf/2111.12126v2"}
{"entry_id": "http://arxiv.org/abs/1510.03282v1", "date": "2015-10-12", "title": "Forbush Decrease Prediction Based on the Remote Solar Observations", "authors": "Mateja Dumbovic, Bojan Vrsnak, Jasa Calogovic", "abstract": "We employ remote observations of coronal mass ejections (CMEs) and the\nassociated solar flares to forecast the CME-related Forbush decreases, i.e.,\nshort-term depressions in the galactic cosmic-ray flux. The relationship\nbetween the Forbush effect at the Earth and remote observations of CMEs and\nassociated solar flares is studied via a statistical analysis. Relationships\nbetween Forbush decrease magnitude and several CME/flare parameters was found,\nnamely the initial CME speed, apparent width, source position, associated\nsolar-flare class and the effect of successive-CME occurrence. Based on the\nstatistical analysis, remote solar observations are employed for a\nForbush-decrease forecast. For that purpose, an empirical probabilistic model\nis constructed that uses selected remote solar observations of CME and\nassociated solar flare as an input, and gives expected Forbush-decrease\nmagnitude range as an output. The forecast method is evaluated using several\nverification measures, indicating that as the forecast tends to be more\nspecific it is less reliable, which is its main drawback. However, the\nadvantages of the method are that it provides early prediction, and that the\ninput is not necessarily spacecraft-dependent.", "journal": "", "doi": "10.1007/s11207-015-0819-4", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1510.03282v1"}
{"entry_id": "http://arxiv.org/abs/2012.11922v1", "date": "2020-12-22", "title": "Learning Structures in Earth Observation Data with Gaussian Processes", "authors": "Fernando Mateo, Jordi Munoz-Mari, Valero Laparra, Jochem Verrelst, Gustau Camps-Valls", "abstract": "Gaussian Processes (GPs) has experienced tremendous success in geoscience in\ngeneral and for bio-geophysical parameter retrieval in the last years. GPs\nconstitute a solid Bayesian framework to formulate many function approximation\nproblems consistently. This paper reviews the main theoretical GP developments\nin the field. We review new algorithms that respect the signal and noise\ncharacteristics, that provide feature rankings automatically, and that allow\napplicability of associated uncertainty intervals to transport GP models in\nspace and time. All these developments are illustrated in the field of\ngeoscience and remote sensing at a local and global scales through a set of\nillustrative examples.", "journal": "in Advanced Analysis and Learning on Temporal Data. AALTD\n  2015.Lecture Notes in Computer Science, vol 9785. Springer, Cham", "doi": "10.1007/978-3-319-44412-3_6", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "physics.app-ph", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2012.11922v1"}
{"entry_id": "http://arxiv.org/abs/1806.00908v2", "date": "2018-06-04", "title": "Accurate Building Detection in VHR Remote Sensing Images using Geometric Saliency", "authors": "Jin Huang, Gui-Song Xia, Fan Hu, Liangpei Zhang", "abstract": "This paper aims to address the problem of detecting buildings from remote\nsensing images with very high resolution (VHR). Inspired by the observation\nthat buildings are always more distinguishable in geometries than in texture or\nspectral, we propose a new geometric building index (GBI) for accurate building\ndetection, which relies on the geometric saliency of building structures. The\ngeometric saliency of buildings is derived from a mid-level geometric\nrepresentations based on meaningful junctions that can locally describe\nanisotropic geometrical structures of images. The resulting GBI is measured by\nintegrating the derived geometric saliency of buildings. Experiments on three\npublic datasets demonstrate that the proposed GBI achieves very promising\nperformance, and meanwhile shows impressive generalization capability.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1806.00908v2"}
{"entry_id": "http://arxiv.org/abs/2201.04432v1", "date": "2022-01-12", "title": "Multilevel T-spline Approximation for Scattered Observations with Application to Land Remote Sensing", "authors": "Ga\u00ebl Kermarrec, Philipp Morgenstern", "abstract": "In this contribution, we introduce a multilevel approximation method with\nT-splines for fitting scattered point clouds iteratively, with an application\nto land remote sensing. This new procedure provides a local surface\napproximation by an explicit computation of the control points and is called a\nmultilevel T-splines approximation (MTA). It is computationally efficient\ncompared with the traditional global least-squares (LS) approach, which may\nfail when there is an unfavourable point density from a given refinement level.\nWe validate our approach within a simulated framework and apply it to two real\ndatasets: (i) a surface with holes scanned with a terrestrial laser scanner,\nand (ii) a patch on a sand-dune in the Netherlands. Both examples highlight the\npotential of the MTA for rapidly fitting large and noisy point clouds with\nvariable point density and with similar results compared to the global LS\napproximation.", "journal": "", "doi": null, "primary_category": "math.NA", "categories": ["math.NA", "cs.NA", "65D07, 65D10", "G.1.2; J.2"], "pdf_url": "http://arxiv.org/pdf/2201.04432v1"}
{"entry_id": "http://arxiv.org/abs/1303.2574v1", "date": "2013-03-08", "title": "Tracking the momentum flux of a CME and quantifying its influence on geomagnetically induced currents at Earth", "authors": "Neel P. Savani, A. Vourlidas, A. Pulkkinen, T. Nieves-Chinchilla, B. Lavraud, M. J. Owens", "abstract": "We investigate a CME propagating towards Earth on 29 March 2011. This event\nis specifically chosen for its predominately northward directed magnetic field,\nso that the influence from the momentum flux onto Earth can be isolated. We\nfocus our study on understanding how a small Earth-directed segment propagates.\nMass images are created from the white-light cameras onboard STEREO which are\nalso converted into mass height-time maps (mass J-maps). The mass tracks on\nthese J-maps correspond to the sheath region between the CME and its associated\nshock front as detected by in situ measurements at L1. A time-series of mass\nmeasurements from the STEREO COR-2A instrument are made along the Earth\npropagation direction. Qualitatively, this mass time-series shows a remarkable\nresemblance to the L1 in situ density series. The in situ measurements are used\nas inputs into a 3D magnetospheric space weather simulation from CCMC. These\nsimulations display a sudden compression of the magnetosphere from the large\nmomentum flux at the leading edge of the CME and predictions are made for the\ntime-derivative of the magnetic field (dB/dt) on the ground. The predicted\ndB/dt were then compared with observations from specific equatorially-located\nground stations and show notable similarity. This study of the momentum of a\nCME from the Sun down to its influence on magnetic ground stations on Earth is\npresented as preliminary proof of concept, such that future attempts may try to\nuse remote sensing to create density and velocity time-series as inputs to\nmagnetospheric simulations.", "journal": "Space Weather 2013", "doi": "10.1002/swe.20038", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1303.2574v1"}
{"entry_id": "http://arxiv.org/abs/1005.4216v1", "date": "2010-05-23", "title": "Classification of LULC Change Detection using Remotely Sensed Data for Coimbatore City, Tamilnadu, India", "authors": "Y. Babykalpana, K. ThanushKodi", "abstract": "Maps are used to describe far-off places . It is an aid for navigation and\nmilitary strategies. Mapping of the lands are important and the mapping work is\nbased on (i). Natural resource management & development (ii). Information\ntechnology ,(iii). Environmental development ,(iv). Facility management and\n(v). e-governance. The Landuse / Landcover system espoused by almost all\nOrganisations and scientists, engineers and remote sensing community who are\ninvolved in mapping of earth surface features, is a system which is derived\nfrom the united States Geological Survey (USGS) LULC classification system. The\napplication of RS and GIS involves influential of homogeneous zones, drift\nanalysis of land use integration of new area changes or change detection\netc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a\ngeneralized LULC classification system respect to the Indian conditions based\non the various categories of Earth surface features , resolution of available\nsatellite data, capabilities of sensors and present and future applications.\nThe profusion information of the earth surface offered by the high resolution\nsatellite images for remote sensing applications. Using change detection\nmethodologies to extract the target changes in the areas from high resolution\nimages and rapidly updates geodatabase information processing.Traditionally,\nclassification approaches have focused on per-pixel technologies. Pixels within\nareas assumed to be automatically homogeneous are analyzed independently.", "journal": "Journal of Computing, Volume 2, Issue 5, May 2010", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1005.4216v1"}
{"entry_id": "http://arxiv.org/abs/2110.07658v1", "date": "2021-10-14", "title": "Predicting Solar Flares with Remote Sensing and Machine Learning", "authors": "Erik Larsen", "abstract": "High energy solar flares and coronal mass ejections have the potential to\ndestroy Earth's ground and satellite infrastructures, causing trillions of\ndollars in damage and mass human suffering. Destruction of these critical\nsystems would disable power grids and satellites, crippling communications and\ntransportation. This would lead to food shortages and an inability to respond\nto emergencies. A solution to this impending problem is proposed herein using\nsatellites in solar orbit that continuously monitor the Sun, use artificial\nintelligence and machine learning to calculate the probability of massive solar\nexplosions from this sensed data, and then signal defense mechanisms that will\nmitigate the threat. With modern technology there may be only safeguards that\ncan be implemented with enough warning, which is why the best algorithm must be\nidentified and continuously trained with existing and new data to maximize true\npositive rates while minimizing false negatives. This paper conducts a survey\nof current machine learning models using open source solar flare prediction\ndata. The rise of edge computing allows machine learning hardware to be placed\non the same satellites as the sensor arrays, saving critical time by not having\nto transmit remote sensing data across the vast distances of space. A system of\nsystems approach will allow enough warning for safety measures to be put into\nplace mitigating the risk of disaster.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2110.07658v1"}
{"entry_id": "http://arxiv.org/abs/2107.06132v1", "date": "2021-07-13", "title": "Deep learning approaches to Earth Observation change detection", "authors": "Antonio Di Pilato, Nicol\u00f2 Taggio, Alexis Pompili, Michele Iacobellis, Adriano Di Florio, Davide Passarelli, Sergio Samarelli", "abstract": "The interest for change detection in the field of remote sensing has\nincreased in the last few years. Searching for changes in satellite images has\nmany useful applications, ranging from land cover and land use analysis to\nanomaly detection. In particular, urban change detection provides an efficient\ntool to study urban spread and growth through several years of observation. At\nthe same time, change detection is often a computationally challenging and\ntime-consuming task, which requires innovative methods to guarantee optimal\nresults with unquestionable value and within reasonable time. In this paper we\npresent two different approaches to change detection (semantic segmentation and\nclassification) that both exploit convolutional neural networks to achieve good\nresults, which can be further refined and used in a post-processing workflow\nfor a large variety of applications.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2107.06132v1"}
{"entry_id": "http://arxiv.org/abs/1302.4808v4", "date": "2013-02-20", "title": "Verifying the Consistency of Remote Untrusted Services with Conflict-Free Operations", "authors": "Christian Cachin, Olga Ohrimenko", "abstract": "A group of mutually trusting clients outsources a computation service to a\nremote server, which they do not fully trust and that may be subject to\nattacks. The clients do not communicate with each other and would like to\nverify the correctness of the remote computation and the consistency of the\nserver's responses. This paper presents the Conflict-free Operation\nverification Protocol (COP) that ensures linearizability when the server is\ncorrect and preserves fork-linearizability in any other case. All clients that\nobserve each other's operations are consistent, in the sense that their own\noperations and those operations of other clients that they see are\nlinearizable. If the server forks two clients by hiding an operation, these\nclients never again see operations of each other. COP supports wait-free client\noperations in the sense that when executed with a correct server,\nnon-conflicting operations can run without waiting for other clients, allowing\nmore parallelism than earlier protocols. A conflict arises when an operation\ncauses a subsequent operation to produce a different output value for the\nclient who runs it. The paper gives a precise model for the guarantees of COP\nand includes a formal analysis that these are achieved.", "journal": "", "doi": "10.1007/978-3-319-14472-6_1", "primary_category": "cs.DC", "categories": ["cs.DC"], "pdf_url": "http://arxiv.org/pdf/1302.4808v4"}
{"entry_id": "http://arxiv.org/abs/1702.00399v1", "date": "2017-02-01", "title": "A propagation tool to connect remote-sensing observations with in-situ measurements of heliospheric structures", "authors": "A. P. Rouillard, B. Lavraud, V. Genot, M. Bouchemit, N. Dufourg, I. Plotnikov, R. F. Pinto, E. Sanchez-Diaz, M. Lavarra, M. Penou, C. Jacquey, N. Andre, S. Caussarieu, J. -P. Toniutti, D. Popescu, E. Buchlin, S. Caminade, P. Alingery, J. A. Davies, D. Odstrcil, L. Mays", "abstract": "The remoteness of the Sun and the harsh conditions prevailing in the solar\ncorona have so far limited the observational data used in the study of solar\nphysics to remote-sensing observations taken either from the ground or from\nspace. In contrast, the `solar wind laboratory' is directly measured in situ by\na fleet of spacecraft measuring the properties of the plasma and magnetic\nfields at specific points in space. Since 2007, the solar-terrestrial relations\nobservatory (STEREO) has been providing images of the solar wind that flows\nbetween the solar corona and spacecraft making in-situ measurements. This has\nallowed scientists to directly connect processes imaged near the Sun with the\nsubsequent effects measured in the solar wind. This new capability prompted the\ndevelopment of a series of tools and techniques to track heliospheric\nstructures through space. This article presents one of these tools, a web-based\ninterface called the 'Propagation Tool' that offers an integrated research\nenvironment to study the evolution of coronal and solar wind structures, such\nas Coronal Mass Ejections (CMEs), Corotating Interaction Regions (CIRs) and\nSolar Energetic Particles (SEPs). These structures can be propagated from the\nSun outwards to or alternatively inwards from planets and spacecraft situated\nin the inner and outer heliosphere. In this paper, we present the global\narchitecture of the tool, discuss some of the assumptions made to simulate the\nevolution of the structures and show how the tool connects to different\ndatabases.", "journal": "", "doi": "10.1016/j.pss.2017.07.001", "primary_category": "physics.space-ph", "categories": ["physics.space-ph", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1702.00399v1"}
{"entry_id": "http://arxiv.org/abs/1807.01232v3", "date": "2018-07-03", "title": "SpaceNet: A Remote Sensing Dataset and Challenge Series", "authors": "Adam Van Etten, Dave Lindenbaum, Todd M. Bacastow", "abstract": "Foundational mapping remains a challenge in many parts of the world,\nparticularly in dynamic scenarios such as natural disasters when timely updates\nare critical. Updating maps is currently a highly manual process requiring a\nlarge number of human labelers to either create features or rigorously validate\nautomated outputs. We propose that the frequent revisits of earth imaging\nsatellite constellations may accelerate existing efforts to quickly update\nfoundational maps when combined with advanced machine learning techniques.\nAccordingly, the SpaceNet partners (CosmiQ Works, Radiant Solutions, and\nNVIDIA), released a large corpus of labeled satellite imagery on Amazon Web\nServices (AWS) called SpaceNet. The SpaceNet partners also launched a series of\npublic prize competitions to encourage improvement of remote sensing machine\nlearning algorithms. The first two of these competitions focused on automated\nbuilding footprint extraction, and the most recent challenge focused on road\nnetwork extraction. In this paper we discuss the SpaceNet imagery, labels,\nevaluation metrics, prize challenge results to date, and future plans for the\nSpaceNet challenge series.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.01232v3"}
{"entry_id": "http://arxiv.org/abs/1910.10047v1", "date": "2019-10-22", "title": "Complex organic molecules in comets from remote-sensing observations at millimeter wavelengths", "authors": "Nicolas Biver, Dominique Bockel\u00e9e-Morvan", "abstract": "Remote observations of comets, especially using high spectral resolution\nmillimeter spectroscopy, have enabled the detection of over 25 molecules in\ncomets for the last twenty years. Among the molecules identified at radio\nwavelengths, complex organic molecules (COMs) such as acetaldehyde,\nethylene-glycol, formamide, methyl-formate or ethanol have been observed in\nseveral comets and their abundances relative to water and methanol precisely\ndetermined. Significant upper limits on the abundance of several other COMs\nhave been determined and put constraints on the dominant isomer for three of\nthem. The abundances measured in comets are generally of comparable order of\nmagnitude as those measured in star-forming regions, suggesting that comets\ncontain preserved material from the presolar cloud from which the solar system\nwas born.", "journal": "ACS Earth Space Chem.2019,3,8,1550-1555", "doi": "10.1021/acsearthspacechem.9b00130", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1910.10047v1"}
{"entry_id": "http://arxiv.org/abs/1904.04329v1", "date": "2019-04-08", "title": "Automated Monitoring Cropland Using Remote Sensing Data: Challenges and Opportunities for Machine Learning", "authors": "Xiaowei Jia, Ankush Khandelwal, Vipin Kumar", "abstract": "This paper provides an overview of how recent advances in machine learning\nand the availability of data from earth observing satellites can dramatically\nimprove our ability to automatically map croplands over long period and over\nlarge regions. It discusses three applications in the domain of crop monitoring\nwhere ML approaches are beginning to show great promise. For each application,\nit highlights machine learning challenges, proposed approaches, and recent\nresults. The paper concludes with discussion of major challenges that need to\nbe addressed before ML approaches will reach their full potential for this\nproblem of great societal relevance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1904.04329v1"}
{"entry_id": "http://arxiv.org/abs/2107.04316v1", "date": "2021-07-09", "title": "Prediction of butt rot volume in Norway spruce forest stands using harvester, remotely sensed and environmental data", "authors": "Janne R\u00e4ty, Johannes Breidenbach, Marius Hauglin, Rasmus Astrup", "abstract": "Butt rot (BR) damages associated with Norway spruce (Picea abies [L.] Karst.)\naccount for considerable economic losses in timber production across the\nnorthern hemisphere. While information on BR damages is critical for optimal\ndecision-making in forest management, the maps of BR damages are typically\nlacking in forest information systems. We predicted timber volume damaged by BR\nat the stand-level in Norway using harvester information of 186,026 stems\n(clear-cuts), remotely sensed, and environmental data (e.g. climate and terrain\ncharacteristics). We utilized random forest (RF) models with two sets of\npredictor variables: (1) predictor variables available after harvest\n(theoretical case) and (2) predictor variables available prior to harvest\n(mapping case). We found that forest attributes characterizing the maturity of\nforest, such as remote sensing-based height, harvested timber volume and\nquadratic mean diameter at breast height, were among the most important\npredictor variables. Remotely sensed predictor variables obtained from airborne\nlaser scanning data and Sentinel-2 imagery were more important than the\nenvironmental variables. The theoretical case with a leave-stand-out\ncross-validation achieved an RMSE of 11.4 $m^3ha^{-1}$ (pseudo $R^2$: 0.66)\nwhereas the mapping case resulted in a pseudo $R^2$ of 0.60. When the spatially\ndistinct k-means clusters of harvested forest stands were used as units in the\ncross-validation, the RMSE value and pseudo $R^2$ associated with the mapping\ncase were 15.6 $m^3ha^{-1}$ and 0.37, respectively. This indicates that the\nknowledge about the BR status of spatially close stands is of high importance\nfor obtaining satisfactory error rates in the mapping of BR damages.", "journal": "International Journal of Applied Earth Observation and\n  Geoinformation, 2021", "doi": "10.1016/j.jag.2021.102624", "primary_category": "stat.AP", "categories": ["stat.AP", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2107.04316v1"}
{"entry_id": "http://arxiv.org/abs/1504.06332v1", "date": "2015-04-23", "title": "Short term Variability of the Sun Earth System: An Overview of Progress Made during the CAWSES II Period", "authors": "Nat Gopalswamy, Bruce Tsurutani, Yihua Yan", "abstract": "This paper presents an overview of results obtained during the CAWSES II\nperiod on the short term variability of the Sun and how it affects the near\nEarth space environment. CAWSES II was planned to examine the behavior of the\nsolar terrestrial system as the solar activity climbed to its maximum phase in\nsolar cycle 24. After a deep minimum following cycle 23, the Sun climbed to a\nvery weak maximum in terms of the sunspot number in cycle 24 (MiniMax24), so\nmany of the results presented here refer to this weak activity in comparison\nwith cycle 23. The short term variability that has immediate consequence to\nEarth and geospace manifests as solar eruptions from closed field regions and\nhigh speed streams from coronal holes. Both electromagnetic (flares) and mass\nemissions (coronal mass ejections, CMEs) are involved in solar eruptions, while\ncoronal holes result in high speed streams that collide with slow wind forming\nthe so called corotating interaction regions (CIRs). Fast CMEs affect Earth via\nleading shocks accelerating energetic particles and creating large geomagnetic\nstorms. CIRs and their trailing high speed streams (HSSs), on the other hand,\nare responsible for recurrent small geomagnetic storms and extended (days) of\nauroral zone activity, respectively. The latter lead to the acceleration of\nrelativistic magnetospheric killer electrons. One of the major consequences of\nthe weak solar activity is the altered physical state of the heliosphere that\nhas serious implications for the shock-driving and storm causing properties of\nCMEs. Finally, a discussion is presented on extreme space weather events\nprompted by the 2012 July 23 super storm event that occurred on the backside of\nthe Sun. Many of these studies were enabled by the simultaneous availability of\nremote-sensing and in situ observations from multiple vantage points with\nrespect to the Sun Earth line.", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1504.06332v1"}
{"entry_id": "http://arxiv.org/abs/2012.05140v3", "date": "2020-12-09", "title": "Estimating heterogeneous wildfire effects using synthetic controls and satellite remote sensing", "authors": "Feliu Serra-Burriel, Pedro Delicado, Andrew T. Prata, Fernando M. Cucchietti", "abstract": "Wildfires have become one of the biggest natural hazards for environments\nworldwide. The effects of wildfires are heterogeneous, meaning that the\nmagnitude of their effects depends on many factors such as geographical region,\nclimate and land cover/vegetation type. Yet, which areas are more affected by\nthese events remains unclear. Here we present a novel application of the\nGeneralised Synthetic Control (GSC) method that enables quantification and\nprediction of vegetation changes due to wildfires through a time-series\nanalysis of in situ and satellite remote sensing data. We apply this method to\nmedium to large wildfires ($>$ 1000 acres) in California throughout a time-span\nof two decades (1996--2016). The method's ability for estimating counterfactual\nvegetation characteristics for burned regions is explored in order to quantify\nabrupt system changes. We find that the GSC method is better at predicting\nvegetation changes than the more traditional approach of using nearby regions\nto assess wildfire impacts. We evaluate the GSC method by comparing its\npredictions of spectral vegetation indices to observations during pre-wildfire\nperiods and find improvements in correlation coefficient from $R^2 = 0.66$ to\n$R^2 = 0.93$ in Normalised Difference Vegetation Index (NDVI), from $R^2 =\n0.48$ to $R^2 = 0.81$ for Normalised Burn Ratio (NBR), and from $R^2 = 0.49$ to\n$R^2 = 0.85$ for Normalised Difference Moisture Index (NDMI). Results show\ngreater changes in NDVI, NBR, and NDMI post-fire on regions classified as\nhaving a lower Burning Index. The GSC method also reveals that wildfire effects\non vegetation can last for more than a decade post-wildfire, and in some cases\nnever return to their previous vegetation cycles within our study period.\nLastly, we discuss the usefulness of using GSC in remote sensing analyses.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP"], "pdf_url": "http://arxiv.org/pdf/2012.05140v3"}
{"entry_id": "http://arxiv.org/abs/1105.1841v1", "date": "2011-05-10", "title": "Earth's surface fluid variations and deformations from GPS and GRACE in global warming", "authors": "Shuanggen Jin, Liangjing Zhang, Guiping Feng", "abstract": "Global warming is affecting our Earth's environment. For example, sea level\nis rising with thermal expansion of water and fresh water input from the\nmelting of continental ice sheets due to human-induced global warming. However,\nobserving and modeling Earth's surface change has larger uncertainties in the\nchanging rate and the scale and distribution of impacts due to the lack of\ndirect measurements. Nowadays, the Earth observation from space provides a\nunique opportunity to monitor surface mass transfer and deformations related to\nclimate change, particularly the global positioning system (GPS) and the\nGravity Recovery and Climate Experiment (GRACE) with capability of estimating\nglobal land and ocean water mass. In this paper, the Earth's surface fluid\nvariations and deformations are derived and analyzed from global GPS and GRACE\nmeasurements. The fluids loading deformation and its interaction with Earth\nsystem, e.g., Earth Rotation, are further presented and discussed.", "journal": "", "doi": "10.1109/GeoInformatics.2011.5981143", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/1105.1841v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0406238v1", "date": "2004-06-09", "title": "Thermal infrared observations of near-Earth asteroid 2002 NY40", "authors": "T. G. Mueller, M. F. Sterzig, O. Schuetz, P. Pravec, R. Siebenmorgen", "abstract": "We obtained N-band observations of the Apollo asteroid 2002 NY40 during its\nclose Earth fly-by in August 2002 with TIMMI2 at the ESO 3.6 m telescope. The\nphotometric measurement allowed us to derive a radiometric diameter of\n0.28+/-0.03 km and an albedo of 0.34+/-0.06 through the near-Earth asteroid\nthermal model (NEATM) and a thermophysical model (TPM). The values are in\nagreement with results from radar data, visual and near-IR observations. In\nthis first comparison between these two model approaches we found that the\nempirical NEATM beaming parameter $\\eta$=1.0 corresponds to a thermal inertia\nvalues of about 100 $\\mathrm{J m^{-2} s^{-0.5} K^{-1}}$ for a typical range of\nsurface roughness, assuming an equator-on viewing angle. Our TPM analysis\nindicated that the surface of 2002 NY40 consists of rocky material with a thin\nor no dust regolith. The asteroid very likely has a prograde sense of rotation\nwith a cold terminator at the time of our observations. Although both model\napproaches can fit the thermal spectra taken at phase angles of 22$^{\\circ}$\nand 59$^{\\circ}$, we did not find a consistent model solution that describes\nall pieces of photometric and spectroscopic data. In addition to the 2002 NY40\nanalysis, we discuss the possibilities to distinguish between different models\nwith only very few photometric and/or spectroscopic measurements spread over a\nrange of phase angles.", "journal": "", "doi": "10.1051/0004-6361:20041061", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0406238v1"}
{"entry_id": "http://arxiv.org/abs/2105.13902v1", "date": "2021-05-28", "title": "Demotivate adversarial defense in remote sensing", "authors": "Adrien Chan-Hon-Tong, Gaston Lenczner, Aurelien Plyer", "abstract": "Convolutional neural networks are currently the state-of-the-art algorithms\nfor many remote sensing applications such as semantic segmentation or object\ndetection. However, these algorithms are extremely sensitive to over-fitting,\ndomain change and adversarial examples specifically designed to fool them.\nWhile adversarial attacks are not a threat in most remote sensing applications,\none could wonder if strengthening networks to adversarial attacks could also\nincrease their resilience to over-fitting and their ability to deal with the\ninherent variety of worldwide data. In this work, we study both adversarial\nretraining and adversarial regularization as adversarial defenses to this\npurpose. However, we show through several experiments on public remote sensing\ndatasets that adversarial robustness seems uncorrelated to geographic and\nover-fitting robustness.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2105.13902v1"}
{"entry_id": "http://arxiv.org/abs/2209.13418v1", "date": "2022-09-27", "title": "UAV-based Visual Remote Sensing for Automated Building Inspection", "authors": "Kushagra Srivastava, Dhruv Patel, Aditya Kumar Jha, Mohhit Kumar Jha, Jaskirat Singh, Ravi Kiran Sarvadevabhatla, Pradeep Kumar Ramancharla, Harikumar Kandath, K. Madhava Krishna", "abstract": "Unmanned Aerial Vehicle (UAV) based remote sensing system incorporated with\ncomputer vision has demonstrated potential for assisting building construction\nand in disaster management like damage assessment during earthquakes. The\nvulnerability of a building to earthquake can be assessed through inspection\nthat takes into account the expected damage progression of the associated\ncomponent and the component's contribution to structural system performance.\nMost of these inspections are done manually, leading to high utilization of\nmanpower, time, and cost. This paper proposes a methodology to automate these\ninspections through UAV-based image data collection and a software library for\npost-processing that helps in estimating the seismic structural parameters. The\nkey parameters considered here are the distances between adjacent buildings,\nbuilding plan-shape, building plan area, objects on the rooftop and rooftop\nlayout. The accuracy of the proposed methodology in estimating the\nabove-mentioned parameters is verified through field measurements taken using a\ndistance measuring sensor and also from the data obtained through Google Earth.\nAdditional details and code can be accessed from https://uvrsabi.github.io/ .", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.RO"], "pdf_url": "http://arxiv.org/pdf/2209.13418v1"}
{"entry_id": "http://arxiv.org/abs/1109.2929v1", "date": "2011-09-13", "title": "Earth-Affecting Solar Causes Observatory (EASCO): A mission at the Sun-Earth L5", "authors": "Nat Gopalswamy, Joseph M. Davila, Fr\u00e9d\u00e9ric Auch\u00e8re, Jesper Schou, Clarence Korendike, Albert Shih, Janet C. Johnston, Robert J. MacDowall, Milan Maksimovic, Edward Sittler, Adam Szabo, Richard Wesenberg, Suzanne Vennerstrom, Bernd Heber", "abstract": "Coronal mass ejections (CMEs) and corotating interaction regions (CIRs) as\nwell as their source regions are important because of their space weather\nconsequences. The current understanding of CMEs primarily comes from the Solar\nand Heliospheric Observatory (SOHO) and the Solar Terrestrial Relations\nObservatory (STEREO) missions, but these missions lacked some key measurements:\nSTEREO did not have a magnetograph; SOHO did not have in-situ magnetometer.\nSOHO and other imagers such as the Solar Mass Ejection Imager (SMEI) located on\nthe Sun-Earth line are also not well-suited to measure Earth-directed CMEs. The\nEarth-Affecting Solar Causes Observatory (EASCO) is a proposed mission to be\nlocated at the Sun-Earth L5 that overcomes these deficiencies. The mission\nconcept was recently studied at the Mission Design Laboratory (MDL), NASA\nGoddard Space Flight Center, to see how the mission can be implemented. The\nstudy found that the scientific payload (seven remote-sensing and three in-situ\ninstruments) can be readily accommodated and can be launched using an\nintermediate size vehicle; a hybrid propulsion system consisting of a Xenon ion\nthruster and hydrazine has been found to be adequate to place the payload at\nL5. Following a 2-year transfer time, a 4-year operation is considered around\nthe next solar maximum in 2025.", "journal": "", "doi": "10.1117/12.901538", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1109.2929v1"}
{"entry_id": "http://arxiv.org/abs/1803.03409v2", "date": "2018-03-09", "title": "Real-time and Seamless Monitoring of Ground-level PM2.5 Using Satellite Remote Sensing", "authors": "Tongwen Li, Chengyue Zhang, Huanfeng Shen, Qiangqiang Yuan, Liangpei Zhang", "abstract": "Satellite remote sensing has been reported to be a promising approach for the\nmonitoring of atmospheric PM2.5. However, the satellite-based monitoring of\nground-level PM2.5 is still challenging. First, the previously used\npolar-orbiting satellite observations, which can be usually acquired only once\nper day, are hard to monitor PM2.5 in real time. Second, many data gaps exist\nin satellite-derived PM2.5 due to the cloud contamination. In this paper, the\nhourly geostationary satellite (i.e., Himawari-8) observations were adopted for\nthe real-time monitoring of PM2.5 in a deep learning architecture. On this\nbasis, the satellite-derived PM2.5 in conjunction with ground PM2.5\nmeasurements are incorporated into a spatio-temporal fusion model to fill the\ndata gaps. Using Wuhan Urban Agglomeration as an example, we have successfully\nderived the real-time and seamless PM2.5 distributions. The results demonstrate\nthat Himawari-8 satellite-based deep learning model achieves a satisfactory\nperformance (out-of-sample cross-validation R2=0.80, RMSE=17.49 ug/m3) for the\nestimation of PM2.5. The missing data in satellite-derive PM2.5 are accurately\nrecovered, with R2 between recoveries and ground measurements of 0.75. Overall,\nthis study has inherently provided an effective strategy for the real-time and\nseamless monitoring of ground-level PM2.5.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1803.03409v2"}
{"entry_id": "http://arxiv.org/abs/2301.01214v2", "date": "2022-12-31", "title": "Comparison of tree-based ensemble algorithms for merging satellite and earth-observed precipitation data at the daily time scale", "authors": "Georgia Papacharalampous, Hristos Tyralis, Anastasios Doulamis, Nikolaos Doulamis", "abstract": "Merging satellite products and ground-based measurements is often required\nfor obtaining precipitation datasets that simultaneously cover large regions\nwith high density and are more accurate than pure satellite precipitation\nproducts. Machine and statistical learning regression algorithms are regularly\nutilized in this endeavour. At the same time, tree-based ensemble algorithms\nare adopted in various fields for solving regression problems with high\naccuracy and low computational cost. Still, information on which tree-based\nensemble algorithm to select for correcting satellite precipitation products\nfor the contiguous United States (US) at the daily time scale is missing from\nthe literature. In this study, we worked towards filling this methodological\ngap by conducting an extensive comparison between three algorithms of the\ncategory of interest, specifically between random forests, gradient boosting\nmachines (gbm) and extreme gradient boosting (XGBoost). We used daily data from\nthe PERSIANN (Precipitation Estimation from Remotely Sensed Information using\nArtificial Neural Networks) and the IMERG (Integrated Multi-satellitE\nRetrievals for GPM) gridded datasets. We also used earth-observed precipitation\ndata from the Global Historical Climatology Network daily (GHCNd) database. The\nexperiments referred to the entire contiguous US and additionally included the\napplication of the linear regression algorithm for benchmarking purposes. The\nresults suggest that XGBoost is the best-performing tree-based ensemble\nalgorithm among those compared...", "journal": "Hydrology 10 (2023) 50", "doi": "10.3390/hydrology10020050", "primary_category": "cs.LG", "categories": ["cs.LG", "stat.AP", "stat.CO", "stat.ME"], "pdf_url": "http://arxiv.org/pdf/2301.01214v2"}
{"entry_id": "http://arxiv.org/abs/quant-ph/0511012v1", "date": "2005-11-02", "title": "Entanglement of remote atomic qubits", "authors": "D. N. Matsukevich, T. Chaneliere, S. D. Jenkins, S. -Y. Lan, T. A. B. Kennedy, A. Kuzmich", "abstract": "We report observations of entanglement of two remote atomic qubits, achieved\nby generating an entangled state of an atomic qubit and a single photon at Site\nA, transmitting the photon to Site B in an adjacent laboratory through an\noptical fiber, and converting the photon into an atomic qubit. Entanglement of\nthe two remote atomic qubits is inferred by performing, locally, quantum state\ntransfer of each of the atomic qubits onto a photonic qubit and subsequent\nmeasurement of polarization correlations in violation of the Bell inequality\n|S| <2. We experimentally determine S =2.16 +/- 0.03. Entanglement of two\nremote atomic qubits, each qubit consisting of two independent spin wave\nexcitations, and reversible, coherent transfer of entanglement between matter\nand light, represent important advances in quantum information science.", "journal": "Physical Review Letters 96, 030405 (2006)", "doi": "10.1103/PhysRevLett.96.030405", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/quant-ph/0511012v1"}
{"entry_id": "http://arxiv.org/abs/2109.08487v2", "date": "2021-09-17", "title": "Improvement of Flood Extent Representation with Remote Sensing Data and Data Assimilation", "authors": "Thanh Huy Nguyen, Sophie Ricci, Christophe Fatras, Andrea Piacentini, Anth\u00e9a Delmotte, Emeric Lavergne, Peter Kettig", "abstract": "Flood simulation and forecast capability have been greatly improved thanks to\nadvances in data assimilation. Such an approach combines in-situ gauge\nmeasurements with numerical hydrodynamic models to correct the hydraulic states\nand reduce the uncertainties in the model parameters. However, these methods\ndepend strongly on the availability and quality of observations, thus\nnecessitating other data sources to improve the flood simulation and forecast\nperformances. Using Sentinel-1 images, a flood extent mapping method was\ncarried out by applying a Random Forest algorithm trained on past flood events\nusing manually delineated flood maps. The study area concerns a 50-km reach of\nthe Garonne Marmandaise catchment. Two recent flood events are simulated in\nanalysis and forecast modes, with a +24h lead time. This study demonstrates the\nmerits of using SAR-derived flood extent maps to validate and improve the\nforecast results based on hydrodynamic numerical models with Telemac2D-EnKF.\nQuantitative 1D and 2D metrics were computed to assess water level time-series\nand flood extents between the simulations and observations. It was shown that\nthe free run experiment without DA under-estimates flooding. On the other hand,\nthe validation of DA results with respect to independent SAR-derived flood\nextent allows to diagnose a model-observation bias that leads to over-flooding.\nOnce this bias is taken into account, DA provides a sequential correction of\narea-based friction coefficients and inflow discharge, yielding a better flood\nextent representation. This study paves the way towards a reliable solution for\nflood forecasting over poorly gauged catchments, thanks to available remote\nsensing datasets.", "journal": "", "doi": "10.1109/TGRS.2022.3147429", "primary_category": "eess.IV", "categories": ["eess.IV", "physics.data-an"], "pdf_url": "http://arxiv.org/pdf/2109.08487v2"}
{"entry_id": "http://arxiv.org/abs/1202.4946v1", "date": "2012-02-22", "title": "Depolarization remote sensing by orthogonality breaking", "authors": "Julien Fade, Mehdi Alouini", "abstract": "A new concept devoted to sensing the depolarization strength of materials\nfrom a single measurement is proposed and successfully validated on a variety\nof samples. It relies on the measurement of the orthogonality breaking between\ntwo orthogonal states of polarization after interaction with the material to be\ncharacterized. The two fields orthogonality being preserved after propagation\nin birefringent media, this concept is shown to be perfectly suited to\ndepolarization remote sensing through fibers, opening the way to real time\ndepolarization endoscopy.", "journal": "", "doi": "10.1103/PhysRevLett.109.043901", "primary_category": "physics.optics", "categories": ["physics.optics", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/1202.4946v1"}
{"entry_id": "http://arxiv.org/abs/2106.15417v1", "date": "2021-06-29", "title": "The 2019 International Women's Day event: A two-step solar flare with multiple eruptive signatures and low Earth impact", "authors": "Dumbovic, M., Veronig, A. M., Podladchikova, T., Thalmann, J. K., Chikunova, G., Dissauer, K., Magdalenic, J., Temmer, M., Guo, J., Samara, E", "abstract": "We present a detailed analysis of an eruptive event that occurred on early\n2019 March 8 in active region AR 12734, to which we refer as the International\nWomen's day event. The event under study is intriguing in several aspects: 1)\nlow-coronal eruptive signatures come in ''pairs'' (a double-peak flare, two\ncoronal dimmings, and two EUV waves); 2) although the event is characterized by\na complete chain of eruptive signatures, the corresponding coronagraphic\nsignatures are weak; 3) although the source region of the eruption is located\nclose to the center of the solar disc and the eruption is thus presumably\nEarth-directed, heliospheric signatures are very weak with little Earth-impact.\nWe analyze a number of multi-spacecraft and multi-instrument (both\nremote-sensing and in situ) observations, including Soft X-ray, (extreme-)\nultraviolet (E)UV), radio and white-light emission, as well as plasma, magnetic\nfield and particle measurements. We employ 3D NLFF modeling to investigate the\ncoronal magnetic field configuration in and around the active region, the GCS\nmodel to make a 3D reconstruction of the CME geometry and the 3D MHD numerical\nmodel EUHFORIA to model the background state of the heliosphere. Our results\nindicate two subsequent eruptions of two systems of sheared and twisted\nmagnetic fields, which merge already in the upper corona and start to evolve\nfurther out as a single entity. The large-scale magnetic field significantly\ninfluences both, the early and the interplanetary evolution of the structure.\nDuring the first eruption the stability of the overlying field was disrupted\nwhich enabled the second eruption. We find that during the propagation in the\ninterplanetary space the large-scale magnetic field, i.e. , the location of\nheliospheric current sheet between the AR and the Earth likely influences\npropagation and the evolution of the erupted structure(s).", "journal": "A&A 652, A159 (2021)", "doi": "10.1051/0004-6361/202140752", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2106.15417v1"}
{"entry_id": "http://arxiv.org/abs/2103.17035v1", "date": "2021-02-26", "title": "Hyperspectral Absorption Microscopy Using Photoacoustic Remote Sensing", "authors": "Kevan Bell, Lyazzat Mukhangaliyeva, Layla Khalili, Parsin Haji Reza", "abstract": "An improved method of remote optical absorption spectroscopy and\nhyperspectral optical absorption imaging is described which takes advantage of\nthe photoacoustic remote sensing detection architecture. A wide range of\nphotoacoustic excitation wavelengths ranging from 210 nm to 1550 nm was\nprovided by a nanosecond tunable source allowing access to various salient\nendogenous chromophores such as DNA, hemeproteins, and lipids. Sensitivity of\nthe device was demonstrated by characterizing the infrared absorption spectrum\nof water. Meanwhile, the efficacy of the technique was explored by recovering\ncell nuclei and oxygen saturation from a live chicken embryo model and by\nrecovering adipocytes from freshly resected murine adipose tissue. This\nrepresents a continued investigation into the characteristics of the\nhyperspectral photoacoustic remote sensing technique which may represent an\neffective means of non-destructive endogenous contrast characterization and\nvisualization.", "journal": "", "doi": "10.1364/OE.430403", "primary_category": "physics.bio-ph", "categories": ["physics.bio-ph", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/2103.17035v1"}
{"entry_id": "http://arxiv.org/abs/2210.09851v1", "date": "2022-10-18", "title": "Sensing Remote Bulk Defects Through Resistance Noise in a Large Area Graphene Field Effect Transistor", "authors": "Shubhadip Moulick, Rafiqul Alam, Atindra Nath Pal", "abstract": "Substrate plays a crucial role in determining transport and low frequency\nnoise behavior of graphene field effect devices. Typically, heavily dope\nSi/SiO$_2$ substrate is used to fabricate these devices for efficient gating.\nTrapping-detrapping processes closed to the graphene/substrate interface are\nthe dominant sources of resistance fluctuations in the graphene channel, while\nCoulomb fluctuations arising due to any remote charge fluctuations inside the\nbulk of the substrate are effectively screened by the heavily doped substrate.\nHere, we present electronic transport and low frequency noise characteristics\nof large area CVD graphene field effect transistor (FET) prepared on a lightly\ndoped Si/SiO$_2$ substrate (N$_A$ $\\sim$ 10$^{15}$cm$^{-3}$). Through a\nsystematic characterization of transport, noise and capacitance at various\ntemperature, we reveal that remote Si/SiO$_2$ interface can affect the charge\ntransport in graphene severely and any charge fluctuations inside bulk of the\nsilicon substrate can be sensed by the graphene channel. The resistance (R) vs.\nback gate voltage (V$_{bg}$) characteristics of the device shows a hump around\nthe depletion region formed at the SiO$_2$/Si interface, confirmed by the\ncapacitance (C) - Voltage (V) measurement. Low frequency noise measurement on\nthese fabricated devices shows a peak in the noise amplitude close to the\ndepletion region. This indicates that due to the absence of any charge layer at\nSi/SiO$_2$ interface, screening ability decreases and as a consequence, any\nfluctuations in the deep level coulomb impurities inside the silicon substrate\ncan be observed as a noise in resistance in graphene channel via mobility\nfluctuations. Noise behavior on ionic liquid gated graphene on the same\nsubstrate exhibits no such peak in noise and can be explained by the\ninterfacial trapping - detrapping processes closed to the graphene channel.", "journal": "", "doi": null, "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/2210.09851v1"}
{"entry_id": "http://arxiv.org/abs/1501.07680v2", "date": "2015-01-30", "title": "Disaggregation of Remotely Sensed Soil Moisture in Heterogeneous Landscapes using Holistic Structure based Models", "authors": "Subit Chakrabarti, Jasmeet Judge, Anand Rangarajan, Sanjay Ranka", "abstract": "In this study, a novel machine learning algorithm is presented for\ndisaggregation of satellite soil moisture (SM) based on self-regularized\nregressive models (SRRM) using high-resolution correlated information from\nauxiliary sources. It includes regularized clustering that assigns soft\nmemberships to each pixel at fine-scale followed by a kernel regression that\ncomputes the value of the desired variable at all pixels. Coarse-scale remotely\nsensed SM were disaggregated from 10km to 1km using land cover, precipitation,\nland surface temperature, leaf area index, and in-situ observations of SM. This\nalgorithm was evaluated using multi-scale synthetic observations in NC Florida\nfor heterogeneous agricultural land covers. It was found that the root mean\nsquare error (RMSE) for 96% of the pixels was less than 0.02 $m^3/m^3$. The\nclusters generated represented the data well and reduced the RMSE by upto 40%\nduring periods of high heterogeneity in land-cover and meteorological\nconditions. The Kullback Leibler divergence (KLD) between the true SM and the\ndisaggregated estimates is close to 0, for both vegetated and baresoil\nlandcovers. The disaggregated estimates were compared to those generated by the\nPrinciple of Relevant Information (PRI) method. The RMSE for the PRI\ndisaggregated estimates is higher than the RMSE for the SRRM on each day of the\nseason. The KLD of the disaggregated estimates generated by the SRRM is at\nleast four orders of magnitude lower than those for the PRI disaggregated\nestimates, while the computational time needed was reduced by three times. The\nresults indicate that the SRRM can be used for disaggregating SM with complex\nnon-linear correlations on a grid with high accuracy.", "journal": "IEEE Trans. Geosci. Remote Sens. 54 (2008) 4629-4641", "doi": "10.1109/TGRS.2016.2547389", "primary_category": "cs.CV", "categories": ["cs.CV", "68"], "pdf_url": "http://arxiv.org/pdf/1501.07680v2"}
{"entry_id": "http://arxiv.org/abs/1906.07573v1", "date": "2019-06-14", "title": "Agriculture Commodity Arrival Prediction using Remote Sensing Data: Insights and Beyond", "authors": "Gautam Prasad, Upendra Reddy Vuyyuru, Mithun Das Gupta", "abstract": "In developing countries like India agriculture plays an extremely important\nrole in the lives of the population. In India, around 80\\% of the population\ndepend on agriculture or its by-products as the primary means for employment.\nGiven large population dependency on agriculture, it becomes extremely\nimportant for the government to estimate market factors in advance and prepare\nfor any deviation from those estimates. Commodity arrivals to market is an\nextremely important factor which is captured at district level throughout the\ncountry. Historical data and short-term prediction of important variables such\nas arrivals, prices, crop quality etc. for commodities are used by the\ngovernment to take proactive steps and decide various policy measures.\n  In this paper, we present a framework to work with short timeseries in\nconjunction with remote sensing data to predict future commodity arrivals. We\ndeal with extremely high dimensional data which exceed the observation sizes by\nmultiple orders of magnitude. We use cascaded layers of dimensionality\nreduction techniques combined with regularized regression models for\nprediction. We present results to predict arrivals to major markets and state\nwide prices for `Tur' (red gram) crop in Karnataka, India. Our model\nconsistently beats popular ML techniques on many instances. Our model is\nscalable, time efficient and can be generalized to many other crops and\nregions. We draw multiple insights from the regression parameters, some of\nwhich are important aspects to consider when predicting more complex quantities\nsuch as prices in the future. We also combine the insights to generate\nimportant recommendations for different government organizations.", "journal": "", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY", "cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1906.07573v1"}
{"entry_id": "http://arxiv.org/abs/2008.11201v1", "date": "2020-08-25", "title": "Deep Active Learning in Remote Sensing for data efficient Change Detection", "authors": "V\u00edt R\u016f\u017ei\u010dka, Stefano D'Aronco, Jan Dirk Wegner, Konrad Schindler", "abstract": "We investigate active learning in the context of deep neural network models\nfor change detection and map updating. Active learning is a natural choice for\na number of remote sensing tasks, including the detection of local surface\nchanges: changes are on the one hand rare and on the other hand their\nappearance is varied and diffuse, making it hard to collect a representative\ntraining set in advance. In the active learning setting, one starts from a\nminimal set of training examples and progressively chooses informative samples\nthat are annotated by a user and added to the training set. Hence, a core\ncomponent of an active learning system is a mechanism to estimate model\nuncertainty, which is then used to pick uncertain, informative samples. We\nstudy different mechanisms to capture and quantify this uncertainty when\nworking with deep networks, based on the variance or entropy across explicit or\nimplicit model ensembles. We show that active learning successfully finds\nhighly informative samples and automatically balances the training\ndistribution, and reaches the same performance as a model supervised with a\nlarge, pre-annotated training set, with $\\approx$99% fewer annotated samples.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.11201v1"}
{"entry_id": "http://arxiv.org/abs/2010.00793v1", "date": "2020-10-02", "title": "A Parallel Down-Up Fusion Network for Salient Object Detection in Optical Remote Sensing Images", "authors": "Chongyi Li, Runmin Cong, Chunle Guo, Hua Li, Chunjie Zhang, Feng Zheng, Yao Zhao", "abstract": "The diverse spatial resolutions, various object types, scales and\norientations, and cluttered backgrounds in optical remote sensing images (RSIs)\nchallenge the current salient object detection (SOD) approaches. It is commonly\nunsatisfactory to directly employ the SOD approaches designed for nature scene\nimages (NSIs) to RSIs. In this paper, we propose a novel Parallel Down-up\nFusion network (PDF-Net) for SOD in optical RSIs, which takes full advantage of\nthe in-path low- and high-level features and cross-path multi-resolution\nfeatures to distinguish diversely scaled salient objects and suppress the\ncluttered backgrounds. To be specific, keeping a key observation that the\nsalient objects still are salient no matter the resolutions of images are in\nmind, the PDF-Net takes successive down-sampling to form five parallel paths\nand perceive scaled salient objects that are commonly existed in optical RSIs.\nMeanwhile, we adopt the dense connections to take advantage of both low- and\nhigh-level information in the same path and build up the relations of cross\npaths, which explicitly yield strong feature representations. At last, we fuse\nthe multiple-resolution features in parallel paths to combine the benefits of\nthe features with different resolutions, i.e., the high-resolution feature\nconsisting of complete structure and clear details while the low-resolution\nfeatures highlighting the scaled salient objects. Extensive experiments on the\nORSSD dataset demonstrate that the proposed network is superior to the\nstate-of-the-art approaches both qualitatively and quantitatively.", "journal": "", "doi": "10.1016/j.neucom.2020.05.108", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2010.00793v1"}
{"entry_id": "http://arxiv.org/abs/2210.06901v2", "date": "2022-10-13", "title": "Entropy Approximation by Machine Learning Regression: Application for Irregularity Evaluation of Images in Remote Sensing", "authors": "Andrei Velichko, Maksim Belyaev, Matthias P. Wagner, Alireza Taravat", "abstract": "Approximation of entropies of various types using machine learning (ML)\nregression methods are shown for the first time. The ML models presented in\nthis study define the complexity of the short time series by approximating\ndissimilar entropy techniques such as Singular value decomposition entropy\n(SvdEn), Permutation entropy (PermEn), Sample entropy (SampEn) and Neural\nNetwork entropy (NNetEn) and their 2D analogies. A new method for calculating\nSvdEn2D, PermEn2D and SampEn2D for 2D images was tested using the technique of\ncircular kernels. Training and testing datasets on the basis of Sentinel-2\nimages are presented (two training images and one hundred and ninety-eight\ntesting images). The results of entropy approximation are demonstrated using\nthe example of calculating the 2D entropy of Sentinel-2 images and R^2 metric\nevaluation. The applicability of the method for the short time series with a\nlength from N = 5 to N = 113 elements is shown. A tendency for the R^2 metric\nto decrease with an increase in the length of the time series was found. For\nSvdEn entropy, the regression accuracy is R^2 > 0.99 for N = 5 and R^2 > 0.82\nfor N = 113. The best metrics were observed for the ML_SvdEn2D and ML_NNetEn2D\nmodels. The results of the study can be used for fundamental research of\nentropy approximations of various types using ML regression, as well as for\naccelerating entropy calculations in remote sensing. The versatility of the\nmodel is shown on a synthetic chaotic time series using Planck map and logistic\nmap.", "journal": "Remote Sens. 2022, 14, 5983", "doi": "10.3390/rs14235983", "primary_category": "cs.LG", "categories": ["cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2210.06901v2"}
{"entry_id": "http://arxiv.org/abs/2212.05245v3", "date": "2022-12-10", "title": "Joint Spatio-Temporal Modeling for the Semantic Change Detection in Remote Sensing Images", "authors": "Lei Ding, Jing Zhang, Kai Zhang, Haitao Guo, Bing Liu, Lorenzo Bruzzone", "abstract": "Semantic Change Detection (SCD) refers to the task of simultaneously\nextracting the changed areas and the semantic categories (before and after the\nchanges) in Remote Sensing Images (RSIs). This is more meaningful than Binary\nChange Detection (BCD) since it enables detailed change analysis in the\nobserved areas. Previous works established triple-branch Convolutional Neural\nNetwork (CNN) architectures as the paradigm for SCD. However, it remains\nchallenging to exploit semantic information with a limited amount of change\nsamples. In this work, we investigate to jointly consider the spatio-temporal\ndependencies to improve the accuracy of SCD. First, we propose a Semantic\nChange Transformer (SCanFormer) to explicitly model the 'from-to' semantic\ntransitions between the bi-temporal RSIs. Then, we introduce a semantic\nlearning scheme to leverage the spatio-temporal constraints, which are coherent\nto the SCD task, to guide the learning of semantic changes. The resulting\nnetwork (SCanNet) significantly outperforms the baseline method in terms of\nboth detection of critical semantic changes and semantic consistency in the\nobtained bi-temporal results. It achieves the SOTA accuracy on two benchmark\ndatasets for the SCD.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2212.05245v3"}
{"entry_id": "http://arxiv.org/abs/1209.4098v2", "date": "2012-09-18", "title": "Colors of extreme exo-Earth environments", "authors": "Siddharth Hegde, Lisa Kaltenegger", "abstract": "The search for extrasolar planets has already detected rocky planets and\nseveral planetary candidates with minimum masses that are consistent with rocky\nplanets in the habitable zone of their host stars. A low-resolution spectrum in\nthe form of a color-color diagram of an exoplanet is likely to be one of the\nfirst post-detection quantities to be measured for the case of direct\ndetection. In this paper, we explore potentially detectable surface features on\nrocky exoplanets and their connection to, and importance as, a habitat for\nextremophiles, as known on Earth. Extremophiles provide us with the minimum\nknown envelope of environmental limits for life on our planet. The color of a\nplanet reveals information on its properties, especially for surface features\nof rocky planets with clear atmospheres. We use filter photometry in the\nvisible waveband as a first step in the characterization of rocky exoplanets to\nprioritize targets for follow-up spectroscopy. Many surface environments on\nEarth have characteristic albedos and occupy a different color space in the\nvisible waveband (0.4-0.9 microns) that can be distinguished remotely. These\ndetectable surface features can be linked to the extreme niches that support\nextremophiles on Earth and provide a link between geomicrobiology and\nobservational astronomy. This paper explores how filter photometry can serve as\na first step in characterizing Earth-like exoplanets for an aerobic as well as\nan anaerobic atmosphere, thereby prioritizing targets to search for atmospheric\nbiosignatures.\n  Key Words: Color-color, Habitability, Extrasolar terrestrial planet, Extreme\nenvironments, Extremophiles, Reflectivity.", "journal": "Astrobiology 13(1):47-56 (2013)", "doi": "10.1089/ast.2012.0849", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1209.4098v2"}
{"entry_id": "http://arxiv.org/abs/2003.07784v1", "date": "2020-03-17", "title": "A novel Deep Structure U-Net for Sea-Land Segmentation in Remote Sensing Images", "authors": "Pourya Shamsolmoali, Masoumeh Zareapoor, Ruili Wang, Huiyu Zhou, Jie Yang", "abstract": "Sea-land segmentation is an important process for many key applications in\nremote sensing. Proper operative sea-land segmentation for remote sensing\nimages remains a challenging issue due to complex and diverse transition\nbetween sea and lands. Although several Convolutional Neural Networks (CNNs)\nhave been developed for sea-land segmentation, the performance of these CNNs is\nfar from the expected target. This paper presents a novel deep neural network\nstructure for pixel-wise sea-land segmentation, a Residual Dense U-Net\n(RDU-Net), in complex and high-density remote sensing images. RDU-Net is a\ncombination of both down-sampling and up-sampling paths to achieve satisfactory\nresults. In each down- and up-sampling path, in addition to the convolution\nlayers, several densely connected residual network blocks are proposed to\nsystematically aggregate multi-scale contextual information. Each dense network\nblock contains multilevel convolution layers, short-range connections and an\nidentity mapping connection which facilitates features re-use in the network\nand makes full use of the hierarchical features from the original images. These\nproposed blocks have a certain number of connections that are designed with\nshorter distance backpropagation between the layers and can significantly\nimprove segmentation results whilst minimizing computational costs. We have\nperformed extensive experiments on two real datasets Google Earth and ISPRS and\ncompare the proposed RDUNet against several variations of Dense Networks. The\nexperimental results show that RDUNet outperforms the other state-of-the-art\napproaches on the sea-land segmentation tasks.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2003.07784v1"}
{"entry_id": "http://arxiv.org/abs/1010.0975v1", "date": "2010-10-05", "title": "Remote Sensing and Control of Phase Qubits", "authors": "Dale Li, Fabio C. S. da Silva, Danielle A. Braje, Raymond W. Simmonds, David P. Pappas", "abstract": "We demonstrate a remote sensing design of phase qubits by separating the\ncontrol and readout circuits from the qubit loop. This design improves\nmeasurement reliability because the control readout chip can be fabricated\nusing more robust materials and can be reused to test different qubit chips.\nTypical qubit measurements such as Rabi oscillations, spectroscopy, and\nexcited-state energy relaxation are presented.", "journal": "Applied Physics Letters 97, 102507 (2010)", "doi": "10.1063/1.3488804", "primary_category": "cond-mat.supr-con", "categories": ["cond-mat.supr-con"], "pdf_url": "http://arxiv.org/pdf/1010.0975v1"}
{"entry_id": "http://arxiv.org/abs/1901.00600v1", "date": "2019-01-03", "title": "A Remote Sensing Image Dataset for Cloud Removal", "authors": "Daoyu Lin, Guangluan Xu, Xiaoke Wang, Yang Wang, Xian Sun, Kun Fu", "abstract": "Cloud-based overlays are often present in optical remote sensing images, thus\nlimiting the application of acquired data. Removing clouds is an indispensable\npre-processing step in remote sensing image analysis. Deep learning has\nachieved great success in the field of remote sensing in recent years,\nincluding scene classification and change detection. However, deep learning is\nrarely applied in remote sensing image removal clouds. The reason is the lack\nof data sets for training neural networks. In order to solve this problem, this\npaper first proposed the Remote sensing Image Cloud rEmoving dataset (RICE).\nThe proposed dataset consists of two parts: RICE1 contains 500 pairs of images,\neach pair has images with cloud and cloudless size of 512*512; RICE2 contains\n450 sets of images, each set contains three 512*512 size images. ,\nrespectively, the reference picture without clouds, the picture of the cloud\nand the mask of its cloud. The dataset is freely available at\n\\url{https://github.com/BUPTLdy/RICE_DATASET}.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1901.00600v1"}
{"entry_id": "http://arxiv.org/abs/2002.05928v1", "date": "2020-02-14", "title": "Counting dense objects in remote sensing images", "authors": "Guangshuai Gao, Qingjie Liu, Yunhong Wang", "abstract": "Estimating accurate number of interested objects from a given image is a\nchallenging yet important task. Significant efforts have been made to address\nthis problem and achieve great progress, yet counting number of ground objects\nfrom remote sensing images is barely studied. In this paper, we are interested\nin counting dense objects from remote sensing images. Compared with object\ncounting in natural scene, this task is challenging in following factors: large\nscale variation, complex cluttered background and orientation arbitrariness.\nMore importantly, the scarcity of data severely limits the development of\nresearch in this field. To address these issues, we first construct a\nlarge-scale object counting dataset based on remote sensing images, which\ncontains four kinds of objects: buildings, crowded ships in harbor,\nlarge-vehicles and small-vehicles in parking lot. We then benchmark the dataset\nby designing a novel neural network which can generate density map of an input\nimage. The proposed network consists of three parts namely convolution block\nattention module (CBAM), scale pyramid module (SPM) and deformable convolution\nmodule (DCM). Experiments on the proposed dataset and comparisons with state of\nthe art methods demonstrate the challenging of the proposed dataset, and\nsuperiority and effectiveness of our method.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2002.05928v1"}
{"entry_id": "http://arxiv.org/abs/2204.02825v2", "date": "2022-04-06", "title": "An Empirical Study of Remote Sensing Pretraining", "authors": "Di Wang, Jing Zhang, Bo Du, Gui-Song Xia, Dacheng Tao", "abstract": "Deep learning has largely reshaped remote sensing (RS) research for aerial\nimage understanding and made a great success. Nevertheless, most of the\nexisting deep models are initialized with the ImageNet pretrained weights.\nSince natural images inevitably present a large domain gap relative to aerial\nimages, probably limiting the finetuning performance on downstream aerial scene\ntasks. This issue motivates us to conduct an empirical study of remote sensing\npretraining (RSP) on aerial images. To this end, we train different networks\nfrom scratch with the help of the largest RS scene recognition dataset up to\nnow -- MillionAID, to obtain a series of RS pretrained backbones, including\nboth convolutional neural networks (CNN) and vision transformers such as Swin\nand ViTAE, which have shown promising performance on computer vision tasks.\nThen, we investigate the impact of RSP on representative downstream tasks\nincluding scene recognition, semantic segmentation, object detection, and\nchange detection using these CNN and vision transformer backbones. Empirical\nstudy shows that RSP can help deliver distinctive performances in scene\nrecognition tasks and in perceiving RS related semantics such as \"Bridge\" and\n\"Airplane\". We also find that, although RSP mitigates the data discrepancies of\ntraditional ImageNet pretraining on RS images, it may still suffer from task\ndiscrepancies, where downstream tasks require different representations from\nscene recognition tasks. These findings call for further research efforts on\nboth large-scale pretraining datasets and effective pretraining methods. The\ncodes and pretrained models will be released at\nhttps://github.com/ViTAE-Transformer/ViTAE-Transformer-Remote-Sensing.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.02825v2"}
{"entry_id": "http://arxiv.org/abs/1701.08595v1", "date": "2017-01-30", "title": "Determining the Intrinsic CME Flux Rope Type Using Remote-sensing Solar Disk Observations", "authors": "Erika Palmerio, Emilia K. J. Kilpua, Alexander W. James, Lucie M. Green, Jens Pomoell, Alexey Isavnin, Gherardo Valori", "abstract": "A key aim in space weather research is to be able to use remote-sensing\nobservations of the solar atmosphere to extend the lead time of predicting the\ngeoeffectiveness of a coronal mass ejection (CME). In order to achieve this,\nthe magnetic structure of the CME as it leaves the Sun must be known. In this\narticle we address this issue by developing a method to determine the intrinsic\nflux rope type of a CME solely from solar disk observations. We use several\nwell known proxies for the magnetic helicity sign, the axis orientation, and\nthe axial magnetic field direction to predict the magnetic structure of the\ninterplanetary flux rope. We present two case studies: the 2 June 2011 and the\n14 June 2012 CMEs. Both of these events erupted from an active region and,\ndespite having clear in situ counterparts, their eruption characteristics were\nrelatively complex. The first event was associated with an active region\nfilament that erupted in two stages, while for the other event the eruption\noriginated from a relatively high coronal altitude and the source region did\nnot feature the presence of a filament. Our magnetic helicity sign proxies\ninclude the analysis of magnetic tongues, soft X-ray and/or EUV sigmoids,\ncoronal arcade skew, filament emission and absorption threads, and filament\nrotation. Since the inclination of the post-eruption arcades was not clear, we\nuse the tilt of the polarity inversion line to determine the flux rope axis\norientation, and coronal dimmings to determine the flux rope footpoints and,\ntherefore, the direction of the axial magnetic field. The comparison of the\nestimated intrinsic flux rope structure to in situ observations at the\nLagrangian point L1 indicated a good agreement with the predictions. Our\nresults highlight the flux rope type determination techniques that are\nparticularly useful for active region eruptions, where most geoeffective CMEs\noriginate.", "journal": "Solar Phys., 292:39, 2017", "doi": "10.1007/s11207-017-1063-x", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1701.08595v1"}
{"entry_id": "http://arxiv.org/abs/2004.03467v1", "date": "2020-04-07", "title": "Aerosol characterization using satellite remote sensing of light pollution sources at night", "authors": "Miroslav Kocifaj, Salvador Bar\u00e1", "abstract": "A demanding challenge in atmospheric research is the night-time\ncharacterization of aerosols using passive techniques, that is, by extracting\ninformation from scattered light that has not been emitted by the observer.\nSatellite observations of artificial night-time lights have been used to\nretrieve some basic integral parameters, like the aerosol optical depth.\nHowever, a thorough analysis of the scattering processes allows one to obtain\nsubstantially more detailed information on aerosol properties. In this Letter\nwe demonstrate a practicable approach for determining the aerosol particle size\nnumber distribution function in the air column, based on the measurement of the\nangular radiance distribution of the scattered light emitted by night-time\nlights of cities and towns, recorded from low Earth orbit. The method is\nself-calibrating and does not require the knowledge of the absolute city\nemissions. The input radiance data are readily available from several\nspaceborne platforms, like the VIIRS-DNB radiometer onboard the Suomi-NPP\nsatellite.", "journal": "", "doi": "10.1093/mnrasl/slaa060", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2004.03467v1"}
{"entry_id": "http://arxiv.org/abs/2210.07598v1", "date": "2022-10-14", "title": "Lightweight Stepless Super-Resolution of Remote Sensing Images via Saliency-Aware Dynamic Routing Strategy", "authors": "Hanlin Wu, Ning Ni, Libao Zhang", "abstract": "Deep learning-based algorithms have greatly improved the performance of\nremote sensing image (RSI) super-resolution (SR). However, increasing network\ndepth and parameters cause a huge burden of computing and storage. Directly\nreducing the depth or width of existing models results in a large performance\ndrop. We observe that the SR difficulty of different regions in an RSI varies\ngreatly, and existing methods use the same deep network to process all regions\nin an image, resulting in a waste of computing resources. In addition, existing\nSR methods generally predefine integer scale factors and cannot perform\nstepless SR, i.e., a single model can deal with any potential scale factor.\nRetraining the model on each scale factor wastes considerable computing\nresources and model storage space. To address the above problems, we propose a\nsaliency-aware dynamic routing network (SalDRN) for lightweight and stepless SR\nof RSIs. First, we introduce visual saliency as an indicator of region-level SR\ndifficulty and integrate a lightweight saliency detector into the SalDRN to\ncapture pixel-level visual characteristics. Then, we devise a saliency-aware\ndynamic routing strategy that employs path selection switches to adaptively\nselect feature extraction paths of appropriate depth according to the SR\ndifficulty of sub-image patches. Finally, we propose a novel lightweight\nstepless upsampling module whose core is an implicit feature function for\nrealizing mapping from low-resolution feature space to high-resolution feature\nspace. Comprehensive experiments verify that the SalDRN can achieve a good\ntrade-off between performance and complexity. The code is available at\n\\url{https://github.com/hanlinwu/SalDRN}.", "journal": "", "doi": "10.1109/TGRS.2023.3236624", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.07598v1"}
{"entry_id": "http://arxiv.org/abs/2107.05276v1", "date": "2021-07-12", "title": "Geographical Knowledge-driven Representation Learning for Remote Sensing Images", "authors": "Wenyuan Li, Keyan Chen, Hao Chen, Zhenwei Shi", "abstract": "The proliferation of remote sensing satellites has resulted in a massive\namount of remote sensing images. However, due to human and material resource\nconstraints, the vast majority of remote sensing images remain unlabeled. As a\nresult, it cannot be applied to currently available deep learning methods. To\nfully utilize the remaining unlabeled images, we propose a Geographical\nKnowledge-driven Representation learning method for remote sensing images\n(GeoKR), improving network performance and reduce the demand for annotated\ndata. The global land cover products and geographical location associated with\neach remote sensing image are regarded as geographical knowledge to provide\nsupervision for representation learning and network pre-training. An efficient\npre-training framework is proposed to eliminate the supervision noises caused\nby imaging times and resolutions difference between remote sensing images and\ngeographical knowledge. A large scale pre-training dataset Levir-KR is proposed\nto support network pre-training. It contains 1,431,950 remote sensing images\nfrom Gaofen series satellites with various resolutions. Experimental results\ndemonstrate that our proposed method outperforms ImageNet pre-training and\nself-supervised representation learning methods and significantly reduces the\nburden of data annotation on downstream tasks such as scene classification,\nsemantic segmentation, object detection, and cloud / snow detection. It\ndemonstrates that our proposed method can be used as a novel paradigm for\npre-training neural networks. Codes will be available on\nhttps://github.com/flyakon/Geographical-Knowledge-driven-Representaion-Learning.", "journal": "", "doi": "10.1109/TGRS.2021.3115569", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2107.05276v1"}
{"entry_id": "http://arxiv.org/abs/2301.07528v1", "date": "2023-01-15", "title": "Quantum-inspired tensor network for Earth science", "authors": "Soronzonbold Otgonbaatar, Dieter Kranzlm\u00fcller", "abstract": "Deep Learning (DL) is one of many successful methodologies to extract\ninformative patterns and insights from ever increasing noisy large-scale\ndatasets (in our case, satellite images). However, DL models consist of a few\nthousand to millions of training parameters, and these training parameters\nrequire tremendous amount of electrical power for extracting informative\npatterns from noisy large-scale datasets (e.g., computationally expensive).\nHence, we employ a quantum-inspired tensor network for compressing trainable\nparameters of physics-informed neural networks (PINNs) in Earth science. PINNs\nare DL models penalized by enforcing the law of physics; in particular, the law\nof physics is embedded in DL models. In addition, we apply tensor decomposition\nto HyperSpectral Images (HSIs) to improve their spectral resolution. A\nquantum-inspired tensor network is also the native formulation to efficiently\nrepresent and train quantum machine learning models on big datasets on GPU\ntensor cores. Furthermore, the key contribution of this paper is twofold: (I)\nwe reduced a number of trainable parameters of PINNs by using a\nquantum-inspired tensor network, and (II) we improved the spectral resolution\nof remotely-sensed images by employing tensor decomposition. As a benchmark\nPDE, we solved Burger's equation. As practical satellite data, we employed HSIs\nof Indian Pine, USA and of Pavia University, Italy.", "journal": "IGARSS 2023", "doi": null, "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "cs.LG", "quant-ph"], "pdf_url": "http://arxiv.org/pdf/2301.07528v1"}
{"entry_id": "http://arxiv.org/abs/1503.00701v1", "date": "2015-03-02", "title": "Better Than Earth", "authors": "Ren\u00e9 Heller", "abstract": "Do We Inhabit The Best O All Possible Worlds? German mathematician Gottfried\nLeibniz thought so, writing in 1710 that our planet, warts and all, must be the\nmost optimal one imaginable. Leibniz's idea was roundly scorned as unscientific\nwishful thinking, most notably by French author Voltaire in his magnum opus,\nCandide. Yet Leibniz might find sympathy from at least one group of scientists\n- the astronomers who have for decades treated Earth as a golden standard as\nthey search for worlds beyond our own solar system. Because earthlings still\nknow of just one living world - our own - it makes some sense to use Earth as a\ntemplate in the search for life elsewhere, such as in the most Earth-like\nregions of Mars or Jupiter's watery moon Europa. Now, however, discoveries of\npotentially habitable planets orbiting stars other than our sun - exoplanets,\nthat is - are challenging that geocentric approach.", "journal": "Scientific American, 2015, Vol. 312, Issue 1, pp. 32-39", "doi": "10.1038/scientificamerican0115-32", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1503.00701v1"}
{"entry_id": "http://arxiv.org/abs/1802.03090v1", "date": "2018-02-09", "title": "Formation of Super-Earths", "authors": "Hilke E Schlichting", "abstract": "Super-Earths are the most abundant planets known to date and are\ncharacterized by having sizes between that of Earth and Neptune, typical\norbital periods of less than 100 days and gaseous envelopes that are often\nmassive enough to significantly contribute to the planet's overall radius.\nFurthermore, super-Earths regularly appear in tightly-packed multiple-planet\nsystems, but resonant configurations in such systems are rare. This chapters\nsummarizes current super-Earth formation theories. It starts from the formation\nof rocky cores and subsequent accretion of gaseous envelopes. We follow the\nthermal evolution of newly formed super-Earths and discuss their atmospheric\nmass loss due to disk dispersal, photoevaporation, core-cooling and collisions.\nWe conclude with a comparison of observations and theoretical predictions,\nhighlighting that even super-Earths that appear as barren rocky cores today\nlikely formed with primordial hydrogen and helium envelopes and discuss some\npaths forward for the future.", "journal": "", "doi": "10.1007/978-3-319-30648-3_141-1", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1802.03090v1"}
{"entry_id": "http://arxiv.org/abs/1806.09495v1", "date": "2018-06-25", "title": "3-Phase Evolution of a Coronal Hole, Part I: 360\u00b0 remote sensing and in-situ observations", "authors": "S. G. Heinemann, M. Temmer, S. J. Hofmeister, A. M. Veronig, S. Vennerstroem", "abstract": "We investigate the evolution of a well-observed, long-lived, low-latitude\ncoronal hole (CH) over 10 solar rotations in the year 2012. By combining EUV\nimagery from STEREO-A/B and SDO we are able to track and study the entire\nevolution of the CH having a continuous 360$\\deg$ coverage of the Sun. The\nremote sensing data are investigated together with in-situ solar wind plasma\nand magnetic field measurements from STEREO-A/B, ACE and WIND. From this we\nobtain how different evolutionary states of the CH as observed in the solar\natmosphere (changes in EUV intensity and area) affect the properties of the\nassociated high-speed stream measured at $1$AU. Most distinctly pronounced for\nthe CH area, three development phases are derived: a) growing, b) maximum, and\nc) decaying phase. During these phases the CH area a) increases over a duration\nof around three months from about $1 \\cdot 10^{10} \\mathrm{km}^{2}$ to $6 \\cdot\n10^{10} \\mathrm{km}^{2}$, b) keeps a rather constant area for about one month\nof $> 9 \\cdot 10^{10} \\mathrm{km}^{2}$, and c) finally decreases in the\nfollowing three months below $1 \\cdot 10^{10} \\mathrm{km}^{2}$ until the CH\ncannot be identified anymore. The three phases manifest themselves also in the\nEUV intensity and in in-situ measured solar wind proton bulk velocity.\nInterestingly, the three phases are related to a different range in solar wind\nspeed variations and we find for the growing phase a range of\n$460-600$~km~s$^{-1}$, for the maximum phase $600-720$~km~s$^{-1}$, and for the\ndecaying phase a more irregular behavior connected to slow and fast solar wind\nspeed of $350-550$~km~s$^{-1}$.", "journal": "", "doi": "10.3847/1538-4357/aac897", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1806.09495v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/9508041v1", "date": "1995-08-09", "title": "Remote Control and Experience at ESO", "authors": "Anders Wallander, Albert Zijlstra", "abstract": "Remote observing can be broadly defined as those observations where the\nastronomer is not physically present at the telescope. Different\nimplementations presently in use include robotic telescopes, service observing\nwith or without eavesdropping and active remote observing. We briefly describe\nthe terminology, the pros and cons, the observing modes, and their\nimplementation at optical observatories.\n  In the second part of the paper, we discuss the example of remote observing\nwith ESO's NTT. Different aspects of the technical setup and the support given\nto observers, with emphasis on problems encountered, are described. With the\npresent system, we find that the observing efficiencies for local and remote\nobserving are identical: few projects still require local observations.", "journal": "", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/9508041v1"}
{"entry_id": "http://arxiv.org/abs/2010.01734v1", "date": "2020-10-05", "title": "Finding Signs of Life on Earth-like Planets: High-resolution Transmission Spectra of Earth through time around FGKM stars", "authors": "L. Kaltenegger, Z. Lin, S. Rugheimer", "abstract": "The search for life in the universe mainly uses modern Earth as a template.\nHowever, we know that Earth's atmospheric composition changed significantly\nthrough its geological evolution. Recent discoveries show that transiting,\npotentially Earth-like exoplanets orbit a wide range of host stars, which\nstrongly influence their atmospheric composition and remotely detectable\nspectra. Thus, a database for transiting terrestrial exoplanet around different\nhost stars at different geological times is a crucial missing ingredient to\nsupport observational searches for signs of life in exoplanet atmospheres.\nHere, we present the first high-resolution transmission spectra database for\nEarth-like planets, orbiting a wide range of host stars, throughout four\nrepresentative stages of Earth's history. These correspond to a prebiotic high\nCO2-world - about 3.9 billion years ago in Earth's history - and three epochs\nthrough the rise of oxygen from 0.2% to modern atmospheric levels of 21%. We\ndemonstrate that the spectral biosignature pairs O2 + CH4 and O3 + CH4 in the\natmosphere of a transiting Earth-like planet would show a remote observer that\na biosphere exists for oxygen concentrations of about 1% modern Earth's -\ncorresponding to about 1 to 2 billion years ago in Earth's history - for all\nhost stars. The full model and high-resolution transmission spectra database,\ncovering 0.4 to 20microns, for transiting exoplanets - from young prebiotic\nworlds to modern Earths-analogs - orbiting a wide range of host stars is\navailable online. It can be used as a tool to plan and optimize our observation\nstrategy, train retrieval methods, and interpret upcoming observations with\nground- and space-based telescopes.", "journal": "", "doi": "10.3847/1538-4357/abb9b2", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2010.01734v1"}
{"entry_id": "http://arxiv.org/abs/1408.3914v1", "date": "2014-08-18", "title": "The Transit Spectra of Earth and Jupiter", "authors": "Patrick G. J. Irwin, Joanna K. Barstow, Neil E. Bowles, Leigh N. Fletcher, Suzanne Aigrain, Jae-Min Lee", "abstract": "In recent years, a number of observations have been made of the transits of\n'Hot Jupiters', such as HD 189733b, which have been modelled to derive\natmospheric structure and composition. As measurement techniques improve, the\ntransit spectra of 'Super-Earths' such as GJ 1214b are becoming better\nconstrained, allowing model atmospheres to be fitted for this class of planet\nalso. While it is not yet possible to constrain the atmospheric states of small\nplanets such as the Earth or cold planets like Jupiter, this may become\npractical in the coming decades and if so, it is of interest to determine what\nwe might infer from such measurements. Here we have constructed atmospheric\nmodels of the Solar System planets from 0.4 - 15.5 microns that are consistent\nwith ground-based and satellite observations and from these calculate the\nprimary transit and secondary eclipse spectra (with respect to the Sun and\ntypical M-dwarfs) that would be observed by a 'remote observer', many light\nyears away. From these spectra we test what current retrieval models might\ninfer about their atmospheres and compare these with the 'ground truths' in\norder to assess: a) the inherent uncertainties in transit spectra observations;\nb) the relative merits of primary transit and secondary eclipse spectra; and c)\nthe advantages of directly imaged spectra. We find that secondary eclipses\nwould not give sufficient information, but that primary transits give much\nbetter determination. We find that a single transit of Jupiter in front of the\nSun could potentially be used to determine temperature and stratospheric\ncomposition, but for the Earth the mean atmospheric composition could only be\ndetermined if it were orbiting an M-dwarf. For both planets we note that direct\nimaging with sufficient nulling of the light from the parent star provides the\nbest method of determining the atmospheric properties of such planets.", "journal": "", "doi": "10.1016/j.icarus.2014.08.005", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1408.3914v1"}
{"entry_id": "http://arxiv.org/abs/1308.2592v1", "date": "2013-08-12", "title": "Sparse Command Generator for Remote Control", "authors": "Masaaki Nagahara, Daniel E. Quevedo, Jan Ostergaard, Takahiro Matsuda, Kazunori Hayashi", "abstract": "In this article, we consider remote-controlled systems, where the command\ngenerator and the controlled object are connected with a bandwidth-limited\ncommunication link. In the remote-controlled systems, efficient representation\nof control commands is one of the crucial issues because of the bandwidth\nlimitations of the link. We propose a new representation method for control\ncommands based on compressed sensing. In the proposed method, compressed\nsensing reduces the number of bits in each control signal by representing it as\na sparse vector. The compressed sensing problem is solved by an L1-L2\noptimization, which can be effectively implemented with an iterative shrinkage\nalgorithm. A design example also shows the effectiveness of the proposed\nmethod.", "journal": "The 9th IEEE International Conference on Control & Automation\n  (ICCA), pp. 1055-1059, Dec. 2011", "doi": "10.1109/ICCA.2011.6137938", "primary_category": "cs.SY", "categories": ["cs.SY", "cs.IT", "math.IT", "math.OC"], "pdf_url": "http://arxiv.org/pdf/1308.2592v1"}
{"entry_id": "http://arxiv.org/abs/2204.01807v1", "date": "2022-04-04", "title": "Revisiting Near/Remote Sensing with Geospatial Attention", "authors": "Scott Workman, M. Usman Rafique, Hunter Blanton, Nathan Jacobs", "abstract": "This work addresses the task of overhead image segmentation when auxiliary\nground-level images are available. Recent work has shown that performing joint\ninference over these two modalities, often called near/remote sensing, can\nyield significant accuracy improvements. Extending this line of work, we\nintroduce the concept of geospatial attention, a geometry-aware attention\nmechanism that explicitly considers the geospatial relationship between the\npixels in a ground-level image and a geographic location. We propose an\napproach for computing geospatial attention that incorporates geometric\nfeatures and the appearance of the overhead and ground-level imagery. We\nintroduce a novel architecture for near/remote sensing that is based on\ngeospatial attention and demonstrate its use for five segmentation tasks. The\nresults demonstrate that our method significantly outperforms the previous\nstate-of-the-art methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.01807v1"}
{"entry_id": "http://arxiv.org/abs/2209.02329v1", "date": "2022-09-06", "title": "Multimodal contrastive learning for remote sensing tasks", "authors": "Umangi Jain, Alex Wilson, Varun Gulshan", "abstract": "Self-supervised methods have shown tremendous success in the field of\ncomputer vision, including applications in remote sensing and medical imaging.\nMost popular contrastive-loss based methods like SimCLR, MoCo, MoCo-v2 use\nmultiple views of the same image by applying contrived augmentations on the\nimage to create positive pairs and contrast them with negative examples.\nAlthough these techniques work well, most of these techniques have been tuned\non ImageNet (and similar computer vision datasets). While there have been some\nattempts to capture a richer set of deformations in the positive samples, in\nthis work, we explore a promising alternative to generating positive examples\nfor remote sensing data within the contrastive learning framework. Images\ncaptured from different sensors at the same location and nearby timestamps can\nbe thought of as strongly augmented instances of the same scene, thus removing\nthe need to explore and tune a set of hand crafted strong augmentations. In\nthis paper, we propose a simple dual-encoder framework, which is pre-trained on\na large unlabeled dataset (~1M) of Sentinel-1 and Sentinel-2 image pairs. We\ntest the embeddings on two remote sensing downstream tasks: flood segmentation\nand land cover mapping, and empirically show that embeddings learnt from this\ntechnique outperform the conventional technique of collecting positive examples\nvia aggressive data augmentations.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2209.02329v1"}
{"entry_id": "http://arxiv.org/abs/2106.00493v1", "date": "2021-06-01", "title": "Biosignatures of the Earth I. Airborne spectropolarimetric detection of photosynthetic life", "authors": "C. H. Lucas Patty, Jonas G. K\u00fchn, Petar H. Lambrev, Stefano Spadaccia, H. Jens Hoeijmakers, Christoph Keller, Willeke Mulder, Vidhya Pallichadath, Olivier Poch, Frans Snik, Daphne M. Stam, Antoine Pommerol, Brice O. Demory", "abstract": "Context. Homochirality is a generic and unique property of life on Earth and\nis considered a universal and agnostic biosignature. Homochirality induces\nfractional circular polarization in the incident light that it reflects.\nBecause this circularly polarized light can be sensed remotely, it can be one\nof the most compelling candidate biosignatures in life detection missions.\nWhile there are also other sources of circular polarization, these result in\nspectrally flat signals with lower magnitude. Additionally, circular\npolarization can be a valuable tool in Earth remote sensing because the\ncircular polarization signal directly relates to vegetation physiology. Aims.\nWhile high-quality circular polarization measurements can be obtained in the\nlaboratory and under semi-static conditions in the field, there has been a\nsignificant gap to more realistic remote sensing conditions. Methods. In this\nstudy, we present sensitive circular spectropolarimetric measurements of\nvarious landscape elements taken from a fast-moving helicopter. Results. We\ndemonstrate that during flight, within mere seconds of measurements, we can\ndifferentiate (S/N>5) between grass fields, forests, and abiotic urban areas.\nImportantly, we show that with only nonzero circular polarization as a\ndiscriminant, photosynthetic organisms can even be measured in lakes.\nConclusions. Circular spectropolarimetry can be a powerful technique to detect\nlife beyond Earth, and we emphasize the potential of utilizing circular\nspectropolarimetry as a remote sensing tool to characterize and monitor in\ndetail the vegetation physiology and terrain features of Earth itself.", "journal": "A&A 651, A68 (2021)", "doi": "10.1051/0004-6361/202140845", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM", "physics.bio-ph", "q-bio.BM"], "pdf_url": "http://arxiv.org/pdf/2106.00493v1"}
{"entry_id": "http://arxiv.org/abs/2301.04136v1", "date": "2023-01-09", "title": "Focused Space Weather Strategy for Securing Earth, and Human Exploration of the Moon and Mars", "authors": "A. Posner, N. Arge, K. Cho, B. Heber, F. Effenberger, T. Y. Chen, S. Krucker, P. K\u00fchl, O. Malandraki, Y. -D. Park, A. Pulkkinen, N. Raouafi, S. K. Solanki, O. C. StCyr, R. D. Strauss", "abstract": "This white paper recognizes gaps in observations that will, when addressed,\nmuch improve solar radiation hazard and geomagnetic storm forecasting.\nRadiation forecasting depends on observations of the entire \"Solar Radiation\nHemisphere\" that we will define. Mars exploration needs strategic placement of\nradiation-relevant observations. We also suggest an orbital solution that will\nimprove geomagnetic storm forecasting through improved in situ and\nsolar/heliospheric remote sensing.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2301.04136v1"}
{"entry_id": "http://arxiv.org/abs/2301.13539v1", "date": "2023-01-31", "title": "IR Spectroscopy of Synthetic Glasses with Mercury Surface Composition: Analogs for Remote Sensing", "authors": "Andreas Morlok, Stephan Klemme, Iris Weber, Aleksandra N. Stojic, Martin Sohn, Harald Hiesinger", "abstract": "In a study to provide ground truth data for mid infrared observations of the\nsurface of Mercury with the MERTIS (Mercury Radiometer and Thermal Infrared\nSpectrometer) instrument onboard the ESA/JAXA BepiColombo mission, we have\nstudied 17 synthetic glasses. These samples have the chemical compositions of\ncharacteristic Hermean surface areas based on MESSENGER data. The samples have\nbeen characterized using optical microscopy, EMPA and Raman spectroscopy. Mid\ninfrared spectra have been obtained from polished thin sections using Micro\nFTIR, and of powdered size fractions of bulk material (0-25, 25-63, 93-125 and\n125-250 micron) in the 2.5 to 18 micron range. The synthetic glasses display\nmostly spectra typical for amorphous materials with a dominating, single\nReststrahlen Band (RB) at 9.5 micron to 10.7 micron. RB Features of crystalline\nforsterite are found in some cases at 9.5 to 10.2 micron, 10.4 to 11.2 micron,\nand at 11.9 micron. Dendritic crystallization starts at a MgO content higher\nthan 23 wt.% MgO. The Reststrahlen Bands, Christiansen Features (CF), and\nTransparency Features (TF) shift depending on the SiO2 and MgO contents. Also a\nshift of the Christiansen Feature of the glasses compared with the SCFM\n(SiO2/(SiO2+CaO+FeO+MgO)) index is observed. This shift could potentially help\ndistinguish crystalline and amorphous material in remote sensing data. A\ncomparison between the degree of polymerization of the glass and the width of\nthe characteristic strong silicate feature shows a weak positive correlation. A\ncomparison with a high-quality mid-IR spectrum of Mercury shows some moderate\nsimilarity to the results of this study, but does not explain all features.", "journal": "Icarus (2017), Volume 296, p. 123-138", "doi": "10.1016/j.icarus.2017.05.024", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2301.13539v1"}
{"entry_id": "http://arxiv.org/abs/2204.11301v1", "date": "2022-04-24", "title": "Satellite Image Time Series Analysis for Big Earth Observation Data", "authors": "Rolf Simoes, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R. Andrade, Lorena Santos, Alexandre Carvalho, Karine Ferreira", "abstract": "The development of analytical software for big Earth observation data faces\nseveral challenges. Designers need to balance between conflicting factors.\nSolutions that are efficient for specific hardware architectures can not be\nused in other environments. Packages that work on generic hardware and open\nstandards will not have the same performance as dedicated solutions. Software\nthat assumes that its users are computer programmers are flexible but may be\ndifficult to learn for a wide audience. This paper describes sits, an\nopen-source R package for satellite image time series analysis using machine\nlearning. To allow experts to use satellite imagery to the fullest extent, sits\nadopts a time-first, space-later approach. It supports the complete cycle of\ndata analysis for land classification. Its API provides a simple but powerful\nset of functions. The software works in different cloud computing environments.\nSatellite image time series are input to machine learning classifiers, and the\nresults are post-processed using spatial smoothing. Since machine learning\nmethods need accurate training data, sits includes methods for quality\nassessment of training samples. The software also provides methods for\nvalidation and accuracy measurement. The package thus comprises a production\nenvironment for big EO data analysis. We show that this approach produces high\naccuracy for land use and land cover maps through a case study in the Cerrado\nbiome, one of the world's fast moving agricultural frontiers for the year 2018.", "journal": "Remote Sensing, 13,2428, 2021", "doi": "10.3390/rs13132428", "primary_category": "cs.LG", "categories": ["cs.LG"], "pdf_url": "http://arxiv.org/pdf/2204.11301v1"}
{"entry_id": "http://arxiv.org/abs/2004.07124v2", "date": "2020-04-15", "title": "A Novel CNN-based Method for Accurate Ship Detection in HR Optical Remote Sensing Images via Rotated Bounding Box", "authors": "Linhao Li, Zhiqiang Zhou, Bo Wang, Lingjuan Miao, Hua Zong", "abstract": "Currently, reliable and accurate ship detection in optical remote sensing\nimages is still challenging. Even the state-of-the-art convolutional neural\nnetwork (CNN) based methods cannot obtain very satisfactory results. To more\naccurately locate the ships in diverse orientations, some recent methods\nconduct the detection via the rotated bounding box. However, it further\nincreases the difficulty of detection, because an additional variable of ship\norientation must be accurately predicted in the algorithm. In this paper, a\nnovel CNN-based ship detection method is proposed, by overcoming some common\ndeficiencies of current CNN-based methods in ship detection. Specifically, to\ngenerate rotated region proposals, current methods have to predefine\nmulti-oriented anchors, and predict all unknown variables together in one\nregression process, limiting the quality of overall prediction. By contrast, we\nare able to predict the orientation and other variables independently, and yet\nmore effectively, with a novel dual-branch regression network, based on the\nobservation that the ship targets are nearly rotation-invariant in remote\nsensing images. Next, a shape-adaptive pooling method is proposed, to overcome\nthe limitation of typical regular ROI-pooling in extracting the features of the\nships with various aspect ratios. Furthermore, we propose to incorporate\nmultilevel features via the spatially-variant adaptive pooling. This novel\napproach, called multilevel adaptive pooling, leads to a compact feature\nrepresentation more qualified for the simultaneous ship classification and\nlocalization. Finally, detailed ablation study performed on the proposed\napproaches is provided, along with some useful insights. Experimental results\ndemonstrate the great superiority of the proposed method in ship detection.", "journal": "[J]. IEEE Transactions on Geoscience and Remote Sensing, 2020,\n  59(1): 686-699", "doi": "10.1109/TGRS.2020.2995477", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2004.07124v2"}
{"entry_id": "http://arxiv.org/abs/1812.07770v3", "date": "2018-12-19", "title": "Mini-Unmanned Aerial Vehicle-Based Remote Sensing: Techniques, Applications, and Prospects", "authors": "Tian-Zhu Xiang, Gui-Song Xia, Liangpei Zhang", "abstract": "The past few decades have witnessed the great progress of unmanned aircraft\nvehicles (UAVs) in civilian fields, especially in photogrammetry and remote\nsensing. In contrast with the platforms of manned aircraft and satellite, the\nUAV platform holds many promising characteristics: flexibility, efficiency,\nhigh-spatial/temporal resolution, low cost, easy operation, etc., which make it\nan effective complement to other remote-sensing platforms and a cost-effective\nmeans for remote sensing. Considering the popularity and expansion of UAV-based\nremote sensing in recent years, this paper provides a systematic survey on the\nrecent advances and future prospectives of UAVs in the remote-sensing\ncommunity. Specifically, the main challenges and key technologies of\nremote-sensing data processing based on UAVs are discussed and summarized\nfirstly. Then, we provide an overview of the widespread applications of UAVs in\nremote sensing. Finally, some prospects for future work are discussed. We hope\nthis paper will provide remote-sensing researchers an overall picture of recent\nUAV-based remote sensing developments and help guide the further research on\nthis topic.", "journal": "IEEE Geoscience and Remote Sensing Magazine, 2019, Vol. 7, No. 3,\n  pp. 29-63", "doi": "10.1109/MGRS.2019.2918840", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1812.07770v3"}
{"entry_id": "http://arxiv.org/abs/1912.11149v1", "date": "2019-12-24", "title": "High-Resolution Transmission Spectra of Earth through Geological Time", "authors": "Lisa Kaltenegger, Zifan Lin, Jack Madden", "abstract": "The next generation of ground- and space-based telescopes will be able to\nobserve rocky Earth-like planets in the near future, transiting their host\nstar. We explore how the transmission spectrum of Earth changed through its\ngeological history. These transmission spectra provide a template for how to\ncharacterize an Earth-like exoplanet - from a young prebiotic world to a modern\nEarth. They also allow us to explore at what point in its evolution a distant\nobserver could identify life on our Pale Blue Dot and other worlds like it. We\nchose atmosphere models representative of five geological epochs of Earth's\nhistory, corresponding to a prebiotic high CO2-world 3.9 billion years ago\n(Ga), an anoxic world around 3.5 Ga, and 3 epochs through the rise of oxygen\nfrom 0.2 percent to present atmospheric levels of 21 percent.\n  Our transmission spectra show atmospheric spectral features, which would show\na remote observer that Earth had a biosphere since about 2 billion years ago.\nThese high-resolution transmission spectral database of Earth through\ngeological time from the VIS to the IR is available online and can be used as a\ntool to optimize our observation strategy, train retrieval methods, and\ninterpret upcoming observations with JWST, the Extremely Large Telescopes and\nfuture mission concepts like Origins, HabEx, and LUOVIR.", "journal": "", "doi": "10.3847/2041-8213/ab789f", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1912.11149v1"}
{"entry_id": "http://arxiv.org/abs/2003.07093v1", "date": "2020-03-16", "title": "AC-frequency switchable correlated transports in rare-earth perovskite nickelates", "authors": "Jikun Chen, Haifan Li, Jiaou Wang, Xinyou Ke, Binghui Ge, Jinhao Chen, Hongliang Dong, Yong Jiang, Nuofu Chen", "abstract": "Whilst electron correlations were previously recognized to trigger beyond\nconventional direct current (DC) electronic transportations (e.g.\nmetal-to-insulator transitions, bad metal, thermistors), their respective\ninfluences to the alternation current (AC) transport are largely overlooked.\nHerein, we demonstrate active regulations in the electronic functionalities of\nd-band correlated rare-earth nickelate (ReNiO3) thin films, by simply utilizing\ntheir electronic responses to AC-frequencies (fAC). Assisted by temperature\ndependent near edge X-ray absorption fine structure analysis, we discovered\npositive temperature dependences in Coulomb viscosity of ReNiO3 that moderates\ntheir AC impedance. Distinguished crosslinking among R(Real)-fAC measured in\nnearby temperatures is observed that differs to conventional oxides. It enables\nactive adjustability in correlated transports of ReNiO3, among NTCR-, TDelta-\nand PTCR- thermistors, via fAC from the electronic perspective without varying\nmaterials or device structures. The TDelta-fAC relationship can be further\nwidely adjusted via Re composition and interfacial strains. The AC-frequency\nsensitivity discovered in ReNiO3 brings in a new freedom to regulating and\nswitching the device working states beyond the present semiconductor\ntechnologies. It opens a new paradigm for enriching novel electronic\napplications catering automatic transmission or artificial intelligence in\nsensing temperatures and frequencies.", "journal": "", "doi": null, "primary_category": "cond-mat.mtrl-sci", "categories": ["cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/2003.07093v1"}
{"entry_id": "http://arxiv.org/abs/1611.03589v1", "date": "2016-11-11", "title": "Adaptive Deep Pyramid Matching for Remote Sensing Scene Classification", "authors": "Qingshan Liu, Renlong Hang, Huihui Song, Fuping Zhu, Javier Plaza, Antonio Plaza", "abstract": "Convolutional neural networks (CNNs) have attracted increasing attention in\nthe remote sensing community. Most CNNs only take the last fully-connected\nlayers as features for the classification of remotely sensed images, discarding\nthe other convolutional layer features which may also be helpful for\nclassification purposes. In this paper, we propose a new adaptive deep pyramid\nmatching (ADPM) model that takes advantage of the features from all of the\nconvolutional layers for remote sensing image classification. To this end, the\noptimal fusing weights for different convolutional layers are learned from the\ndata itself. In remotely sensed scenes, the objects of interest exhibit\ndifferent scales in distinct scenes, and even a single scene may contain\nobjects with different sizes. To address this issue, we select the CNN with\nspatial pyramid pooling (SPP-net) as the basic deep network, and further\nconstruct a multi-scale ADPM model to learn complementary information from\nmulti-scale images. Our experiments have been conducted using two widely used\nremote sensing image databases, and the results show that the proposed method\nsignificantly improves the performance when compared to other state-of-the-art\nmethods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1611.03589v1"}
{"entry_id": "http://arxiv.org/abs/physics/0006060v1", "date": "2000-06-23", "title": "Remote sensing of bubble clouds in seawater", "authors": "Piotr J. Flatau, Maria Flatau, J. R. V. Zaneveld, Curtis D. Mobley", "abstract": "We report on the influence of submerged bubble clouds on the remote sensing\nproperties of water. We show that the optical effect of bubbles on radiative\ntransfer and on the estimate of the ocean color is significant. We present a\nglobal map of the volume fraction of air in water derived from daily wind speed\ndata. This map, together with the parameterization of the microphysical\nproperties, shows the possible significance of bubble clouds on the albedo of\nincoming solar energy", "journal": "", "doi": "10.1002/qj.49712656808", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/physics/0006060v1"}
{"entry_id": "http://arxiv.org/abs/1708.05513v5", "date": "2017-08-18", "title": "Yarkovsky Drift Detections for 247 Near-Earth Asteroids", "authors": "Adam H. Greenberg, Jean-Luc Margot, Ashok K. Verma, Patrick A. Taylor, Susan E. Hodge", "abstract": "The Yarkovsky effect is a thermal process acting upon the orbits of small\ncelestial bodies, which can cause these orbits to slowly expand or contract\nwith time. The effect is subtle (da/dt ~ 10^-4 au/My for a 1 km diameter\nobject) and is thus generally difficult to measure. We analyzed both optical\nand radar astrometry for 600 near-Earth asteroids (NEAs) for the purpose of\ndetecting and quantifying the Yarkovsky effect. We present 247 NEAs with\nmeasured drift rates, which is the largest published set of Yarkovsky\ndetections. This large sample size provides an opportunity to examine the\nYarkovsky effect in a statistical manner. In particular, we describe two\nindependent population-based tests that verify the measurement of Yarkovsky\norbital drift. First, we provide observational confirmation for the Yarkovsky\neffect's theoretical size dependence of 1/D, where D is diameter. Second, we\nfind that the observed ratio of negative to positive drift rates in our sample\nis 2.34, which, accounting for bias and sampling uncertainty, implies an actual\nratio of $2.7^{+0.3}_{-0.7}$. This ratio has a vanishingly small probability of\noccurring due to chance or statistical noise. The observed ratio of retrograde\nto prograde rotators is two times lower than the ratio expected from numerical\npredictions from NEA population studies and traditional assumptions about the\nsense of rotation of NEAs originating from various main belt escape routes. We\nalso examine the efficiency with which solar energy is converted into orbital\nenergy and find a median efficiency in our sample of 12%. We interpret this\nefficiency in terms of NEA spin and thermal properties.", "journal": "", "doi": "10.3847/1538-3881/ab62a3", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1708.05513v5"}
{"entry_id": "http://arxiv.org/abs/1502.01846v1", "date": "2015-02-06", "title": "A Space Weather Information Service Based Upon Remote and In-Situ Measurements of Coronal Mass Ejections Heading for Earth", "authors": "Birgit Ritter, Arjan J. H. Meskers, Oscar Miles, Michael Ru\u00dfwurm, Stephen Scully, Andr\u00e9s Rold\u00e1n, Oliver Hartkorn, Peter J\u00fcstel, Victor R\u00e9ville, Sorina Lupu, Alexis Ruffenach", "abstract": "The Earth's magnetosphere is formed as a consequence of interaction between\nthe planet's magnetic field and the solar wind, a continuous plasma stream from\nthe Sun. A number of different solar wind phenomena have been studied over the\npast forty years with the intention of understanding and forecasting solar\nbehavior. One of these phenomena in particular, Earth-bound interplanetary\ncoronal mass ejections (CMEs), can significantly disturb the Earth's\nmagnetosphere for a short time and cause geomagnetic storms. This publication\npresents a mission concept consisting of six spacecraft that are equally spaced\nin a heliocentric orbit at 0.72 AU. These spacecraft will monitor the plasma\nproperties, the magnetic field's orientation and magnitude, and the\n3D-propagation trajectory of CMEs heading for Earth. The primary objective of\nthis mission is to increase space weather (SW) forecasting time by means of a\nnear real-time information service, that is based upon in-situ and remote\nmeasurements of the aforementioned CME properties. The mission's secondary\nobjective is to provide vital data to update scientific models. In-situ\nmeasurements are performed using a Solar Wind Analyzer instrumentation package\nand flux gate magnetometers, while coronagraphs execute remote measurements.\nCommunication with the six identical spacecraft is realized via a deep space\nnetwork consisting of six ground stations. They provide an information service\nthat is in uninterrupted contact with the spacecraft, allowing for continuous\nSW monitoring. The data will be handled by a dedicated processing center before\nbeing forwarded to the SSA Space Weather Coordination Center who will manage\nthe SW forecasting. The data processing center will additionally archive the\ndata for the scientific community. The proposed concept mission allows for\nmajor advances in SW forecasting time and the scientific modelling of SW.", "journal": "", "doi": "10.1051/swsc/2015006", "primary_category": "physics.space-ph", "categories": ["physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1502.01846v1"}
{"entry_id": "http://arxiv.org/abs/2012.10568v1", "date": "2020-12-19", "title": "Implementing Remote Observing at the JCMT", "authors": "Harriet Parsons, Jessica Dempsey, Dan Bintley, Craig Walther, Sarah Graves, William Stahm, Maren Purves, Kevin Silva, Alexis Acohido, Graham Bell, Ryan Berthold, Jamie Cookson, Vernon DeMattos, Devin Estrada, Miriam Fuchs, David Fuselier, Paul Ho, John Kuroda, Shaoliang Li, Steven Mairs, Mark Rawlings", "abstract": "The James Clerk Maxwell Telescope (JCMT) is the largest single dish telescope\nin the world focused on sub-millimeter astronomy - and it remains at the\nforefront of sub-millimeter discovery space. JCMT continues itspush for higher\nefficiency and greater science impact with a switch to fully remote operation.\nThis switch toremote operations occurred on November 1st 2019. The switch to\nremote operations should be recognized to bepart of a decade long process\ninvolving incremental changes leading to Extended Observing - observing\nbeyondthe classical night shift - and eventually to full remote operations. The\nsuccess of Remote Observing is indicatedin the number of productive hours and\ncontinued low fault rate from before and after the switch.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2012.10568v1"}
{"entry_id": "http://arxiv.org/abs/2001.08768v2", "date": "2020-01-23", "title": "Cloud and Cloud Shadow Segmentation for Remote Sensing Imagery via Filtered Jaccard Loss Function and Parametric Augmentation", "authors": "Sorour Mohajerani, Parvaneh Saeedi", "abstract": "Cloud and cloud shadow segmentation are fundamental processes in optical\nremote sensing image analysis. Current methods for cloud/shadow identification\nin geospatial imagery are not as accurate as they should, especially in the\npresence of snow and haze. This paper presents a deep learning-based framework\nfor the detection of cloud/shadow in Landsat 8 images. Our method benefits from\na convolutional neural network, Cloud-Net+ (a modification of our previously\nproposed Cloud-Net \\cite{myigarss}) that is trained with a novel loss function\n(Filtered Jaccard Loss). The proposed loss function is more sensitive to the\nabsence of foreground objects in an image and penalizes/rewards the predicted\nmask more accurately than other common loss functions. In addition, a sunlight\ndirection-aware data augmentation technique is developed for the task of cloud\nshadow detection to extend the generalization ability of the proposed model by\nexpanding existing training sets. The combination of Cloud-Net+, Filtered\nJaccard Loss function, and the proposed augmentation algorithm delivers\nsuperior results on four public cloud/shadow detection datasets. Our\nexperiments on Pascal VOC dataset exemplifies the applicability and quality of\nour proposed network and loss function in other computer vision applications.", "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and\n  Remote Sensing (JSTARS), 2021", "doi": "10.1109/JSTARS.2021.3070786", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "cs.NE", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2001.08768v2"}
{"entry_id": "http://arxiv.org/abs/2111.03845v1", "date": "2021-11-06", "title": "Multi-modal land cover mapping of remote sensing images using pyramid attention and gated fusion networks", "authors": "Qinghui Liu, Michael Kampffmeyer, Robert Jenssen, Arnt-B\u00f8rre Salberg", "abstract": "Multi-modality data is becoming readily available in remote sensing (RS) and\ncan provide complementary information about the Earth's surface. Effective\nfusion of multi-modal information is thus important for various applications in\nRS, but also very challenging due to large domain differences, noise, and\nredundancies. There is a lack of effective and scalable fusion techniques for\nbridging multiple modality encoders and fully exploiting complementary\ninformation. To this end, we propose a new multi-modality network (MultiModNet)\nfor land cover mapping of multi-modal remote sensing data based on a novel\npyramid attention fusion (PAF) module and a gated fusion unit (GFU). The PAF\nmodule is designed to efficiently obtain rich fine-grained contextual\nrepresentations from each modality with a built-in cross-level and cross-view\nattention fusion mechanism, and the GFU module utilizes a novel gating\nmechanism for early merging of features, thereby diminishing hidden\nredundancies and noise. This enables supplementary modalities to effectively\nextract the most valuable and complementary information for late feature\nfusion. Extensive experiments on two representative RS benchmark datasets\ndemonstrate the effectiveness, robustness, and superiority of the MultiModNet\nfor multi-modal land cover classification.", "journal": "", "doi": "10.1080/01431161.2022.2098078", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2111.03845v1"}
{"entry_id": "http://arxiv.org/abs/2112.04627v1", "date": "2021-12-09", "title": "Hypotheses for Triton's Plumes: New Analyses and Future Remote Sensing Tests", "authors": "Jason D. Hofgartner, Samuel P. D. Birch, Julie Castillo, Will M. Grundy, Candice J. Hansen, Alexander G. Hayes, Carly J. A. Howett, Terry A. Hurford, Emily S. Martin, Karl L. Mitchell, Tom A. Nordheim, Michael J. Poston, Louise M. Prockter, Lynnae C. Quick, Paul Schenk, Rebecca N. Schindhelm, Orkan M. Umurhan", "abstract": "At least two active plumes were observed on Neptune's moon Triton during the\nVoyager 2 flyby in 1989. Models for Triton's plumes have previously been\ngrouped into five hypotheses, two of which are primarily atmospheric phenomena\nand are generally considered unlikely, and three of which include eruptive\nprocesses and are plausible. These hypotheses are compared, including new\narguments, such as comparisons based on current understanding of Mars,\nEnceladus, and Pluto. An eruption model based on a solar-powered, solid-state\ngreenhouse effect was previously considered the leading hypothesis for Triton's\nplumes, in part due to the proximity of the plumes to the subsolar latitude\nduring the Voyager 2 flyby and the distribution of Triton's fans that are\nputatively deposits from former plumes. The other two eruption hypotheses are\npowered by internal heat, not solar insolation. Based on new analyses of the\nostensible relation between the latitude of the subsolar point on Triton and\nthe geographic locations of the plumes and fans, we argue that neither the\nlocations of the plumes nor fans are strong evidence in favor of the\nsolar-powered hypothesis. We conclude that all three eruption hypotheses should\nbe considered further. Five tests are presented that could be implemented with\nremote sensing observations from future spacecraft to confidently distinguish\namong the eruption hypotheses for Triton's plumes. The five tests are based on\nthe: (1) composition and thickness of Triton's southern hemisphere terrains,\n(2) composition of fan deposits, (3) distribution of active plumes, (4)\ndistribution of fans, and (5) surface temperature at the locations of plumes\nand/or fans. The tests are independent, but complementary, and implementable\nwith a single flyby mission such as the Trident mission concept. We note that,\nin the case of the solar-driven hypothesis, the 2030s and 2040s may be the last\n...", "journal": "", "doi": "10.1016/j.icarus.2021.114835", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2112.04627v1"}
{"entry_id": "http://arxiv.org/abs/2003.07333v2", "date": "2020-03-16", "title": "RSVQA: Visual Question Answering for Remote Sensing Data", "authors": "Sylvain Lobry, Diego Marcos, Jesse Murray, Devis Tuia", "abstract": "This paper introduces the task of visual question answering for remote\nsensing data (RSVQA). Remote sensing images contain a wealth of information\nwhich can be useful for a wide range of tasks including land cover\nclassification, object counting or detection. However, most of the available\nmethodologies are task-specific, thus inhibiting generic and easy access to the\ninformation contained in remote sensing data. As a consequence, accurate remote\nsensing product generation still requires expert knowledge. With RSVQA, we\npropose a system to extract information from remote sensing data that is\naccessible to every user: we use questions formulated in natural language and\nuse them to interact with the images. With the system, images can be queried to\nobtain high level information specific to the image content or relational\ndependencies between objects visible in the images. Using an automatic method\nintroduced in this article, we built two datasets (using low and high\nresolution data) of image/question/answer triplets. The information required to\nbuild the questions and answers is queried from OpenStreetMap (OSM). The\ndatasets can be used to train (when using supervised methods) and evaluate\nmodels to solve the RSVQA task. We report the results obtained by applying a\nmodel based on Convolutional Neural Networks (CNNs) for the visual part and on\na Recurrent Neural Network (RNN) for the natural language part to this task.\nThe model is trained on the two datasets, yielding promising results in both\ncases.", "journal": "", "doi": "10.1109/TGRS.2020.2988782", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2003.07333v2"}
{"entry_id": "http://arxiv.org/abs/2108.00688v1", "date": "2021-08-02", "title": "Self-supervised Audiovisual Representation Learning for Remote Sensing Data", "authors": "Konrad Heidler, Lichao Mou, Di Hu, Pu Jin, Guangyao Li, Chuang Gan, Ji-Rong Wen, Xiao Xiang Zhu", "abstract": "Many current deep learning approaches make extensive use of backbone networks\npre-trained on large datasets like ImageNet, which are then fine-tuned to\nperform a certain task. In remote sensing, the lack of comparable large\nannotated datasets and the wide diversity of sensing platforms impedes similar\ndevelopments. In order to contribute towards the availability of pre-trained\nbackbone networks in remote sensing, we devise a self-supervised approach for\npre-training deep neural networks. By exploiting the correspondence between\ngeo-tagged audio recordings and remote sensing imagery, this is done in a\ncompletely label-free manner, eliminating the need for laborious manual\nannotation. For this purpose, we introduce the SoundingEarth dataset, which\nconsists of co-located aerial imagery and audio samples all around the world.\nUsing this dataset, we then pre-train ResNet models to map samples from both\nmodalities into a common embedding space, which encourages the models to\nunderstand key properties of a scene that influence both visual and auditory\nappearance. To validate the usefulness of the proposed approach, we evaluate\nthe transfer learning performance of pre-trained weights obtained against\nweights obtained through other means. By fine-tuning the models on a number of\ncommonly used remote sensing datasets, we show that our approach outperforms\nexisting pre-training strategies for remote sensing imagery. The dataset, code\nand pre-trained model weights will be available at\nhttps://github.com/khdlr/SoundingEarth.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2108.00688v1"}
{"entry_id": "http://arxiv.org/abs/1910.13222v2", "date": "2019-10-29", "title": "Adversarial Example in Remote Sensing Image Recognition", "authors": "Li Chen, Guowei Zhu, Qi Li, Haifeng Li", "abstract": "With the wide application of remote sensing technology in various fields, the\naccuracy and security requirements for remote sensing images (RSIs) recognition\nare also increasing. In recent years, due to the rapid development of deep\nlearning in the field of image recognition, RSI recognition models based on\ndeep convolution neural networks (CNNs) outperform traditional hand-craft\nfeature techniques. However, CNNs also pose security issues when they show\ntheir capability of accurate classification. By adding a very small variation\nof the adversarial perturbation to the input image, the CNN model can be caused\nto produce erroneous results with extremely high confidence, and the\nmodification of the image is not perceived by the human eye. This added\nadversarial perturbation image is called an adversarial example, which poses a\nserious security problem for systems based on CNN model recognition results.\nThis paper, for the first time, analyzes adversarial example problem of RSI\nrecognition under CNN models. In the experiments, we used different attack\nalgorithms to fool multiple high-accuracy RSI recognition models trained on\nmultiple RSI datasets. The results show that RSI recognition models are also\nvulnerable to adversarial examples, and the models with different structures\ntrained on the same RSI dataset also have different vulnerabilities. For each\nRSI dataset, the number of features also affects the vulnerability of the\nmodel. Many features are good for defensive adversarial examples. Further, we\nfind that the attacked class of RSI has an attack selectivity property. The\nmisclassification of adversarial examples of the RSIs are related to the\nsimilarity of the original classes in the CNN feature space. In addition,\nadversarial examples in RSI recognition are of great significance for the\nsecurity of remote sensing applications, showing a huge potential for future\nresearch.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1910.13222v2"}
{"entry_id": "http://arxiv.org/abs/2204.07052v1", "date": "2022-04-14", "title": "CroCo: Cross-Modal Contrastive learning for localization of Earth Observation data", "authors": "Wei-Hsin Tseng, Ho\u00e0ng-\u00c2n L\u00ea, Alexandre Boulch, S\u00e9bastien Lef\u00e8vre, Dirk Tiede", "abstract": "It is of interest to localize a ground-based LiDAR point cloud on remote\nsensing imagery. In this work, we tackle a subtask of this problem, i.e. to map\na digital elevation model (DEM) rasterized from aerial LiDAR point cloud on the\naerial imagery. We proposed a contrastive learning-based method that trains on\nDEM and high-resolution optical imagery and experiment the framework on\ndifferent data sampling strategies and hyperparameters. In the best scenario,\nthe Top-1 score of 0.71 and Top-5 score of 0.81 are obtained. The proposed\nmethod is promising for feature learning from RGB and DEM for localization and\nis potentially applicable to other data sources too. Source code will be\nreleased at https://github.com/wtseng530/AVLocalization.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.07052v1"}
{"entry_id": "http://arxiv.org/abs/2011.10404v1", "date": "2020-11-20", "title": "A Remote Carrier Synchronization Technique for Coherent Distributed Remote Sensing Systems", "authors": "Juan Merlano Duncan, Liz Martinez-Marrero, Jorge Querol, Sumit Kumar, Adriano Camps, Symeon Chatzinotas, Bjorn Ottersten", "abstract": "Phase, frequency, and time synchronization are crucial requirements for many\napplications, such as multi-static remote sensing and communication systems.\nMoreover, the synchronization solution becomes even more challenging when the\nnodes are orbiting or flying on airborne or spaceborne platforms. This paper\ncompares the available technologies used for the synchronization and\ncoordination of nodes in distributed remote sensing applications. Additionally,\nthis paper proposes a general system model and identifies preliminary\nguidelines and critical elements for implementing the synchronization\nmechanisms exploiting the inter-satellite communication link. The distributed\nphase synchronization loop introduced in this work deals with the\nself-interference in a full-duplex point to point scenario by transmitting two\ncarriers at each node. All carriers appear with different frequency offsets\naround a central frequency, called the application central-frequency or the\nbeamforming frequency. This work includes a detailed analysis of the proposed\nalgorithm and the required simulations to verify its performance for different\nphase noise, AWGN, and Doppler shift scenarios.", "journal": "", "doi": null, "primary_category": "eess.SP", "categories": ["eess.SP"], "pdf_url": "http://arxiv.org/pdf/2011.10404v1"}
{"entry_id": "http://arxiv.org/abs/1810.05801v3", "date": "2018-10-13", "title": "Deep learning based cloud detection for medium and high resolution remote sensing images of different sensors", "authors": "Zhiwei Li, Huanfeng Shen, Qing Cheng, Yuhao Liu, Shucheng You, Zongyi He", "abstract": "Cloud detection is an important preprocessing step for the precise\napplication of optical satellite imagery. In this paper, we propose a deep\nlearning based cloud detection method named multi-scale convolutional feature\nfusion (MSCFF) for remote sensing images of different sensors. In the network\narchitecture of MSCFF, the symmetric encoder-decoder module, which provides\nboth local and global context by densifying feature maps with trainable\nconvolutional filter banks, is utilized to extract multi-scale and high-level\nspatial features. The feature maps of multiple scales are then up-sampled and\nconcatenated, and a novel multi-scale feature fusion module is designed to fuse\nthe features of different scales for the output. The two output feature maps of\nthe network are cloud and cloud shadow maps, which are in turn fed to binary\nclassifiers outside the model to obtain the final cloud and cloud shadow mask.\nThe MSCFF method was validated on hundreds of globally distributed optical\nsatellite images, with spatial resolutions ranging from 0.5 to 50 m, including\nLandsat-5/7/8, Gaofen-1/2/4, Sentinel-2, Ziyuan-3, CBERS-04, Huanjing-1, and\ncollected high-resolution images exported from Google Earth. The experimental\nresults show that MSCFF achieves a higher accuracy than the traditional\nrule-based cloud detection methods and the state-of-the-art deep learning\nmodels, especially in bright surface covered areas. The effectiveness of MSCFF\nmeans that it has great promise for the practical application of cloud\ndetection for multiple types of medium and high-resolution remote sensing\nimages. Our established global high-resolution cloud detection validation\ndataset has been made available online.", "journal": "ISPRS Journal of Photogrammetry and Remote Sensing, vol. 150,\n  pp.197-212, 2019", "doi": "10.1016/j.isprsjprs.2019.02.017", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1810.05801v3"}
{"entry_id": "http://arxiv.org/abs/1612.08879v3", "date": "2016-12-28", "title": "MARTA GANs: Unsupervised Representation Learning for Remote Sensing Image Classification", "authors": "Daoyu Lin, Kun Fu, Yang Wang, Guangluan Xu, Xian Sun", "abstract": "With the development of deep learning, supervised learning has frequently\nbeen adopted to classify remotely sensed images using convolutional networks\n(CNNs). However, due to the limited amount of labeled data available,\nsupervised learning is often difficult to carry out. Therefore, we proposed an\nunsupervised model called multiple-layer feature-matching generative\nadversarial networks (MARTA GANs) to learn a representation using only\nunlabeled data. MARTA GANs consists of both a generative model $G$ and a\ndiscriminative model $D$. We treat $D$ as a feature extractor. To fit the\ncomplex properties of remote sensing data, we use a fusion layer to merge the\nmid-level and global features. $G$ can produce numerous images that are similar\nto the training data; therefore, $D$ can learn better representations of\nremotely sensed images using the training data provided by $G$. The\nclassification results on two widely used remote sensing image databases show\nthat the proposed method significantly improves the classification performance\ncompared with other state-of-the-art methods.", "journal": "IEEE Geoscience and Remote Sensing Letters ( Volume: 14, Issue:\n  11, Nov. 2017 )", "doi": "10.1109/LGRS.2017.2752750", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1612.08879v3"}
{"entry_id": "http://arxiv.org/abs/1405.4557v1", "date": "2014-05-18", "title": "Detection of Ocean Glint and Ozone Absorption Using LCROSS Earth Observations", "authors": "Tyler D. Robinson, Kimberly Ennico, Victoria S. Meadows, William Sparks, D. Ben J. Bussey, Edward W. Schwieterman, Jonathan Breiner", "abstract": "The Lunar CRater Observation and Sensing Satellite (LCROSS) observed the\ndistant Earth on three occasions in 2009. These data span a range of phase\nangles, including a rare crescent phase view. For each epoch, the satellite\nacquired near-infrared and mid-infrared full-disk images, and partial-disk\nspectra at 0.26-0.65 microns (R~500) and 1.17-2.48 microns (R~50). Spectra show\nstrong absorption features due to water vapor and ozone, which is a\nbiosignature gas. We perform a significant recalibration of the UV-visible\nspectra and provide the first comparison of high-resolution visible Earth\nspectra to the NASA Astrobiology Institute's Virtual Planetary Laboratory\nthree-dimensional spectral Earth model. We find good agreement with the\nobservations, reproducing the absolute brightness and dynamic range at all\nwavelengths for all observation epochs, thus validating the model to within the\n~10% data calibration uncertainty. Data-model comparisons reveal a strong ocean\nglint signature in the crescent phase dataset, which is well matched by our\nmodel predictions throughout the observed wavelength range. This provides the\nfirst observational test of a technique that could be used to determine\nexoplanet habitability from disk-integrated observations at visible and\nnear-infrared wavelengths, where the glint signal is strongest. We examine the\ndetection of the ozone 255 nm Hartley and 400-700 nm Chappuis bands. While the\nHartley band is the strongest ozone feature in Earth's spectrum, false\npositives for its detection could exist. Finally, we discuss the implications\nof these findings for future exoplanet characterization missions.", "journal": "ApJ 787 (2014), 171", "doi": "10.1088/0004-637X/787/2/171", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1405.4557v1"}
{"entry_id": "http://arxiv.org/abs/1903.04215v2", "date": "2019-03-11", "title": "Earth-Moon VLBI project. Modeling of scientific outcome", "authors": "Sergei L. Kurdubov, Dmitry A. Pavlov, Svetlana M. Mironova, Sergey A. Kaplev", "abstract": "Modern radio astrometry has reached the limit of the resolution that is\ndetermined by the size of the Earth. The only way to overcome that limit is to\ncreate the radio telescopes outside our planet. It is proposed to build an\nautonomous remote-controlled radio observatory on the Moon. Working together\nwith the existing radio telescopes on Earth in the VLBI mode, the new\nobservatory will form an interferometer baseline up to 410000 km, enhancing the\npresent astrometric and geodetic capabilities of VLBI. We perform numerical\nsimulations of Earth-Moon VLBI observations operating simultaneously with the\ninternational VLBI network. It is shown that these observations will\nsignificantly improve the precision of determination of Moon's orbital motion,\nlibration angles, ICRF, and relativistic parameters.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1903.04215v2"}
{"entry_id": "http://arxiv.org/abs/2203.05759v1", "date": "2022-03-11", "title": "Federated Remote Physiological Measurement with Imperfect Data", "authors": "Xin Liu, Mingchuan Zhang, Ziheng Jiang, Shwetak Patel, Daniel McDuff", "abstract": "The growing need for technology that supports remote healthcare is being\nacutely highlighted by an aging population and the COVID-19 pandemic. In\nhealth-related machine learning applications the ability to learn predictive\nmodels without data leaving a private device is attractive, especially when\nthese data might contain features (e.g., photographs or videos of the body)\nthat make identifying a subject trivial and/or the training data volume is\nlarge (e.g., uncompressed video). Camera-based remote physiological sensing\nfacilitates scalable and low-cost measurement, but is a prime example of a task\nthat involves analysing high bit-rate videos containing identifiable images and\nsensitive health information. Federated learning enables privacy-preserving\ndecentralized training which has several properties beneficial for camera-based\nsensing. We develop the first mobile federated learning camera-based sensing\nsystem and show that it can perform competitively with traditional\nstate-of-the-art supervised approaches. However, in the presence of corrupted\ndata (e.g., video or label noise) from a few devices the performance of weight\naveraging quickly degrades. To address this, we leverage knowledge about the\nexpected noise profile within the video to intelligently adjust how the model\nweights are averaged on the server. Our results show that this significantly\nimproves upon the robustness of models even when the signal-to-noise ratio is\nlow", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2203.05759v1"}
{"entry_id": "http://arxiv.org/abs/2301.13422v1", "date": "2023-01-31", "title": "Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors", "authors": "Jingtao Li, Xinyu Wang, Hengwei Zhao, Shaoyu Wang, Yanfei Zhong", "abstract": "Anomaly segmentation in high spatial resolution (HSR) remote sensing imagery\nis aimed at segmenting anomaly patterns of the earth deviating from normal\npatterns, which plays an important role in various Earth vision applications.\nHowever, it is a challenging task due to the complex distribution and the\nirregular shapes of objects, and the lack of abnormal samples. To tackle these\nproblems, an anomaly segmentation model based on pixel descriptors (ASD) is\nproposed for anomaly segmentation in HSR imagery. Specifically, deep one-class\nclassification is introduced for anomaly segmentation in the feature space with\ndiscriminative pixel descriptors. The ASD model incorporates the data argument\nfor generating virtual ab-normal samples, which can force the pixel descriptors\nto be compact for normal data and meanwhile to be diverse to avoid the model\ncollapse problems when only positive samples participated in the training. In\naddition, the ASD introduced a multi-level and multi-scale feature extraction\nstrategy for learning the low-level and semantic information to make the pixel\ndescriptors feature-rich. The proposed ASD model was validated using four HSR\ndatasets and compared with the recent state-of-the-art models, showing its\npotential value in Earth vision applications.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "I.4.6; I.5.4"], "pdf_url": "http://arxiv.org/pdf/2301.13422v1"}
{"entry_id": "http://arxiv.org/abs/1904.06701v2", "date": "2019-04-14", "title": "Quantum remote sensing of angular rotation of structured objects", "authors": "Wuhong Zhang, Dongkai Zhang, Xiaodong Qiu, Lixiang Chen", "abstract": "Based on two-photon entanglement, quantum remote sensing enables the\nmeasurement and detection to be done non-locally and remotely. However, little\nattention has been paid to implement a noncontact way to sense a real objects\nangular rotation, which is a key step towards the practical applications of\nprecise measurements with entangled twisted photons. Here, we use photon pairs\nentangled in orbital angular momentum (OAM) to show that a real object's\nangular rotation can be measured non-locally. Our experiment reveals that the\nangular sensitivity of the object encoded with idler photons is proportional to\nthe measured OAM values of signal photons. It suggests potential applications\nin developing a noncontact way for angle remote sensing of an object with\ncustomized measurement resolution. Moreover, this feature may provide potential\napplication in sensing of some light-sensitive specimens when the entangled\nphoton pairs, which have significantly different wavelengths, are used, such as\none photon is infrared but the other one is visible.", "journal": "Phys. Rev. A 100, 043832 (2019)", "doi": "10.1103/PhysRevA.100.043832", "primary_category": "physics.optics", "categories": ["physics.optics", "quant-ph"], "pdf_url": "http://arxiv.org/pdf/1904.06701v2"}
{"entry_id": "http://arxiv.org/abs/2104.00704v1", "date": "2021-04-01", "title": "Remote Sensing Image Classification with the SEN12MS Dataset", "authors": "Michael Schmitt, Yu-Lun Wu", "abstract": "Image classification is one of the main drivers of the rapid developments in\ndeep learning with convolutional neural networks for computer vision. So is the\nanalogous task of scene classification in remote sensing. However, in contrast\nto the computer vision community that has long been using well-established,\nlarge-scale standard datasets to train and benchmark high-capacity models, the\nremote sensing community still largely relies on relatively small and often\napplication-dependend datasets, thus lacking comparability. With this letter,\nwe present a classification-oriented conversion of the SEN12MS dataset. Using\nthat, we provide results for several baseline models based on two standard CNN\narchitectures and different input data configurations. Our results support the\nbenchmarking of remote sensing image classification and provide insights to the\nbenefit of multi-spectral data and multi-sensor data fusion over conventional\nRGB imagery.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2104.00704v1"}
{"entry_id": "http://arxiv.org/abs/2205.08147v2", "date": "2022-05-17", "title": "Pairwise Comparison Network for Remote Sensing Scene Classification", "authors": "Zhang Yue, Zheng Xiangtao, Lu Xiaoqiang", "abstract": "Remote sensing scene classification aims to assign a specific semantic label\nto a remote sensing image. Recently, convolutional neural networks have greatly\nimproved the performance of remote sensing scene classification. However, some\nconfused images may be easily recognized as the incorrect category, which\ngenerally degrade the performance. The differences between image pairs can be\nused to distinguish image categories. This paper proposed a pairwise comparison\nnetwork, which contains two main steps: pairwise selection and pairwise\nrepresentation. The proposed network first selects similar image pairs, and\nthen represents the image pairs with pairwise representations. The\nself-representation is introduced to highlight the informative parts of each\nimage itself, while the mutual-representation is proposed to capture the subtle\ndifferences between image pairs. Comprehensive experimental results on two\nchallenging datasets (AID, NWPU-RESISC45) demonstrate the effectiveness of the\nproposed network. The codes are provided in\nhttps://github.com/spectralpublic/PCNet.git.", "journal": "IEEE Geoscience and Remote Sensing Letters, vol. 19, pp. 1-5, 2022", "doi": "10.1109/LGRS.2021.3139695", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2205.08147v2"}
{"entry_id": "http://arxiv.org/abs/1805.06561v1", "date": "2018-05-17", "title": "DeepGlobe 2018: A Challenge to Parse the Earth through Satellite Images", "authors": "Ilke Demir, Krzysztof Koperski, David Lindenbaum, Guan Pang, Jing Huang, Saikat Basu, Forest Hughes, Devis Tuia, Ramesh Raskar", "abstract": "We present the DeepGlobe 2018 Satellite Image Understanding Challenge, which\nincludes three public competitions for segmentation, detection, and\nclassification tasks on satellite images. Similar to other challenges in\ncomputer vision domain such as DAVIS and COCO, DeepGlobe proposes three\ndatasets and corresponding evaluation methodologies, coherently bundled in\nthree competitions with a dedicated workshop co-located with CVPR 2018.\n  We observed that satellite imagery is a rich and structured source of\ninformation, yet it is less investigated than everyday images by computer\nvision researchers. However, bridging modern computer vision with remote\nsensing data analysis could have critical impact to the way we understand our\nenvironment and lead to major breakthroughs in global urban planning or climate\nchange research. Keeping such bridging objective in mind, DeepGlobe aims to\nbring together researchers from different domains to raise awareness of remote\nsensing in the computer vision community and vice-versa. We aim to improve and\nevaluate state-of-the-art satellite image understanding approaches, which can\nhopefully serve as reference benchmarks for future research in the same topic.\nIn this paper, we analyze characteristics of each dataset, define the\nevaluation criteria of the competitions, and provide baselines for each task.", "journal": "", "doi": "10.1109/CVPRW.2018.00031", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1805.06561v1"}
{"entry_id": "http://arxiv.org/abs/2204.12620v1", "date": "2022-04-26", "title": "Rate-Constrained Remote Contextual Bandits", "authors": "Francesco Pase, Deniz G\u00fcnd\u00fcz, Michele Zorzi", "abstract": "We consider a rate-constrained contextual multi-armed bandit (RC-CMAB)\nproblem, in which a group of agents are solving the same contextual multi-armed\nbandit (CMAB) problem. However, the contexts are observed by a remotely\nconnected entity, i.e., the decision-maker, that updates the policy to maximize\nthe returned rewards, and communicates the arms to be sampled by the agents to\na controller over a rate-limited communications channel. This framework can be\napplied to personalized ad placement, whenever the content owner observes the\nwebsite visitors, and hence has the context, but needs to transmit the ads to\nbe shown to a controller that is in charge of placing the marketing content.\nConsequently, the rate-constrained CMAB (RC-CMAB) problem requires the study of\nlossy compression schemes for the policy to be employed whenever the constraint\non the channel rate does not allow the uncompressed transmission of the\ndecision-maker's intentions. We characterize the fundamental information\ntheoretic limits of this problem by letting the number of agents go to\ninfinity, and study the regret that can be achieved, identifying the two\ndistinct rate regions leading to linear and sub-linear regrets respectively. We\nthen analyze the optimal compression scheme achievable in the limit with\ninfinite agents, when using the forward and reverse KL divergence as distortion\nmetric. Based on this, we also propose a practical coding scheme, and provide\nnumerical results.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2204.12620v1"}
{"entry_id": "http://arxiv.org/abs/2001.09614v1", "date": "2020-01-27", "title": "Convolution Neural Network Architecture Learning for Remote Sensing Scene Classification", "authors": "Jie Chen, Haozhe Huang, Jian Peng, Jiawei Zhu, Li Chen, Wenbo Li, Binyu Sun, Haifeng Li", "abstract": "Remote sensing image scene classification is a fundamental but challenging\ntask in understanding remote sensing images. Recently, deep learning-based\nmethods, especially convolutional neural network-based (CNN-based) methods have\nshown enormous potential to understand remote sensing images. CNN-based methods\nmeet with success by utilizing features learned from data rather than features\ndesigned manually. The feature-learning procedure of CNN largely depends on the\narchitecture of CNN. However, most of the architectures of CNN used for remote\nsensing scene classification are still designed by hand which demands a\nconsiderable amount of architecture engineering skills and domain knowledge,\nand it may not play CNN's maximum potential on a special dataset. In this\npaper, we proposed an automatically architecture learning procedure for remote\nsensing scene classification. We designed a parameters space in which every set\nof parameters represents a certain architecture of CNN (i.e., some parameters\nrepresent the type of operators used in the architecture such as convolution,\npooling, no connection or identity, and the others represent the way how these\noperators connect). To discover the optimal set of parameters for a given\ndataset, we introduced a learning strategy which can allow efficient search in\nthe architecture space by means of gradient descent. An architecture generator\nfinally maps the set of parameters into the CNN used in our experiments.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2001.09614v1"}
{"entry_id": "http://arxiv.org/abs/2202.07054v3", "date": "2022-02-14", "title": "Universal Adversarial Examples in Remote Sensing: Methodology and Benchmark", "authors": "Yonghao Xu, Pedram Ghamisi", "abstract": "Deep neural networks have achieved great success in many important remote\nsensing tasks. Nevertheless, their vulnerability to adversarial examples should\nnot be neglected. In this study, we systematically analyze the universal\nadversarial examples in remote sensing data for the first time, without any\nknowledge from the victim model. Specifically, we propose a novel black-box\nadversarial attack method, namely Mixup-Attack, and its simple variant\nMixcut-Attack, for remote sensing data. The key idea of the proposed methods is\nto find common vulnerabilities among different networks by attacking the\nfeatures in the shallow layer of a given surrogate model. Despite their\nsimplicity, the proposed methods can generate transferable adversarial examples\nthat deceive most of the state-of-the-art deep neural networks in both scene\nclassification and semantic segmentation tasks with high success rates. We\nfurther provide the generated universal adversarial examples in the dataset\nnamed UAE-RS, which is the first dataset that provides black-box adversarial\nsamples in the remote sensing field. We hope UAE-RS may serve as a benchmark\nthat helps researchers to design deep neural networks with strong resistance\ntoward adversarial attacks in the remote sensing field. Codes and the UAE-RS\ndataset are available online (https://github.com/YonghaoXu/UAE-RS).", "journal": "IEEE Trans. Geos. Remote Sens., vol. 60, pp. 1-15, 2022", "doi": "10.1109/TGRS.2022.3156392", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2202.07054v3"}
{"entry_id": "http://arxiv.org/abs/2211.08044v1", "date": "2022-11-15", "title": "Backdoor Attacks for Remote Sensing Data with Wavelet Transform", "authors": "Nikolaus Dr\u00e4ger, Yonghao Xu, Pedram Ghamisi", "abstract": "Recent years have witnessed the great success of deep learning algorithms in\nthe geoscience and remote sensing realm. Nevertheless, the security and\nrobustness of deep learning models deserve special attention when addressing\nsafety-critical remote sensing tasks. In this paper, we provide a systematic\nanalysis of backdoor attacks for remote sensing data, where both scene\nclassification and semantic segmentation tasks are considered. While most of\nthe existing backdoor attack algorithms rely on visible triggers like squared\npatches with well-designed patterns, we propose a novel wavelet transform-based\nattack (WABA) method, which can achieve invisible attacks by injecting the\ntrigger image into the poisoned image in the low-frequency domain. In this way,\nthe high-frequency information in the trigger image can be filtered out in the\nattack, resulting in stealthy data poisoning. Despite its simplicity, the\nproposed method can significantly cheat the current state-of-the-art deep\nlearning models with a high attack success rate. We further analyze how\ndifferent trigger images and the hyper-parameters in the wavelet transform\nwould influence the performance of the proposed method. Extensive experiments\non four benchmark remote sensing datasets demonstrate the effectiveness of the\nproposed method for both scene classification and semantic segmentation tasks\nand thus highlight the importance of designing advanced backdoor defense\nalgorithms to address this threat in remote sensing scenarios. The code will be\navailable online at \\url{https://github.com/ndraeger/waba}.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2211.08044v1"}
{"entry_id": "http://arxiv.org/abs/1501.01407v3", "date": "2015-01-07", "title": "Remote State Preparation for Quantum Fields", "authors": "Ran Ber, Erez Zohar", "abstract": "Remote state preparation is generation of a desired state by a remote\nobserver. In spite of causality, it is well known, according to the\nReeh-Schlieder theorem, that it is possible for relativistic quantum field\ntheories, and a \"physical\" process achieving this task, involving\nsuperoscillatory functions, has recently been introduced. In this work we deal\nwith non-relativistic fields, and show that remote state preparation is also\npossible for them, hence obtaining a Reeh-Schlieder-like result for general\nfields. Interestingly, in the nonrelativistic case, the process may rely on\ncompletely different resources than the ones used in the relativistic case.", "journal": "", "doi": "10.1007/s10701-016-0001-3", "primary_category": "quant-ph", "categories": ["quant-ph", "hep-th", "math-ph", "math.MP"], "pdf_url": "http://arxiv.org/pdf/1501.01407v3"}
{"entry_id": "http://arxiv.org/abs/1002.1148v1", "date": "2010-02-05", "title": "A Comparative Study of Removal Noise from Remote Sensing Image", "authors": "Salem Saleh Al-amri, N. V. Kalyankar, S. D. Khamitkar", "abstract": "This paper attempts to undertake the study of three types of noise such as\nSalt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).\nDifferent noise densities have been removed between 10% to 60% by using five\ntypes of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian\nFilter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The\nsame is applied to the Saturn remote sensing image and they are compared with\none another. The comparative study is conducted with the help of Mean Square\nErrors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base\nmethod for removal of noise from remote sensing image.", "journal": "International Journal of Computer Science Issues, IJCSI, Vol. 7,\n  Issue 1, No. 1, January 2010,\n  http://ijcsi.org/articles/A-Comparative-Study-of-Removal-Noise-from-Remote-Sensing-Image.php", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1002.1148v1"}
{"entry_id": "http://arxiv.org/abs/1906.11514v1", "date": "2019-06-27", "title": "Coaxial nanowires as plasmon-mediated remote nanosensors", "authors": "Daniel Funes-Hernando, Mario Pelaez-Fernandez, Dominik Winterauer, Jean-Yves Mevellec, Raul Arenal, Tim Batten, Bernard Humbert, Jean Luc Duvail", "abstract": "This study reports on the plasmon-mediated remote Raman sensing promoted by\nspecially designed coaxial nanowires. This unusual geometry for Raman study is\nbased on the separation, by several micrometres, of the excitation laser spot,\non one tip of the nanowire, and the Raman detection at the other tip. The very\nweak efficiency of Raman emission makes it challenging in a remote\nconfiguration. For the proof-of-concept, we designed coaxial nanowires\nconsisting in a gold core to propagate the surface plasmon polaritons and a\nRaman-emitting shell of poly(3,4-ethylene-dioxythiophene). The success of the\nfabrication was demonstrated by correlating, for the same single nanowire, a\nmorphological analysis by electron microscopy and Raman spectroscopy analysis.\nImportantly for probing remote-Raman effect, the original hard template-based\nprocess allows to control the location of the polymer shell all along the\nnanowire, or only close to one or the two nanowire tips. Such all-in-one single\nnanowires could have applications in the remote detection of photo-degradable\nsubstances and for exploring 1D nanosources for integrated photonic and\nplasmonic systems.", "journal": "Funes Hernando, D. et al. Coaxial nanowires as plasmon mediated\n  remote nanosensors. Nanoscale 10, 6437 6444 2018", "doi": "10.1039/C8NR00125A", "primary_category": "physics.app-ph", "categories": ["physics.app-ph", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/1906.11514v1"}
{"entry_id": "http://arxiv.org/abs/1908.06381v1", "date": "2019-08-18", "title": "Long-Duration Fully Autonomous Operation of Rotorcraft Unmanned Aerial Systems for Remote-Sensing Data Acquisition", "authors": "Danylo Malyuta, Christian Brommer, Daniel Hentzen, Thomas Stastny, Roland Siegwart, Roland Brockers", "abstract": "Recent applications of unmanned aerial systems (UAS) to precision agriculture\nhave shown increased ease and efficiency in data collection at precise remote\nlocations. However, further enhancement of the field requires operation over\nlong periods of time, e.g. days or weeks. This has so far been impractical due\nto the limited flight times of such platforms and the requirement of humans in\nthe loop for operation. To overcome these limitations, we propose a fully\nautonomous rotorcraft UAS that is capable of performing repeated flights for\nlong-term observation missions without any human intervention. We address two\nkey technologies that are critical for such a system: full platform autonomy to\nenable mission execution independently from human operators and the ability of\nvision-based precision landing on a recharging station for automated energy\nreplenishment. High-level autonomous decision making is implemented as a\nhierarchy of master and slave state machines. Vision-based precision landing is\nenabled by estimating the landing pad's pose using a bundle of AprilTag\nfiducials configured for detection from a wide range of altitudes. We provide\nan extensive evaluation of the landing pad pose estimation accuracy as a\nfunction of the bundle's geometry. The functionality of the complete system is\ndemonstrated through two indoor experiments with a duration of 11 and 10.6\nhours, and one outdoor experiment with a duration of 4 hours. The UAS executed\n16, 48 and 22 flights respectively during these experiments. In the outdoor\nexperiment, the ratio between flying to collect data and charging was 1 to 10,\nwhich is similar to past work in this domain. All flights were fully autonomous\nwith no human in the loop. To our best knowledge this is the first research\npublication about the long-term outdoor operation of a quadrotor system with no\nhuman interaction.", "journal": "J Field Robotics (2019) 1-21", "doi": "10.1002/rob.21898", "primary_category": "cs.RO", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "pdf_url": "http://arxiv.org/pdf/1908.06381v1"}
{"entry_id": "http://arxiv.org/abs/1610.04371v1", "date": "2016-10-14", "title": "Aboveground biomass mapping in French Guiana by combining remote sensing, forest inventories and environmental data", "authors": "Ibrahim Fayad, Nicolas Baghdadi, St\u00e9phane Guitet, Jean-St\u00e9phane Bailly, Bruno H\u00e9rault, Val\u00e9ry Gond, Mahmoud Hajj, Dinh Ho Tong Minh", "abstract": "Mapping forest aboveground biomass (AGB) has become an important task,\nparticularly for the reporting of carbon stocks and changes. AGB can be mapped\nusing synthetic aperture radar data (SAR) or passive optical data. However,\nthese data are insensitive to high AGB levels (\\textgreater{}150 Mg/ha, and\n\\textgreater{}300 Mg/ha for P-band), which are commonly found in tropical\nforests. Studies have mapped the rough variations in AGB by combining optical\nand environmental data at regional and global scales. Nevertheless, these maps\ncannot represent local variations in AGB in tropical forests. In this paper, we\nhypothesize that the problem of misrepresenting local variations in AGB and AGB\nestimation with good precision occurs because of both methodological limits\n(signal saturation or dilution bias) and a lack of adequate calibration data in\nthis range of AGB values. We test this hypothesis by developing a calibrated\nregression model to predict variations in high AGB values (mean\n\\textgreater{}300 Mg/ha) in French Guiana by a methodological approach for\nspatial extrapolation with data from the optical geoscience laser altimeter\nsystem (GLAS), forest inventories, radar, optics, and environmental variables\nfor spatial inter-and extrapolation. Given their higher point count, GLAS data\nallow a wider coverage of AGB values. We find that the metrics from GLAS\nfootprints are correlated with field AGB estimations (R 2 =0.54, RMSE=48.3\nMg/ha) with no bias for high values. First, predictive models, including\nremote-sensing, environmental variables and spatial correlation functions,\nallow us to obtain \"wall-to-wall\" AGB maps over French Guiana with an RMSE for\nthe in situ AGB estimates of ~51 Mg/ha and R${}^2$=0.48 at a 1-km grid size. We\nconclude that a calibrated regression model based on GLAS with dependent\nenvironmental data can produce good AGB predictions even for high AGB values if\nthe calibration data fit the AGB range. We also demonstrate that small temporal\nand spatial mismatches between field data and GLAS footprints are not a problem\nfor regional and global calibrated regression models because field data aim to\npredict large and deep tendencies in AGB variations from environmental\ngradients and do not aim to represent high but stochastic and temporally\nlimited variations from forest dynamics. Thus, we advocate including a greater\nvariety of data, even if less precise and shifted, to better represent high AGB\nvalues in global models and to improve the fitting of these models for high\nvalues.", "journal": "International Journal of Applied Earth Observation and\n  Geoinformation, Elsevier, 2016, 52, pp.502 - 514", "doi": "10.1016/j.jag.2016.07.015", "primary_category": "stat.ML", "categories": ["stat.ML", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/1610.04371v1"}
{"entry_id": "http://arxiv.org/abs/2102.12185v1", "date": "2021-02-24", "title": "Radial Evolution of the April 2020 Stealth Coronal Mass Ejection between 0.8 and 1 AU -- A Comparison of Forbush Decreases at Solar Orbiter and Earth", "authors": "Johan L. Freiherr von Forstner, Mateja Dumbovi\u0107, Christian M\u00f6stl, Jingnan Guo, Athanasios Papaioannou, Robert Elftmann, Zigong Xu, Jan Christoph Terasa, Alexander Kollhoff, Robert F. Wimmer-Schweingruber, Javier Rodr\u00edguez-Pacheco, Andreas J. Weiss, J\u00fcrgen Hinterreiter, Tanja Amerstorfer, Maike Bauer, Anatoly V. Belov, Maria A. Abunina, Timothy Horbury, Emma E. Davies, Helen O'Brien, Robert C. Allen, G. Bruce Andrews, Lars Berger, Sebastian Boden, Ignacio Cernuda Cangas, Sandra Eldrum, Francisco Espinosa Lara, Ra\u00fal G\u00f3mez Herrero, John R. Hayes, George C. Ho, Shrinivasrao R. Kulkarni, W. Jeffrey Lees, C\u00e9sar Mart\u00edn, Glenn M. Mason, Daniel Pacheco, Manuel Prieto Mateo, Ali Ravanbakhsh, Oscar Rodr\u00edguez Polo, Sebasti\u00e1n S\u00e1nchez Prieto, Charles E. Schlemm, Helmut Seifert, Kush Tyagi, Mahesh Yedla", "abstract": "Aims. We present observations of the first coronal mass ejection (CME)\nobserved at the Solar Orbiter spacecraft on April 19, 2020, and the associated\nForbush decrease (FD) measured by its High Energy Telescope (HET). This CME is\na multispacecraft event also seen near Earth the next day. Methods. We\nhighlight the capabilities of HET for observing small short-term variations of\nthe galactic cosmic ray count rate using its single detector counters. The\nanalytical ForbMod model is applied to the FD measurements to reproduce the\nForbush decrease at both locations. Input parameters for the model are derived\nfrom both in situ and remote-sensing observations of the CME. Results. The very\nslow (~350 km/s) stealth CME caused a FD with an amplitude of 3 % in the\nlow-energy cosmic ray measurements at HET and 2 % in a comparable channel of\nthe Cosmic Ray Telescope for the Effects of Radiation (CRaTER) on the Lunar\nReconnaissance Orbiter, as well as a 1 % decrease in neutron monitor\nmeasurements. Significant differences are observed in the expansion behavior of\nthe CME at different locations, which may be related to influence of the\nfollowing high speed solar wind stream. Under certain assumptions, ForbMod is\nable to reproduce the observed FDs in low-energy cosmic ray measurements from\nHET as well as CRaTER, but with the same input parameters, the results do not\nagree with the FD amplitudes at higher energies measured by neutron monitors on\nEarth. We study these discrepancies and provide possible explanations.\nConclusions. This study highlights that the novel measurements of the Solar\nOrbiter can be coordinated with other spacecraft to improve our understanding\nof space weather in the inner heliosphere. Multi-spacecraft observations\ncombined with data-based modeling are also essential to understand the\npropagation and evolution of CMEs as well as their space weather impacts.", "journal": "A&A 656, A1 (2021)", "doi": "10.1051/0004-6361/202039848", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "astro-ph.EP", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2102.12185v1"}
{"entry_id": "http://arxiv.org/abs/1705.07077v1", "date": "2017-05-19", "title": "What do We Learn by Semantic Scene Understanding for Remote Sensing imagery in CNN framework?", "authors": "Haifeng Li, Jian Peng, Chao Tao, Jie Chen, Min Deng", "abstract": "Recently, deep convolutional neural network (DCNN) achieved increasingly\nremarkable success and rapidly developed in the field of natural image\nrecognition. Compared with the natural image, the scale of remote sensing image\nis larger and the scene and the object it represents are more macroscopic. This\nstudy inquires whether remote sensing scene and natural scene recognitions\ndiffer and raises the following questions: What are the key factors in remote\nsensing scene recognition? Is the DCNN recognition mechanism centered on object\nrecognition still applicable to the scenarios of remote sensing scene\nunderstanding? We performed several experiments to explore the influence of the\nDCNN structure and the scale of remote sensing scene understanding from the\nperspective of scene complexity. Our experiment shows that understanding a\ncomplex scene depends on an in-depth network and multiple-scale perception.\nUsing a visualization method, we qualitatively and quantitatively analyze the\nrecognition mechanism in a complex remote sensing scene and demonstrate the\nimportance of multi-objective joint semantic support.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1705.07077v1"}
{"entry_id": "http://arxiv.org/abs/2007.08568v1", "date": "2020-07-16", "title": "The Crucial Role of Ground- and Space-Based Remote Sensing Studies of Cometary Volatiles in the Next Decade (2023-2032)", "authors": "Nathan X. Roth, Dennis Bodewits, Boncho Bonev, Anita Cochran, Michael Combi, Martin Cordiner, Neil Dello Russo, Michael DiSanti, Sara Faggi, Lori Feaga, Yan Fernandez, Manuela Lippi, Adam McKay, Matthew Knight, Stefanie Milam, John W. Noonan, Anthony Remijan, Geronimo Villanueva", "abstract": "The study of comets affords a unique window into the birth, infancy, and\nsubsequent history of the solar system. There is strong evidence that comets\nincorporated pristine interstellar material as well as processed nebular\nmatter, providing insights into the composition and prevailing conditions over\nwide swaths of the solar nebula at the time of planet formation. Dynamically\nnew Oort cloud comets harbor primitive ices that have been stored thousands of\nastronomical units from the Sun and have suffered minimal thermal or radiative\nprocessing since their emplacement ~4.5 Gyr ago. Periodic, more dynamically\nevolved comets such as the Halley-type and Jupiter-family comets reveal the\neffects of lives spent over a range of heliocentric distances, including\nperihelion passages into the very inner solar system. Systematically\ncharacterizing the information imprinted in the native ice compositions of\nthese objects is critical to understanding the formation and evolution of the\nsolar system, the presence of organic matter and water on the terrestrial\nplanets, the chemistry present in protoplanetary disks around other stars, and\nthe nature of interstellar interlopers such as 2I/Borisov. Although comet\nrendezvous and sample return missions can provide remarkable insights into the\nproperties of a few short-period comets, the on-sky capacity necessary to\nperform population-level comet studies while simultaneously remaining sensitive\nto the paradigm-challenging science that individual comets can reveal can only\nbe provided by remote sensing observations. Here we report the state-of-the-art\nin ground- and space-based remote sensing of cometary volatiles, review the\nremarkable progress of the previous decade, articulate the pressing questions\nthat ground- and space-based work will address over the next ten years, and\nadvocate for the technology and resources necessary to realize these\naspirations.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2007.08568v1"}
{"entry_id": "http://arxiv.org/abs/1904.12586v1", "date": "2019-04-03", "title": "Robust object extraction from remote sensing data", "authors": "Sophie Crommelinck, Mila Koeva, Michael Ying Yang, George Vosselman", "abstract": "The extraction of object outlines has been a research topic during the last\ndecades. In spite of advances in photogrammetry, remote sensing and computer\nvision, this task remains challenging due to object and data complexity. The\ndevelopment of object extraction approaches is promoted through publically\navailable benchmark datasets and evaluation frameworks. Many aspects of\nperformance evaluation have already been studied. This study collects the best\npractices from literature, puts the various aspects in one evaluation\nframework, and demonstrates its usefulness to a case study on mapping object\noutlines. The evaluation framework includes five dimensions: the robustness to\nchanges in resolution, input, location, parameters, and application. Examples\nfor investigating these dimensions are provided, as well as accuracy measures\nfor their qualitative analysis. The measures consist of time efficiency and a\nprocedure for line-based accuracy assessment regarding quantitative\ncompleteness and spatial correctness. The delineation approach to which the\nevaluation framework is applied, was previously introduced and is substantially\nimproved in this study.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1904.12586v1"}
{"entry_id": "http://arxiv.org/abs/2302.10473v1", "date": "2023-02-21", "title": "Oriented Object Detection in Optical Remote Sensing Images: A Survey", "authors": "Kun Wang, Zhang Li, Ang Su, Zi Wang", "abstract": "Oriented object detection is one of the most fundamental and challenging\ntasks in remote sensing, aiming at locating the oriented objects of numerous\npredefined object categories. Recently, deep learning based methods have\nachieved remarkable performance in detecting oriented objects in remote sensing\nimagery. However, a thorough review of the literature in remote sensing has not\nyet emerged. Therefore, we give a comprehensive survey of recent advances and\ncover many aspects of oriented object detection, including problem definition,\ncommonly used datasets, evaluation protocols, detection frameworks, oriented\nobject representations, and feature representations. Besides, we analyze and\ndiscuss state-of-the-art methods. We finally discuss future research directions\nto put forward some useful research guidance. We believe that this survey shall\nbe valuable to researchers across academia and industry.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2302.10473v1"}
{"entry_id": "http://arxiv.org/abs/2205.04160v1", "date": "2022-05-09", "title": "Improved-Flow Warp Module for Remote Sensing Semantic Segmentation", "authors": "Yinjie Zhang, Yi Liu, Wei Guo", "abstract": "Remote sensing semantic segmentation aims to assign automatically each pixel\non aerial images with specific label. In this letter, we proposed a new module,\ncalled improved-flow warp module (IFWM), to adjust semantic feature maps across\ndifferent scales for remote sensing semantic segmentation. The improved-flow\nwarp module is applied along with the feature extraction process in the\nconvolutional neural network. First, IFWM computes the offsets of pixels by a\nlearnable way, which can alleviate the misalignment of the multi-scale\nfeatures. Second, the offsets help with the low-resolution deep feature\nup-sampling process to improve the feature accordance, which boosts the\naccuracy of semantic segmentation. We validate our method on several remote\nsensing datasets, and the results prove the effectiveness of our method..", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2205.04160v1"}
{"entry_id": "http://arxiv.org/abs/1603.09707v2", "date": "2016-03-31", "title": "Capacity of Remotely Powered Communication", "authors": "Dor Shaviv, Ayfer \u00d6zg\u00fcr, Haim H. Permuter", "abstract": "Motivated by recent developments in wireless power transfer, we study\ncommunication with a remotely powered transmitter. We propose an\ninformation-theoretic model where a charger can dynamically decide on how much\npower to transfer to the transmitter based on its side information regarding\nthe communication, while the transmitter needs to dynamically adapt its coding\nstrategy to its instantaneous energy state, which in turn depends on the\nactions previously taken by the charger. We characterize the capacity as an\n$n$-letter mutual information rate under various levels of side information\navailable at the charger. When the charger is finely tunable to different\nenergy levels, referred to as a \"precision charger\", we show that these\nexpressions reduce to single-letter form and there is a simple and intuitive\njoint charging and coding scheme achieving capacity. The precision charger\nscenario is motivated by the observation that in practice the transferred\nenergy can be controlled by simply changing the amplitude of the beamformed\nsignal. When the charger does not have sufficient precision, for example when\nit is restricted to use a few discrete energy levels, we show that the\ncomputation of the $n$-letter capacity can be cast as a Markov decision process\nif the channel is noiseless. This allows us to numerically compute the capacity\nfor specific cases and obtain insights on the corresponding optimal policy, or\neven to obtain closed form analytical solutions by solving the corresponding\nBellman equations, as we demonstrate through examples. Our findings provide\nsome surprising insights on how side information at the charger can be used to\nincrease the overall capacity of the system.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1603.09707v2"}
{"entry_id": "http://arxiv.org/abs/1710.04824v1", "date": "2017-10-13", "title": "The basic equation for target detection in remote sensing", "authors": "Xiurui Geng, Luyan Ji, Yongchao Zhao", "abstract": "Our research has revealed a hidden relationship among several basic\ncomponents, which leads to the best target detection result. Further, we have\nproved that the matched filter (MF) is always superior to the constrained\nenergy minimization (CEM) operator, both of which were originally of parallel\nimportance in the field of target detection for remotely sensed image.", "journal": "", "doi": null, "primary_category": "stat.ME", "categories": ["stat.ME"], "pdf_url": "http://arxiv.org/pdf/1710.04824v1"}
{"entry_id": "http://arxiv.org/abs/1406.2187v1", "date": "2014-06-09", "title": "Remote-excitation and remote-detection of single quantum dot using propagating surface plasmons on silver nanowire", "authors": "Qiang Li, Hong Wei, Hong-Xing Xu", "abstract": "Using propagating surface plasmons (SPs) on silver nanowire (NW), we\ndemonstrate that focused laser light at the end of silver nanowire can excite\nsingle quantum dot (QD) microns away from the excitation spot. The QD-NW\ninteraction allows the excited QD convert part of its energy into propagating\nSPs which then can be detected at the remote sites. Simultaneous multi-QDs\nremote-excitation and detection are also realized. Furthermore, the tight\nconfinement of propagating SPs around the NW surface enables selective\nexcitation of QDs very close in space, which cannot be realized under\nconventional excitation condition. This remote excitation and detection\napproach may find applications in optical imaging and sensing of chemical and\nbiological systems.", "journal": "", "doi": "10.1088/1674-1056/23/9/097302", "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/1406.2187v1"}
{"entry_id": "http://arxiv.org/abs/1706.03939v2", "date": "2017-06-13", "title": "Mesoscopic magnetic resonance spectroscopy with a remote spin sensor", "authors": "Tianyu Xie, Fazhan Shi, Sanyou Chen, Maosen Guo, Yisheng Chen, Yixing Zhang, Yu Yang, Xingyu Gao, Xi Kong, Pengfei Wang, Kenichiro Tateishi, Tomohiro Uesaka, Ya Wang, Bo Zhang, Jiangfeng Du", "abstract": "Quantum sensing based on nitrogen-vacancy (NV) centers in diamond has been\ndeveloped as a powerful tool for microscopic magnetic resonance. However, the\nreported sensor-to-sample distance is limited within tens of nanometers because\nthe signal of spin fluctuation decreases cubically with the increasing\ndistance. Here we extend the sensing distance to tens of micrometers by\ndetecting spin polarization rather than spin fluctuation. We detected the\nmesoscopic magnetic resonance spectra of polarized electrons of a\npentacene-doped crystal, measured its two typical decay times and observed the\noptically enhanced spin polarization. This work paves the way for the NV-based\nmesoscopic magnetic resonance spectroscopy and imaging at ambient conditions.", "journal": "Phys. Rev. Applied 9, 064003 (2018)", "doi": "10.1103/PhysRevApplied.9.064003", "primary_category": "quant-ph", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/1706.03939v2"}
{"entry_id": "http://arxiv.org/abs/2008.05457v1", "date": "2020-08-12", "title": "More Diverse Means Better: Multimodal Deep Learning Meets Remote Sensing Imagery Classification", "authors": "Danfeng Hong, Lianru Gao, Naoto Yokoya, Jing Yao, Jocelyn Chanussot, Qian Du, Bing Zhang", "abstract": "Classification and identification of the materials lying over or beneath the\nEarth's surface have long been a fundamental but challenging research topic in\ngeoscience and remote sensing (RS) and have garnered a growing concern owing to\nthe recent advancements of deep learning techniques. Although deep networks\nhave been successfully applied in single-modality-dominated classification\ntasks, yet their performance inevitably meets the bottleneck in complex scenes\nthat need to be finely classified, due to the limitation of information\ndiversity. In this work, we provide a baseline solution to the aforementioned\ndifficulty by developing a general multimodal deep learning (MDL) framework. In\nparticular, we also investigate a special case of multi-modality learning (MML)\n-- cross-modality learning (CML) that exists widely in RS image classification\napplications. By focusing on \"what\", \"where\", and \"how\" to fuse, we show\ndifferent fusion strategies as well as how to train deep networks and build the\nnetwork architecture. Specifically, five fusion architectures are introduced\nand developed, further being unified in our MDL framework. More significantly,\nour framework is not only limited to pixel-wise classification tasks but also\napplicable to spatial information modeling with convolutional neural networks\n(CNNs). To validate the effectiveness and superiority of the MDL framework,\nextensive experiments related to the settings of MML and CML are conducted on\ntwo different multimodal RS datasets. Furthermore, the codes and datasets will\nbe available at https://github.com/danfenghong/IEEE_TGRS_MDL-RS, contributing\nto the RS community.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, 2020", "doi": "10.1109/TGRS.2020.3016820", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2008.05457v1"}
{"entry_id": "http://arxiv.org/abs/1303.4421v3", "date": "2013-03-18", "title": "Analysis of Remote Synchronization in Complex Networks", "authors": "Lucia Valentina Gambuzza, Alessio Cardillo, Alessandro Fiasconaro, Luigi Fortuna, Jes\u00fas G\u00f3mez-Garde\u00f1es, Mattia Frasca", "abstract": "A novel regime of synchronization, called remote synchronization, where the\nperipheral nodes form a phase synchronized cluster not including the hub, was\nrecently observed in star motifs. We show the existence of a more general\ndynamical state of remote synchronization in arbitrary networks of coupled\noscillators. This state is characterized by the synchronization of pairs of\nnodes that are not directly connected via a physical link or any sequence of\nsynchronized nodes. This phenomenon is almost negligible in networks of phase\noscillators as its underlying mechanism is the modulation of the amplitude of\nthose intermediary nodes between the remotely synchronized units. Our findings\nthus show the ubiquity and robustness of these states and bridge the gap from\ntheir recent observation in simple toy graphs to complex networks.", "journal": "Chaos 23, 043103 (2013)", "doi": "10.1063/1.4824312", "primary_category": "physics.soc-ph", "categories": ["physics.soc-ph", "nlin.AO"], "pdf_url": "http://arxiv.org/pdf/1303.4421v3"}
{"entry_id": "http://arxiv.org/abs/1212.6054v1", "date": "2012-12-25", "title": "New design of Robotics Remote lab", "authors": "Mohammad Alkafagee, Seifedine Kadry", "abstract": "The Robotic Remote Laboratory controls the Robot labs via the Internet and\napplies the Robot experiment in easy and advanced way. If we want to enhance\nthe RRL system, we must study requirements of the Robot experiment in a deeply\nway. One of key requirements of the Robot experiment is the Control algorithm\nthat includes all important activities to affect the Robot; one of them relates\nthe path or obstacle. Our goal is to produce a new design of the RRL includes a\nnew treatment to the Control algorithm depends on isolation one of the Control\nalgorithm's activities that relates the paths in a separated algorithm, i.e.,\ndesign the (Path planning algorithm) is independent of the original Control\nalgorithm. This aim can be achieved by depending on the light to produce the\nLight obstacle. To apply the Light obstacle, we need to hardware (Light control\nserver and Light arms) and soft ware (path planning algorithm).The NXT 2.0\nRobot will sense the Light obstacle depending on the Light sensor of it. The\nnew design has two servers, one for the path (Light control server) and other\nfor the other activities of the Control algorithm (Robot control server).The\nwebsite of the new design includes three main parts (Lab Reservation, Open Lab,\nDownload Simulation).We proposed a set of scenarios for organizing the\nreservation of the Remote Lab. Additionally, we developed an appropriate\nsoftware to simulate the Robot and to practice it before usage the Remote lab.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO"], "pdf_url": "http://arxiv.org/pdf/1212.6054v1"}
{"entry_id": "http://arxiv.org/abs/2012.02519v1", "date": "2020-12-04", "title": "Bistatic Radar Observations of Near-Earth Asteroid (163899) 2003 SD220 from the Southern Hemisphere", "authors": "Shinji Horiuchi, Blake Molyneux, Jamie B. Stevens, Graham Baines, Craig Benson, Zohair Abu-Shaban, Jon D. Giorgini, Lance A. M. Benner, Shantanu P. Naidu, Chris J. Phillips, Philip G. Edwards, Ed Kruzins, Nick J. S. Stacy, Martin A. Slade, John E. Reynolds, Joseph Lazio", "abstract": "We report results of Canberra-ATCA Doppler-only continuous wave (CW) radar\nobservations of near-Earth asteroid (163899) 2003 SD220 at a receiving\nfrequency of 7159 MHz (4.19 cm) on 2018 December 20, 21, and 22 during its\nclose approach within 0.019 au (7.4 lunar distances). Echo power spectra\nprovide evidence that the shape is significantly elongated, asymmetric, and has\nat least one relatively large concavity. An average spectrum per track yields\nan OC (opposite sense of circular polarisation) radar cross section of 0.39,\n0.27, and 0.25 km$^{2}$, respectively, with an uncertainty of 35 \\%. Variations\nby roughly a factor of two in the limb-to-limb bandwidth over the three days\nindicate rotation of an elongated object. We obtain a circular polarization\nratio of 0.21 $\\pm$ 0.07 that is consistent with, but somewhat lower than, the\naverage among other S-class near-Earth asteroids observed by radar.", "journal": "", "doi": "10.1016/j.icarus.2020.114250", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2012.02519v1"}
{"entry_id": "http://arxiv.org/abs/2006.12119v1", "date": "2020-06-22", "title": "The color out of space: learning self-supervised representations for Earth Observation imagery", "authors": "Stefano Vincenzi, Angelo Porrello, Pietro Buzzega, Marco Cipriano, Pietro Fronte, Roberto Cuccu, Carla Ippoliti, Annamaria Conte, Simone Calderara", "abstract": "The recent growth in the number of satellite images fosters the development\nof effective deep-learning techniques for Remote Sensing (RS). However, their\nfull potential is untapped due to the lack of large annotated datasets. Such a\nproblem is usually countered by fine-tuning a feature extractor that is\npreviously trained on the ImageNet dataset. Unfortunately, the domain of\nnatural images differs from the RS one, which hinders the final performance. In\nthis work, we propose to learn meaningful representations from satellite\nimagery, leveraging its high-dimensionality spectral bands to reconstruct the\nvisible colors. We conduct experiments on land cover classification\n(BigEarthNet) and West Nile Virus detection, showing that colorization is a\nsolid pretext task for training a feature extractor. Furthermore, we\nqualitatively observe that guesses based on natural images and colorization\nrely on different parts of the input. This paves the way to an ensemble model\nthat eventually outperforms both the above-mentioned techniques.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "68T07", "I.4"], "pdf_url": "http://arxiv.org/pdf/2006.12119v1"}
{"entry_id": "http://arxiv.org/abs/1009.3843v1", "date": "2010-09-20", "title": "Instrument for Measuring the Earth's Time-Retarded Transverse Gravitational Vector Potential", "authors": "J. C. Hafele", "abstract": "Here within the basic design for a ground-based instrument for measuring the\nmagnitude of the Earth's time-retarded transverse gravitational vector\npotential is described. The formula for the Earth's transverse vector potential\nis derived from the known formula for the neoclassical time-retarded transverse\ngravitational field (arXiv:0904.0383v2 [physics.gen-ph] 25May2010). The device\nsenses the relativistic shift in the frequency of laser-diode oscillators set\ninto circular motion at the tips of a two-arm rotor. The instrument employs\nfiber optics and a digital electronic interferometer/spectrometer to measure\nthe effect of the relativistic time dilation on the frequency-modulated (FM)\nharmonic amplitudes in the beat signals between the tip-diodes and a stationary\nreference diode. The FM amplitudes depend on the orientation of the rotor. For\nthe vertical-east-west orientation with a rotor frequency of 73.9 Hz, the\npredicted FM amplitudes for overtones at 148 Hz, 222 Hz, and 296 Hz are\nrespectively 7x10^-10 Hz, 4x10^-11 Hz, and 9x10^-11 Hz. The overtones in the\nbeat signals can be amplified and observed with a tunable FM digital audio\namplifier. The measured values for the harmonics of the vector potential can be\ndetermined by back-calculating what the amplitudes must have been at the input\nto the amplifier. The instrument can be used to establish the speed of the\nEarth's gravitational field and to study the structure of the Earth's mantle\nand outer core.", "journal": "", "doi": null, "primary_category": "physics.gen-ph", "categories": ["physics.gen-ph"], "pdf_url": "http://arxiv.org/pdf/1009.3843v1"}
{"entry_id": "http://arxiv.org/abs/0710.3582v3", "date": "2007-10-18", "title": "Earth's extensive entropy bound", "authors": "A. M. Lisewski", "abstract": "The possibility of planetary mass black hole production by crossing entropy\nlimits is addressed. Such a possibility is given by pointing out that two\ngeophysical quantities have comparable values: first, Earth's total negative\nentropy flux integrated over geological time and, second, its extensive entropy\nbound, which follows as a tighter bound to the Bekenstein limit when entropy is\nan extensive function. The similarity between both numbers suggests that the\nformation of black holes from planets may be possible through a strong\nfluctuation toward thermodynamic equilibrium which results in gravothermal\ninstability and final collapse. Briefly discussed are implications for the\nastronomical observation of low mass black holes and for Fermi's paradox.", "journal": "", "doi": null, "primary_category": "gr-qc", "categories": ["gr-qc"], "pdf_url": "http://arxiv.org/pdf/0710.3582v3"}
{"entry_id": "http://arxiv.org/abs/physics/0002033v1", "date": "2000-02-17", "title": "Remote Sensing of Geomagnetic Field and Applications to Climate Prediction", "authors": "A. Mary Selvam", "abstract": "Observations show that geomagnetic field lines follow closely the atmospheric\ncirculation patterns and that geomagnetic field variations are precursors to\nclimate change . The exact mechanism for the observed close relationship\nbetween global geomagnetic field and the tropospheric weather patterns is not\nclear. In this paper a universal theory of atmospheric eddy dynamics is\npresented which shows that the global geomagnetic field, atmospheric electric\nfield and weather systems are manifestations of a semi permanent scale\ninvariant hierarchical atmospheric eddy continuum. Quantitative equations are\nderived to show that the full continuum of atmospheric eddies exist as a\nunified whole and originate from buoyant energy supply from frictional\nturbulence at the planetary surface . Large eddy growth occurs from turbulence\nscale by the universal period doubling route to chaos . The turbulent eddies\nare carried upwards on the large eddy envelopes and vertical mixing occurs by\nthe turbulent eddy fluctuations resulting in downward transport of negative\nspace charges from higher levels and simultaneous upward transport of positive\nspace charges from surface levels. The eddy circulations therefore generate a\nlarge-scale vertical aerosol current, which is of the correct sign and\nmagnitude to generate the horizontal component of the geomagnetic field.\nTherefore, atmospheric circulation patterns leave signature on the geomagnetic\nfield lines whose global variations can be easily monitored by satellite borne\nsensors and thus assist in weather and climate prediction.", "journal": "", "doi": null, "primary_category": "physics.gen-ph", "categories": ["physics.gen-ph"], "pdf_url": "http://arxiv.org/pdf/physics/0002033v1"}
{"entry_id": "http://arxiv.org/abs/1906.09677v1", "date": "2019-06-24", "title": "Remote Sensor Design for Visual Recognition with Convolutional Neural Networks", "authors": "Lucas Jaffe, Michael Zelinski, Wesam Sakla", "abstract": "While deep learning technologies for computer vision have developed rapidly\nsince 2012, modeling of remote sensing systems has remained focused around\nhuman vision. In particular, remote sensing systems are usually constructed to\noptimize sensing cost-quality trade-offs with respect to human image\ninterpretability. While some recent studies have explored remote sensing system\ndesign as a function of simple computer vision algorithm performance, there has\nbeen little work relating this design to the state-of-the-art in computer\nvision: deep learning with convolutional neural networks. We develop\nexperimental systems to conduct this analysis, showing results with modern deep\nlearning algorithms and recent overhead image data. Our results are compared to\nstandard image quality measurements based on human visual perception, and we\nconclude not only that machine and human interpretability differ significantly,\nbut that computer vision performance is largely self-consistent across a range\nof disparate conditions. This research is presented as a cornerstone for a new\ngeneration of sensor design systems which focus on computer algorithm\nperformance instead of human visual perception.", "journal": "", "doi": "10.1109/TGRS.2019.2925813", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/1906.09677v1"}
{"entry_id": "http://arxiv.org/abs/2009.01569v1", "date": "2020-09-03", "title": "Remote Joint Strong Coordination and Reliable Communication", "authors": "Giulia Cervia, Tobias J. Oechtering, Mikael Skoglund", "abstract": "We consider a three-node network, in which two agents wish to communicate\nover a noisy channel, while controlling the distribution observed by a third\nexternal agent. We use strong coordination to constrain the distribution, and\nwe provide a complete characterization of the \"remote strong coordination and\nreliable communication\" region.", "journal": "2020 IEEE International Symposium on Information Theory (ISIT)", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2009.01569v1"}
{"entry_id": "http://arxiv.org/abs/2006.07826v2", "date": "2020-06-14", "title": "Few-shot Object Detection on Remote Sensing Images", "authors": "Jingyu Deng, Xiang Li, Yi Fang", "abstract": "In this paper, we deal with the problem of object detection on remote sensing\nimages. Previous methods have developed numerous deep CNN-based methods for\nobject detection on remote sensing images and the report remarkable\nachievements in detection performance and efficiency. However, current\nCNN-based methods mostly require a large number of annotated samples to train\ndeep neural networks and tend to have limited generalization abilities for\nunseen object categories. In this paper, we introduce a few-shot learning-based\nmethod for object detection on remote sensing images where only a few annotated\nsamples are provided for the unseen object categories. More specifically, our\nmodel contains three main components: a meta feature extractor that learns to\nextract feature representations from input images, a reweighting module that\nlearn to adaptively assign different weights for each feature representation\nfrom the support images, and a bounding box prediction module that carries out\nobject detection on the reweighted feature maps. We build our few-shot object\ndetection model upon YOLOv3 architecture and develop a multi-scale object\ndetection framework. Experiments on two benchmark datasets demonstrate that\nwith only a few annotated samples our model can still achieve a satisfying\ndetection performance on remote sensing images and the performance of our model\nis significantly better than the well-established baseline models.", "journal": "TGRS. 60 (2021)", "doi": "10.1109/TGRS.2021.3051383", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2006.07826v2"}
{"entry_id": "http://arxiv.org/abs/2108.05094v1", "date": "2021-08-11", "title": "Representation Learning for Remote Sensing: An Unsupervised Sensor Fusion Approach", "authors": "Aidan M. Swope, Xander H. Rudelis, Kyle T. Story", "abstract": "In the application of machine learning to remote sensing, labeled data is\noften scarce or expensive, which impedes the training of powerful models like\ndeep convolutional neural networks. Although unlabeled data is abundant, recent\nself-supervised learning approaches are ill-suited to the remote sensing\ndomain. In addition, most remote sensing applications currently use only a\nsmall subset of the multi-sensor, multi-channel information available,\nmotivating the need for fused multi-sensor representations. We propose a new\nself-supervised training objective, Contrastive Sensor Fusion, which exploits\ncoterminous data from multiple sources to learn useful representations of every\npossible combination of those sources. This method uses information common\nacross multiple sensors and bands by training a single model to produce a\nrepresentation that remains similar when any subset of its input channels is\nused. Using a dataset of 47 million unlabeled coterminous image triplets, we\ntrain an encoder to produce semantically meaningful representations from any\npossible combination of channels from the input sensors. These representations\noutperform fully supervised ImageNet weights on a remote sensing classification\ntask and improve as more sensors are fused. Our code is available at\nhttps://storage.cloud.google.com/public-published-datasets/csf_code.zip.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2108.05094v1"}
{"entry_id": "http://arxiv.org/abs/2212.10411v1", "date": "2022-12-20", "title": "DDIPNet and DDIPNet+: Discriminant Deep Image Prior Networks for Remote Sensing Image Classification", "authors": "Daniel F. S. Santos, Rafael G. Pires, Leandro A. Passos, Jo\u00e3o P. Papa", "abstract": "Research on remote sensing image classification significantly impacts\nessential human routine tasks such as urban planning and agriculture. Nowadays,\nthe rapid advance in technology and the availability of many high-quality\nremote sensing images create a demand for reliable automation methods. The\ncurrent paper proposes two novel deep learning-based architectures for image\nclassification purposes, i.e., the Discriminant Deep Image Prior Network and\nthe Discriminant Deep Image Prior Network+, which combine Deep Image Prior and\nTriplet Networks learning strategies. Experiments conducted over three\nwell-known public remote sensing image datasets achieved state-of-the-art\nresults, evidencing the effectiveness of using deep image priors for remote\nsensing image classification.", "journal": "", "doi": "10.1109/IGARSS47720.2021.9554277", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2212.10411v1"}
{"entry_id": "http://arxiv.org/abs/2109.01184v1", "date": "2021-09-02", "title": "Remote Multilinear Compressive Learning with Adaptive Compression", "authors": "Dat Thanh Tran, Moncef Gabbouj, Alexandros Iosifidis", "abstract": "Multilinear Compressive Learning (MCL) is an efficient signal acquisition and\nlearning paradigm for multidimensional signals. The level of signal compression\naffects the detection or classification performance of a MCL model, with higher\ncompression rates often associated with lower inference accuracy. However,\nhigher compression rates are more amenable to a wider range of applications,\nespecially those that require low operating bandwidth and minimal energy\nconsumption such as Internet-of-Things (IoT) applications. Many communication\nprotocols provide support for adaptive data transmission to maximize the\nthroughput and minimize energy consumption. By developing compressive sensing\nand learning models that can operate with an adaptive compression rate, we can\nmaximize the informational content throughput of the whole application. In this\npaper, we propose a novel optimization scheme that enables such a feature for\nMCL models. Our proposal enables practical implementation of adaptive\ncompressive signal acquisition and inference systems. Experimental results\ndemonstrated that the proposed approach can significantly reduce the amount of\ncomputations required during the training phase of remote learning systems but\nalso improve the informational content throughput via adaptive-rate sensing.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2109.01184v1"}
{"entry_id": "http://arxiv.org/abs/2202.10693v2", "date": "2022-02-22", "title": "Universal adversarial perturbation for remote sensing images", "authors": "Qingyu Wang, Guorui Feng, Zhaoxia Yin, Bin Luo", "abstract": "Recently, with the application of deep learning in the remote sensing image\n(RSI) field, the classification accuracy of the RSI has been dramatically\nimproved compared with traditional technology. However, even the\nstate-of-the-art object recognition convolutional neural networks are fooled by\nthe universal adversarial perturbation (UAP). The research on UAP is mostly\nlimited to ordinary images, and RSIs have not been studied. To explore the\nbasic characteristics of UAPs of RSIs, this paper proposes a novel method\ncombining an encoder-decoder network with an attention mechanism to generate\nthe UAP of RSIs. Firstly, the former is used to generate the UAP, which can\nlearn the distribution of perturbations better, and then the latter is used to\nfind the sensitive regions concerned by the RSI classification model. Finally,\nthe generated regions are used to fine-tune the perturbation making the model\nmisclassified with fewer perturbations. The experimental results show that the\nUAP can make the classification model misclassify, and the attack success rate\nof our proposed method on the RSI data set is as high as 97.09%.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2202.10693v2"}
{"entry_id": "http://arxiv.org/abs/0805.3868v6", "date": "2008-05-26", "title": "A hypothesis of earth quake", "authors": "Yeong-Shyeong Tsai", "abstract": "Without a model, it is impossible for a geophysicist to study the possibility\nof forecasting earth quakes. We will define a quantity, the event-degree, in\nthe paper. This quantity plays an important role in the model of quakes\nforecasting. In order to make a simple model, we make a hypothesis of earth\nquakes. The hypothesis is: \"(i) There are two kinds of earth quakes, one is the\ntriggered breaking (earth quake), the other is spontaneous breaking (earth\nquake). (ii) Most major quakes in continental plates such as Eurasian Plate,\nNorth America Plate, South America Plate, Africa Plate and Australia Plate are\ntriggered breaking. (iii) These triggered quakes are triggered by the evolution\nof high pressure centers and low pressure centers of the atmosphere on the\nplates. (iv) How can the evolution of the high pressure centers trigger a quake\nin quantitative sense? It depends on the event-degree, the extent of the high\npressure center, the rate of evolution of event-degree and the the degree of\nstored energy for reaching breaking point.\"", "journal": "", "doi": null, "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "physics.soc-ph"], "pdf_url": "http://arxiv.org/pdf/0805.3868v6"}
{"entry_id": "http://arxiv.org/abs/1811.05586v2", "date": "2018-11-14", "title": "Quantum remote sensing with asymmetric information gain", "authors": "Yuki Takeuchi, Yuichiro Matsuzaki, Koichiro Miyanishi, Takanori Sugiyama, William J. Munro", "abstract": "Typically, the aim of quantum metrology is to sense target fields with high\nprecision utilizing quantum properties. Unlike the typical aim, in this paper,\nwe use quantum properties for adding a new functionality to quantum sensors.\nMore concretely, we propose a delegated quantum sensor (a client-server model)\nwith security inbuilt. Suppose that a client wants to measure some target\nfields with high precision, but he/she does not have any high-precision sensor.\nThis leads the client to delegate the sensing to a remote server who possesses\na high-precision sensor. The client gives the server instructions about how to\ncontrol the sensor. The server lets the sensor interact with the target fields\nin accordance with the instructions, and then sends the sensing measurement\nresults to the client. In this case, since the server knows the control process\nand readout results of the sensor, the information of the target fields is\navailable not only for the client but also for the server. We show that, by\nusing an entanglement between the client and the server, an asymmetric\ninformation gain is possible so that only the client can obtain the sufficient\ninformation of the target fields. In our scheme, the server generates the\nentanglement between a solid state system (that can interact with the target\nfields) and a photon, and sends the photon to the client. On the other hand,\nthe client is required to possess linear optics elements only including wave\nplates, polarizing beam splitters, and single-photon detectors. Our scheme is\nfeasible with the current technology, and our results pave the way for a novel\napplication of quantum metrology.", "journal": "Phys. Rev. A 99, 022325 (2019)", "doi": "10.1103/PhysRevA.99.022325", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1811.05586v2"}
{"entry_id": "http://arxiv.org/abs/1109.0097v1", "date": "2011-09-01", "title": "Website Detection Using Remote Traffic Analysis", "authors": "Xun Gong, Negar Kiyavash, Nab\u00edl Schear, Nikita Borisov", "abstract": "Recent work in traffic analysis has shown that traffic patterns leaked\nthrough side channels can be used to recover important semantic information.\nFor instance, attackers can find out which website, or which page on a website,\na user is accessing simply by monitoring the packet size distribution. We show\nthat traffic analysis is even a greater threat to privacy than previously\nthought by introducing a new attack that can be carried out remotely. In\nparticular, we show that, to perform traffic analysis, adversaries do not need\nto directly observe the traffic patterns. Instead, they can gain sufficient\ninformation by sending probes from a far-off vantage point that exploits a\nqueuing side channel in routers. To demonstrate the threat of such remote\ntraffic analysis, we study a remote website detection attack that works against\nhome broadband users. Because the remotely observed traffic patterns are more\nnoisy than those obtained using previous schemes based on direct local traffic\nmonitoring, we take a dynamic time warping (DTW) based approach to detecting\nfingerprints from the same website. As a new twist on website fingerprinting,\nwe consider a website detection attack, where the attacker aims to find out\nwhether a user browses a particular web site, and its privacy implications. We\nshow experimentally that, although the success of the attack is highly\nvariable, depending on the target site, for some sites very low error rates. We\nalso show how such website detection can be used to deanonymize message board\nusers.", "journal": "", "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR"], "pdf_url": "http://arxiv.org/pdf/1109.0097v1"}
{"entry_id": "http://arxiv.org/abs/2302.09987v1", "date": "2023-02-20", "title": "Mid-infrared spectroscopy of planetary analogs: A database for planetary remote sensing", "authors": "A. Morlok, S. Klemme, I. Weber, A. N. Stojic, M. Sohn, H. Hiesinger, J. Helbert", "abstract": "The MERTIS (MErcury Radiometer and Thermal Infrared Spectrometer) instrument\nonboard the ESA/JAXA BepiColombo mission will provide mid-infrared data, which\nwill be crucial to characterize the surface mineralogy of Mercury. In order to\ninterpret the results, we are creating a database of mid infrared spectra. As\npart of a study of synthetic glasses which are to serve as analog materials for\nthe interpretation of remote sensing and modeling data, we present mid infrared\ndata for analog materials of Mercury regolith, surface and mantle compositions.\nIn addition, we provide data for similar analogs of Earth, Moon, Venus, and\nMars rocks for a coherent picture. The analog samples have been first\ncharacterized by optical microscopy, Raman spectroscopy and EMPA. Powdered size\nfractions (0-25 micron, 25-63 micron, 63-125 micron, and 125 -250 micron) were\nstudied in reflectance in the mid-infrared range from 2.5 to 18 micron (550 to\n2000cm-1), additional micro FTIR analyses were also obtained. Results for the\nsize fractions of the surface and regolith analogs for Mercury show typical\nfeatures for amorphous material with Christiansen Features (CF) at 8 to 8.1\nmicron, Reststrahlen Bands (RB) at 9.8 to 9.9 micron, and the Transparency\nFeature (TF) at 12 micron. The six bulk silicate Mercury analogs have varying\nCF positions from 8.1 to 9 micron, with RB crystalline features of various\nolivines dominating in most samples. Similarly, bulk silicate analogs of the\nother planetary bodies show glassy features for the surface analogs with CF\nfrom 7.9 micron (Earth Continental Crust) to 8.3 micron (Lunar Mare), strong RB\nfrom 9.5 micron (Earth Continental Crust ) to 10.6 micron (Lunar Mare and\nHighlands). TF are usually very weak for the glassy analogs.", "journal": "Icarus(2019) 324, 86-103", "doi": "10.1016/j.icarus.2019.02.010", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2302.09987v1"}
{"entry_id": "http://arxiv.org/abs/1805.02804v3", "date": "2018-05-08", "title": "Unconfirmed Near-Earth Objects", "authors": "Peter Vere\u0161, Matthew J. Payne, Matthew J. Holman, Davide Farnocchia, Gareth V. Williams, Sonia Keys, Ian Boardman", "abstract": "We studied the Near-Earth Asteroid (NEA) candidates posted on the Minor\nPlanet Center's Near-Earth Object Confirmation Page (NEOCP) between years 2013\nand 2016. Out of more than 17,000 NEA candidates, while the majority became\neither new discoveries or were associated with previously known objects, about\n11% were unable to be followed-up or confirmed. We further demonstrate that of\nthe unconfirmed candidates, 926+/-50 are likely to be NEAs, representing 18% of\ndiscovered NEAs in that period. Only 11% (~93) of the unconfirmed NEA\ncandidates were large (having absolute magnitude H<22). To identify the reasons\nwhy these NEAs were not recovered, we analyzed those from the most prolific\nasteroid surveys: Pan-STARRS, the Catalina Sky Survey, the Dark Energy Survey,\nand the Space Surveillance Telescope. We examined the influence of plane-of-sky\npositions and rates of motion, brightnesses, submission delays, and computed\nabsolute magnitudes, as well as correlations with the phase of the moon and\nseasonal effects. We find that delayed submission of newly discovered NEA\ncandidate to the NEOCP drove a large fraction of the unconfirmed NEA\ncandidates. A high rate of motion was another significant contributing factor.\nWe suggest that prompt submission of suspected NEA discoveries and rapid\nresponse to fast moving targets and targets with fast growing ephemeris\nuncertainty would allow better coordination among dedicated follow-up\nobservers, decrease the number of unconfirmed NEA candidates, and increase the\ndiscovery rate of NEAs.", "journal": "2018, Astronomical Journal, Vol 156, Number 1", "doi": "10.3847/1538-3881/aac37d", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1805.02804v3"}
{"entry_id": "http://arxiv.org/abs/quant-ph/0609215v1", "date": "2006-09-27", "title": "Quantum interference of electromagnetic fields from remote quantum memories", "authors": "T. Chaneliere, D. N. Matsukevich, S. D. Jenkins, S. -Y. Lan, R. Zhao, T. A. B. Kennedy, A. Kuzmich", "abstract": "We observe quantum, Hong-Ou-Mandel, interference of fields produced by two\nremote atomic memories. High-visibility interference is obtained by utilizing\nthe finite atomic memory time in four-photon delayed coincidence measurements.\nInterference of fields from remote atomic memories is a crucial element in\nprotocols for scalable generation of multi-node remote qubit entanglement.", "journal": "Physical Review Letters 98, 113602 (2007)", "doi": "10.1103/PhysRevLett.98.113602", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/quant-ph/0609215v1"}
{"entry_id": "http://arxiv.org/abs/2209.02884v2", "date": "2022-09-07", "title": "Multi-Grained Angle Representation for Remote Sensing Object Detection", "authors": "Hao Wang, Zhanchao Huang, Zhengchao Chen, Ying Song, Wei Li", "abstract": "Arbitrary-oriented object detection (AOOD) plays a significant role for image\nunderstanding in remote sensing scenarios. The existing AOOD methods face the\nchallenges of ambiguity and high costs in angle representation. To this end, a\nmulti-grained angle representation (MGAR) method, consisting of coarse-grained\nangle classification (CAC) and fine-grained angle regression (FAR), is\nproposed. Specifically, the designed CAC avoids the ambiguity of angle\nprediction by discrete angular encoding (DAE) and reduces complexity by\ncoarsening the granularity of DAE. Based on CAC, FAR is developed to refine the\nangle prediction with much lower costs than narrowing the granularity of DAE.\nFurthermore, an Intersection over Union (IoU) aware FAR-Loss (IFL) is designed\nto improve accuracy of angle prediction using an adaptive re-weighting\nmechanism guided by IoU. Extensive experiments are performed on several public\nremote sensing datasets, which demonstrate the effectiveness of the proposed\nMGAR. Moreover, experiments on embedded devices demonstrate that the proposed\nMGAR is also friendly for lightweight deployments.", "journal": "Transactions on Geoscience and Remote Sensing, 2022", "doi": "10.1109/TGRS.2022.3212592", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2209.02884v2"}
{"entry_id": "http://arxiv.org/abs/gr-qc/9408039v4", "date": "1994-08-31", "title": "On the remote sensing of Hawking grey pulses", "authors": "H. C. Rosu", "abstract": "This is a short note on the black hole remote-sensing problem, i.e., finding\nout `surface' temperature distributions of various types of small\n(micron-sized) black holes from the spectral measurements of their Hawking grey\npulses. Chen's modified Moebius inverse transform is illustrated in this\ncontext", "journal": "Mod. Phys. Lett. A 13 (1998) 695-699", "doi": "10.1142/S0217732398000759", "primary_category": "gr-qc", "categories": ["gr-qc", "astro-ph"], "pdf_url": "http://arxiv.org/pdf/gr-qc/9408039v4"}
{"entry_id": "http://arxiv.org/abs/2101.10657v3", "date": "2021-01-26", "title": "Advantages and Bottlenecks of Quantum Machine Learning for Remote Sensing", "authors": "Daniela A. Zaidenberg, Alessandro Sebastianelli, Dario Spiller, Bertrand Le Saux, Silvia Liberata Ullo", "abstract": "This concept paper aims to provide a brief outline of quantum computers,\nexplore existing methods of quantum image classification techniques, so\nfocusing on remote sensing applications, and discuss the bottlenecks of\nperforming these algorithms on currently available open source platforms.\nInitial results demonstrate feasibility. Next steps include expanding the size\nof the quantum hidden layer and increasing the variety of output image options.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2101.10657v3"}
{"entry_id": "http://arxiv.org/abs/1910.01432v2", "date": "2019-10-03", "title": "The Bouncer Problem: Challenges to Remote Explainability", "authors": "Erwan Le Merrer, Gilles Tredan", "abstract": "The concept of explainability is envisioned to satisfy society's demands for\ntransparency on machine learning decisions. The concept is simple: like humans,\nalgorithms should explain the rationale behind their decisions so that their\nfairness can be assessed. While this approach is promising in a local context\n(e.g. to explain a model during debugging at training time), we argue that this\nreasoning cannot simply be transposed in a remote context, where a trained\nmodel by a service provider is only accessible through its API. This is\nproblematic as it constitutes precisely the target use-case requiring\ntransparency from a societal perspective. Through an analogy with a club\nbouncer (which may provide untruthful explanations upon customer reject), we\nshow that providing explanations cannot prevent a remote service from lying\nabout the true reasons leading to its decisions. More precisely, we prove the\nimpossibility of remote explainability for single explanations, by constructing\nan attack on explanations that hides discriminatory features to the querying\nuser. We provide an example implementation of this attack. We then show that\nthe probability that an observer spots the attack, using several explanations\nfor attempting to find incoherences, is low in practical settings. This\nundermines the very concept of remote explainability in general.", "journal": "Nat Mach Intell (2020)", "doi": "10.1038/s42256-020-0216-z", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CR", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1910.01432v2"}
{"entry_id": "http://arxiv.org/abs/2009.13015v2", "date": "2020-09-28", "title": "Cloud Removal for Remote Sensing Imagery via Spatial Attention Generative Adversarial Network", "authors": "Heng Pan", "abstract": "Optical remote sensing imagery has been widely used in many fields due to its\nhigh resolution and stable geometric properties. However, remote sensing\nimagery is inevitably affected by climate, especially clouds. Removing the\ncloud in the high-resolution remote sensing satellite image is an indispensable\npre-processing step before analyzing it. For the sake of large-scale training\ndata, neural networks have been successful in many image processing tasks, but\nthe use of neural networks to remove cloud in remote sensing imagery is still\nrelatively small. We adopt generative adversarial network to solve this task\nand introduce the spatial attention mechanism into the remote sensing imagery\ncloud removal task, proposes a model named spatial attention generative\nadversarial network (SpA GAN), which imitates the human visual mechanism, and\nrecognizes and focuses the cloud area with local-to-global spatial attention,\nthereby enhancing the information recovery of these areas and generating\ncloudless images with better quality...", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2009.13015v2"}
{"entry_id": "http://arxiv.org/abs/2209.14969v1", "date": "2022-09-28", "title": "Transfer Learning with Pretrained Remote Sensing Transformers", "authors": "Anthony Fuller, Koreen Millard, James R. Green", "abstract": "Although the remote sensing (RS) community has begun to pretrain transformers\n(intended to be fine-tuned on RS tasks), it is unclear how these models perform\nunder distribution shifts. Here, we pretrain a new RS transformer--called\nSatViT-V2--on 1.3 million satellite-derived RS images, then fine-tune it (along\nwith five other models) to investigate how it performs on distributions not\nseen during training. We split an expertly labeled land cover dataset into 14\ndatasets based on source biome. We train each model on each biome separately\nand test them on all other biomes. In all, this amounts to 1638 biome transfer\nexperiments. After fine-tuning, we find that SatViT-V2 outperforms SatViT-V1 by\n3.1% on in-distribution (matching biomes) and 2.8% on out-of-distribution\n(mismatching biomes) data. Additionally, we find that initializing fine-tuning\nfrom the linear probed solution (i.e., leveraging LPFT [1]) improves\nSatViT-V2's performance by another 1.2% on in-distribution and 2.4% on\nout-of-distribution data. Next, we find that pretrained RS transformers are\nbetter calibrated under distribution shifts than non-pretrained models and\nleveraging LPFT results in further improvements in model calibration. Lastly,\nwe find that five measures of distribution shift are moderately correlated with\nbiome transfer performance. We share code and pretrained model weights.\n(https://github.com/antofuller/SatViT)", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2209.14969v1"}
{"entry_id": "http://arxiv.org/abs/1603.04964v1", "date": "2016-03-16", "title": "Optimal Remote State Estimation for Self-Propelled Particle Models", "authors": "Shinkyu Park, Nuno C. Martins", "abstract": "We investigate the design of a remote state estimation system for a\nself-propelled particle (SPP). Our framework consists of a sensing unit that\naccesses the full state of the SPP and an estimator that is remotely located\nfrom the sensing unit. The sensing unit must pay a cost when it chooses to\ntransmit information on the state of the SPP to the estimator; and the\nestimator computes the best estimate of the state of the SPP based on received\ninformation. In this paper, we provide methods to design transmission policies\nand estimation rules for the sensing unit and estimator, respectively, that are\noptimal for a given cost functional that combines state estimation distortion\nand communication costs. We consider two notions of optimality: joint\noptimality and person-by-person optimality. Our main results show the existence\nof a jointly optimal solution and describe an iterative procedure to find a\nperson-by-person optimal solution. In addition, we explain how the remote\nestimation scheme can be applied to tracking of animal movements over a costly\ncommunication link. We also provide experimental results to show the\neffectiveness of the scheme.", "journal": "", "doi": null, "primary_category": "math.OC", "categories": ["math.OC"], "pdf_url": "http://arxiv.org/pdf/1603.04964v1"}
{"entry_id": "http://arxiv.org/abs/2004.04491v1", "date": "2020-04-09", "title": "Multi-Granularity Canonical Appearance Pooling for Remote Sensing Scene Classification", "authors": "S. Wang, Y. Guan, L. Shao", "abstract": "Recognising remote sensing scene images remains challenging due to large\nvisual-semantic discrepancies. These mainly arise due to the lack of detailed\nannotations that can be employed to align pixel-level representations with\nhigh-level semantic labels. As the tagging process is labour-intensive and\nsubjective, we hereby propose a novel Multi-Granularity Canonical Appearance\nPooling (MG-CAP) to automatically capture the latent ontological structure of\nremote sensing datasets. We design a granular framework that allows\nprogressively cropping the input image to learn multi-grained features. For\neach specific granularity, we discover the canonical appearance from a set of\npre-defined transformations and learn the corresponding CNN features through a\nmaxout-based Siamese style architecture. Then, we replace the standard CNN\nfeatures with Gaussian covariance matrices and adopt the proper matrix\nnormalisations for improving the discriminative power of features. Besides, we\nprovide a stable solution for training the eigenvalue-decomposition function\n(EIG) in a GPU and demonstrate the corresponding back-propagation using matrix\ncalculus. Extensive experiments have shown that our framework can achieve\npromising results in public remote sensing scene datasets.", "journal": "IEEE Transactions on Image Processing 29, 5396--5407 (2020)", "doi": "10.1109/TIP.2020.2983560", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2004.04491v1"}
{"entry_id": "http://arxiv.org/abs/2105.04996v1", "date": "2021-05-11", "title": "Instance-aware Remote Sensing Image Captioning with Cross-hierarchy Attention", "authors": "Chengze Wang, Zhiyu Jiang, Yuan Yuan", "abstract": "The spatial attention is a straightforward approach to enhance the\nperformance for remote sensing image captioning. However, conventional spatial\nattention approaches consider only the attention distribution on one fixed\ncoarse grid, resulting in the semantics of tiny objects can be easily ignored\nor disturbed during the visual feature extraction. Worse still, the fixed\nsemantic level of conventional spatial attention limits the image understanding\nin different levels and perspectives, which is critical for tackling the huge\ndiversity in remote sensing images. To address these issues, we propose a\nremote sensing image caption generator with instance-awareness and\ncross-hierarchy attention. 1) The instances awareness is achieved by\nintroducing a multi-level feature architecture that contains the visual\ninformation of multi-level instance-possible regions and their surroundings. 2)\nMoreover, based on this multi-level feature extraction, a cross-hierarchy\nattention mechanism is proposed to prompt the decoder to dynamically focus on\ndifferent semantic hierarchies and instances at each time step. The\nexperimental results on public datasets demonstrate the superiority of proposed\napproach over existing methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2105.04996v1"}
{"entry_id": "http://arxiv.org/abs/2108.11535v1", "date": "2021-08-26", "title": "ChessMix: Spatial Context Data Augmentation for Remote Sensing Semantic Segmentation", "authors": "Matheus Barros Pereira, Jefersson Alex dos Santos", "abstract": "Labeling semantic segmentation datasets is a costly and laborious process if\ncompared with tasks like image classification and object detection. This is\nespecially true for remote sensing applications that not only work with\nextremely high spatial resolution data but also commonly require the knowledge\nof experts of the area to perform the manual labeling. Data augmentation\ntechniques help to improve deep learning models under the circumstance of few\nand imbalanced labeled samples. In this work, we propose a novel data\naugmentation method focused on exploring the spatial context of remote sensing\nsemantic segmentation. This method, ChessMix, creates new synthetic images from\nthe existing training set by mixing transformed mini-patches across the dataset\nin a chessboard-like grid. ChessMix prioritizes patches with more examples of\nthe rarest classes to alleviate the imbalance problems. The results in three\ndiverse well-known remote sensing datasets show that this is a promising\napproach that helps to improve the networks' performance, working especially\nwell in datasets with few available data. The results also show that ChessMix\nis capable of improving the segmentation of objects with few labeled pixels\nwhen compared to the most common data augmentation methods widely used.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2108.11535v1"}
{"entry_id": "http://arxiv.org/abs/2011.10666v1", "date": "2020-11-20", "title": "Enhancing Poaching Predictions for Under-Resourced Wildlife Conservation Parks Using Remote Sensing Imagery", "authors": "Rachel Guo, Lily Xu, Drew Cronin, Francis Okeke, Andrew Plumptre, Milind Tambe", "abstract": "Illegal wildlife poaching is driving the loss of biodiversity. To combat\npoaching, rangers patrol expansive protected areas for illegal poaching\nactivity. However, rangers often cannot comprehensively search such large\nparks. Thus, the Protection Assistant for Wildlife Security (PAWS) was\nintroduced as a machine learning approach to help identify the areas with\nhighest poaching risk. As PAWS is deployed to parks around the world, we\nrecognized that many parks have limited resources for data collection and\ntherefore have scarce feature sets. To ensure under-resourced parks have access\nto meaningful poaching predictions, we introduce the use of publicly available\nremote sensing data to extract features for parks. By employing this data from\nGoogle Earth Engine, we also incorporate previously unavailable dynamic data to\nenrich predictions with seasonal trends. We automate the entire\ndata-to-deployment pipeline and find that, with only using publicly available\ndata, we recuperate prediction performance comparable to predictions made using\nfeatures manually computed by park specialists. We conclude that the inclusion\nof satellite imagery creates a robust system through which parks of any\nresource level can benefit from poaching risks for years to come.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CY"], "pdf_url": "http://arxiv.org/pdf/2011.10666v1"}
{"entry_id": "http://arxiv.org/abs/2202.13275v1", "date": "2022-02-27", "title": "A Dual Neighborhood Hypergraph Neural Network for Change Detection in VHR Remote Sensing Images", "authors": "Junzheng Wu, Ruigang Fu, Qiang Liu, Weiping Ni, Kenan Cheng, Biao Li, Yuli Sun", "abstract": "The very high spatial resolution (VHR) remote sensing images have been an\nextremely valuable source for monitoring changes occurred on the earth surface.\nHowever, precisely detecting relevant changes in VHR images still remains a\nchallenge, due to the complexity of the relationships among ground objects. To\naddress this limitation, a dual neighborhood hypergraph neural network is\nproposed in this article, which combines the multiscale superpixel segmentation\nand hypergraph convolution to model and exploit the complex relationships.\nFirst, the bi-temporal image pairs are segmented under two scales and fed to a\npre-trained U-net to obtain node features by treating each object under the\nfine scale as a node. The dual neighborhood is then defined using the\nfather-child and adjacent relationships of the segmented objects to construct\nthe hypergraph, which permits models to represent the higher-order structured\ninformation far more complex than just pairwise relationships. The hypergraph\nconvolutions are conducted on the constructed hypergraph to propagate the label\ninformation from a small amount of labeled nodes to the other unlabeled ones by\nthe node-edge-node transform. Moreover, to alleviate the problem of imbalanced\nsample, the focal loss function is adopted to train the hypergraph neural\nnetwork. The experimental results on optical, SAR and heterogeneous optical/SAR\ndata sets demonstrate that the proposed method comprises better effectiveness\nand robustness compared to many state-of-the-art methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2202.13275v1"}
{"entry_id": "http://arxiv.org/abs/1901.07111v1", "date": "2019-01-21", "title": "A New Method for Estimating the Absolute Magnitude Frequency Distribution of Near Earth Asteroids (NEAs)", "authors": "Francisco Valdes", "abstract": "The distribution of solar system absolute magnitudes ($H$) for the near-Earth\nasteroids (NEAs) observable near opposition -- i.e. Amors, Apollos, and Atens\n($A^3$) -- is derived from the set of ALL currently known NEAs. The result is\nbased only on common sense assumptions of uniformly random distributions and\nthat the orbital phase space and $H$-magnitude distribution of known NEAs is\nrepresentative of the total population. There is no population or other\nmodeling and no assumption on albedo except in interpreting the result as a\nsize-frequency distribution (SFD). The analysis is based on the 18355 $A^3$\nNEAs cataloged by the MPC as of June 2018. The observations from 9 of the top\nprograms (in terms of number of distinct NEAs observed) and the smaller but\ndeeper DECam NEO Survey are used, comprising 74696 measurements of 13466 NEAs\nobserved within 30 deg of opposition. The only parameter in the analysis is an\nestimate of the detection magnitude limits for each program.\n  A single power-law slope for the cumulative distribution,\n$\\log(N<H)=0.50\\pm0.03H$, for $H < 27$ is found with no evidence for additional\nstructure. A turn-over fainter than 27th magnitude may occur, but the\npopulation of known NEAs is dropping off rapidly because they are difficult to\ndetect and so possibly is a completeness effect. Connecting to the nearly\ncomplete census of the brightest/biggest NEAs (diameter $> {\\sim}2$Km) provides\na normalization that estimates ${\\sim}10^8 A^3$ NEAs with $H < {\\sim}27$\ncorresponding to NEAs greater than ${\\sim}10$m in diameter for reasonable\ntypical albedos.\n  Restricting the analysis to Earth crossing asteroids (10839 known, 7336\nselected, 36541 observed) produces the same power-law slope.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1901.07111v1"}
{"entry_id": "http://arxiv.org/abs/2101.09427v1", "date": "2021-01-23", "title": "Towards Natural Language Question Answering over Earth Observation Linked Data using Attention-based Neural Machine Translation", "authors": "Abhishek V. Potnis, Rajat C. Shinde, Surya S. Durbha", "abstract": "With an increase in Geospatial Linked Open Data being adopted and published\nover the web, there is a need to develop intuitive interfaces and systems for\nseamless and efficient exploratory analysis of such rich heterogeneous\nmulti-modal datasets. This work is geared towards improving the exploration\nprocess of Earth Observation (EO) Linked Data by developing a natural language\ninterface to facilitate querying. Questions asked over Earth Observation Linked\nData have an inherent spatio-temporal dimension and can be represented using\nGeoSPARQL. This paper seeks to study and analyze the use of RNN-based neural\nmachine translation with attention for transforming natural language questions\ninto GeoSPARQL queries. Specifically, it aims to assess the feasibility of a\nneural approach for identifying and mapping spatial predicates in natural\nlanguage to GeoSPARQL's topology vocabulary extension including - Egenhofer and\nRCC8 relations. The queries can then be executed over a triple store to yield\nanswers for the natural language questions. A dataset consisting of mappings\nfrom natural language questions to GeoSPARQL queries over the Corine Land\nCover(CLC) Linked Data has been created to train and validate the deep neural\nnetwork. From our experiments, it is evident that neural machine translation\nwith attention is a promising approach for the task of translating spatial\npredicates in natural language questions to GeoSPARQL queries.", "journal": "", "doi": "10.1109/IGARSS39084.2020.9323183", "primary_category": "cs.CL", "categories": ["cs.CL", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2101.09427v1"}
{"entry_id": "http://arxiv.org/abs/2206.11766v1", "date": "2022-06-23", "title": "Physics-Informed Statistical Modeling for Wildfire Aerosols Process Using Multi-Source Geostationary Satellite Remote-Sensing Data Streams", "authors": "Guanzhou Wei, Venkat Krishnan, Yu Xie, Manajit Sengupta, Yingchen Zhang, Haitao Liao, Xiao Liu", "abstract": "Increasingly frequent wildfires significantly affect solar energy production\nas the atmospheric aerosols generated by wildfires diminish the incoming solar\nradiation to the earth. Atmospheric aerosols are measured by Aerosol Optical\nDepth (AOD), and AOD data streams can be retrieved and monitored by\ngeostationary satellites. However, multi-source remote-sensing data streams\noften present heterogeneous characteristics, including different data missing\nrates, measurement errors, systematic biases, and so on. To accurately estimate\nand predict the underlying AOD propagation process, there exist practical needs\nand theoretical interests to propose a physics-informed statistical approach\nfor modeling wildfire AOD propagation by simultaneously utilizing, or fusing,\nmulti-source heterogeneous satellite remote-sensing data streams. Leveraging a\nspectral approach, the proposed approach integrates multi-source satellite data\nstreams with a fundamental advection-diffusion equation that governs the AOD\npropagation process. A bias correction process is included in the statistical\nmodel to account for the bias of the physics model and the truncation error of\nthe Fourier series. The proposed approach is applied to California wildfires\nAOD data streams obtained from the National Oceanic and Atmospheric\nAdministration. Comprehensive numerical examples are provided to demonstrate\nthe predictive capabilities and model interpretability of the proposed\napproach. Computer code has been made available on GitHub.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2206.11766v1"}
{"entry_id": "http://arxiv.org/abs/1507.00078v1", "date": "2015-07-01", "title": "Evidence of the Solar EUV hot channel as a magnetic flux rope from remote-sensing and in-situ observations", "authors": "Hongqiang Song, Yao Chen, Jie Zhang, Xin Cheng, Bing Wang, Qiang Hu, Gang Li, Yuming Wang", "abstract": "Hot channels (HCs), high temperature erupting structures in the lower corona\nof the Sun, have been proposed as a proxy of magnetic flux ropes (MFRs) since\ntheir initial discovery. However, it is difficult to make definitive proof\ngiven the fact that there is no direct measurement of magnetic field in the\ncorona. An alternative way is to use the magnetic field measurement in the\nsolar wind from in-situ instruments. On 2012 July 12, an HC was observed prior\nto and during a coronal mass ejection (CME) by the AIA high-temperature images.\nThe HC is invisible in the EUVI low-temperature images, which only show the\ncooler leading front (LF). However, both the LF and an ejecta can be observed\nin the coronagraphic images. These are consistent with the high temperature and\nhigh density of the HC and support that the ejecta is the erupted HC. In the\nmeanwhile, the associated CME shock was identified ahead of the ejecta and the\nsheath through the COR2 images, and the corresponding ICME was detected by\n\\textit{ACE}, showing the shock, sheath and magnetic cloud (MC) sequentially,\nwhich agrees with the coronagraphic observations. Further, the MC contained a\nlow-ionization-state center and a high-ionization-state shell, consistent with\nthe pre-existing HC observation and its growth through magnetic reconnection.\nAll of these observations support that the MC detected near the Earth is the\ncounterpart of the erupted HC in the corona for this event. Therefore, our\nstudy provides strong observational evidence of the HC as an MFR.", "journal": "", "doi": "10.1088/2041-8205/808/1/L15", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1507.00078v1"}
{"entry_id": "http://arxiv.org/abs/2104.14960v1", "date": "2021-04-30", "title": "Signatures of coronal hole substructure in the solar wind: combined Solar Orbiter remote sensing and in situ measurements", "authors": "T. S. Horbury, R. Laker, L. Rodriguez, K. Steinvall, M. Maksimovic, S. Livi, D. Berghmans, F. Auchere, A. N. Zhukov, Yu. V. Khotyaintsev, L. Woodham, L. Matteini, J. Stawarz, T. Woolley, S. D. Bale, A. Rouillard, H. O'Brien, V. Evans, V. Angelini, C. Owen, S. K. Solanki, B. Nicula, D. Muller, I. Zouganelis", "abstract": "Context. The Sun's complex corona is the source of the solar wind and\ninterplanetary magnetic field. While the large scale morphology is well\nunderstood, the impact of variations in coronal properties on the scale of a\nfew degrees on properties of the interplanetary medium is not known. Solar\nOrbiter, carrying both remote sensing and in situ instruments into the inner\nsolar system, is intended to make these connections better than ever before.\nAims. We combine remote sensing and in situ measurements from Solar Orbiter's\nfirst perihelion at 0.5 AU to study the fine scale structure of the solar wind\nfrom the equatorward edge of a polar coronal hole with the aim of identifying\ncharacteristics of the corona which can explain the in situ variations.\nMethods. We use in situ measurements of the magnetic field, density and solar\nwind speed to identify structures on scales of hours at the spacecraft. Using\nPotential Field Source Surface mapping we estimate the source locations of the\nmeasured solar wind as a function of time and use EUI images to characterise\nthese solar sources. Results. We identify small scale stream interactions in\nthe solar wind with compressed magnetic field and density along with speed\nvariations which are associated with corrugations in the edge of the coronal\nhole on scales of several degrees, demonstrating that fine scale coronal\nstructure can directly influence solar wind properties and drive variations\nwithin individual streams. Conclusions. This early analysis already\ndemonstrates the power of Solar Orbiter's combined remote sensing and in situ\npayload and shows that with future, closer perihelia it will be possible\ndramatically to improve our knowledge of the coronal sources of fine scale\nsolar wind structure, which is important both for understanding the phenomena\ndriving the solar wind and predicting its impacts at the Earth and elsewhere.", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2104.14960v1"}
{"entry_id": "http://arxiv.org/abs/2009.03063v1", "date": "2020-09-07", "title": "A Light-Weight Object Detection Framework with FPA Module for Optical Remote Sensing Imagery", "authors": "Xi Gu, Lingbin Kong, Zhicheng Wang, Jie Li, Zhaohui Yu, Gang Wei", "abstract": "With the development of remote sensing technology, the acquisition of remote\nsensing images is easier and easier, which provides sufficient data resources\nfor the task of detecting remote sensing objects. However, how to detect\nobjects quickly and accurately from many complex optical remote sensing images\nis a challenging hot issue. In this paper, we propose an efficient anchor free\nobject detector, CenterFPANet. To pursue speed, we use a lightweight backbone\nand introduce the asymmetric revolution block. To improve the accuracy, we\ndesigned the FPA module, which links the feature maps of different levels, and\nintroduces the attention mechanism to dynamically adjust the weights of each\nlevel of feature maps, which solves the problem of detection difficulty caused\nby large size range of remote sensing objects. This strategy can improve the\naccuracy of remote sensing image object detection without reducing the\ndetection speed. On the DOTA dataset, CenterFPANet mAP is 64.00%, and FPS is\n22.2, which is close to the accuracy of the anchor-based methods currently used\nand much faster than them. Compared with Faster RCNN, mAP is 6.76% lower but\n60.87% faster. All in all, CenterFPANet achieves a balance between speed and\naccuracy in large-scale optical remote sensing object detection.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2009.03063v1"}
{"entry_id": "http://arxiv.org/abs/2204.09120v1", "date": "2022-04-18", "title": "Optical Remote Sensing Image Understanding with Weak Supervision: Concepts, Methods, and Perspectives", "authors": "Jun Yue, Leyuan Fang, Pedram Ghamisi, Weiying Xie, Jun Li, Jocelyn Chanussot, Antonio J Plaza", "abstract": "In recent years, supervised learning has been widely used in various tasks of\noptical remote sensing image understanding, including remote sensing image\nclassification, pixel-wise segmentation, change detection, and object\ndetection. The methods based on supervised learning need a large amount of\nhigh-quality training data and their performance highly depends on the quality\nof the labels. However, in practical remote sensing applications, it is often\nexpensive and time-consuming to obtain large-scale data sets with high-quality\nlabels, which leads to a lack of sufficient supervised information. In some\ncases, only coarse-grained labels can be obtained, resulting in the lack of\nexact supervision. In addition, the supervised information obtained manually\nmay be wrong, resulting in a lack of accurate supervision. Therefore, remote\nsensing image understanding often faces the problems of incomplete, inexact,\nand inaccurate supervised information, which will affect the breadth and depth\nof remote sensing applications. In order to solve the above-mentioned problems,\nresearchers have explored various tasks in remote sensing image understanding\nunder weak supervision. This paper summarizes the research progress of weakly\nsupervised learning in the field of remote sensing, including three typical\nweakly supervised paradigms: 1) Incomplete supervision, where only a subset of\ntraining data is labeled; 2) Inexact supervision, where only coarse-grained\nlabels of training data are given; 3) Inaccurate supervision, where the labels\ngiven are not always true on the ground.", "journal": "", "doi": "10.1109/MGRS.2022.3161377", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.09120v1"}
{"entry_id": "http://arxiv.org/abs/1602.06335v4", "date": "2016-02-16", "title": "A Machine Learning Approach to Forecasting Remotely Sensed Vegetation Health", "authors": "John J. Nay, Emily Burchfield, Jonathan Gilligan", "abstract": "Drought threatens food and water security around the world, and this threat\nis likely to become more severe under climate change. High resolution\npredictive information can help farmers, water managers, and others to manage\nthe effects of drought. We have created an open source tool to produce\nshort-term forecasts of vegetation health at high spatial resolution, using\ndata that are global in coverage. The tool automates downloading and processing\nModerate Resolution Imaging Spectroradiometer (MODIS) datasets, and training\ngradient-boosted machine models on hundreds of millions of observations to\npredict future values of the Enhanced Vegetation Index. We compared the\npredictive power of different sets of variables (raw spectral MODIS data and\nLevel-3 MODIS products) in two regions with distinct agro-ecological systems,\nclimates, and cloud coverage: Sri Lanka and California. Our tool provides\nconsiderably greater predictive power on held-out datasets than simpler\nbaseline models.", "journal": "", "doi": null, "primary_category": "q-bio.OT", "categories": ["q-bio.OT", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/1602.06335v4"}
{"entry_id": "http://arxiv.org/abs/1310.1784v2", "date": "2013-10-07", "title": "Non-Markovian effect on remote state preparation", "authors": "Zhen-Yu Xu, Chen Liu, Shunlong Luo, Shiqun Zhu", "abstract": "Memory effect of non-Markovian dynamics in open quantum systems is often\nbelieved to be beneficial for quantum information processing. In this work, we\nemploy an experimentally controllable two-photon open system, with one photon\nexperiencing a dephasing environment and the other being free from noise, to\nshow that non-Markovian effect may also have a negative impact on quantum tasks\nsuch as remote state preparation: For a certain period of controlled time\ninterval, stronger non-Markovian effect yields lower fidelity of remote state\npreparation, as opposed to the common wisdom that more information leads to\nbetter performance. As a comparison, a positive non-Markovian effect on the RSP\nfidelity with another typical non-Markovian noise is analyzed. Consequently,\nthe observed dual character of non-Markovian effect will be of great importance\nin the field of open systems engineering.", "journal": "Annals of Physics 356, 29 (2015)", "doi": "10.1016/j.aop.2015.02.026", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1310.1784v2"}
{"entry_id": "http://arxiv.org/abs/2003.11756v1", "date": "2020-03-26", "title": "The 1st Challenge on Remote Physiological Signal Sensing (RePSS)", "authors": "Xiaobai Li, Hu Han, Hao Lu, Xuesong Niu, Zitong Yu, Antitza Dantcheva, Guoying Zhao, Shiguang Shan", "abstract": "Remote measurement of physiological signals from videos is an emerging topic.\nThe topic draws great interests, but the lack of publicly available benchmark\ndatabases and a fair validation platform are hindering its further development.\nFor this concern, we organize the first challenge on Remote Physiological\nSignal Sensing (RePSS), in which two databases of VIPL and OBF are provided as\nthe benchmark for kin researchers to evaluate their approaches. The 1st\nchallenge of RePSS focuses on measuring the average heart rate from facial\nvideos, which is the basic problem of remote physiological measurement. This\npaper presents an overview of the challenge, including data, protocol, analysis\nof results and discussion. The top ranked solutions are highlighted to provide\ninsights for researchers, and future directions are outlined for this topic and\nthis challenge.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2003.11756v1"}
{"entry_id": "http://arxiv.org/abs/1212.2638v1", "date": "2012-12-11", "title": "Spectral Fingerprints of Earth-like Planets Around FGK Stars", "authors": "Sarah Rugheimer, Lisa Kaltenegger, Andras Zsom, Ant\u00edgona Segura, Dimitar Sasselov", "abstract": "We present model atmospheres for an Earth-like planet orbiting the entire\ngrid of main sequence FGK stars with effective temperatures ranging from Teff =\n4250K to Teff = 7000K in 250K intervals. We model the remotely detectable\nspectra of Earth-like planets for clear and cloudy atmospheres at the 1AU\nequivalent distance from the VIS to IR (0.4 {\\mu}m - 20 {\\mu}m) to compare\ndetectability of features in different wavelength ranges in accordance with\nJWST and future design concepts to characterize exo-Earths. We also explore the\neffect of the stellar UV levels as well as spectral energy distribution on a\nterrestrial atmosphere concentrating on detectable atmospheric features that\nindicate habitability on Earth, namely: H2O, O3, CH4, N2O and CH3Cl. The\nincrease in UV dominates changes of O3, OH, CH4, N2O and CH3Cl whereas the\nincrease in stellar temperature dominates changes in H2O. The overall effect as\nstellar effective temperatures and corresponding UV increase, is a lower\nsurface temperature of the planet due to a bigger part of the stellar flux\nbeing reflected at short wavelengths, as well as increased photolysis.\nEarth-like atmospheric models show more O3 and OH but less stratospheric CH4,\nN2O, CH3Cl and tropospheric H2O (but more stratospheric H2O) with increasing\neffective temperature of Main Sequence stars. The corresponding spectral\nfeatures on the other hand show different detectability depending on the\nwavelength observed. We concentrate on directly imaged planets here as\nframework to interpret future lightcurves, direct imaging and secondary eclipse\nmeasurements of atmospheres of terrestrial planets in the HZ at varying orbital\npositions.", "journal": "Astrobiology. March 2013, 13(3): 251-269", "doi": "10.1089/ast.2012.0888", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1212.2638v1"}
{"entry_id": "http://arxiv.org/abs/1911.04008v1", "date": "2019-11-10", "title": "Auto-Calibration of Remote Sensing Solar Telescopes with Deep Learning", "authors": "Brad Neuberg, Souvik Bose, Valentina Salvatelli, Luiz F. G. dos Santos, Mark Cheung, Miho Janvier, Atilim Gunes Baydin, Yarin Gal, Meng Jin", "abstract": "As a part of NASA's Heliophysics System Observatory (HSO) fleet of\nsatellites,the Solar Dynamics Observatory (SDO) has continuously monitored the\nSun since2010. Ultraviolet (UV) and Extreme UV (EUV) instruments in orbit, such\nasSDO's Atmospheric Imaging Assembly (AIA) instrument, suffer time-dependent\ndegradation which reduces instrument sensitivity. Accurate calibration for\n(E)UV instruments currently depends on periodic sounding rockets, which are\ninfrequent and not practical for heliophysics missions in deep space. In the\npresent work, we develop a Convolutional Neural Network (CNN) that\nauto-calibrates SDO/AIA channels and corrects sensitivity degradation by\nexploiting spatial patterns in multi-wavelength observations to arrive at a\nself-calibration of (E)UV imaging instruments. Our results remove a major\nimpediment to developing future HSOmissions of the same scientific caliber as\nSDO but in deep space, able to observe the Sun from more vantage points than\njust SDO's current geosynchronous orbit.This approach can be adopted to perform\nautocalibration of other imaging systems exhibiting similar forms of\ndegradation", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "astro-ph.IM", "cs.LG", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1911.04008v1"}
{"entry_id": "http://arxiv.org/abs/1302.2606v2", "date": "2013-02-11", "title": "A new bio-inspired method for remote sensing imagery classification", "authors": "Amghar Yasmina Teldja, Fizazi Hadria", "abstract": "The problem of supervised classification of the satellite image is considered\nto be the task of grouping pixels into a number of homogeneous regions in space\nintensity. This paper proposes a novel approach that combines a radial basic\nfunction clustering network with a growing neural gas include utility factor\nclassifier to yield improved solutions, obtained with previous networks. The\ndouble objective technique is first used to the development of a method to\nperform the satellite images classification, and finally, the implementation to\naddress the issue of the number of nodes in the hidden layer of the classic\nRadial Basis functions network. Results demonstrating the effectiveness of the\nproposed technique are provided for numeric remote sensing imagery. Moreover,\nthe remotely sensed image of Oran city in Algeria has been classified using the\nproposed technique to establish its utility.", "journal": "", "doi": null, "primary_category": "cs.NE", "categories": ["cs.NE", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/1302.2606v2"}
{"entry_id": "http://arxiv.org/abs/1704.03530v1", "date": "2017-04-11", "title": "Feature Selection Parallel Technique for Remotely Sensed Imagery Classification", "authors": "Nhien-An Le-Khac, M-Tahar Kechadi, Bo Wu, C. Chen", "abstract": "Remote sensing research focusing on feature selection has long attracted the\nattention of the remote sensing community because feature selection is a\nprerequisite for image processing and various applications. Different feature\nselection methods have been proposed to improve the classification accuracy.\nThey vary from basic search techniques to clonal selections, and various\noptimal criteria have been investigated. Recently, methods using\ndependence-based measures have attracted much attention due to their ability to\ndeal with very high dimensional datasets. However, these methods are based on\nCramers V test, which has performance issues with large datasets. In this\npaper, we propose a parallel approach to improve their performance. We evaluate\nour approach on hyper-spectral and high spatial resolution images and compare\nit to the proposed methods with a centralized version as preliminary results.\nThe results are very promising.", "journal": "", "doi": null, "primary_category": "cs.DC", "categories": ["cs.DC", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/1704.03530v1"}
{"entry_id": "http://arxiv.org/abs/1801.10240v1", "date": "2018-01-30", "title": "Non-local tensor completion for multitemporal remotely sensed images inpainting", "authors": "Teng-Yu Ji, Naoto Yokoya, Xiao Xiang Zhu, Ting-Zhu Huang", "abstract": "Remotely sensed images may contain some missing areas because of poor weather\nconditions and sensor failure. Information of those areas may play an important\nrole in the interpretation of multitemporal remotely sensed data. The paper\naims at reconstructing the missing information by a non-local low-rank tensor\ncompletion method (NL-LRTC). First, nonlocal correlations in the spatial domain\nare taken into account by searching and grouping similar image patches in a\nlarge search window. Then low-rankness of the identified 4-order tensor groups\nis promoted to consider their correlations in spatial, spectral, and temporal\ndomains, while reconstructing the underlying patterns. Experimental results on\nsimulated and real data demonstrate that the proposed method is effective both\nqualitatively and quantitatively. In addition, the proposed method is\ncomputationally efficient compared to other patch based methods such as the\nrecent proposed PM-MTGSR method.", "journal": "", "doi": "10.1109/TGRS.2018.2790262", "primary_category": "eess.SP", "categories": ["eess.SP", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1801.10240v1"}
{"entry_id": "http://arxiv.org/abs/1803.10036v1", "date": "2018-03-27", "title": "Recent Developments from Attribute Profiles for Remote Sensing Image Classification", "authors": "Minh-Tan Pham, S\u00e9bastien Lef\u00e8vre, Erchan Aptoula, Lorenzo Bruzzone", "abstract": "Morphological attribute profiles (APs) are among the most effective methods\nto model the spatial and contextual information for the analysis of remote\nsensing images, especially for classification task. Since their first\nintroduction to this field in early 2010's, many research studies have been\ncontributed not only to exploit and adapt their use to different applications,\nbut also to extend and improve their performance for better dealing with more\ncomplex data. In this paper, we revisit and discuss different developments and\nextensions from APs which have drawn significant attention from researchers in\nthe past few years. These studies are analyzed and gathered based on the\nconcept of multi-stage AP construction. In our experiments, a comparative study\non classification results of two remote sensing data is provided in order to\nshow their significant improvements compared to the originally proposed APs.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1803.10036v1"}
{"entry_id": "http://arxiv.org/abs/1810.11603v1", "date": "2018-10-27", "title": "A Miniaturized Semantic Segmentation Method for Remote Sensing Image", "authors": "Shou-Yu Chen, Guang-Sheng Chen, Wei-Peng Jing", "abstract": "In order to save the memory, we propose a miniaturization method for neural\nnetwork to reduce the parameter quantity existed in remote sensing (RS) image\nsemantic segmentation model. The compact convolution optimization method is\nfirst used for standard U-Net to reduce the weights quantity. With the purpose\nof decreasing model performance loss caused by miniaturization and based on the\ncharacteristics of remote sensing image, fewer down-samplings and improved\ncascade atrous convolution are then used to improve the performance of the\nminiaturized U-Net. Compared with U-Net, our proposed Micro-Net not only\nachieves 29.26 times model compression, but also basically maintains the\nperformance unchanged on the public dataset. We provide a Keras and Tensorflow\nhybrid programming implementation for our model:\nhttps://github.com/Isnot2bad/Micro-Net", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/1810.11603v1"}
{"entry_id": "http://arxiv.org/abs/1807.11766v1", "date": "2018-07-31", "title": "Remote sensing image regression for heterogeneous change detection", "authors": "Luigi T. Luppino, Filippo M. Bianchi, Gabriele Moser, Stian N. Anfinsen", "abstract": "Change detection in heterogeneous multitemporal satellite images is an\nemerging topic in remote sensing. In this paper we propose a framework, based\non image regression, to perform change detection in heterogeneous multitemporal\nsatellite images, which has become a main topic in remote sensing. Our method\nlearns a transformation to map the first image to the domain of the other\nimage, and vice versa. Four regression methods are selected to carry out the\ntransformation: Gaussian processes, support vector machines, random forests,\nand a recently proposed kernel regression method called homogeneous pixel\ntransformation. To evaluate not only potentials and limitations of our\nframework, but also the pros and cons of each regression method, we perform\nexperiments on two data sets. The results indicates that random forests achieve\ngood performance, are fast and robust to hyperparameters, whereas the\nhomogeneous pixel transformation method can achieve better accuracy at the cost\nof a higher complexity.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.11766v1"}
{"entry_id": "http://arxiv.org/abs/2003.08793v1", "date": "2020-03-17", "title": "Deep Active Learning for Remote Sensing Object Detection", "authors": "Zhenshen Qu, Jingda Du, Yong Cao, Qiuyu Guan, Pengbo Zhao", "abstract": "Recently, CNN object detectors have achieved high accuracy on remote sensing\nimages but require huge labor and time costs on annotation. In this paper, we\npropose a new uncertainty-based active learning which can select images with\nmore information for annotation and detector can still reach high performance\nwith a fraction of the training images. Our method not only analyzes objects'\nclassification uncertainty to find least confident objects but also considers\ntheir regression uncertainty to declare outliers. Besides, we bring out two\nextra weights to overcome two difficulties in remote sensing datasets,\nclass-imbalance and difference in images' objects amount. We experiment our\nactive learning algorithm on DOTA dataset with CenterNet as object detector. We\nachieve same-level performance as full supervision with only half images. We\neven override full supervision with 55% images and augmented weights on least\nconfident images.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2003.08793v1"}
{"entry_id": "http://arxiv.org/abs/2103.04928v1", "date": "2021-03-08", "title": "Ethane clathrate hydrate infrared signatures for solar system remote sensing", "authors": "Emmanuel Dartois, Fran\u00e7ois Langlet", "abstract": "Hydrocarbons such as methane and ethane are present in many solar system\nobjects, including comets, moons and planets. The interaction of these\nhydrocarbons with water ice at low temperatures could lead to the formation of\ninclusion compounds, such as clathrate hydrates (water based host cages\ntrapping hydrocarbons guest molecules), modifying their retention, stability\nand therefore evolution. The occurrence of {\\cor clathrate hydrates} on solar\nsystem surfaces could be established by remote sensing of their spectroscopic\nsignatures. In this study, we measure and analyse ethane clathrate hydrate\nspectra recorded in the temperature range from 5.3 to 160K, covering most of\nthe temperature range of interest for solar system objects. Specific infrared\nband signatures are identified for the ethane encaged guest. We provide\nevidence that ethane clathrate hydrate outcrops can be detected by remote\nsensing on the surface of planetary bodies.", "journal": "Icarus 357 (2021) 114255", "doi": "10.1016/j.icarus.2020.114255", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2103.04928v1"}
{"entry_id": "http://arxiv.org/abs/2202.13251v1", "date": "2022-02-26", "title": "Supervising Remote Sensing Change Detection Models with 3D Surface Semantics", "authors": "Isaac Corley, Peyman Najafirad", "abstract": "Remote sensing change detection, identifying changes between scenes of the\nsame location, is an active area of research with a broad range of\napplications. Recent advances in multimodal self-supervised pretraining have\nresulted in state-of-the-art methods which surpass vision models trained solely\non optical imagery. In the remote sensing field, there is a wealth of\noverlapping 2D and 3D modalities which can be exploited to supervise\nrepresentation learning in vision models. In this paper we propose Contrastive\nSurface-Image Pretraining (CSIP) for joint learning using optical RGB and above\nground level (AGL) map pairs. We then evaluate these pretrained models on\nseveral building segmentation and change detection datasets to show that our\nmethod does, in fact, extract features relevant to downstream applications\nwhere natural and artificial surface information is relevant.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2202.13251v1"}
{"entry_id": "http://arxiv.org/abs/1809.11123v2", "date": "2018-09-28", "title": "Remote State Preparation using Correlations beyond Discord", "authors": "Som Kanjilal, Aiman Khan, C. Jebarathinam, Dipankar Home", "abstract": "In recent years, exploring the possible use of separable states as resource\nfor achieving quantum information processing(QIP) tasks has been gaining\nincreasing significance. In this context, a particularly important\ndemonstration has been that non-vanishing discord is the necessary condition\nfor the separable states to be used as resource for remotely preparing any\narbitrary pure target state [Nature Physics $8$, $666$ $(2012)$]. The present\nwork stems from our observation that not only resource states with same discord\ncan imply different efficiencies (in terms of average fidelity) of the remote\nstate preparation (RSP) protocol, but also states with higher discord can imply\nlower RSP efficiency. This, therefore, necessitates identification of the\nrelevant feature of quantum correlations which can appropriately quantify\neffectiveness of the resource state for the RSP protocol. To this end, for the\ntwo-qubit Bell-diagonal states, we show that an appropriate measure of\nsimultaneous correlations in three mutually unbiased bases can serve to\nquantify usefulness of the resource for the RSP task using entangled as well as\nseparable states, including non-discordant states as resource. In particular,\nit is revealed that zero-discord states having such non-vanishing measure can\nbe useful for remotely preparing a subset of pure target states. Thus, this\nwork shows that, using separable states, an effective resource for QIP tasks\nsuch as RSP can be provided by simultaneous correlations in mutually unbiased\nbases.", "journal": "Phys. Rev. A 98, 062320 (2018)", "doi": "10.1103/PhysRevA.98.062320", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1809.11123v2"}
{"entry_id": "http://arxiv.org/abs/1907.06678v2", "date": "2019-07-15", "title": "Remote Dipole Field Reconstruction with Dusty Galaxies", "authors": "Fiona McCarthy, Matthew C. Johnson", "abstract": "The kinetic Sunyaev Zel'dovich (kSZ) effect, cosmic microwave background\n(CMB) temperature anisotropies induced by scattering of CMB photons from free\nelectrons, forms the dominant blackbody component of the CMB on small angular\nscales. Future CMB experiments on the resolution/sensitivity frontier will\nmeasure the kSZ effect with high significance. Through the cross-correlation\nwith tracers of structure, it will be possible to reconstruct the remote CMB\ndipole field (e.g. the CMB dipole observed at different locations in the\nUniverse) using the technique of kSZ tomography. In this paper, we derive a\nquadratic estimator for the remote dipole field using the Cosmic Infrared\nBackground (CIB) as a tracer of structure. We forecast the ability of current\nand next-generation measurements of the CMB and CIB to perform kSZ tomography.\nThe total signal-to-noise of the reconstruction is order unity for current\ndatasets, and can improve by a factor of up to $10^3$ for future datasets,\nbased on statistical error only. The CIB-based reconstruction is highly\ncorrelated with a galaxy survey-based reconstruction of the remote dipole\nfield, which can be exploited to improve constraints on cosmological parameters\nand models for the CIB and distribution of baryons.", "journal": "Phys. Rev. D 102, 043520 (2020)", "doi": "10.1103/PhysRevD.102.043520", "primary_category": "astro-ph.CO", "categories": ["astro-ph.CO", "astro-ph.GA", "gr-qc", "hep-ph"], "pdf_url": "http://arxiv.org/pdf/1907.06678v2"}
{"entry_id": "http://arxiv.org/abs/2301.11387v1", "date": "2023-01-26", "title": "Universal Domain Adaptation for Remote Sensing Image Scene Classification", "authors": "Qingsong Xu, Yilei Shi, Xin Yuan, Xiao Xiang Zhu", "abstract": "The domain adaptation (DA) approaches available to date are usually not well\nsuited for practical DA scenarios of remote sensing image classification, since\nthese methods (such as unsupervised DA) rely on rich prior knowledge about the\nrelationship between label sets of source and target domains, and source data\nare often not accessible due to privacy or confidentiality issues. To this end,\nwe propose a practical universal domain adaptation setting for remote sensing\nimage scene classification that requires no prior knowledge on the label sets.\nFurthermore, a novel universal domain adaptation method without source data is\nproposed for cases when the source data is unavailable. The architecture of the\nmodel is divided into two parts: the source data generation stage and the model\nadaptation stage. The first stage estimates the conditional distribution of\nsource data from the pre-trained model using the knowledge of\nclass-separability in the source domain and then synthesizes the source data.\nWith this synthetic source data in hand, it becomes a universal DA task to\nclassify a target sample correctly if it belongs to any category in the source\nlabel set, or mark it as ``unknown\" otherwise. In the second stage, a novel\ntransferable weight that distinguishes the shared and private label sets in\neach domain promotes the adaptation in the automatically discovered shared\nlabel set and recognizes the ``unknown'' samples successfully. Empirical\nresults show that the proposed model is effective and practical for remote\nsensing image scene classification, regardless of whether the source data is\navailable or not. The code is available at https://github.com/zhu-xlab/UniDA.", "journal": "", "doi": "10.1109/TGRS.2023.3235988", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.11387v1"}
{"entry_id": "http://arxiv.org/abs/1812.08287v1", "date": "2018-12-19", "title": "Multisource and Multitemporal Data Fusion in Remote Sensing", "authors": "Pedram Ghamisi, Behnood Rasti, Naoto Yokoya, Qunming Wang, Bernhard Hofle, Lorenzo Bruzzone, Francesca Bovolo, Mingmin Chi, Katharina Anders, Richard Gloaguen, Peter M. Atkinson, Jon Atli Benediktsson", "abstract": "The sharp and recent increase in the availability of data captured by\ndifferent sensors combined with their considerably heterogeneous natures poses\na serious challenge for the effective and efficient processing of remotely\nsensed data. Such an increase in remote sensing and ancillary datasets,\nhowever, opens up the possibility of utilizing multimodal datasets in a joint\nmanner to further improve the performance of the processing approaches with\nrespect to the application at hand. Multisource data fusion has, therefore,\nreceived enormous attention from researchers worldwide for a wide variety of\napplications. Moreover, thanks to the revisit capability of several spaceborne\nsensors, the integration of the temporal information with the spatial and/or\nspectral/backscattering information of the remotely sensed data is possible and\nhelps to move from a representation of 2D/3D data to 4D data structures, where\nthe time variable adds new information as well as challenges for the\ninformation extraction algorithms. There are a huge number of research works\ndedicated to multisource and multitemporal data fusion, but the methods for the\nfusion of different modalities have expanded in different paths according to\neach research community. This paper brings together the advances of multisource\nand multitemporal data fusion approaches with respect to different research\ncommunities and provides a thorough and discipline-specific starting point for\nresearchers at different levels (i.e., students, researchers, and senior\nresearchers) willing to conduct novel investigations on this challenging topic\nby supplying sufficient detail and references.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "eess.SP", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1812.08287v1"}
{"entry_id": "http://arxiv.org/abs/2107.12016v2", "date": "2021-07-26", "title": "Cost-effective Land Cover Classification for Remote Sensing Images", "authors": "Dongwei Li, Shuliang Wang, Qiang He, Yun Yang", "abstract": "Land cover maps are of vital importance to various fields such as land use\npolicy development, ecosystem services, urban planning and agriculture\nmonitoring, which are mainly generated from remote sensing image classification\ntechniques. Traditional land cover classification usually needs tremendous\ncomputational resources, which often becomes a huge burden to the remote\nsensing community. Undoubtedly cloud computing is one of the best choices for\nland cover classification, however, if not managed properly, the computation\ncost on the cloud could be surprisingly high. Recently, cutting the unnecessary\ncomputation long tail has become a promising solution for saving the cost in\nthe cloud. For land cover classification, it is generally not necessary to\nachieve the best accuracy and 85% can be regarded as a reliable land cover\nclassification. Therefore, in this paper, we propose a framework for\ncost-effective remote sensing classification. Given the desired accuracy, the\nclustering algorithm can stop early for cost-saving whilst achieving sufficient\naccuracy for land cover image classification. Experimental results show that\nachieving 85%-99.9% accuracy needs only 27.34%-60.83% of the total cloud\ncomputation cost for achieving a 100% accuracy. To put it into perspective, for\nthe US land cover classification example, the proposed approach can save over\n$1,593,490.18 for the government in each single-use when the desired accuracy\nis 90%.", "journal": "", "doi": null, "primary_category": "cs.DC", "categories": ["cs.DC"], "pdf_url": "http://arxiv.org/pdf/2107.12016v2"}
{"entry_id": "http://arxiv.org/abs/1711.03934v1", "date": "2017-11-10", "title": "All-optical control of long-lived nuclear spins in rare-earth doped nanoparticles", "authors": "D. Serrano, J. Karlsson, A. Fossati, A. Ferrier, P. Goldner", "abstract": "Nanoscale systems offer key capabilities for quantum technologies that\ninclude single qubit control and readout, multiple qubit gate operation,\nextremely sensitive and localized sensing and imaging, as well as the ability\nto build hybrid quantum systems. To fully exploit these functionalities,\nmultiple degrees of freedom are highly desirable: in this respect, nanoscale\nsystems that coherently couple to light and possess spins, allow for storage of\nphotonic qubits or light-matter entanglement together with processing\ncapabilities. In addition, all-optical control of spins can be possible for\nfaster gate operations and higher spatial selectivity compared to direct RF\nexcitation. Such systems are therefore of high interest for quantum\ncommunications and processing. However, an outstanding challenge is to preserve\nproperties, and especially optical and spin coherence lifetimes, at the\nnanoscale. Indeed, interactions with surfaces related perturbations strongly\nincrease as sizes decrease, although the smallest objects present the highest\nflexibility for integration with other systems. Here, we demonstrate optically\ncontrolled nuclear spins with long coherence lifetimes (T2) in rare earth doped\nnanoparticles. We observed spins echoes and measured T2 of 2.9 +/- 0.3 ms at 5\nK and under a magnetic field of 9 mT, a value comparable to those obtained in\nbulk single crystals. Moreover, we achieve, for the first time, spin T2\nextension using all-optical spin dynamical decoupling and observe high fidelity\nbetween excitation and echo phases. Rare-earth doped nanoparticles are thus the\nonly reported nano-materials in which optically controlled spins with\nmillisecond coherence lifetimes have been observed. These results open the way\nto providing quantum light-atom-spin interfaces with long storage time within\nhybrid architectures.", "journal": "", "doi": "10.1038/s41467-018-04509-w", "primary_category": "quant-ph", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/1711.03934v1"}
{"entry_id": "http://arxiv.org/abs/1908.04450v1", "date": "2019-08-13", "title": "Quantifying the Propagation of Fast Coronal Mass Ejections from the Sun to Interplanetary Space Combining Remote Sensing and Multi-Point in-situ Observations", "authors": "Xiaowei Zhao, Ying D. Liu, Huidong Hu, Rui Wang", "abstract": "In order to have a comprehensive view of the propagation and evolution of\ncoronal mass ejections (CMEs) from the Sun to deep interplanetary space beyond\n1 au, we carry out a kinematic analysis of 7 CMEs in solar cycle 23. The events\nare required to have coordinated coronagraph observations, interplanetary type\nII radio bursts, and multi-point in-situ measurements at the Earth and Ulysses.\nA graduated cylindrical shell model, an analytical model without free\nparameters and a magnetohydrodynamic model are used to derive CME kinematics\nnear the Sun, to quantify the CME/shock propagation in the Sun-Earth space, and\nto connect in-situ signatures at the Earth and Ulysses, respectively. We find\nthat each of the 7 CME-driven shocks experienced a major deceleration before\nreaching 1 au and thereafter propagated with a gradual deceleration from the\nEarth to larger distances. The resulting CME/shock propagation profile for each\ncase is roughly consistent with all the data, which verifies the usefulness of\nthe simple analytical model for CME/shock propagation in the heliosphere. The\nstatistical analysis of CME kinematics indicates a tendency that the faster the\nCME, the larger the deceleration, and the shorter the deceleration time period\nwithin 1 au. For several of these events, the associated geomagnetic storms\nwere mainly caused by the southward magnetic fields in the sheath region. In\nparticular, the interaction between a CME-driven shock and a preceding ejecta\nsignificantly enhanced the preexisting southward magnetic fields and gave rise\nto a severe complex geomagnetic storm.", "journal": "", "doi": "10.3847/1538-4357/ab379b", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1908.04450v1"}
{"entry_id": "http://arxiv.org/abs/1401.7743v1", "date": "2014-01-30", "title": "Effective Features of Remote Sensing Image Classification Using Interactive Adaptive Thresholding Method", "authors": "T. Balaji, Dr. M. Sumathi", "abstract": "Remote sensing image classification can be performed in many different ways\nto extract meaningful features. One common approach is to perform edge\ndetection. A second approach is to try and detect whole shapes, given the fact\nthat these shapes usually tend to have distinctive properties such as object\nforeground or background. To get optimal results, these two approaches can be\ncombined. This paper adopts a combinatorial optimization method to adaptively\nselect threshold based features to improve remote sensing image. Feature\nselection is an important combinatorial optimization problem in the remote\nsensing image classification. The feature selection method has to achieve three\ncharacteristics: first the performance issues by facilitating data collection\nand reducing storage space and classification time, second to perform semantics\nanalysis helping to understand the problem, and third to improve prediction\naccuracy by avoiding the curse of dimensionality. The goal of this thresholding\nan image is to classify pixels as either dark or light and evaluation of\nclassification results. Interactive adaptive thresholding is a form of\nthresholding that takes into account spatial variations in illumination of\nremote sensing image. We present a technique for remote sensing based adaptive\nthresholding using the interactive satellite image of the input. However, our\nsolution is more robust to illumination changes in the remote sensing image.\nAdditionally, our method is simple and easy to implement but it is effective\nalgorithm to classify the image pixels. This technique is suitable for\npreprocessing the remote sensing image classification, making it a valuable\ntool for interactive remote based applications such as augmented reality of the\nclassification procedure.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1401.7743v1"}
{"entry_id": "http://arxiv.org/abs/1905.00022v2", "date": "2019-04-30", "title": "Gravitationally trapped axions on Earth", "authors": "Kyle Lawson, Xunyu Liang, Alexander Mead, Md Shahriar Rahim Siddiqui, Ludovic Van Waerbeke, Ariel Zhitnitsky", "abstract": "We advocate for the idea that there is a fundamentally new mechanism for\naxion production on Earth, as recently suggested in Fischer et al. (2018) and\nLiang & Zhitnitsky (2018). We specifically focus on production of axions within\nEarth, with low velocities such that they will be trapped in the gravitational\nfield. Our computations are based on the so-called Axion Quark Nugget (AQN)\ndark matter model, which was originally invented to explain the similarity of\nthe dark and visible cosmological matter densities. This occurs in the model\nirrespective of the axion mass $m_\\mathrm{a}$ or initial misalignment angle\n$\\theta_0$. Annihilation of antimatter AQNs with visible matter inevitably\nproduce axions when AQNs hit Earth. The emission rate of axions with velocities\nbelow escape velocity is very tiny compared to the overall emission, however\nthese axions will be accumulated over the 4.5 billion year life time of the\nEarth, which greatly enhances the discovery potential. We perform numerical\nsimulations with a realistically modeled incoming AQN velocity and mass\ndistribution, and explore how AQNs interact as they travel through the interior\nof the Earth. We use this to estimate the axion flux on the surface of the\nEarth, the velocity-spectral features of trapped axions, the typical\nannihilation pattern of AQN, and the density profile of the axion halo around\nthe Earth. Knowledge of these properties is necessary to make predictions for\nthe observability of trapped axions using CAST, ADMX, MADMAX, CULTASK, ORPHEUS,\nARIADNE, CASPEr, ABRACADABRA, QUAX, DM Radio.", "journal": "Phys. Rev. D 100, 043531 (2019)", "doi": "10.1103/PhysRevD.100.043531", "primary_category": "astro-ph.CO", "categories": ["astro-ph.CO", "hep-ph"], "pdf_url": "http://arxiv.org/pdf/1905.00022v2"}
{"entry_id": "http://arxiv.org/abs/1211.2215v1", "date": "2012-11-09", "title": "Remote Observatory for Variable Object Research (ROVOR)", "authors": "J. W. Moody, B. Boizelle, K. Bates, B. Little, T. McCombs, J. Nelson, C. Pace, R. L. Pearson III, J. Harrison, P. J. Brown, J. Barnes", "abstract": "Observatories constructed solely for photometric monitoring make it possible\nto understand the temporal nature of objects over time scales that historically\nhave been difficult to achieve. We report on one such observatory, the Remote\nObservatory for Variable Object Research (ROVOR) which was constructed to\nenable both long-term and rapid cadence observations of brighter objects. ROVOR\nis an 0.4m optical telescope located in central Utah and commissioned for\nscientific observations in 2008. Principle research has been monitoring\nblazars, x-ray binaries, AGN, and an occasional gamma-ray burst afterglow. We\ndescribe the observatory, the control system, and its unique roof.", "journal": "PASP, 124, 956-962, 2012", "doi": "10.1086/667712", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1211.2215v1"}
{"entry_id": "http://arxiv.org/abs/2103.00208v3", "date": "2021-02-27", "title": "Remote Sensing Image Change Detection with Transformers", "authors": "Hao Chen, Zipeng Qi, Zhenwei Shi", "abstract": "Modern change detection (CD) has achieved remarkable success by the powerful\ndiscriminative ability of deep convolutions. However, high-resolution remote\nsensing CD remains challenging due to the complexity of objects in the scene.\nObjects with the same semantic concept may show distinct spectral\ncharacteristics at different times and spatial locations. Most recent CD\npipelines using pure convolutions are still struggling to relate long-range\nconcepts in space-time. Non-local self-attention approaches show promising\nperformance via modeling dense relations among pixels, yet are computationally\ninefficient. Here, we propose a bitemporal image transformer (BIT) to\nefficiently and effectively model contexts within the spatial-temporal domain.\nOur intuition is that the high-level concepts of the change of interest can be\nrepresented by a few visual words, i.e., semantic tokens. To achieve this, we\nexpress the bitemporal image into a few tokens, and use a transformer encoder\nto model contexts in the compact token-based space-time. The learned\ncontext-rich tokens are then feedback to the pixel-space for refining the\noriginal features via a transformer decoder. We incorporate BIT in a deep\nfeature differencing-based CD framework. Extensive experiments on three CD\ndatasets demonstrate the effectiveness and efficiency of the proposed method.\nNotably, our BIT-based model significantly outperforms the purely convolutional\nbaseline using only 3 times lower computational costs and model parameters.\nBased on a naive backbone (ResNet18) without sophisticated structures (e.g.,\nFPN, UNet), our model surpasses several state-of-the-art CD methods, including\nbetter than four recent attention-based methods in terms of efficiency and\naccuracy. Our code is available at https://github.com/justchenhao/BIT\\_CD.", "journal": "", "doi": "10.1109/TGRS.2021.3095166", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2103.00208v3"}
{"entry_id": "http://arxiv.org/abs/1301.5617v1", "date": "2013-01-23", "title": "Earth tides in MacDonald's model", "authors": "S. Ferraz-Mello", "abstract": "We expand the equations used in MacDonald's 1964 theory and Fourier analyze\nthe tidal variations of the height at one point on the Earth surface, and also\nthe tidal potential at such point. It is shown that no intrinsic law is\nrelating the lag of the tide components to their frequencies. In other words,\nno simple rheology is being intrinsically fixed by MacDonald's equations. The\nsame is true of the modification proposed by Singer(1968). At variance with\nthese two cases, the modification proposed by Williams and Efroimsky (2012) fix\nthe standard Darwin rheology in which the lags are proportional to the\nfrequencies and their model is, in this sense, equivalent to Mignard's 1979\nformulation of Darwin's theory.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1301.5617v1"}
{"entry_id": "http://arxiv.org/abs/2207.11166v2", "date": "2022-07-22", "title": "METER-ML: A Multi-Sensor Earth Observation Benchmark for Automated Methane Source Mapping", "authors": "Bryan Zhu, Nicholas Lui, Jeremy Irvin, Jimmy Le, Sahil Tadwalkar, Chenghao Wang, Zutao Ouyang, Frankie Y. Liu, Andrew Y. Ng, Robert B. Jackson", "abstract": "Reducing methane emissions is essential for mitigating global warming. To\nattribute methane emissions to their sources, a comprehensive dataset of\nmethane source infrastructure is necessary. Recent advancements with deep\nlearning on remotely sensed imagery have the potential to identify the\nlocations and characteristics of methane sources, but there is a substantial\nlack of publicly available data to enable machine learning researchers and\npractitioners to build automated mapping approaches. To help fill this gap, we\nconstruct a multi-sensor dataset called METER-ML containing 86,599\ngeoreferenced NAIP, Sentinel-1, and Sentinel-2 images in the U.S. labeled for\nthe presence or absence of methane source facilities including concentrated\nanimal feeding operations, coal mines, landfills, natural gas processing\nplants, oil refineries and petroleum terminals, and wastewater treatment\nplants. We experiment with a variety of models that leverage different spatial\nresolutions, spatial footprints, image products, and spectral bands. We find\nthat our best model achieves an area under the precision recall curve of 0.915\nfor identifying concentrated animal feeding operations and 0.821 for oil\nrefineries and petroleum terminals on an expert-labeled test set, suggesting\nthe potential for large-scale mapping. We make METER-ML freely available at\nhttps://stanfordmlgroup.github.io/projects/meter-ml/ to support future work on\nautomated methane source mapping.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2207.11166v2"}
{"entry_id": "http://arxiv.org/abs/1203.1751v1", "date": "2012-03-08", "title": "Remote Sensing and Control for Establishing and Maintaining Digital Irrigation", "authors": "Akin cellatoglu, Balasubramanian Karuppanan", "abstract": "The remotely sensed data from an unknown location is transmitted in real time\nthrough internet and gathered in a PC. The data is collected for a considerable\nperiod of time and analyzed in PC as to assess the suitability and fertility of\nthe land for establishing an electronic plantation in that area. The analysis\nalso helps deciding the plantation of appropriate plants in the location\nidentified. The system performing this task with appropriate transducers\ninstalled in remote area, the methodologies involved in transmission and data\ngathering are reported.. The second part of the project deals with data\ngathering from remote site and issuing control signals to remote appliances in\nthe site; all performed through internet. Therefore, this control scheme is a\nduplex system monitoring the irrigation activities by collecting data in one\ndirection and issuing commands on the opposite direction. This scheme maintains\nthe digital irrigation systems effectively and efficiently as to utilize the\nresources optimally for yielding enhanced production. The methodologies\ninvolved in extending the two way communication of data are presented.", "journal": "", "doi": null, "primary_category": "cs.SY", "categories": ["cs.SY"], "pdf_url": "http://arxiv.org/pdf/1203.1751v1"}
{"entry_id": "http://arxiv.org/abs/1812.05329v2", "date": "2018-12-13", "title": "Wider Channel Attention Network for Remote Sensing Image Super-resolution", "authors": "Jun Gu, Guangluan Xu, Yue Zhang, Xian Sun, Ran Wen, Lei Wang", "abstract": "Recently, deep convolutional neural networks (CNNs) have obtained promising\nresults in image processing tasks including super-resolution (SR). However,\nmost CNN-based SR methods treat low-resolution (LR) inputs and features equally\nacross channels, rarely notice the loss of information flow caused by the\nactivation function and fail to leverage the representation ability of CNNs. In\nthis letter, we propose a novel single-image super-resolution (SISR) algorithm\nnamed Wider Channel Attention Network (WCAN) for remote sensing images.\nFirstly, the channel attention mechanism is used to adaptively recalibrate the\nimportance of each channel at the middle of the wider attention block (WAB).\nSecondly, we propose the Local Memory Connection (LMC) to enhance the\ninformation flow. Finally, the features within each WAB are fused to take\nadvantage of the network's representation capability and further improve\ninformation and gradient flow. Analytic experiments on a public remote sensing\ndata set (UC Merced) show that our WCAN achieves better accuracy and visual\nimprovements against most state-of-the-art methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1812.05329v2"}
{"entry_id": "http://arxiv.org/abs/2001.03899v2", "date": "2020-01-12", "title": "Wearable Haptics for Remote Social Walking", "authors": "Tommaso Lisini Baldi, Gianluca Paolocci, Davide Barcelli, Domenico Prattichizzo", "abstract": "Walking is an essential activity for a healthy life, which becomes less\ntiring and more enjoyable if done together. Common difficulties we have in\nperforming sufficient physical exercise, for instance the lack of motivation,\ncan be overcome by exploiting its social aspect. However, our lifestyle\nsometimes makes it very difficult to find time together with others who live\nfar away from us to go for a walk. In this paper we propose a novel system\nenabling people to have a 'remote social walk' by streaming the gait cadence\nbetween two persons walking in different places, increasing the sense of mutual\npresence. Vibrations provided at the users' ankles display the partner's\nsensation perceived during the heel-strike. In order to achieve the\naforementioned goal in a two users experiment, we envisaged a four-step\nincremental validation process: i) a single walker has to adapt the cadence\nwith a virtual reference generated by a software; ii) a single user is tasked\nto follow a predefined time varying gait cadence; iii) a leader-follower\nscenario in which the haptic actuation is mono-directional; iv) a peer-to-peer\ncase with bi-directional haptic communication. Careful experimental validation\nwas conducted involving a total of 50 people, which confirmed the efficacy of\nour system in perceiving the partners' gait cadence in each of the proposed\nscenarios.", "journal": "IEEE Transactions on Haptics, 2020", "doi": "10.1109/TOH.2020.2967049", "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/2001.03899v2"}
{"entry_id": "http://arxiv.org/abs/2002.04759v1", "date": "2020-02-12", "title": "Collaborative Inference for Efficient Remote Monitoring", "authors": "Chi Zhang, Yong Sheng Soh, Ling Feng, Tianyi Zhou, Qianxiao Li", "abstract": "While current machine learning models have impressive performance over a wide\nrange of applications, their large size and complexity render them unsuitable\nfor tasks such as remote monitoring on edge devices with limited storage and\ncomputational power. A naive approach to resolve this on the model level is to\nuse simpler architectures, but this sacrifices prediction accuracy and is\nunsuitable for monitoring applications requiring accurate detection of the\nonset of adverse events. In this paper, we propose an alternative solution to\nthis problem by decomposing the predictive model as the sum of a simple\nfunction which serves as a local monitoring tool, and a complex correction term\nto be evaluated on the server. A sign requirement is imposed on the latter to\nensure that the local monitoring function is safe, in the sense that it can\neffectively serve as an early warning system. Our analysis quantifies the\ntrade-offs between model complexity and performance, and serves as a guidance\nfor architecture design. We validate our proposed framework on a series of\nmonitoring experiments, where we succeed at learning monitoring models with\nsignificantly reduced complexity that minimally violate the safety requirement.\nMore broadly, our framework is useful for learning classifiers in applications\nwhere false negatives are significantly more costly compared to false\npositives.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2002.04759v1"}
{"entry_id": "http://arxiv.org/abs/2205.02344v1", "date": "2022-05-04", "title": "Remote Sensing of Coronal Forces During a Solar Prominence Eruption", "authors": "V. M. Uritsky, B. J. Thompson, C. R. DeVore", "abstract": "We present a new methodology -- the Keplerian Optical Dynamics Analysis\n(KODA) -- for analyzing the dynamics of dense, cool material in the solar\ncorona. The technique involves adaptive spatiotemporal tracking of propagating\nintensity gradients and their characterization in terms of time-evolving\nKeplerian areas swept out by the position vectors of moving plasma blobs.\nWhereas gravity induces purely ballistic motions consistent with Kepler's\nsecond law, non-central forces such as the Lorentz force introduce non-zero\ntorques resulting in more complex motions. KODA algorithms enable direct\nevaluation of the line-of-sight component of the net torque density from the\nimage-plane projection of the areal acceleration. The method is applied to the\nprominence eruption of 2011 June 7, observed by the Solar Dynamics\nObservatory's Atmospheric Imaging Assembly. Results obtained include\nquantitative estimates of the magnetic forces, field intensities, and blob\nmasses and energies across a vast region impacted by the post-reconnection\nredistribution of the prominence material. The magnetic pressure and energy are\nstrongly dominant during the early, rising phase of the eruption, while the\ndynamic pressure and kinetic energy become significant contributors during the\nsubsequent falling phases. Measured intensive properties of the prominence\nblobs are consistent with those of typical active-region prominences; measured\nextensive properties are compared with those of the whole pre-eruption\nprominence and the post-eruption coronal mass ejection of 2011 June 7, all\nderived by other investigators and techniques. We argue that KODA provides\nvaluable information on characteristics of erupting prominences that are not\nreadily available via alternative means, thereby shedding new light on their\nenvironment and evolution.", "journal": "", "doi": "10.3847/1538-4357/ac74b4", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.plasm-ph", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2205.02344v1"}
{"entry_id": "http://arxiv.org/abs/gr-qc/0210030v4", "date": "2002-10-10", "title": "On the Possibility of Measuring the Gravitomagnetic Clock Effect in an Earth Space-Based Experiment", "authors": "Lorenzo Iorio, Herbert I. M. Lichtenegger", "abstract": "In this paper the effect of the post-Newtonian gravitomagnetic force on the\nmean longitudes $l$ of a pair of counter-rotating Earth artificial satellites\nfollowing almost identical circular equatorial orbits is investigated. The\npossibility of measuring it is examined. The observable is the difference of\nthe times required to $l$ in passing from 0 to 2$\\pi$ for both senses of\nmotion. Such gravitomagnetic time shift, which is independent of the orbital\nparameters of the satellites, amounts to 5$\\times 10^{-7}$ s for Earth; it is\ncumulative and should be measured after a sufficiently high number of\nrevolutions. The major limiting factors are the unavoidable imperfect\ncancellation of the Keplerian periods, which yields a constraint of 10$^{-2}$\ncm in knowing the difference between the semimajor axes $a$ of the satellites,\nand the difference $I$ of the inclinations $i$ of the orbital planes which, for\n$i\\sim 0.01^\\circ$, should be less than $0.006^\\circ$. A pair of spacecrafts\nendowed with a sophisticated intersatellite tracking apparatus and drag-free\ncontrol down to 10$^{-9}$ cm s$^{-2}$ Hz$^{-{1/2}}$ level might allow to meet\nthe stringent requirements posed by such a mission.", "journal": "Class.Quant.Grav. 22 (2005) 119-132", "doi": "10.1088/0264-9381/22/1/008", "primary_category": "gr-qc", "categories": ["gr-qc", "astro-ph"], "pdf_url": "http://arxiv.org/pdf/gr-qc/0210030v4"}
{"entry_id": "http://arxiv.org/abs/2207.13866v1", "date": "2022-07-28", "title": "MKANet: A Lightweight Network with Sobel Boundary Loss for Efficient Land-cover Classification of Satellite Remote Sensing Imagery", "authors": "Zhiqi Zhang, Wen Lu, Jinshan Cao, Guangqi Xie", "abstract": "Land cover classification is a multi-class segmentation task to classify each\npixel into a certain natural or man-made category of the earth surface, such as\nwater, soil, natural vegetation, crops, and human infrastructure. Limited by\nhardware computational resources and memory capacity, most existing studies\npreprocessed original remote sensing images by down sampling or cropping them\ninto small patches less than 512*512 pixels before sending them to a deep\nneural network. However, down sampling images incurs spatial detail loss,\nrenders small segments hard to discriminate, and reverses the spatial\nresolution progress obtained by decades of years of efforts. Cropping images\ninto small patches causes a loss of long-range context information, and\nrestoring the predicted results to their original size brings extra latency. In\nresponse to the above weaknesses, we present an efficient lightweight semantic\nsegmentation network termed MKANet. Aimed at the characteristics of top view\nhigh-resolution remote sensing imagery, MKANet utilizes sharing kernels to\nsimultaneously and equally handle ground segments of inconsistent scales, and\nalso employs parallel and shallow architecture to boost inference speed and\nfriendly support image patches more than 10X larger. To enhance boundary and\nsmall segments discrimination, we also propose a method that captures category\nimpurity areas, exploits boundary information and exerts an extra penalty on\nboundaries and small segment misjudgment. Both visual interpretations and\nquantitative metrics of extensive experiments demonstrate that MKANet acquires\nstate-of-the-art accuracy on two land-cover classification datasets and infers\n2X faster than other competitive lightweight networks. All these merits\nhighlight the potential of MKANet in practical applications.", "journal": "Remote Sens. 2022, 14(18), 4514", "doi": "10.3390/rs14184514", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2207.13866v1"}
{"entry_id": "http://arxiv.org/abs/2301.12541v1", "date": "2023-01-29", "title": "Supervised and Contrastive Self-Supervised In-Domain Representation Learning for Dense Prediction Problems in Remote Sensing", "authors": "Ali Ghanbarzade, Dr. Hossein Soleimani", "abstract": "In recent years Convolutional neural networks (CNN) have made significant\nprogress in computer vision. These advancements have been applied to other\nareas, such as remote sensing and have shown satisfactory results. However, the\nlack of large labeled datasets and the inherent complexity of remote sensing\nproblems have made it difficult to train deep CNNs for dense prediction\nproblems. To solve this issue, ImageNet pretrained weights have been used as a\nstarting point in various dense predictions tasks. Although this type of\ntransfer learning has led to improvements, the domain difference between\nnatural and remote sensing images has also limited the performance of deep\nCNNs. On the other hand, self-supervised learning methods for learning visual\nrepresentations from large unlabeled images have grown substantially over the\npast two years. Accordingly, in this paper we have explored the effectiveness\nof in-domain representations in both supervised and self-supervised forms to\nsolve the domain difference between remote sensing and the ImageNet dataset.\nThe obtained weights from remote sensing images are utilized as initial weights\nfor solving semantic segmentation and object detection tasks and\nstate-of-the-art results are obtained. For self-supervised pre-training, we\nhave utilized the SimSiam algorithm as it is simple and does not need huge\ncomputational resources. One of the most influential factors in acquiring\ngeneral visual representations from remote sensing images is the pre-training\ndataset. To examine the effect of the pre-training dataset, equal-sized remote\nsensing datasets are used for pre-training. Our results have demonstrated that\nusing datasets with a high spatial resolution for self-supervised\nrepresentation learning leads to high performance in downstream tasks.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.12541v1"}
{"entry_id": "http://arxiv.org/abs/1901.09317v2", "date": "2019-01-27", "title": "A Structured Approach to the Analysis of Remote Sensing Images", "authors": "Donghui Yan, Congcong Li, Na Cong, Le Yu, Peng Gong", "abstract": "The number of studies for the analysis of remote sensing images has been\ngrowing exponentially in the last decades. Many studies, however, only report\nresults---in the form of certain performance metrics---by a few selected\nalgorithms on a training and testing sample. While this often yields valuable\ninsights, it tells little about some important aspects. For example, one might\nbe interested in understanding the nature of a study by the interaction of\nalgorithm, features, and the sample as these collectively contribute to the\noutcome; among these three, which would be a more productive direction in\nimproving a study; how to assess the sample quality or the value of a set of\nfeatures etc. With a focus on land-use classification, we advocate the use of a\nstructured analysis. The output of a study is viewed as the result of the\ninterplay among three input dimensions: feature, sample, and algorithm.\nSimilarly, another dimension, the error, can be decomposed into error along\neach input dimension. Such a structural decomposition of the inputs or error\ncould help better understand the nature of the problem and potentially suggest\ndirections for improvement. We use the analysis of a remote sensing image at a\nstudy site in Guangzhou, China, to demonstrate how such a structured analysis\ncould be carried out and what insights it generates. The structured analysis\ncould be applied to a new study, or as a diagnosis to an existing one. We\nexpect this will inform practice in the analysis of remote sensing images, and\nhelp advance the state-of-the-art of land-use classification.", "journal": "", "doi": "10.1080/01431161.2019.1607611", "primary_category": "stat.AP", "categories": ["stat.AP"], "pdf_url": "http://arxiv.org/pdf/1901.09317v2"}
{"entry_id": "http://arxiv.org/abs/2205.04056v2", "date": "2022-05-09", "title": "Exploiting Digital Surface Models for Inferring Super-Resolution for Remotely Sensed Images", "authors": "Savvas Karatsiolis, Chirag Padubidri, Andreas Kamilaris", "abstract": "Despite the plethora of successful Super-Resolution Reconstruction (SRR)\nmodels applied to natural images, their application to remote sensing imagery\ntends to produce poor results. Remote sensing imagery is often more complicated\nthan natural images and has its peculiarities such as being of lower\nresolution, it contains noise, and often depicting large textured surfaces. As\na result, applying non-specialized SRR models on remote sensing imagery results\nin artifacts and poor reconstructions. To address these problems, this paper\nproposes an architecture inspired by previous research work, introducing a\nnovel approach for forcing an SRR model to output realistic remote sensing\nimages: instead of relying on feature-space similarities as a perceptual loss,\nthe model considers pixel-level information inferred from the normalized\nDigital Surface Model (nDSM) of the image. This strategy allows the application\nof better-informed updates during the training of the model which sources from\na task (elevation map inference) that is closely related to remote sensing.\nNonetheless, the nDSM auxiliary information is not required during production\nand thus the model infers a super-resolution image without any additional data\nbesides its low-resolution pairs. We assess our model on two remotely sensed\ndatasets of different spatial resolutions that also contain the DSM pairs of\nthe images: the DFC2018 dataset and the dataset containing the national Lidar\nfly-by of Luxembourg. Based on visual inspection, the inferred super-resolution\nimages exhibit particularly superior quality. In particular, the results for\nthe high-resolution DFC2018 dataset are realistic and almost indistinguishable\nfrom the ground truth images.", "journal": "", "doi": "10.1109/TGRS.2022.3209340", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2205.04056v2"}
{"entry_id": "http://arxiv.org/abs/2208.04441v1", "date": "2022-08-08", "title": "Txt2Img-MHN: Remote Sensing Image Generation from Text Using Modern Hopfield Networks", "authors": "Yonghao Xu, Weikang Yu, Pedram Ghamisi, Michael Kopp, Sepp Hochreiter", "abstract": "The synthesis of high-resolution remote sensing images based on text\ndescriptions has great potential in many practical application scenarios.\nAlthough deep neural networks have achieved great success in many important\nremote sensing tasks, generating realistic remote sensing images from text\ndescriptions is still very difficult. To address this challenge, we propose a\nnovel text-to-image modern Hopfield network (Txt2Img-MHN). The main idea of\nTxt2Img-MHN is to conduct hierarchical prototype learning on both text and\nimage embeddings with modern Hopfield layers. Instead of directly learning\nconcrete but highly diverse text-image joint feature representations for\ndifferent semantics, Txt2Img-MHN aims to learn the most representative\nprototypes from text-image embeddings, achieving a coarse-to-fine learning\nstrategy. These learned prototypes can then be utilized to represent more\ncomplex semantics in the text-to-image generation task. To better evaluate the\nrealism and semantic consistency of the generated images, we further conduct\nzero-shot classification on real remote sensing data using the classification\nmodel trained on synthesized images. Despite its simplicity, we find that the\noverall accuracy in the zero-shot classification may serve as a good metric to\nevaluate the ability to generate an image from text. Extensive experiments on\nthe benchmark remote sensing text-image dataset demonstrate that the proposed\nTxt2Img-MHN can generate more realistic remote sensing images than existing\nmethods. Code and pre-trained models are available online\n(https://github.com/YonghaoXu/Txt2Img-MHN).", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2208.04441v1"}
{"entry_id": "http://arxiv.org/abs/1709.00179v1", "date": "2017-09-01", "title": "Effective Use of Dilated Convolutions for Segmenting Small Object Instances in Remote Sensing Imagery", "authors": "Ryuhei Hamaguchi, Aito Fujita, Keisuke Nemoto, Tomoyuki Imaizumi, Shuhei Hikosaka", "abstract": "Thanks to recent advances in CNNs, solid improvements have been made in\nsemantic segmentation of high resolution remote sensing imagery. However, most\nof the previous works have not fully taken into account the specific\ndifficulties that exist in remote sensing tasks. One of such difficulties is\nthat objects are small and crowded in remote sensing imagery. To tackle with\nthis challenging task we have proposed a novel architecture called local\nfeature extraction (LFE) module attached on top of dilated front-end module.\nThe LFE module is based on our findings that aggressively increasing dilation\nfactors fails to aggregate local features due to sparsity of the kernel, and\ndetrimental to small objects. The proposed LFE module solves this problem by\naggregating local features with decreasing dilation factor. We tested our\nnetwork on three remote sensing datasets and acquired remarkably good results\nfor all datasets especially for small objects.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1709.00179v1"}
{"entry_id": "http://arxiv.org/abs/2104.07070v2", "date": "2021-04-14", "title": "Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding", "authors": "Vladan Stojni\u0107, Vladimir Risojevi\u0107", "abstract": "In recent years self-supervised learning has emerged as a promising candidate\nfor unsupervised representation learning. In the visual domain its applications\nare mostly studied in the context of images of natural scenes. However, its\napplicability is especially interesting in specific areas, like remote sensing\nand medicine, where it is hard to obtain huge amounts of labeled data. In this\nwork, we conduct an extensive analysis of the applicability of self-supervised\nlearning in remote sensing image classification. We analyze the influence of\nthe number and domain of images used for self-supervised pre-training on the\nperformance on downstream tasks. We show that, for the downstream task of\nremote sensing image classification, using self-supervised pre-training on\nremote sensing images can give better results than using supervised\npre-training on images of natural scenes. Besides, we also show that\nself-supervised pre-training can be easily extended to multispectral images\nproducing even better results on our downstream tasks.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2104.07070v2"}
{"entry_id": "http://arxiv.org/abs/2207.08156v1", "date": "2022-07-17", "title": "Stochastic accretion of the Earth", "authors": "Paolo A. Sossi, Ingo L. Stotz, Seth A. Jacobson, Alessandro Morbidelli, Hugh St. C. O'Neill", "abstract": "Earth is depleted in volatile elements relative to chondritic meteorites, its\npossible building blocks. The extent of this depletion increases with\ndecreasing condensation temperature, and is approximated by a cumulative normal\ndistribution, unlike that in any chondrite. However, moderately volatile\nelements, occupying the mid-range of the distribution, have chondritic isotope\nratios, contrary to that expected from loss by partial\nvaporisation/condensation. Here we reconcile these observations by showing,\nusing N-body simulations, that Earth accreted stochastically from many\nprecursor bodies whose variable compositions reflect the temperatures at which\nthey formed. Impact-induced atmospheric loss was efficient only when the\nproto-Earth was small, and elements that accreted thereafter retain\nnear-chondritic isotope ratios. Earth's composition is reproduced when initial\ntemperatures of planetesimal- to embryo-sized bodies are set by disk accretion\nrates of (1.08 $\\pm$ 0.17) $\\times$ 10$^{-7}$ solar masses/yr, although they\nmay be perturbed by $^{26}$Al heating on bodies formed at different times. The\nmodel implies a heliocentric gradient in composition and rapid planetesimal\nformation within $\\sim$ 1 Myr, in accord with radiometric volatile depletion\nages of Earth.", "journal": "", "doi": "10.1038/s41550-022-01702-2", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2207.08156v1"}
{"entry_id": "http://arxiv.org/abs/0904.2821v4", "date": "2009-04-18", "title": "Remote Inflation: Hybrid-like inflation without hybrid-type potential", "authors": "Tomohiro Matsuda", "abstract": "A new scenario of hybrid-like inflation is considered without using\nhybrid-type potential. Radiation raised continuously by a dissipating inflaton\nfield keeps symmetry restoration in a remote sector, and the false-vacuum\nenergy of the remote sector dominates the energy density during inflation.\nRemote inflation is terminated when the temperature reaches the critical\ntemperature, or when the slow-roll condition is violated. Without introducing a\ncomplex form of couplings, inflaton field may either roll-in (like a standard\nhybrid inflation) or roll-out (like an inverted-hybrid model or quintessential\ninflation) on arbitrary inflaton potential. Significant signatures of remote\ninflation can be observed in the spectrum caused by (1) the inhomogeneous phase\ntransition in the remote sector, or (2) a successive phase transition in the\nremote sector. Remote inflation can predict strong amplification or suppression\nof small-scale perturbations without introducing multiple inflation. Since the\ninflaton may have a run-away potential, it is also possible to identify the\ninflaton with quintessence, without introducing additional mechanisms. Even if\nthe false-vacuum energy is not dominated by the remote sector, the phase\ntransition in the remote sector is possible during warm inflation, which may\ncause significant amplification/suppression of the curvature perturbations.", "journal": "JCAP 0907:003,2009", "doi": "10.1088/1475-7516/2009/07/003", "primary_category": "astro-ph.CO", "categories": ["astro-ph.CO", "hep-ph", "hep-th"], "pdf_url": "http://arxiv.org/pdf/0904.2821v4"}
{"entry_id": "http://arxiv.org/abs/1510.00059v1", "date": "2015-09-30", "title": "On Remote Estimation with Multiple Communication Channels", "authors": "Xiaobin Gao, Emrah Akyol, Tamer Basar", "abstract": "This paper considers a sequential estimation and sensor scheduling problem in\nthe presence of multiple communication channels. As opposed to the classical\nremote estimation problem that involves one perfect (noiseless) channel and one\nextremely noisy channel (which corresponds to not transmitting the observed\nstate), a more realistic additive noise channel with fixed power constraint\nalong with a more costly perfect channel is considered. It is shown, via a\ncounter-example, that the common folklore of applying symmetric threshold\npolicy, which is well known to be optimal (for unimodal state densities) in the\nclassical two-channel remote estimation problem, can be suboptimal for the\nsetting considered. Next, in order to make the problem tractable, a side\nchannel which signals the sign of the underlying state is considered. It is\nshown that, under some technical assumptions, threshold-in-threshold\ncommunication scheduling is optimal for this setting. The impact of the\npresence of a noisy channel is analyzed numerically based on dynamic\nprogramming. This numerical analysis uncovers some rather surprising results\ninheriting known properties from the noisy and noiseless settings.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "cs.SY", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1510.00059v1"}
{"entry_id": "http://arxiv.org/abs/1604.00994v1", "date": "2016-04-01", "title": "Quorum sensing and remote synchronization in networks of Kuramoto oscillators: a biological interpretation", "authors": "Vincenzo Fioriti", "abstract": "Non-linear oscillator networks have revealed properties as the remote\nsynchronization and the quorum sensing. The remote synchronization, defined as\nthe synchronization of nodes not directly connected by any sequence of\nsynchronized nodes, was found firstly in networks of amplitude oscillators and\nrecently in bipartite delayed networks of phase oscillators. The quorum\nsensing, a biological information scheme discovered in cell aggregates, has\nbeen investigated in amplitude oscillators coupled by a common medium.\nImplications of such findings are important in technology and biology. We show\nboth of them in non-bipartite, biologically plausible networks of Kuramoto\noscillators. The quorum sensing emerges using the graph edge density, while the\nremote synchronization is obtained by means of an oscillator acting as a\npacemaker. In the remote synchronization two distinct groups of well inter and\ninfra-synchronized nodes, separated by non-synchronized paths, appear clearly.\nOur biological interpretation is that the remote synchronization, bypassing the\nnormal quorum sensing mechanism, is responsible of the pathological cell\nproliferation. This approach seems suitable to study the quorum sensing\nalterations due to genetic mutation or to the environmental action before the\nactual mass replication begins.", "journal": "", "doi": null, "primary_category": "nlin.AO", "categories": ["nlin.AO", "math-ph", "math.MP"], "pdf_url": "http://arxiv.org/pdf/1604.00994v1"}
{"entry_id": "http://arxiv.org/abs/2112.00570v1", "date": "2021-12-01", "title": "Toward Foundation Models for Earth Monitoring: Proposal for a Climate Change Benchmark", "authors": "Alexandre Lacoste, Evan David Sherwin, Hannah Kerner, Hamed Alemohammad, Bj\u00f6rn L\u00fctjens, Jeremy Irvin, David Dao, Alex Chang, Mehmet Gunturkun, Alexandre Drouin, Pau Rodriguez, David Vazquez", "abstract": "Recent progress in self-supervision shows that pre-training large neural\nnetworks on vast amounts of unsupervised data can lead to impressive increases\nin generalisation for downstream tasks. Such models, recently coined as\nfoundation models, have been transformational to the field of natural language\nprocessing. While similar models have also been trained on large corpuses of\nimages, they are not well suited for remote sensing data. To stimulate the\ndevelopment of foundation models for Earth monitoring, we propose to develop a\nnew benchmark comprised of a variety of downstream tasks related to climate\nchange. We believe that this can lead to substantial improvements in many\nexisting applications and facilitate the development of new applications. This\nproposal is also a call for collaboration with the aim of developing a better\nevaluation process to mitigate potential downsides of foundation models for\nEarth monitoring.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2112.00570v1"}
{"entry_id": "http://arxiv.org/abs/2104.12572v1", "date": "2021-04-26", "title": "Multi-scale PIIFD for Registration of Multi-source Remote Sensing Images", "authors": "Chenzhong Gao, Wei Li", "abstract": "This paper aims at providing multi-source remote sensing images registered in\ngeometric space for image fusion. Focusing on the characteristics and\ndifferences of multi-source remote sensing images, a feature-based registration\nalgorithm is implemented. The key technologies include image scale-space for\nimplementing multi-scale properties, Harris corner detection for keypoints\nextraction, and partial intensity invariant feature descriptor (PIIFD) for\nkeypoints description. Eventually, a multi-scale Harris-PIIFD image\nregistration algorithm framework is proposed. The experimental results of four\nsets of representative real data show that the algorithm has excellent, stable\nperformance in multi-source remote sensing image registration, and can achieve\naccurate spatial alignment, which has strong practical application value and\ncertain generalization ability.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2104.12572v1"}
{"entry_id": "http://arxiv.org/abs/2107.10894v1", "date": "2021-07-22", "title": "Power Plant Classification from Remote Imaging with Deep Learning", "authors": "Michael Mommert, Linus Scheibenreif, Jo\u00eblle Hanna, Damian Borth", "abstract": "Satellite remote imaging enables the detailed study of land use patterns on a\nglobal scale. We investigate the possibility to improve the information content\nof traditional land use classification by identifying the nature of industrial\nsites from medium-resolution remote sensing images. In this work, we focus on\nclassifying different types of power plants from Sentinel-2 imaging data. Using\na ResNet-50 deep learning model, we are able to achieve a mean accuracy of\n90.0% in distinguishing 10 different power plant types and a background class.\nFurthermore, we are able to identify the cooling mechanisms utilized in thermal\npower plants with a mean accuracy of 87.5%. Our results enable us to\nqualitatively investigate the energy mix from Sentinel-2 imaging data, and\nprove the feasibility to classify industrial sites on a global scale from\nfreely available satellite imagery.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2107.10894v1"}
{"entry_id": "http://arxiv.org/abs/2007.15903v1", "date": "2020-07-31", "title": "Quantum remote sensing under the effect of dephasing", "authors": "Hideaki Okane, Hideaki Hakoshima, Yuki Takeuchi, Yuya Seki, Yuichiro Matsuzaki", "abstract": "The quantum remote sensing (QRS) is a scheme to add security about the\nmeasurement results of a qubit-based sensor. A client delegates a measurement\ntask to a remote server that has a quantum sensor, and eavesdropper (Eve)\nsteals every classical information stored in the server side. By using quantum\nproperties, the QRS provides an asymmetricity about the information gain where\nthe client gets more information about the sensing results than Eve. However,\nquantum states are fragile against decoherence, and so it is not clear whether\nsuch a QRS is practically useful under the effect of realistic noise. Here, we\ninvestigate the performance of the QRS with dephasing during the interaction\nwith the target fields. In the QRS, the client and server need to share a Bell\npair, and an imperfection of the Bell pair leads to a state preparation error\nin a systematic way on the server side for the sensing. We consider the effect\nof both dephasing and state preparation error. The uncertainty of the client\nside decreases with the square root of the repetition number $M$ for small $M$,\nwhich is the same scaling as the standard quantum metrology. On the other hand,\nfor large $M$, the state preparation error becomes as relevant as the\ndephasing, and the uncertainty decreases logarithmically with $M$. We compare\nthe information gain between the client and Eve. This leads us to obtain the\nconditions for the asymmetric gain to be maintained even under the effect of\ndephasing.", "journal": "", "doi": "10.1103/PhysRevA.104.062610", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2007.15903v1"}
{"entry_id": "http://arxiv.org/abs/1710.00575v2", "date": "2017-10-02", "title": "Remote Sensing Image Classification with Large Scale Gaussian Processes", "authors": "Pablo Morales-Alvarez, Adrian Perez-Suay, Rafael Molina, Gustau Camps-Valls", "abstract": "Current remote sensing image classification problems have to deal with an\nunprecedented amount of heterogeneous and complex data sources. Upcoming\nmissions will soon provide large data streams that will make land cover/use\nclassification difficult. Machine learning classifiers can help at this, and\nmany methods are currently available. A popular kernel classifier is the\nGaussian process classifier (GPC), since it approaches the classification\nproblem with a solid probabilistic treatment, thus yielding confidence\nintervals for the predictions as well as very competitive results to\nstate-of-the-art neural networks and support vector machines. However, its\ncomputational cost is prohibitive for large scale applications, and constitutes\nthe main obstacle precluding wide adoption. This paper tackles this problem by\nintroducing two novel efficient methodologies for Gaussian Process (GP)\nclassification. We first include the standard random Fourier features\napproximation into GPC, which largely decreases its computational cost and\npermits large scale remote sensing image classification. In addition, we\npropose a model which avoids randomly sampling a number of Fourier frequencies,\nand alternatively learns the optimal ones within a variational Bayes approach.\nThe performance of the proposed methods is illustrated in complex problems of\ncloud detection from multispectral imagery and infrared sounding data.\nExcellent empirical results support the proposal in both computational cost and\naccuracy.", "journal": "", "doi": "10.1109/TGRS.2017.2758922", "primary_category": "cs.LG", "categories": ["cs.LG", "stat.AP", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1710.00575v2"}
{"entry_id": "http://arxiv.org/abs/1809.02043v1", "date": "2018-09-06", "title": "Oblique Stripe Removal in Remote Sensing Images via Oriented Variation", "authors": "Xinxin Liu, Xiliang Lu, Huanfeng Shen, Qiangqiang Yuan, Liangpei Zhang", "abstract": "Destriping is a classical problem in remote sensing image processing.\nAlthough considerable effort has been made to remove stripes, few of the\nexisting methods can eliminate stripe noise with arbitrary orientations. This\nsituation makes the removal of oblique stripes in the higher-level remote\nsensing products become an unfinished and urgent issue. To overcome the\nchallenging problem, we propose a novel destriping model which is self-adjusted\nto different orientations of stripe noise. First of all, the oriented variation\nmodel is designed to accomplish the stripe orientation approximation. In this\nmodel, the stripe direction is automatically estimated and then imbedded into\nthe constraint term to depict the along-stripe smoothness of the stripe\ncomponent. Mainly based on the oriented variation model, a whole destriping\nframework is proposed by jointly employing an L1-norm constraint and a TV\nregularization to separately capture the global distribution property of stripe\ncomponent and the piecewise smoothness of the clean image. The qualitative and\nquantitative experimental results of both orientation and destriping aspects\nconfirm the effectiveness and stability of the proposed method.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1809.02043v1"}
{"entry_id": "http://arxiv.org/abs/1807.08634v1", "date": "2018-07-23", "title": "Region Convolutional Features for Multi-Label Remote Sensing Image Retrieval", "authors": "Weixun Zhou, Xueqing Deng, Zhenfeng Shao", "abstract": "Conventional remote sensing image retrieval (RSIR) systems usually perform\nsingle-label retrieval where each image is annotated by a single label\nrepresenting the most significant semantic content of the image. This\nassumption, however, ignores the complexity of remote sensing images, where an\nimage might have multiple classes (i.e., multiple labels), thus resulting in\nworse retrieval performance. We therefore propose a novel multi-label RSIR\napproach with fully convolutional networks (FCN). In our approach, we first\ntrain a FCN model using a pixel-wise labeled dataset,and the trained FCN is\nthen used to predict the segmentation maps of each image in the considered\narchive. We finally extract region convolutional features of each image based\non its segmentation map.The region features can be either used to perform\nregion-based retrieval or further post-processed to obtain a feature vector for\nsimilarity measure. The experimental results show that our approach achieves\nstate-of-the-art performance in contrast to conventional single-label and\nrecent multi-label RSIR approaches.", "journal": "IEEE J-STARS, 13 (2020): 318-328", "doi": "10.1109/JSTARS.2019.2961634", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.08634v1"}
{"entry_id": "http://arxiv.org/abs/1905.07852v1", "date": "2019-05-20", "title": "Boundary Loss for Remote Sensing Imagery Semantic Segmentation", "authors": "Alexey Bokhovkin, Evgeny Burnaev", "abstract": "In response to the growing importance of geospatial data, its analysis\nincluding semantic segmentation becomes an increasingly popular task in\ncomputer vision today. Convolutional neural networks are powerful visual models\nthat yield hierarchies of features and practitioners widely use them to process\nremote sensing data. When performing remote sensing image segmentation,\nmultiple instances of one class with precisely defined boundaries are often the\ncase, and it is crucial to extract those boundaries accurately. The accuracy of\nsegments boundaries delineation influences the quality of the whole segmented\nareas explicitly. However, widely-used segmentation loss functions such as BCE,\nIoU loss or Dice loss do not penalize misalignment of boundaries sufficiently.\nIn this paper, we propose a novel loss function, namely a differentiable\nsurrogate of a metric accounting accuracy of boundary detection. We can use the\nloss function with any neural network for binary segmentation. We performed\nvalidation of our loss function with various modifications of UNet on a\nsynthetic dataset, as well as using real-world data (ISPRS Potsdam, INRIA AIL).\nTrained with the proposed loss function, models outperform baseline methods in\nterms of IoU score.", "journal": "Proceedings of 16th International Symposium on Neural Networks,\n  2019", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1905.07852v1"}
{"entry_id": "http://arxiv.org/abs/2008.12958v2", "date": "2020-08-29", "title": "Adaptive Local Structure Consistency based Heterogeneous Remote Sensing Change Detection", "authors": "Lin Lei, Yuli Sun, Gangyao Kuang", "abstract": "Change detection of heterogeneous remote sensing images is an important and\nchallenging topic in remote sensing for emergency situation resulting from\nnature disaster. Due to the different imaging mechanisms of heterogeneous\nsensors, it is difficult to directly compare the images. To address this\nchallenge, we explore an unsupervised change detection method based on adaptive\nlocal structure consistency (ALSC) between heterogeneous images in this letter,\nwhich constructs an adaptive graph representing the local structure for each\npatch in one image domain and then projects this graph to the other image\ndomain to measure the change level. This local structure consistency exploits\nthe fact that the heterogeneous images share the same structure information for\nthe same ground object, which is imaging modality-invariant. To avoid the\nleakage of heterogeneous data, the pixelwise change image is calculated in the\nsame image domain by graph projection. Experiment results demonstrate the\neffectiveness of the proposed ALSC based change detection method by comparing\nwith some state-of-the-art methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.12958v2"}
{"entry_id": "http://arxiv.org/abs/2009.09465v1", "date": "2020-09-20", "title": "Remote sensing image fusion based on Bayesian GAN", "authors": "Junfu Chen, Yue Pan, Yang Chen", "abstract": "Remote sensing image fusion technology (pan-sharpening) is an important means\nto improve the information capacity of remote sensing images. Inspired by the\nefficient arameter space posteriori sampling of Bayesian neural networks, in\nthis paper we propose a Bayesian Generative Adversarial Network based on\nPreconditioned Stochastic Gradient Langevin Dynamics (PGSLD-BGAN) to improve\npan-sharpening tasks. Unlike many traditional generative models that consider\nonly one optimal solution (might be locally optimal), the proposed PGSLD-BGAN\nperforms Bayesian inference on the network parameters, and explore the\ngenerator posteriori distribution, which assists selecting the appropriate\ngenerator parameters. First, we build a two-stream generator network with PAN\nand MS images as input, which consists of three parts: feature extraction,\nfeature fusion and image reconstruction. Then, we leverage Markov discriminator\nto enhance the ability of generator to reconstruct the fusion image, so that\nthe result image can retain more details. Finally, introducing Preconditioned\nStochastic Gradient Langevin Dynamics policy, we perform Bayesian inference on\nthe generator network. Experiments on QuickBird and WorldView datasets show\nthat the model proposed in this paper can effectively fuse PAN and MS images,\nand be competitive with even superior to state of the arts in terms of\nsubjective and objective metrics.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2009.09465v1"}
{"entry_id": "http://arxiv.org/abs/2107.02693v2", "date": "2021-07-06", "title": "Remote sensing and AI for building climate adaptation applications", "authors": "Beril Sirmacek, Ricardo Vinuesa", "abstract": "Urban areas are not only one of the biggest contributors to climate change,\nbut also they are one of the most vulnerable areas with high populations who\nwould together experience the negative impacts. In this paper, we address some\nof the opportunities brought by satellite remote sensing imaging and artificial\nintelligence (AI) in order to measure climate adaptation of cities\nautomatically. We propose a framework combining AI and simulation which may be\nuseful for extracting indicators from remote-sensing images and may help with\npredictive estimation of future states of these climate-adaptation-related\nindicators. When such models become more robust and used in real life\napplications, they may help decision makers and early responders to choose the\nbest actions to sustain the well-being of society, natural resources and\nbiodiversity. We underline that this is an open field and an on-going area of\nresearch for many scientists, therefore we offer an in-depth discussion on the\nchallenges and limitations of data-driven methods and the predictive estimation\nmodels in general.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "68T01", "I.2.1"], "pdf_url": "http://arxiv.org/pdf/2107.02693v2"}
{"entry_id": "http://arxiv.org/abs/2302.14256v1", "date": "2023-02-28", "title": "Remote Sensing Scene Classification with Masked Image Modeling (MIM)", "authors": "Liya Wang, Alex Tien", "abstract": "Remote sensing scene classification has been extensively studied for its\ncritical roles in geological survey, oil exploration, traffic management,\nearthquake prediction, wildfire monitoring, and intelligence monitoring. In the\npast, the Machine Learning (ML) methods for performing the task mainly used the\nbackbones pretrained in the manner of supervised learning (SL). As Masked Image\nModeling (MIM), a self-supervised learning (SSL) technique, has been shown as a\nbetter way for learning visual feature representation, it presents a new\nopportunity for improving ML performance on the scene classification task. This\nresearch aims to explore the potential of MIM pretrained backbones on four\nwell-known classification datasets: Merced, AID, NWPU-RESISC45, and Optimal-31.\nCompared to the published benchmarks, we show that the MIM pretrained Vision\nTransformer (ViTs) backbones outperform other alternatives (up to 18% on top 1\naccuracy) and that the MIM technique can learn better feature representation\nthan the supervised learning counterparts (up to 5% on top 1 accuracy).\nMoreover, we show that the general-purpose MIM-pretrained ViTs can achieve\ncompetitive performance as the specially designed yet complicated Transformer\nfor Remote Sensing (TRS) framework. Our experiment results also provide a\nperformance baseline for future studies.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2302.14256v1"}
{"entry_id": "http://arxiv.org/abs/2111.15627v1", "date": "2021-11-27", "title": "GEOSCAN: Global Earth Observation using Swarm of Coordinated Autonomous Nanosats", "authors": "Changrak Choi, Anthony B. Davis", "abstract": "The climate crisis we are facing calls for significant improvements in our\nunderstanding of natural phenomena, with clouds being identified as a dominant\nsource of uncertainty. To this end, the emerging field of 3D computed cloud\ntomography (CCT) aims to more precisely characterize clouds by utilizing\nmulti-dimensional imaging to reconstruct their outer and inner structure. In\nthis paper, we propose a future Earth observation mission concept, driven by\nthe needs of CCT, that operates constellation of NanoSats to provide\nmulti-angular, spectrally-resolved, spatial and temporal scientific\nmeasurements of natural atmospheric phenomena. Our proposed mission, GEOSCAN,\nwill on-board active steering capability to rapidly reconfigure networked swarm\nof autonomous Nanosats to track evolving phenomena of interest, on-demand, in\nreal-time. We present the structure of the GEOSCAN constellation and discuss\ndetails of the mission concept from both science and engineering perspectives.\nOn the science side, we outline the types of remote Earth observation\nmeasurements that GEOSCAN enables beyond the state-of-the-art, and how such\nmeasurements translate to improvements in CCT that can lead to reduction in\nuncertainty of the global climate models (GCMs). From the engineering side, we\ninvestigate feasibility of the concept starting from hardware components of the\nNanoSat that form the basis of the constellation. In particular, we focus on\nthe active steering capability of the GEOSCAN with algorithmic approaches that\nenable coordination from new software. We identify technology gaps that need to\nbe bridged and discuss other aspects of the mission that require in-depth\nanalysis to further mature the concept.", "journal": "", "doi": null, "primary_category": "eess.SP", "categories": ["eess.SP", "physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2111.15627v1"}
{"entry_id": "http://arxiv.org/abs/1501.04172v1", "date": "2015-01-17", "title": "Remote lensless focusing of a light beam", "authors": "Nikolai I. Petrov", "abstract": "Remote focusing of light in a graded-index medium via mode interference is\ndemonstrated using exact analytical solutions of the wave equation. Strong\nfocusing of light occurs at extremely long distances and it revivals\nperiodically with distance due to mode interference. High efficiency transfer\nof a strongly focused subwavelength spot through optical waveguide over large\ndistances takes place with a period of revival. Super-oscillatory hot-spots\nwith the sizes which are beyond the conventional Abbe diffraction limit can be\nobserved at large distances from the source. This can provide the possibility\nto detect optical super-resolution information in the far-field without any\nevanescent waves. Far-field super-resolution imaging capabilities of a\ngraded-index waveguide are also analyzed.", "journal": "", "doi": "10.1088/1612-2011/13/1/015101", "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/1501.04172v1"}
{"entry_id": "http://arxiv.org/abs/2201.01971v1", "date": "2022-01-06", "title": "Multi-Label Classification on Remote-Sensing Images", "authors": "Aditya Kumar Singh, B. Uma Shankar", "abstract": "Acquiring information on large areas on the earth's surface through satellite\ncameras allows us to see much more than we can see while standing on the\nground. This assists us in detecting and monitoring the physical\ncharacteristics of an area like land-use patterns, atmospheric conditions,\nforest cover, and many unlisted aspects. The obtained images not only keep\ntrack of continuous natural phenomena but are also crucial in tackling the\nglobal challenge of severe deforestation. Among which Amazon basin accounts for\nthe largest share every year. Proper data analysis would help limit detrimental\neffects on the ecosystem and biodiversity with a sustainable healthy\natmosphere. This report aims to label the satellite image chips of the Amazon\nrainforest with atmospheric and various classes of land cover or land use\nthrough different machine learning and superior deep learning models.\nEvaluation is done based on the F2 metric, while for loss function, we have\nboth sigmoid cross-entropy as well as softmax cross-entropy. Images are fed\nindirectly to the machine learning classifiers after only features are\nextracted using pre-trained ImageNet architectures. Whereas for deep learning\nmodels, ensembles of fine-tuned ImageNet pre-trained models are used via\ntransfer learning. Our best score was achieved so far with the F2 metric is\n0.927.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2201.01971v1"}
{"entry_id": "http://arxiv.org/abs/1102.0788v1", "date": "2011-02-03", "title": "Remote Sensing D/H Ratios in Methane Ice: Temperature-Dependent Absorption Coefficients of CH3D in Methane Ice and in Nitrogen Ice", "authors": "W. M. Grundy, S. J. Morrison, M. J. Bovyn, S. C. Tegler, D. M. Cornelison", "abstract": "The existence of strong absorption bands of singly deuterated methane (CH3D)\nat wavelengths where normal methane (CH4) absorbs comparatively weakly could\nenable remote measurement of D/H ratios in methane ice on outer solar system\nbodies. We performed laboratory transmission spectroscopy experiments,\nrecording spectra at wavelengths from 1 to 6 \\mum to study CH3D bands at 2.47,\n2.87, and 4.56 \\mum, wavelengths where ordinary methane absorption is weak. We\nreport temperature-dependent absorption coefficients of these bands when the\nCH3D is diluted in CH4 ice and also when it is dissolved in N2 ice, and\ndescribe how these absorption coefficients can be combined with data from the\nliterature to simulate arbitrary D/H ratio absorption coefficients for CH4 ice\nand for CH4 in N2 ice. We anticipate these results motivating new telescopic\nobservations to measure D/H ratios in CH4 ice on Triton, Pluto, Eris, and\nMakemake.", "journal": "", "doi": "10.1016/j.icarus.2011.01.034", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1102.0788v1"}
{"entry_id": "http://arxiv.org/abs/2106.08428v1", "date": "2021-06-15", "title": "Remote state preparation of single photon orbital angular momentum lattices", "authors": "Andrew R. Cameron, Sandra W. L. Cheng, Sacha Schwarz, Connor Kapahi, Dusan Sarenac, Michael Grabowecky, David G. Cory, Thomas Jennewein, Dmitry A. Pushin, Kevin J. Resch", "abstract": "Optical beams with periodic lattice structures have broadened the study of\nstructured waves. In the present work, we generate spin-orbit entangled photon\nstates with a lattice structure and use them in a remote state preparation\nprotocol. We sequentially measure spatially-dependent correlation rates with an\nelectron-multiplying intensified CCD camera and verify the successful remote\npreparation of spin-orbit states by performing pixel-wise quantum state\ntomography. Control of these novel structured waves in the quantum regime\nprovides a method for quantum sensing and manipulation of periodic structures.", "journal": "", "doi": "10.1103/PhysRevA.104.L051701", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2106.08428v1"}
{"entry_id": "http://arxiv.org/abs/1007.4866v1", "date": "2010-07-28", "title": "Enforced Development Of The Earth's Atmosphere", "authors": "M. Iudin", "abstract": "We review some basic issues of the life-prescribed development of the Earth's\nsystem and the Earth's atmosphere and discourse the unity of Earth's type of\nlife in physical and transcendental divisions. In physical division, we\nexemplify and substantiate the origin of atmospheric phenomena in the metabolic\npathways acquired by the Earth's life forms. We are especially concerned with\nemergence of pro-life superficial environments under elaboration of the energy\ntransformations. Analysis of the coupling phenomena of elaborated ozone-oxygen\ntransformation and Arctic bromine explosion is provided. Sensing is a\nfoundation of life and the Earth's life. We offer our explanation of human-like\nperception, reasoning and creativity. We suggest a number of propositions about\nassociation of transcendental and physical divisions and the purpose of\nexistence. The study relates to the tradition of natural philosophy which it\nfollows. The paper is suitable for the popular reading.", "journal": "", "doi": null, "primary_category": "physics.gen-ph", "categories": ["physics.gen-ph"], "pdf_url": "http://arxiv.org/pdf/1007.4866v1"}
{"entry_id": "http://arxiv.org/abs/1107.4410v1", "date": "2011-07-22", "title": "High-brightness switchable multi-wavelength remote laser in air", "authors": "Jinping Yao, Bin Zeng, Huailiang Xu, Guihua Li, Wei Chu, Jielei Ni, Haisu Zhang, See Leang Chin, Ya Cheng, Zhizhan Xu", "abstract": "Remote laser in air based on amplified spontaneous emission (ASE) has\nproduced rather well-collimated coherent beams in both backward and forward\npropagation directions, opening up possibilities for new remote sensing\napproaches. The remote ASE-based lasers were shown to enable operation either\nat ~391 and 337 nm using molecular nitrogen or at ~845 nm using molecular\noxygen as gain medium, depending on the employed pump lasers. To date, a\nmulti-wavelength laser in air that allows for dynamically switching the\noperating wavelength has not yet been achieved, although this type of laser is\ncertainly of high importance for detecting multiple hazard gases. In this\nLetter, we demonstrate, for the first time to our knowledge, a harmonic-seeded\nswitchable multi-wavelength laser in air driven by intense mid-infrared\nfemtosecond laser pulses. Furthermore, population inversion in the\nmulti-wavelength remote laser occurs at an ultrafast time-scale (i.e., less\nthan ~200 fs) owing to direct formation of excited molecular nitrogen ions by\nstrong-field ionization of inner-valence electrons, which is fundamentally\ndifferent from the previously reported pumping mechanisms based either on\nelectron recombination of ionized molecular nitrogen or on resonant two-photon\nexcitation of atomic oxygen fragments resulting from resonant two-photon\ndissociation of molecular oxygen. The bright multi-wavelength laser in air\nopens the perspective for remote detection of multiple pollutants based on\nnonlinear spectroscopy.", "journal": "", "doi": "10.1103/PhysRevA.84.051802", "primary_category": "physics.atom-ph", "categories": ["physics.atom-ph", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/1107.4410v1"}
{"entry_id": "http://arxiv.org/abs/2103.03163v1", "date": "2021-03-04", "title": "Remote Observation of Field Work on the Farm", "authors": "Wendy Ju, Ilan Mandel, Kevin Weatherwax, Leila Takayama, Nikolas Martelaro, Denis Willett", "abstract": "Travel restrictions and social distancing measures make it difficult to\nobserve, monitor or manage physical fieldwork. We describe research in progress\nthat applies technologies for real-time remote observation and conversation in\non-road vehicles to observe field work on a farm. We collaborated on a pilot\ndeployment of this project at Kreher Eggs in upstate New York. We instrumented\na tractor with equipment to remotely observe and interview farm workers\nperforming vehicle-related work. This work was initially undertaken to allow\nsustained observation of field work over longer periods of time from\ngeographically distant locales; given our current situation, this work provides\na case study in how to perform observational research when geographic and\nbodily distance have become the norm. We discuss our experiences and provide\nsome preliminary insights for others looking to conduct remote observational\nresearch in the field.", "journal": "", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY", "cs.HC"], "pdf_url": "http://arxiv.org/pdf/2103.03163v1"}
{"entry_id": "http://arxiv.org/abs/2103.07678v2", "date": "2021-03-13", "title": "A review of machine learning in processing remote sensing data for mineral exploration", "authors": "Hojat Shirmard, Ehsan Farahbakhsh, R. Dietmar Muller, Rohitash Chandra", "abstract": "The decline of the number of newly discovered mineral deposits and increase\nin demand for different minerals in recent years has led exploration geologists\nto look for more efficient and innovative methods for processing different data\ntypes at each stage of mineral exploration. As a primary step, various\nfeatures, such as lithological units, alteration types, structures, and\nindicator minerals, are mapped to aid decision-making in targeting ore\ndeposits. Different types of remote sensing datasets, such as satellite and\nairborne data, make it possible to overcome common problems associated with\nmapping geological features. The rapid increase in the volume of remote sensing\ndata obtained from different platforms has encouraged scientists to develop\nadvanced, innovative, and robust data processing methodologies. Machine\nlearning methods can help process a wide range of remote sensing datasets and\ndetermine the relationship between components such as the reflectance continuum\nand features of interest. These methods are robust in processing spectral and\nground truth measurements against noise and uncertainties. In recent years,\nmany studies have been carried out by supplementing geological surveys with\nremote sensing datasets, which is now prominent in geoscience research. This\npaper provides a comprehensive review of the implementation and adaptation of\nsome popular and recently established machine learning methods for processing\ndifferent types of remote sensing data and investigates their applications for\ndetecting various ore deposit types. We demonstrate the high capability of\ncombining remote sensing data and machine learning methods for mapping\ndifferent geological features that are critical for providing potential maps.\nMoreover, we find there is scope for advanced methods to process the new\ngeneration of remote sensing data for creating improved mineral prospectivity\nmaps.", "journal": "Remote Sensing of Environment, 268, 112750 (2022)", "doi": "10.1016/j.rse.2021.112750", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/2103.07678v2"}
{"entry_id": "http://arxiv.org/abs/1803.00461v4", "date": "2018-03-01", "title": "Modeling the evolution and propagation of the 2017 September 9th and 10th CMEs and SEPs arriving at Mars constrained by remote-sensing and in-situ measurement", "authors": "Jingnan Guo, Mateja Dumbovi\u0107, Robert F. Wimmer-Schweingruber, Manuela Temmer, Henning Lohf, Yuming Wang, Astrid Veronig, Donald M. Hassler, Leila M. Mays, Cary Zeitlin, Bent Ehresmann, Oliver Witasse, Johan L. Freiherr von Forstner, Bernd Heber, Mats Holmstr\u00f6m, Arik Posner", "abstract": "On 2017-09-10, solar energetic particles (SEPs) originating from the active\nregion 12673 were registered as a ground level enhancement (GLE) at Earth and\nthe biggest GLE on the surface of Mars as observed by the Radiation Assessment\nDetector (RAD) since the landing of the Curiosity rover in August 2012. Based\non multi-point coronagraph images, we identify the initial 3D kinematics of an\nextremely fast CME and its shock front as well as another 2 CMEs launched hours\nearlier (with moderate speeds) using the Graduated Cylindrical Shell (GCS)\nmodel. These three CMEs interacted as they propagated outwards into the\nheliosphere and merged into a complex interplanetary CME (ICME). The arrival of\nthe shock and ICME at Mars caused a very significant Forbush Decrease (FD) seen\nby RAD only a few hours later than that at Earth which is about 0.5 AU closer\nto the Sun. We investigate the propagation of the three CMEs and the consequent\nICME together with the shock using the Drag Based Model (DBM) and the WSA-ENLIL\nplus cone model constrained by the in-situ SEP and FD/shock onset timing. The\nsynergistic modeling of the ICME and SEP arrivals at Earth and Mars suggests\nthat in order to better predict potentially hazardous space weather impacts at\nEarth and other heliospheric locations for human exploration missions, it is\nessential to analyze 1) the CME kinematics, especially during their\ninteractions and 2) the spatially and temporally varying heliospheric\nconditions, such as the evolution and propagation of the stream interaction\nregions.", "journal": "", "doi": "10.1029/2018SW001973", "primary_category": "physics.space-ph", "categories": ["physics.space-ph", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1803.00461v4"}
{"entry_id": "http://arxiv.org/abs/2007.12326v1", "date": "2020-07-24", "title": "Locality-Aware Rotated Ship Detection in High-Resolution Remote Sensing Imagery Based on Multi-Scale Convolutional Network", "authors": "Lingyi Liu, Yunpeng Bai, Ying Li", "abstract": "Ship detection has been an active and vital topic in the field of remote\nsensing for a decade, but it is still a challenging problem due to the large\nscale variations, the high aspect ratios, the intensive arrangement, and the\nbackground clutter disturbance. In this letter, we propose a locality-aware\nrotated ship detection (LARSD) framework based on a multi-scale convolutional\nneural network (CNN) to tackle these issues. The proposed framework applies a\nUNet-like multi-scale CNN to generate multi-scale feature maps with high-level\nsemantic information in high resolution. Then, a rotated anchor-based\nregression is applied for directly predicting the probability, the edge\ndistances, and the angle of ships. Finally, a locality-aware score alignment is\nproposed to fix the mismatch between classification results and location\nresults caused by the independence of each subnet. Furthermore, to enlarge the\ndatasets of ship detection, we build a new high-resolution ship detection\n(HRSD) dataset, where 2499 images and 9269 instances were collected from Google\nEarth with different resolutions. Experiments based on public dataset HRSC2016\nand our HRSD dataset demonstrate that our detection method achieves\nstate-of-the-art performance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2007.12326v1"}
{"entry_id": "http://arxiv.org/abs/2201.05772v1", "date": "2022-01-15", "title": "Asymmetric Hash Code Learning for Remote Sensing Image Retrieval", "authors": "Weiwei Song, Zhi Gao, Renwei Dian, Pedram Ghamisi, Yongjun Zhang, J\u00f3n Atli Benediktsson", "abstract": "Remote sensing image retrieval (RSIR), aiming at searching for a set of\nsimilar items to a given query image, is a very important task in remote\nsensing applications. Deep hashing learning as the current mainstream method\nhas achieved satisfactory retrieval performance. On one hand, various deep\nneural networks are used to extract semantic features of remote sensing images.\nOn the other hand, the hashing techniques are subsequently adopted to map the\nhigh-dimensional deep features to the low-dimensional binary codes. This kind\nof methods attempts to learn one hash function for both the query and database\nsamples in a symmetric way. However, with the number of database samples\nincreasing, it is typically time-consuming to generate the hash codes of\nlarge-scale database images. In this paper, we propose a novel deep hashing\nmethod, named asymmetric hash code learning (AHCL), for RSIR. The proposed AHCL\ngenerates the hash codes of query and database images in an asymmetric way. In\nmore detail, the hash codes of query images are obtained by binarizing the\noutput of the network, while the hash codes of database images are directly\nlearned by solving the designed objective function. In addition, we combine the\nsemantic information of each image and the similarity information of pairs of\nimages as supervised information to train a deep hashing network, which\nimproves the representation ability of deep features and hash codes. The\nexperimental results on three public datasets demonstrate that the proposed\nmethod outperforms symmetric methods in terms of retrieval accuracy and\nefficiency. The source code is available at\nhttps://github.com/weiweisong415/Demo AHCL for TGRS2022.", "journal": "", "doi": "10.1109/TGRS.2022.3143571", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.IR"], "pdf_url": "http://arxiv.org/pdf/2201.05772v1"}
{"entry_id": "http://arxiv.org/abs/2007.10882v1", "date": "2020-07-21", "title": "Estimating crop yields with remote sensing and deep learning", "authors": "Renato Luiz de Freitas Cunha, Bruno Silva", "abstract": "Increasing the accuracy of crop yield estimates may allow improvements in the\nwhole crop production chain, allowing farmers to better plan for harvest, and\nfor insurers to better understand risks of production, to name a few\nadvantages. To perform their predictions, most current machine learning models\nuse NDVI data, which can be hard to use, due to the presence of clouds and\ntheir shadows in acquired images, and due to the absence of reliable crop masks\nfor large areas, especially in developing countries. In this paper, we present\na deep learning model able to perform pre-season and in-season predictions for\nfive different crops. Our model uses crop calendars, easy-to-obtain remote\nsensing data and weather forecast information to provide accurate yield\nestimates.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP", "cs.CY", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2007.10882v1"}
{"entry_id": "http://arxiv.org/abs/1408.5549v2", "date": "2014-08-24", "title": "On the Neuron Response Features of Convolutional Neural Networks for Remote Sensing Image", "authors": "Jie Chen, Min Deng, Haifeng Li", "abstract": "In this paper, some patterns of the Neuron Response of deep Convolutional\nNeural Networks were observed.", "journal": "", "doi": null, "primary_category": "math.DG", "categories": ["math.DG"], "pdf_url": "http://arxiv.org/pdf/1408.5549v2"}
{"entry_id": "http://arxiv.org/abs/2012.14180v1", "date": "2020-12-28", "title": "A Google Earth Engine-enabled Python approach to improve identification of anthropogenic palaeo-landscape features", "authors": "Filippo Brandolini, Guillem Domingo Ribas, Andrea Zerboni, Sam Turner", "abstract": "The necessity of sustainable development for landscapes has emerged as an\nimportant theme in recent decades. Current methods take a holistic approach to\nlandscape heritage and promote an interdisciplinary dialogue to facilitate\ncomplementary landscape management strategies. With the socio-economic values\nof the natural and cultural landscape heritage increasingly recognised\nworldwide, remote sensing tools are being used more and more to facilitate the\nrecording and management of landscape heritage. Satellite remote sensing\ntechnologies have enabled significant improvements in landscape research. The\nadvent of the cloud-based platform of Google Earth Engine has allowed the rapid\nexploration and processing of satellite imagery such as the Landsat and\nCopernicus Sentinel datasets. In this paper, the use of Sentinel-2 satellite\ndata in the identification of palaeo-riverscape features has been assessed in\nthe Po Plain, selected because it is characterized by human exploitation since\nthe Mid-Holocene. A multi-temporal approach has been adopted to investigate the\npotential of satellite imagery to detect buried hydrological and anthropogenic\nfeatures along with Spectral Index and Spectral Decomposition analysis. This\nresearch represents one of the first applications of the GEE Python API in\nlandscape studies. The complete FOSS-cloud protocol proposed here consists of a\nPython code script developed in Google Colab which could be simply adapted and\nreplicated in different areas of the world", "journal": "", "doi": "10.12688/openreseurope.13135.2", "primary_category": "cs.CY", "categories": ["cs.CY", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2012.14180v1"}
{"entry_id": "http://arxiv.org/abs/2302.01793v1", "date": "2023-02-03", "title": "Self-Supervised In-Domain Representation Learning for Remote Sensing Image Scene Classification", "authors": "Ali Ghanbarzade, Hossein Soleimani", "abstract": "Transferring the ImageNet pre-trained weights to the various remote sensing\ntasks has produced acceptable results and reduced the need for labeled samples.\nHowever, the domain differences between ground imageries and remote sensing\nimages cause the performance of such transfer learning to be limited. Recent\nresearch has demonstrated that self-supervised learning methods capture visual\nfeatures that are more discriminative and transferable than the supervised\nImageNet weights. We are motivated by these facts to pre-train the in-domain\nrepresentations of remote sensing imagery using contrastive self-supervised\nlearning and transfer the learned features to other related remote sensing\ndatasets. Specifically, we used the SimSiam algorithm to pre-train the\nin-domain knowledge of remote sensing datasets and then transferred the\nobtained weights to the other scene classification datasets. Thus, we have\nobtained state-of-the-art results on five land cover classification datasets\nwith varying numbers of classes and spatial resolutions. In addition, By\nconducting appropriate experiments, including feature pre-training using\ndatasets with different attributes, we have identified the most influential\nfactors that make a dataset a good choice for obtaining in-domain features. We\nhave transferred the features obtained by pre-training SimSiam on remote\nsensing datasets to various downstream tasks and used them as initial weights\nfor fine-tuning. Moreover, we have linearly evaluated the obtained\nrepresentations in cases where the number of samples per class is limited. Our\nexperiments have demonstrated that using a higher-resolution dataset during the\nself-supervised pre-training stage results in learning more discriminative and\ngeneral representations.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2302.01793v1"}
{"entry_id": "http://arxiv.org/abs/2107.02910v1", "date": "2021-07-05", "title": "Remotely $c$-almost periodic type functions in ${\\mathbb R}^{n}$", "authors": "Marko Kostic, Vipin Kumar", "abstract": "In this paper, we relate the notions of remote almost periodicity and\nquasi-asymptotical almost periodicity; in actual fact, we observe that a\nremotely almost periodic function is nothing else but a bounded, uniformly\ncontinuous quasi-asymptotically almost periodic function. We introduce and\nanalyze several new classes of remotely $c$-almost periodic functions in\n${\\mathbb R}^{n},$ slowly oscillating functions in ${\\mathbb R}^{n},$ and\nfurther analyze the recently introduced class of quasi-asymptotically\n$c$-almost periodic functions in ${\\mathbb R}^{n}.$ We provide certain\napplications of our theoretical results to the abstract Volterra\nintegro-differential equations and the ordinary differential equations.", "journal": "", "doi": null, "primary_category": "math.CA", "categories": ["math.CA", "math.FA"], "pdf_url": "http://arxiv.org/pdf/2107.02910v1"}
{"entry_id": "http://arxiv.org/abs/2105.05516v2", "date": "2021-05-12", "title": "Object-Based Augmentation Improves Quality of Remote Sensing Semantic Segmentation", "authors": "Svetlana Illarionova, Sergey Nesteruk, Dmitrii Shadrin, Vladimir Ignatiev, Mariia Pukalchik, Ivan Oseledets", "abstract": "Today deep convolutional neural networks (CNNs) push the limits for most\ncomputer vision problems, define trends, and set state-of-the-art results. In\nremote sensing tasks such as object detection and semantic segmentation, CNNs\nreach the SotA performance. However, for precise performance, CNNs require much\nhigh-quality training data. Rare objects and the variability of environmental\nconditions strongly affect prediction stability and accuracy. To overcome these\ndata restrictions, it is common to consider various approaches including data\naugmentation techniques. This study focuses on the development and testing of\nobject-based augmentation. The practical usefulness of the developed\naugmentation technique is shown in the remote sensing domain, being one of the\nmost demanded ineffective augmentation techniques. We propose a novel pipeline\nfor georeferenced image augmentation that enables a significant increase in the\nnumber of training samples. The presented pipeline is called object-based\naugmentation (OBA) and exploits objects' segmentation masks to produce new\nrealistic training scenes using target objects and various label-free\nbackgrounds. We test the approach on the buildings segmentation dataset with\nsix different CNN architectures and show that the proposed method benefits for\nall the tested models. We also show that further augmentation strategy\noptimization can improve the results. The proposed method leads to the\nmeaningful improvement of U-Net model predictions from 0.78 to 0.83 F1-score.", "journal": "Proceedings of the IEEE/CVF International Conference on Computer\n  Vision (ICCV) Workshops, 2021, pp. 1659-1668", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2105.05516v2"}
{"entry_id": "http://arxiv.org/abs/2210.00757v1", "date": "2022-10-03", "title": "Fully Transformer Network for Change Detection of Remote Sensing Images", "authors": "Tianyu Yan, Zifu Wan, Pingping Zhang", "abstract": "Recently, change detection (CD) of remote sensing images have achieved great\nprogress with the advances of deep learning. However, current methods generally\ndeliver incomplete CD regions and irregular CD boundaries due to the limited\nrepresentation ability of the extracted visual features. To relieve these\nissues, in this work we propose a novel learning framework named Fully\nTransformer Network (FTN) for remote sensing image CD, which improves the\nfeature extraction from a global view and combines multi-level visual features\nin a pyramid manner. More specifically, the proposed framework first utilizes\nthe advantages of Transformers in long-range dependency modeling. It can help\nto learn more discriminative global-level features and obtain complete CD\nregions. Then, we introduce a pyramid structure to aggregate multi-level visual\nfeatures from Transformers for feature enhancement. The pyramid structure\ngrafted with a Progressive Attention Module (PAM) can improve the feature\nrepresentation ability with additional interdependencies through channel\nattentions. Finally, to better train the framework, we utilize the\ndeeply-supervised learning with multiple boundaryaware loss functions.\nExtensive experiments demonstrate that our proposed method achieves a new\nstate-of-the-art performance on four public CD benchmarks. For model\nreproduction, the source code is released at https://github.com/AI-Zhpp/FTN.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "cs.MM"], "pdf_url": "http://arxiv.org/pdf/2210.00757v1"}
{"entry_id": "http://arxiv.org/abs/2301.10225v1", "date": "2023-01-10", "title": "The Evolution of Real-time Remote Intraoperative Neurophysiological Monitoring (IONM)", "authors": "Jeffrey Balzer, Julia Caviness, Don Krieger", "abstract": "Real-time monitoring of nervous system function with immediate communication\nof relevant information to the surgeon enables prevention and/or mitigation of\niatrogenic injury in many surgical procedures. The hardware and software\ninfrastructure and demonstrated usefulness of telemedicine in support of IONM\noriginated in a busy university health center environment and then spread\nwidely as comparable functional capabilities were added by commercial equipment\nmanufacturers. The earliest implementations included primitive data archival\nand case documentation capabilities and relied primarily on deidentification\nfor security. They emphasized full-featured control of the real-time data\ndisplay by remote observers. Today, remote IONM is routinely utilized in more\nthan 200,000 high-risk surgical procedures/year in the United States. For many\ncases, remote observers rely on screen capture to view the data as it is\ndisplayed in the remote operating room while providing sophisticated security\ncapabilities and data archival and standardized metadata and case\ndocumentation.", "journal": "", "doi": null, "primary_category": "cs.OH", "categories": ["cs.OH", "cs.CY"], "pdf_url": "http://arxiv.org/pdf/2301.10225v1"}
{"entry_id": "http://arxiv.org/abs/1602.08575v2", "date": "2016-02-27", "title": "Superresolution of Noisy Remotely Sensed Images Through Directional Representations", "authors": "Wojciech Czaja, James M. Murphy, Daniel Weinberg", "abstract": "We develop an algorithm for single-image superresolution of remotely sensed\ndata, based on the discrete shearlet transform. The shearlet transform extracts\ndirectional features of signals, and is known to provide near-optimally sparse\nrepresentations for a broad class of images. This often leads to superior\nperformance in edge detection and image representation when compared to\nisotropic frames. We justify the use of shearlets mathematically, before\npresenting a denoising single-image superresolution algorithm that combines the\nshearlet transform with sparse mixing estimators (SME). Our algorithm is\ncompared with a variety of single-image superresolution methods, including\nwavelet SME superresolution. Our numerical results demonstrate competitive\nperformance in terms of PSNR and SSIM.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1602.08575v2"}
{"entry_id": "http://arxiv.org/abs/2109.05275v2", "date": "2021-09-11", "title": "Remote sensing and faithful quantum teleportation through non-localized qubits", "authors": "Hossein Rangani Jahromi", "abstract": "One of the most important applications of quantum physics is quantum\nteleportation, the possibility to transfer quantum states over arbitrary\ndistances. In this paper, we address the idea of remote sensing in a\nteleportation scenario with topological qubits more robust against noise. We\nalso investigate the enhancement of quantum teleportation through non-local\ncharacteristics of the topological qubits. In particular, we show that how this\nnonlocal property, helps us to achieve near-perfect quantum teleportation even\nwith mixed quantum states. Considering the limitations imposed by decoherence\nand the subsequent mixedness of the resource state, we find that our results\nmay solve important challenges in realizing faithful teleportation over long\ndistances.", "journal": "Phys. Lett. A 424, 127850 (2022)", "doi": "10.1016/j.physleta.2021.127850", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2109.05275v2"}
{"entry_id": "http://arxiv.org/abs/1910.13408v2", "date": "2019-10-29", "title": "A framework for deep learning emulation of numerical models with a case study in satellite remote sensing", "authors": "Kate Duffy, Thomas Vandal, Weile Wang, Ramakrishna Nemani, Auroop R. Ganguly", "abstract": "Numerical models based on physics represent the state-of-the-art in earth\nsystem modeling and comprise our best tools for generating insights and\npredictions. Despite rapid growth in computational power, the perceived need\nfor higher model resolutions overwhelms the latest-generation computers,\nreducing the ability of modelers to generate simulations for understanding\nparameter sensitivities and characterizing variability and uncertainty. Thus,\nsurrogate models are often developed to capture the essential attributes of the\nfull-blown numerical models. Recent successes of machine learning methods,\nespecially deep learning, across many disciplines offer the possibility that\ncomplex nonlinear connectionist representations may be able to capture the\nunderlying complex structures and nonlinear processes in earth systems. A\ndifficult test for deep learning-based emulation, which refers to function\napproximation of numerical models, is to understand whether they can be\ncomparable to traditional forms of surrogate models in terms of computational\nefficiency while simultaneously reproducing model results in a credible manner.\nA deep learning emulation that passes this test may be expected to perform even\nbetter than simple models with respect to capturing complex processes and\nspatiotemporal dependencies. Here we examine, with a case study in\nsatellite-based remote sensing, the hypothesis that deep learning approaches\ncan credibly represent the simulations from a surrogate model with comparable\ncomputational efficiency. Our results are encouraging in that the deep learning\nemulation reproduces the results with acceptable accuracy and often even faster\nperformance. We discuss the broader implications of our results in light of the\npace of improvements in high-performance implementations of deep learning as\nwell as the growing desire for higher-resolution simulations in the earth\nsciences.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "eess.IV", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1910.13408v2"}
{"entry_id": "http://arxiv.org/abs/1904.06320v1", "date": "2019-04-12", "title": "Computationally-secure and composable remote state preparation", "authors": "Alexandru Gheorghiu, Thomas Vidick", "abstract": "We introduce a protocol between a classical polynomial-time verifier and a\nquantum polynomial-time prover that allows the verifier to securely delegate to\nthe prover the preparation of certain single-qubit quantum states. The protocol\nrealizes the following functionality, with computational security: the verifier\nchooses one of the observables $Z$, $X$, $Y$, $(X+Y)/\\sqrt{2}$,\n$(X-Y)/\\sqrt{2}$; the prover receives a uniformly random eigenstate of the\nobservable chosen by the verifier; the verifier receives a classical\ndescription of that state. The prover is unaware of which state he received and\nmoreover, the verifier can check with high confidence whether the preparation\nwas successful. The delegated preparation of single-qubit states is an\nelementary building block in many quantum cryptographic protocols. We expect\nour implementation of \"random remote state preparation with verification\", a\nfunctionality first defined in (Dunjko and Kashefi 2014), to be useful for\nremoving the need for quantum communication in such protocols while keeping\nfunctionality. The main application that we detail is to a protocol for blind\nand verifiable delegated quantum computation (DQC) that builds on the work of\n(Fitzsimons and Kashefi 2018), who provided such a protocol with quantum\ncommunication. Recently, both blind an verifiable DQC were shown to be\npossible, under computational assumptions, with a classical polynomial-time\nclient (Mahadev 2017, Mahadev 2018). Compared to the work of Mahadev, our\nprotocol is more modular, applies to the measurement-based model of computation\n(instead of the Hamiltonian model) and is composable. Our proof of security\nbuilds on ideas introduced in (Brakerski et al. 2018).", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph", "cs.CR"], "pdf_url": "http://arxiv.org/pdf/1904.06320v1"}
{"entry_id": "http://arxiv.org/abs/1903.00857v1", "date": "2019-03-03", "title": "CAD-Net: A Context-Aware Detection Network for Objects in Remote Sensing Imagery", "authors": "Gongjie Zhang, Shijian Lu, Wei Zhang", "abstract": "Accurate and robust detection of multi-class objects in optical remote\nsensing images is essential to many real-world applications such as urban\nplanning, traffic control, searching and rescuing, etc. However,\nstate-of-the-art object detection techniques designed for images captured using\nground-level sensors usually experience a sharp performance drop when directly\napplied to remote sensing images, largely due to the object appearance\ndifferences in remote sensing images in term of sparse texture, low contrast,\narbitrary orientations, large scale variations, etc. This paper presents a\nnovel object detection network (CAD-Net) that exploits attention-modulated\nfeatures as well as global and local contexts to address the new challenges in\ndetecting objects from remote sensing images. The proposed CAD-Net learns\nglobal and local contexts of objects by capturing their correlations with the\nglobal scene (at scene-level) and the local neighboring objects or features (at\nobject-level), respectively. In addition, it designs a spatial-and-scale-aware\nattention module that guides the network to focus on more informative regions\nand features as well as more appropriate feature scales. Experiments over two\npublicly available object detection datasets for remote sensing images\ndemonstrate that the proposed CAD-Net achieves superior detection performance.\nThe implementation codes will be made publicly available for facilitating\nfuture researches.", "journal": "", "doi": "10.1109/TGRS.2019.2930982", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1903.00857v1"}
{"entry_id": "http://arxiv.org/abs/2301.10876v1", "date": "2023-01-26", "title": "Reef-insight: A framework for reef habitat mapping with clustering methods via remote sensing", "authors": "Saharsh Barve, Jody Webster, Rohitash Chandra", "abstract": "Environmental damage has been of much concern, particularly coastal areas and\nthe oceans given climate change and drastic effects of pollution and extreme\nclimate events. Our present day analytical capabilities along with the\nadvancements in information acquisition techniques such as remote sensing can\nbe utilized for the management and study of coral reef ecosystems. In this\npaper, we present Reef-insight, an unsupervised machine learning framework that\nfeatures advanced clustering methods and remote sensing for reef community\nmapping. Our framework compares different clustering methods to evaluate them\nfor reef community mapping using remote sensing data. We evaluate four major\nclustering approaches such as k- means, hierarchical clustering, Gaussian\nmixture model, and density-based clustering based on qualitative and visual\nassessment. We utilise remote sensing data featuring Heron reef island region\nin the Great Barrier Reef of Australia. Our results indicate that clustering\nmethods using remote sensing data can well identify benthic and geomorphic\nclusters that are found in reefs when compared to other studies. Our results\nindicate that Reef-insight can generate detailed reef community maps outlining\ndistinct reef habitats and has the potential to enable further insights for\nreef restoration projects. We release our framework as open source software to\nenable its extension to different parts of the world", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.10876v1"}
{"entry_id": "http://arxiv.org/abs/2303.05329v1", "date": "2023-03-09", "title": "Tucker Bilinear Attention Network for Multi-scale Remote Sensing Object Detection", "authors": "Tao Chen, Ruirui Li, Jiafeng Fu, Daguang Jiang", "abstract": "Object detection on VHR remote sensing images plays a vital role in\napplications such as urban planning, land resource management, and rescue\nmissions. The large-scale variation of the remote-sensing targets is one of the\nmain challenges in VHR remote-sensing object detection. Existing methods\nimprove the detection accuracy of high-resolution remote sensing objects by\nimproving the structure of feature pyramids and adopting different attention\nmodules. However, for small targets, there still be seriously missed detections\ndue to the loss of key detail features. There is still room for improvement in\nthe way of multiscale feature fusion and balance. To address this issue, this\npaper proposes two novel modules: Guided Attention and Tucker Bilinear\nAttention, which are applied to the stages of early fusion and late fusion\nrespectively. The former can effectively retain clean key detail features, and\nthe latter can better balance features through semantic-level correlation\nmining. Based on two modules, we build a new multi-scale remote sensing object\ndetection framework. No bells and whistles. The proposed method largely\nimproves the average precisions of small objects and achieves the highest mean\naverage precisions compared with 9 state-of-the-art methods on DOTA, DIOR, and\nNWPU VHR-10.Code and models are available at\nhttps://github.com/Shinichict/GTNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2303.05329v1"}
{"entry_id": "http://arxiv.org/abs/2012.07456v3", "date": "2020-12-14", "title": "In situ multi-spacecraft and remote imaging observations of the first CME detected by Solar Orbiter and BepiColombo", "authors": "E. E. Davies, C. M\u00f6stl, M. J. Owens, A. J. Weiss, T. Amerstorfer, J. Hinterreiter, M. Bauer, R. L. Bailey, M. A. Reiss, R. J. Forsyth, T. S. Horbury, H. O'Brien, V. Evans, V. Angelini, D. Heyner, I. Richter, H-U. Auster, W. Magnes, W. Baumjohann, D. Fischer, D. Barnes, J. A. Davies, R. A. Harrison", "abstract": "On 2020 April 19 a coronal mass ejection (CME) was detected in situ by Solar\nOrbiter at a heliocentric distance of about 0.8 AU. The CME was later observed\nin situ on April 20th by the Wind and BepiColombo spacecraft whilst BepiColombo\nwas located very close to Earth. This CME presents a good opportunity for a\ntriple radial alignment study, as the spacecraft were separated by less than\n5$^\\circ$ in longitude. The source of the CME, which was launched on April\n15th, was an almost entirely isolated streamer blowout. STEREO-A observed the\nevent remotely from -75.1$^\\circ$ longitude, which is an exceptionally well\nsuited viewpoint for heliospheric imaging of an Earth directed CME. The\nconfiguration of the four spacecraft has provided an exceptionally clean link\nbetween remote imaging and in situ observations of the CME. We have used the in\nsitu observations of the CME at Solar Orbiter, Wind, and BepiColombo, and the\nremote observations of the CME at STEREO-A in combination with flux rope models\nto determine the global shape of the CME and its evolution as it propagated\nthrough the inner heliosphere. A clear flattening of the CME cross-section has\nbeen observed by STEREO-A, and further confirmed by comparing profiles of the\nflux rope models to the in situ data, where the distorted flux rope\ncross-section qualitatively agrees most with in situ observations of the\nmagnetic field at Solar Orbiter. Comparing in situ observations of the magnetic\nfield between spacecraft, we find that the dependence of the maximum (mean)\nmagnetic field strength decreases with heliocentric distance as $r^{-1.24 \\pm\n0.50}$ ($r^{-1.12 \\pm 0.14}$), in disagreement with previous studies. Further\nassessment of the axial and poloidal magnetic field strength dependencies\nsuggests that the expansion of the CME is likely neither self-similar nor\ncylindrically symmetric.", "journal": "A&A 656, A2 (2021)", "doi": "10.1051/0004-6361/202040113", "primary_category": "physics.space-ph", "categories": ["physics.space-ph", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2012.07456v3"}
{"entry_id": "http://arxiv.org/abs/1712.07567v2", "date": "2017-12-20", "title": "Deterministic delivery of remote entanglement on a quantum network", "authors": "Peter C. Humphreys, Norbert Kalb, Jaco P. J. Morits, Raymond N. Schouten, Raymond F. L. Vermeulen, Daniel. J. Twitchen, Matthew Markham, Ronald Hanson", "abstract": "Large-scale quantum networks promise to enable secure communication,\ndistributed quantum computing, enhanced sensing and fundamental tests of\nquantum mechanics through the distribution of entanglement across nodes. Moving\nbeyond current two-node networks requires the rate of entanglement generation\nbetween nodes to exceed their decoherence rates. Beyond this critical\nthreshold, intrinsically probabilistic entangling protocols can be subsumed\ninto a powerful building block that deterministically provides remote entangled\nlinks at pre-specified times. Here we surpass this threshold using diamond spin\nqubit nodes separated by 2 metres. We realise a fully heralded single-photon\nentanglement protocol that achieves entangling rates up to 39 Hz, three orders\nof magnitude higher than previously demonstrated two-photon protocols on this\nplatform. At the same time, we suppress the decoherence rate of remote\nentangled states to 5 Hz by dynamical decoupling. By combining these results\nwith efficient charge-state control and mitigation of spectral diffusion, we\nare able to deterministically deliver a fresh remote state with average\nentanglement fidelity exceeding 0.5 at every clock cycle of $\\sim$100 ms\nwithout any pre- or post-selection. These results demonstrate a key building\nblock for extended quantum networks and open the door to entanglement\ndistribution across multiple remote nodes.", "journal": "Nature 558, pages 268-273 (2018)", "doi": "10.1038/s41586-018-0200-5", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1712.07567v2"}
{"entry_id": "http://arxiv.org/abs/0801.2184v1", "date": "2008-01-14", "title": "Bell inequality violation with two remote atomic qubits", "authors": "D. N. Matsukevich, P. Maunz, D. L. Moehring, S. Olmschenk, C. Monroe", "abstract": "We observe violation of a Bell inequality between the quantum states of two\nremote Yb ions separated by a distance of about one meter with the detection\nloophole closed. The heralded entanglement of two ions is established via\ninterference and joint detection of two emitted photons, whose polarization is\nentangled with each ion. The entanglement of remote qubits is also\ncharacterized by full quantum state tomography.", "journal": "Phys. Rev. Lett. 100, 150404 (2008)", "doi": "10.1103/PhysRevLett.100.150404", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/0801.2184v1"}
{"entry_id": "http://arxiv.org/abs/1805.02660v2", "date": "2018-05-07", "title": "The Super Earth-Cold Jupiter Relations", "authors": "Wei Zhu, Yanqin Wu", "abstract": "We report relations between inner ($<1$ au) super Earths (planets with\nmass/radius between Earth and Neptune) and outer ($>1$ au) giant planets (mass\n$>0.3~M_{\\rm J}$, or cold Jupiters) around Sun-like stars, based on data from\nboth ground-based radial velocity (RV) observations and the Kepler mission. We\nfind that cold Jupiters appear three times more often around hosts of super\nEarths than they do around field stars. Given the prevalence of the super Earth\nsystems, their cold Jupiters can account for nearly all cold Jupiters. In other\nwords, cold Jupiters are almost certainly ($\\sim90\\%$) companied by super\nEarths. A few corollaries follow: (1) around metal-rich ([Fe/H]$>0.1$) stars,\nthe fraction of super Earths with cold Jupiters can rise to $60\\%$ or higher;\n(2) the inner architecture can be strongly impacted by the outer giant and we\nreport some observational evidence for this; (3) planetary systems like our\nown, with cold Jupiters but no super Earths, should be rare ($\\sim1\\%$). The\nstrong correlation between super Earths and cold Jupiters establish that super\nEarths and cold Jupiters do not compete for solid material, rather, they share\nsimilar origins, with the cold Jupiter formation requiring a somewhat more\nstringent condition. Lastly, we propose a few immediate observational tests of\nour results, using ground-based RV observations and ongoing/planned space\nmissions.", "journal": "", "doi": "10.3847/1538-3881/aad22a", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1805.02660v2"}
{"entry_id": "http://arxiv.org/abs/2007.12312v1", "date": "2020-07-24", "title": "COVID-19 Remote Patient Monitoring: Social Impact of AI", "authors": "Ashlesha Nesarikar, Waqas Haque, Suchith Vuppala, Abhijit Nesarikar", "abstract": "A primary indicator of success in the fight against COVID-19 is avoiding\nstress on critical care infrastructure and services (CCIS). However, CCIS will\nlikely remain stressed until sustained herd immunity is built. There are also\nsecondary considerations for success: mitigating economic damage; curbing the\nspread of misinformation, improving morale, and preserving a sense of control;\nbuilding global trust for diplomacy, trade and travel; and restoring\nreliability and normalcy to day-to-day life, among others. We envision\ntechnology plays a pivotal role. Here, we focus on the effective use of readily\navailable technology to improve the primary and secondary success criteria for\nthe fight against SARS-CoV-2. In a multifaceted technology approach, we start\nwith effective technology use for remote patient monitoring (RPM) of COVID-19\nwith the following objectives:\n  1. Deploy readily available technology for continuous real-time remote\nmonitoring of patient vitals with the help of biosensors on a large scale.\n  2. Effective and safe remote large-scale communitywide care of low-severity\ncases as a buffer against surges in COVID-19 hospitalizations to reduce strain\non critical care services and emergency hospitals.\n  3. Improve the patient, their family, and their community's sense of control\nand morale.\n  4. Propose a clear technology and medical definition of remote patient\nmonitoring for COVID-19 to address an urgent technology need; address\nobfuscated, narrow, and erroneous information and provide examples; and urge\npublishers to be clear and complete in their disclosures.\n  5. Leverage the cloud-based distributed cognitive RPM platform for community\nleaders and decision makers to enable planning and resource management,\npandemic research, damage prevention and containment, and receiving feedback on\nstrategies and executions.", "journal": "", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2007.12312v1"}
{"entry_id": "http://arxiv.org/abs/1303.6926v1", "date": "2013-03-27", "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing", "authors": "Dr. S. K. Katiyar, Arun P. V.", "abstract": "Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1303.6926v1"}
{"entry_id": "http://arxiv.org/abs/1508.00092v1", "date": "2015-08-01", "title": "Land Use Classification in Remote Sensing Images by Convolutional Neural Networks", "authors": "Marco Castelluccio, Giovanni Poggi, Carlo Sansone, Luisa Verdoliva", "abstract": "We explore the use of convolutional neural networks for the semantic\nclassification of remote sensing scenes. Two recently proposed architectures,\nCaffeNet and GoogLeNet, are adopted, with three different learning modalities.\nBesides conventional training from scratch, we resort to pre-trained networks\nthat are only fine-tuned on the target data, so as to avoid overfitting\nproblems and reduce design time. Experiments on two remote sensing datasets,\nwith markedly different characteristics, testify on the effectiveness and wide\napplicability of the proposed solution, which guarantees a significant\nperformance improvement over all state-of-the-art references.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1508.00092v1"}
{"entry_id": "http://arxiv.org/abs/1603.06201v2", "date": "2016-03-20", "title": "A Survey on Object Detection in Optical Remote Sensing Images", "authors": "Gong Cheng, Junwei Han", "abstract": "Object detection in optical remote sensing images, being a fundamental but\nchallenging problem in the field of aerial and satellite image analysis, plays\nan important role for a wide range of applications and is receiving significant\nattention in recent years. While enormous methods exist, a deep review of the\nliterature concerning generic object detection is still lacking. This paper\naims to provide a review of the recent progress in this field. Different from\nseveral previously published surveys that focus on a specific object class such\nas building and road, we concentrate on more generic object categories\nincluding, but are not limited to, road, building, tree, vehicle, ship,\nairport, urban-area. Covering about 270 publications we survey 1) template\nmatching-based object detection methods, 2) knowledge-based object detection\nmethods, 3) object-based image analysis (OBIA)-based object detection methods,\n4) machine learning-based object detection methods, and 5) five publicly\navailable datasets and three standard evaluation metrics. We also discuss the\nchallenges of current studies and propose two promising research directions,\nnamely deep learning-based feature representation and weakly supervised\nlearning-based geospatial object detection. It is our hope that this survey\nwill be beneficial for the researchers to have better understanding of this\nresearch field.", "journal": "ISPRS Journal of Photogrammetry and Remote Sensing, 117: 11-28,\n  2016", "doi": "10.1016/j.isprsjprs.2016.03.014", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1603.06201v2"}
{"entry_id": "http://arxiv.org/abs/2012.04920v1", "date": "2020-12-09", "title": "Kernel Anomalous Change Detection for Remote Sensing Imagery", "authors": "Jos\u00e9 A. Padr\u00f3n-Hidalgo, Valero Laparra, Nathan Longbotham, Gustau Camps-Valls", "abstract": "Anomalous change detection (ACD) is an important problem in remote sensing\nimage processing. Detecting not only pervasive but also anomalous or extreme\nchanges has many applications for which methodologies are available. This paper\nintroduces a nonlinear extension of a full family of anomalous change\ndetectors. In particular, we focus on algorithms that utilize Gaussian and\nelliptically contoured (EC) distribution and extend them to their nonlinear\ncounterparts based on the theory of reproducing kernels' Hilbert space. We\nillustrate the performance of the kernel methods introduced in both pervasive\nand ACD problems with real and simulated changes in multispectral and\nhyperspectral imagery with different resolutions (AVIRIS, Sentinel-2,\nWorldView-2, and Quickbird). A wide range of situations is studied in real\nexamples, including droughts, wildfires, and urbanization. Excellent\nperformance in terms of detection accuracy compared to linear formulations is\nachieved, resulting in improved detection accuracy and reduced false-alarm\nrates. Results also reveal that the EC assumption may be still valid in Hilbert\nspaces. We provide an implementation of the algorithms as well as a database of\nnatural anomalous changes in real scenarios http://isp.uv.es/kacd.html.", "journal": "IEEE Transactions on Geoscience and Remote Sensing ( Volume: 57,\n  Issue: 10, Oct. 2019)", "doi": "10.1109/TGRS.2019.2916212", "primary_category": "cs.CV", "categories": ["cs.CV", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2012.04920v1"}
{"entry_id": "http://arxiv.org/abs/2210.05417v1", "date": "2022-10-11", "title": "A Perception-Driven Approach To Immersive Remote Telerobotics", "authors": "Y. T. Tefera, D. Mazzanti, S. Anastasi, D. G. Caldwell, P. Fiorini, N. Deshpande", "abstract": "Virtual Reality (VR) interfaces are increasingly used as remote visualization\nmedia in telerobotics. Remote environments captured through RGB-D cameras and\nvisualized using VR interfaces can enhance operators' situational awareness and\nsense of presence. However, this approach has strict requirements for the\nspeed, throughput, and quality of the visualized 3D data.Further, telerobotics\nrequires operators to focus on their tasks fully, requiring high perceptual and\ncognitive skills. This paper shows a work-in-progress framework to address\nthese challenges by taking the human visual system (HVS) as an inspiration.\nHuman eyes use attentional mechanisms to select and draw user engagement to a\nspecific place from the dynamic environment. Inspired by this, the framework\nimplements functionalities to draw users's engagement to a specific place while\nsimultaneously reducing latency and bandwidth requirements.", "journal": "", "doi": null, "primary_category": "cs.HC", "categories": ["cs.HC", "cs.RO"], "pdf_url": "http://arxiv.org/pdf/2210.05417v1"}
{"entry_id": "http://arxiv.org/abs/1610.03023v2", "date": "2016-10-10", "title": "Learning Low Dimensional Convolutional Neural Networks for High-Resolution Remote Sensing Image Retrieval", "authors": "Weixun Zhou, Shawn Newsam, Congmin Li, Zhenfeng Shao", "abstract": "Learning powerful feature representations for image retrieval has always been\na challenging task in the field of remote sensing. Traditional methods focus on\nextracting low-level hand-crafted features which are not only time-consuming\nbut also tend to achieve unsatisfactory performance due to the content\ncomplexity of remote sensing images. In this paper, we investigate how to\nextract deep feature representations based on convolutional neural networks\n(CNN) for high-resolution remote sensing image retrieval (HRRSIR). To this end,\ntwo effective schemes are proposed to generate powerful feature representations\nfor HRRSIR. In the first scheme, the deep features are extracted from the\nfully-connected and convolutional layers of the pre-trained CNN models,\nrespectively; in the second scheme, we propose a novel CNN architecture based\non conventional convolution layers and a three-layer perceptron. The novel CNN\nmodel is then trained on a large remote sensing dataset to learn low\ndimensional features. The two schemes are evaluated on several public and\nchallenging datasets, and the results indicate that the proposed schemes and in\nparticular the novel CNN are able to achieve state-of-the-art performance.", "journal": "Remote Sens., 9(5), 489 (2017)", "doi": "10.3390/rs9050489", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1610.03023v2"}
{"entry_id": "http://arxiv.org/abs/1810.06470v1", "date": "2018-10-15", "title": "Unsupervised Deep Features for Remote Sensing Image Matching via Discriminator Network", "authors": "Mohbat Tharani, Numan Khurshid, Murtaza Taj", "abstract": "The advent of deep perceptual networks brought about a paradigm shift in\nmachine vision and image perception. Image apprehension lately carried out by\nhand-crafted features in the latent space have been replaced by deep features\nacquired from supervised networks for improved understanding. However, such\ndeep networks require strict supervision with a substantial amount of the\nlabeled data for authentic training process. These methods perform poorly in\ndomains lacking labeled data especially in case of remote sensing image\nretrieval. Resolving this, we propose an unsupervised encoder-decoder feature\nfor remote sensing image matching (RSIM). Moreover, we replace the conventional\ndistance metrics with a deep discriminator network to identify the similarity\nof the image pairs. To the best of our knowledge, discriminator network has\nnever been used before for solving RSIM problem. Results have been validated\nwith two publicly available benchmark remote sensing image datasets. The\ntechnique has also been investigated for content-based remote sensing image\nretrieval (CBRSIR); one of the widely used applications of RSIM. Results\ndemonstrate that our technique supersedes the state-of-the-art methods used for\nunsupervised image matching with mean average precision (mAP) of 81%, and image\nretrieval with an overall improvement in mAP score of about 12%.", "journal": "", "doi": "10.1109/TGRS.2019.2951820", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1810.06470v1"}
{"entry_id": "http://arxiv.org/abs/2104.10874v1", "date": "2021-04-22", "title": "Focusing on Shadows for Predicting Heightmaps from Single Remotely Sensed RGB Images with Deep Learning", "authors": "Savvas Karatsiolis, Andreas Kamilaris", "abstract": "Estimating the heightmaps of buildings and vegetation in single remotely\nsensed images is a challenging problem. Effective solutions to this problem can\ncomprise the stepping stone for solving complex and demanding problems that\nrequire 3D information of aerial imagery in the remote sensing discipline,\nwhich might be expensive or not feasible to require. We propose a task-focused\nDeep Learning (DL) model that takes advantage of the shadow map of a remotely\nsensed image to calculate its heightmap. The shadow is computed efficiently and\ndoes not add significant computation complexity. The model is trained with\naerial images and their Lidar measurements, achieving superior performance on\nthe task. We validate the model with a dataset covering a large area of\nManchester, UK, as well as the 2018 IEEE GRSS Data Fusion Contest Lidar\ndataset. Our work suggests that the proposed DL architecture and the technique\nof injecting shadows information into the model are valuable for improving the\nheightmap estimation task for single remotely sensed imagery.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2104.10874v1"}
{"entry_id": "http://arxiv.org/abs/1505.07653v2", "date": "2015-05-28", "title": "Parity measurement of remote qubits using dispersive coupling and photodetection", "authors": "J. Govenius, Y. Matsuzaki, I. G. Savenko, M. M\u00f6tt\u00f6nen", "abstract": "Parity measurement is a key step in many entanglement generation and quantum\nerror correction schemes. We propose a protocol for non-destructive parity\nmeasurement of two remote qubits, i.e., macroscopically separated qubits with\nno direct interaction. The qubits are instead dispersively coupled to separate\nresonators that radiate to shared photodetectors. The scheme is deterministic\nin the sense that there is no fundamental bound on the success probability.\nCompared to previous proposals, our protocol addresses the scenario where\nnumber resolving photodetectors are available but the qubit-resonator coupling\nis time-independent and only dispersive.", "journal": "Phys. Rev. A 92, 042305 (2015)", "doi": "10.1103/PhysRevA.92.042305", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1505.07653v2"}
{"entry_id": "http://arxiv.org/abs/2006.08432v2", "date": "2020-06-15", "title": "SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning", "authors": "Gencer Sumbul, Sonali Nayak, Beg\u00fcm Demir", "abstract": "Deep neural networks (DNNs) have been recently found popular for image\ncaptioning problems in remote sensing (RS). Existing DNN based approaches rely\non the availability of a training set made up of a high number of RS images\nwith their captions. However, captions of training images may contain redundant\ninformation (they can be repetitive or semantically similar to each other),\nresulting in information deficiency while learning a mapping from the image\ndomain to the language domain. To overcome this limitation, in this paper, we\npresent a novel Summarization Driven Remote Sensing Image Captioning (SD-RSIC)\napproach. The proposed approach consists of three main steps. The first step\nobtains the standard image captions by jointly exploiting convolutional neural\nnetworks (CNNs) with long short-term memory (LSTM) networks. The second step,\nunlike the existing RS image captioning methods, summarizes the ground-truth\ncaptions of each training image into a single caption by exploiting sequence to\nsequence neural networks and eliminates the redundancy present in the training\nset. The third step automatically defines the adaptive weights associated to\neach RS image to combine the standard captions with the summarized captions\nbased on the semantic content of the image. This is achieved by a novel\nadaptive weighting strategy defined in the context of LSTM networks.\nExperimental results obtained on the RSCID, UCM-Captions and Sydney-Captions\ndatasets show the effectiveness of the proposed approach compared to the\nstate-of-the-art RS image captioning approaches. The code of the proposed\napproach is publicly available at\nhttps://gitlab.tubit.tu-berlin.de/rsim/SD-RSIC.", "journal": "", "doi": "10.1109/TGRS.2020.3031111", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2006.08432v2"}
{"entry_id": "http://arxiv.org/abs/2001.02988v7", "date": "2020-01-09", "title": "Objects detection for remote sensing images based on polar coordinates", "authors": "Lin Zhou, Haoran Wei, Hao Li, Wenzhe Zhao, Yi Zhang, Yue Zhang", "abstract": "Arbitrary-oriented object detection is an important task in the field of\nremote sensing object detection. Existing studies have shown that the polar\ncoordinate system has obvious advantages in dealing with the problem of\nrotating object modeling, that is, using fewer parameters to achieve more\naccurate rotating object detection. However, present state-of-the-art detectors\nbased on deep learning are all modeled in Cartesian coordinates. In this\narticle, we introduce the polar coordinate system to the deep learning detector\nfor the first time, and propose an anchor free Polar Remote Sensing Object\nDetector (P-RSDet), which can achieve competitive detection accuracy via uses\nsimpler object representation model and less regression parameters. In P-RSDet\nmethod, arbitrary-oriented object detection can be achieved by predicting the\ncenter point and regressing one polar radius and two polar angles. Besides, in\norder to express the geometric constraint relationship between the polar radius\nand the polar angle, a Polar Ring Area Loss function is proposed to improve the\nprediction accuracy of the corner position. Experiments on DOTA, UCAS-AOD and\nNWPU VHR-10 datasets show that our P-RSDet achieves state-of-the-art\nperformances with simpler model and less regression parameters.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2001.02988v7"}
{"entry_id": "http://arxiv.org/abs/1310.6002v3", "date": "2013-10-22", "title": "Weak Values with Remote Postselection and Shared Entanglement", "authors": "Arun Kumar Pati, Uttam Singh", "abstract": "We propose a new protocol for the weak measurement of any observable with\nremote pre and postselections. We show that if two parties share a pure\nentangled state, then by using local operations and classical communication\nthey can preselect and postselect at distant locations leading to the weak\nvalue of an observable as a shift in the pointer of the apparatus at one\nlocation in the process of the weak measurement. This can be achieved with\neither sharing of a pure maximally or non-maximally entangled state. We\ngeneralize the protocol for realizing the weak value of any observable with\nremote pre and postselection of mixed states. Finally, we show how the weak\nvalue is modified in the remote pre and postselection setting if Alice and Bob\nshare a mixed entangled state.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1310.6002v3"}
{"entry_id": "http://arxiv.org/abs/1603.09506v1", "date": "2016-03-31", "title": "Hot Jupiters and Super-Earths", "authors": "Alexander James Mustill, Melvyn B Davies, Anders Johansen", "abstract": "We explore the role of dynamics in shaping planetary system multiplicities,\nfocussing on two particular problems. (1) We propose that the lack of close-in\nsuper-Earths in hot Jupiter systems is a signature of the migration history of\nthe hot Jupiters and helps to discriminate between different mechanisms of\nmigration. We present N-body simulations of dynamical migration scenarios where\nproto-hot Jupiters are excited to high eccentricities prior to tidal\ncircularisation and orbital decay. We show that in this scenario, the eccentric\ngiant planet typically destroys planets in the inner system, in agreement with\nthe observed lack of close super-Earth companions to hot Jupiters. (2) We\nexplore the role of the dynamics of outer systems in affecting the\nmultiplicities of close-in systems such as those discovered by Kepler. We\nconsider specifically the effects of planet--planet scattering and Kozai\nperturbations on an exterior giant planet on the architecture of the inner\nsystem, and evaluate the ability of such scenarios to reduce the inner system's\nmultiplicity and contribute to the observed excess of single Kepler planets.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1603.09506v1"}
{"entry_id": "http://arxiv.org/abs/1206.6962v1", "date": "2012-06-29", "title": "Functional factor analysis for periodic remote sensing data", "authors": "Chong Liu, Surajit Ray, Giles Hooker, Mark Friedl", "abstract": "We present a new approach to factor rotation for functional data. This is\nachieved by rotating the functional principal components toward a predefined\nspace of periodic functions designed to decompose the total variation into\ncomponents that are nearly-periodic and nearly-aperiodic with a predefined\nperiod. We show that the factor rotation can be obtained by calculation of\ncanonical correlations between appropriate spaces which make the methodology\ncomputationally efficient. Moreover, we demonstrate that our proposed rotations\nprovide stable and interpretable results in the presence of highly complex\ncovariance. This work is motivated by the goal of finding interpretable sources\nof variability in gridded time series of vegetation index measurements obtained\nfrom remote sensing, and we demonstrate our methodology through an application\nof factor rotation of this data.", "journal": "Annals of Applied Statistics 2012, Vol. 6, No. 2, 601-624", "doi": "10.1214/11-AOAS518", "primary_category": "stat.AP", "categories": ["stat.AP"], "pdf_url": "http://arxiv.org/pdf/1206.6962v1"}
{"entry_id": "http://arxiv.org/abs/1501.03547v1", "date": "2015-01-15", "title": "Cloud-Assisted Remote Sensor Network Virtualization for Distributed Consensus Estimation", "authors": "Sherif Abdelwahab, Bechir Hamdaoui, Mohsen Guizani", "abstract": "We develop cloud-assisted remote sensing techniques for enabling distributed\nconsensus estimation of unknown parameters in a given geographic area. We first\npropose a distributed sensor network virtualization algorithm that searches\nfor, selects, and coordinates Internet-accessible sensors to perform a sensing\ntask in a specific region. The algorithm converges in linearithmic time for\nlarge-scale networks, and requires exchanging a number of messages that is at\nmost linear in the number of sensors. Second, we design an uncoordinated,\ndistributed algorithm that relies on the selected sensors to estimate a set of\nparameters without requiring synchronization among the sensors. Our simulation\nresults show that the proposed algorithm, when compared to conventional ADMM\n(Alternating Direction Method of Multipliers), reduces communication overhead\nsignificantly without compromising the estimation error. In addition, the\nconvergence time, though increases slightly, is still linear as in the case of\nconventional ADMM.", "journal": "", "doi": null, "primary_category": "cs.NI", "categories": ["cs.NI"], "pdf_url": "http://arxiv.org/pdf/1501.03547v1"}
{"entry_id": "http://arxiv.org/abs/1710.07096v2", "date": "2017-10-19", "title": "Deep Self-taught Learning for Remote Sensing Image Classification", "authors": "Anika Bettge, Ribana Roscher, Susanne Wenzel", "abstract": "This paper addresses the land cover classification task for remote sensing\nimages by deep self-taught learning. Our self-taught learning approach learns\nsuitable feature representations of the input data using sparse representation\nand undercomplete dictionary learning. We propose a deep learning framework\nwhich extracts representations in multiple layers and use the output of the\ndeepest layer as input to a classification algorithm. We evaluate our approach\nusing a multispectral Landsat 5 TM image of a study area in the North of Novo\nProgresso (South America) and the Zurich Summer Data Set provided by the\nUniversity of Zurich. Experiments indicate that features learned by a deep\nself-taught learning framework can be used for classification and improve the\nresults compared to classification results using the original feature\nrepresentation.", "journal": "Proceedings of the 2017 conference on Big Data from Space", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1710.07096v2"}
{"entry_id": "http://arxiv.org/abs/2005.08892v1", "date": "2020-05-18", "title": "Deep Snow: Synthesizing Remote Sensing Imagery with Generative Adversarial Nets", "authors": "Christopher X. Ren, Amanda Ziemann, James Theiler, Alice M. S. Durieux", "abstract": "In this work we demonstrate that generative adversarial networks (GANs) can\nbe used to generate realistic pervasive changes in remote sensing imagery, even\nin an unpaired training setting. We investigate some transformation quality\nmetrics based on deep embedding of the generated and real images which enable\nvisualization and understanding of the training dynamics of the GAN, and may\nprovide a useful measure in terms of quantifying how distinguishable the\ngenerated images are from real images. We also identify some artifacts\nintroduced by the GAN in the generated images, which are likely to contribute\nto the differences seen between the real and generated samples in the deep\nembedding feature space even in cases where the real and generated samples\nappear perceptually similar.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2005.08892v1"}
{"entry_id": "http://arxiv.org/abs/1807.09562v1", "date": "2018-07-25", "title": "Change Detection between Multimodal Remote Sensing Data Using Siamese CNN", "authors": "Zhenchao Zhang, George Vosselman, Markus Gerke, Devis Tuia, Michael Ying Yang", "abstract": "Detecting topographic changes in the urban environment has always been an\nimportant task for urban planning and monitoring. In practice, remote sensing\ndata are often available in different modalities and at different time epochs.\nChange detection between multimodal data can be very challenging since the data\nshow different characteristics. Given 3D laser scanning point clouds and 2D\nimagery from different epochs, this paper presents a framework to detect\nbuilding and tree changes. First, the 2D and 3D data are transformed to image\npatches, respectively. A Siamese CNN is then employed to detect candidate\nchanges between the two epochs. Finally, the candidate patch-based changes are\ngrouped and verified as individual object changes. Experiments on the urban\ndata show that 86.4\\% of patch pairs can be correctly classified by the model.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.09562v1"}
{"entry_id": "http://arxiv.org/abs/1905.10236v1", "date": "2019-05-24", "title": "A Research and Strategy of Remote Sensing Image Denoising Algorithms", "authors": "Ling Li, Junxing Hu, Fengge Wu, Junsuo Zhao", "abstract": "Most raw data download from satellites are useless, resulting in transmission\nwaste, one solution is to process data directly on satellites, then only\ntransmit the processed results to the ground. Image processing is the main data\nprocessing on satellites, in this paper, we focus on image denoising which is\nthe basic image processing. There are many high-performance denoising\napproaches at present, however, most of them rely on advanced computing\nresources or rich images on the ground. Considering the limited computing\nresources of satellites and the characteristics of remote sensing images, we do\nsome research on these high-performance ground image denoising approaches and\ncompare them in simulation experiments to analyze whether they are suitable for\nsatellites. According to the analysis results, we propose two feasible image\ndenoising strategies for satellites based on satellite TianZhi-1.", "journal": "", "doi": "10.1007/978-3-030-32591-6_75", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/1905.10236v1"}
{"entry_id": "http://arxiv.org/abs/2101.06438v1", "date": "2021-01-16", "title": "Adaptive Remote Sensing Image Attribute Learning for Active Object Detection", "authors": "Nuo Xu, Chunlei Huo, Jiacheng Guo, Yiwei Liu, Jian Wang, Chunhong Pan", "abstract": "In recent years, deep learning methods bring incredible progress to the field\nof object detection. However, in the field of remote sensing image processing,\nexisting methods neglect the relationship between imaging configuration and\ndetection performance, and do not take into account the importance of detection\nperformance feedback for improving image quality. Therefore, detection\nperformance is limited by the passive nature of the conventional object\ndetection framework. In order to solve the above limitations, this paper takes\nadaptive brightness adjustment and scale adjustment as examples, and proposes\nan active object detection method based on deep reinforcement learning. The\ngoal of adaptive image attribute learning is to maximize the detection\nperformance. With the help of active object detection and image attribute\nadjustment strategies, low-quality images can be converted into high-quality\nimages, and the overall performance is improved without retraining the\ndetector.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2101.06438v1"}
{"entry_id": "http://arxiv.org/abs/2201.05778v1", "date": "2022-01-15", "title": "Semantic decoupled representation learning for remote sensing image change detection", "authors": "Hao Chen, Yifan Zao, Liqin Liu, Song Chen, Zhenwei Shi", "abstract": "Contemporary transfer learning-based methods to alleviate the data\ninsufficiency in change detection (CD) are mainly based on ImageNet\npre-training. Self-supervised learning (SSL) has recently been introduced to\nremote sensing (RS) for learning in-domain representations. Here, we propose a\nsemantic decoupled representation learning for RS image CD. Typically, the\nobject of interest (e.g., building) is relatively small compared to the vast\nbackground. Different from existing methods expressing an image into one\nrepresentation vector that may be dominated by irrelevant land-covers, we\ndisentangle representations of different semantic regions by leveraging the\nsemantic mask. We additionally force the model to distinguish different\nsemantic representations, which benefits the recognition of objects of interest\nin the downstream CD task. We construct a dataset of bitemporal images with\nsemantic masks in an effortless manner for pre-training. Experiments on two CD\ndatasets show our model outperforms ImageNet pre-training, in-domain supervised\npre-training, and several recent SSL methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2201.05778v1"}
{"entry_id": "http://arxiv.org/abs/2303.00355v1", "date": "2023-03-01", "title": "Progressive Scale-aware Network for Remote sensing Image Change Captioning", "authors": "Chenyang Liu, Jiajun Yang, Zipeng Qi, Zhengxia Zou, Zhenwei Shi", "abstract": "Remote sensing (RS) images contain numerous objects of different scales,\nwhich poses significant challenges for the RS image change captioning (RSICC)\ntask to identify visual changes of interest in complex scenes and describe them\nvia language. However, current methods still have some weaknesses in\nsufficiently extracting and utilizing multi-scale information. In this paper,\nwe propose a progressive scale-aware network (PSNet) to address the problem.\nPSNet is a pure Transformer-based model. To sufficiently extract multi-scale\nvisual features, multiple progressive difference perception (PDP) layers are\nstacked to progressively exploit the differencing features of bitemporal\nfeatures. To sufficiently utilize the extracted multi-scale features for\ncaptioning, we propose a scale-aware reinforcement (SR) module and combine it\nwith the Transformer decoding layer to progressively utilize the features from\ndifferent PDP layers. Experiments show that the PDP layer and SR module are\neffective and our PSNet outperforms previous methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2303.00355v1"}
{"entry_id": "http://arxiv.org/abs/2204.12296v2", "date": "2022-04-26", "title": "Unsupervised Segmentation of Hyperspectral Remote Sensing Images with Superpixels", "authors": "Mirko Paolo Barbato, Paolo Napoletano, Flavio Piccoli, Raimondo Schettini", "abstract": "In this paper, we propose an unsupervised method for hyperspectral remote\nsensing image segmentation. The method exploits the mean-shift clustering\nalgorithm that takes as input a preliminary hyperspectral superpixels\nsegmentation together with the spectral pixel information. The proposed method\ndoes not require the number of segmentation classes as input parameter, and it\ndoes not exploit any a-priori knowledge about the type of land-cover or\nland-use to be segmented (e.g. water, vegetation, building etc.). Experiments\non Salinas, SalinasA, Pavia Center and Pavia University datasets are carried\nout. Performance are measured in terms of normalized mutual information,\nadjusted Rand index and F1-score. Results demonstrate the validity of the\nproposed method in comparison with the state of the art.", "journal": "Volume 28, Year 2022, Page 100823", "doi": "10.1016/j.rsase.2022.100823", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.12296v2"}
{"entry_id": "http://arxiv.org/abs/2211.15790v1", "date": "2022-11-28", "title": "Handling Image and Label Resolution Mismatch in Remote Sensing", "authors": "Scott Workman, Armin Hadzic, M. Usman Rafique", "abstract": "Though semantic segmentation has been heavily explored in vision literature,\nunique challenges remain in the remote sensing domain. One such challenge is\nhow to handle resolution mismatch between overhead imagery and ground-truth\nlabel sources, due to differences in ground sample distance. To illustrate this\nproblem, we introduce a new dataset and use it to showcase weaknesses inherent\nin existing strategies that naively upsample the target label to match the\nimage resolution. Instead, we present a method that is supervised using\nlow-resolution labels (without upsampling), but takes advantage of an exemplar\nset of high-resolution labels to guide the learning process. Our method\nincorporates region aggregation, adversarial learning, and self-supervised\npretraining to generate fine-grained predictions, without requiring\nhigh-resolution annotations. Extensive experiments demonstrate the real-world\napplicability of our approach.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2211.15790v1"}
{"entry_id": "http://arxiv.org/abs/1503.05692v1", "date": "2015-03-19", "title": "An approach to improving edge detection for facial and remotely sensed images using vector order statistics", "authors": "B O. Sadiq, S. M. Sani, S. Garba", "abstract": "This paper presents an improved edge detection algorithm for facial and\nremotely sensed images using vector order statistics. The developed algorithm\nprocesses colored images directly without been converted to gray scale. A\nnumber of the existing algorithms converts the colored images into gray scale\nbefore detection of edges. But this process leads to inaccurate precision of\nrecognized edges, thus producing false and broken edges in the output edge map.\nFacial and remotely sensed images consist of curved edge lines which have to be\ndetected continuously to prevent broken edges. In order to deal with this, a\ncollection of pixel approach is introduced with a view to minimizing the false\nand broken edges that exists in the generated output edge map of facial and\nremotely sensed images.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1503.05692v1"}
{"entry_id": "http://arxiv.org/abs/1911.12517v2", "date": "2019-11-28", "title": "A Discriminative Learned CNN Embedding for Remote Sensing Image Scene Classification", "authors": "Wen Wang, Lijun Du, Yinxing Gao, Yanzhou Su, Feng Wang, Jian Cheng", "abstract": "In this work, a discriminatively learned CNN embedding is proposed for remote\nsensing image scene classification. Our proposed siamese network simultaneously\ncomputes the classification loss function and the metric learning loss function\nof the two input images. Specifically, for the classification loss, we use the\nstandard cross-entropy loss function to predict the classes of the images. For\nthe metric learning loss, our siamese network learns to map the intra-class and\ninter-class input pairs to a feature space where intra-class inputs are close\nand inter-class inputs are separated by a margin. Concretely, for remote\nsensing image scene classification, we would like to map images from the same\nscene to feature vectors that are close, and map images from different scenes\nto feature vectors that are widely separated. Experiments are conducted on\nthree different remote sensing image datasets to evaluate the effectiveness of\nour proposed approach. The results demonstrate that the proposed method\nachieves an excellent classification performance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1911.12517v2"}
{"entry_id": "http://arxiv.org/abs/2003.07955v1", "date": "2020-03-17", "title": "An End-to-end Framework For Low-Resolution Remote Sensing Semantic Segmentation", "authors": "Matheus Barros Pereira, Jefersson Alex dos Santos", "abstract": "High-resolution images for remote sensing applications are often not\naffordable or accessible, especially when in need of a wide temporal span of\nrecordings. Given the easy access to low-resolution (LR) images from\nsatellites, many remote sensing works rely on this type of data. The problem is\nthat LR images are not appropriate for semantic segmentation, due to the need\nfor high-quality data for accurate pixel prediction for this task. In this\npaper, we propose an end-to-end framework that unites a super-resolution and a\nsemantic segmentation module in order to produce accurate thematic maps from LR\ninputs. It allows the semantic segmentation network to conduct the\nreconstruction process, modifying the input image with helpful textures. We\nevaluate the framework with three remote sensing datasets. The results show\nthat the framework is capable of achieving a semantic segmentation performance\nclose to native high-resolution data, while also surpassing the performance of\na network trained with LR inputs.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2003.07955v1"}
{"entry_id": "http://arxiv.org/abs/2007.13083v3", "date": "2020-07-26", "title": "MACU-Net for Semantic Segmentation of Fine-Resolution Remotely Sensed Images", "authors": "Rui Li, Chenxi Duan, Shunyi Zheng, Ce Zhang, Peter M. Atkinson", "abstract": "Semantic segmentation of remotely sensed images plays an important role in\nland resource management, yield estimation, and economic assessment. U-Net, a\ndeep encoder-decoder architecture, has been used frequently for image\nsegmentation with high accuracy. In this Letter, we incorporate multi-scale\nfeatures generated by different layers of U-Net and design a multi-scale skip\nconnected and asymmetric-convolution-based U-Net (MACU-Net), for segmentation\nusing fine-resolution remotely sensed images. Our design has the following\nadvantages: (1) The multi-scale skip connections combine and realign semantic\nfeatures contained in both low-level and high-level feature maps; (2) the\nasymmetric convolution block strengthens the feature representation and feature\nextraction capability of a standard convolution layer. Experiments conducted on\ntwo remotely sensed datasets captured by different satellite sensors\ndemonstrate that the proposed MACU-Net transcends the U-Net, U-NetPPL, U-Net\n3+, amongst other benchmark approaches. Code is available at\nhttps://github.com/lironui/MACU-Net.", "journal": "", "doi": "10.1109/LGRS.2021.3052886", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2007.13083v3"}
{"entry_id": "http://arxiv.org/abs/2111.10079v2", "date": "2021-11-19", "title": "Evaluating Self and Semi-Supervised Methods for Remote Sensing Segmentation Tasks", "authors": "Chaitanya Patel, Shashank Sharma, Valerie J. Pasquarella, Varun Gulshan", "abstract": "Self- and semi-supervised machine learning techniques leverage unlabeled data\nfor improving downstream task performance. These methods are especially\nvaluable for remote sensing tasks where producing labeled ground truth datasets\ncan be prohibitively expensive but there is easy access to a wealth of\nunlabeled imagery. We perform a rigorous evaluation of SimCLR, a\nself-supervised method, and FixMatch, a semi-supervised method, on three remote\nsensing tasks: riverbed segmentation, land cover mapping, and flood mapping. We\nquantify performance improvements on these remote sensing segmentation tasks\nwhen additional imagery outside of the original supervised dataset is made\navailable for training. We also design experiments to test the effectiveness of\nthese techniques when the test set is domain shifted to sample different\ngeographic areas compared to the training and validation sets. We find that\nsuch techniques significantly improve generalization performance when labeled\ndata is limited and there are geographic domain shifts between the training\ndata and the validation/test data.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2111.10079v2"}
{"entry_id": "http://arxiv.org/abs/1804.00292v1", "date": "2018-04-01", "title": "EarthMapper: A Tool Box for the Semantic Segmentation of Remote Sensing Imagery", "authors": "Ronald Kemker, Utsav B. Gewali, Christopher Kanan", "abstract": "Deep learning continues to push state-of-the-art performance for the semantic\nsegmentation of color (i.e., RGB) imagery; however, the lack of annotated data\nfor many remote sensing sensors (i.e. hyperspectral imagery (HSI)) prevents\nresearchers from taking advantage of this recent success. Since generating\nsensor specific datasets is time intensive and cost prohibitive, remote sensing\nresearchers have embraced deep unsupervised feature extraction. Although these\nmethods have pushed state-of-the-art performance on current HSI benchmarks,\nmany of these tools are not readily accessible to many researchers. In this\nletter, we introduce a software pipeline, which we call EarthMapper, for the\nsemantic segmentation of non-RGB remote sensing imagery. It includes\nself-taught spatial-spectral feature extraction, various standard and deep\nlearning classifiers, and undirected graphical models for post-processing. We\nevaluated EarthMapper on the Indian Pines and Pavia University datasets and\nhave released this code for public use.", "journal": "", "doi": null, "primary_category": "stat.ML", "categories": ["stat.ML", "cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1804.00292v1"}
{"entry_id": "http://arxiv.org/abs/1807.06535v2", "date": "2018-07-17", "title": "A framework for remote sensing images processing using deep learning technique", "authors": "R\u00e9mi Cresson", "abstract": "Deep learning techniques are becoming increasingly important to solve a\nnumber of image processing tasks. Among common algorithms, Convolutional Neural\nNetworks and Recurrent Neural Networks based systems achieve state of the art\nresults on satellite and aerial imagery in many applications. While these\napproaches are subject to scientific interest, there is currently no\noperational and generic implementation available at user-level for the remote\nsensing community. In this paper, we presents a framework enabling the use of\ndeep learning techniques with remote sensing images and geospatial data. Our\nsolution takes roots in two extensively used open-source libraries, the remote\nsensing image processing library Orfeo ToolBox, and the high performance\nnumerical computation library TensorFlow. It can apply deep nets without\nrestriction on images size and is computationally efficient, regardless\nhardware configuration.", "journal": "", "doi": "10.1109/LGRS.2018.2867949", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.06535v2"}
{"entry_id": "http://arxiv.org/abs/1904.02302v1", "date": "2019-04-04", "title": "A Training-free, One-shot Detection Framework For Geospatial Objects In Remote Sensing Images", "authors": "Tengfei Zhang, Yue Zhang, Xian Sun, Menglong Yan, Yaoling Wang, Kun Fu", "abstract": "Deep learning based object detection has achieved great success. However,\nthese supervised learning methods are data-hungry and time-consuming. This\nrestriction makes them unsuitable for limited data and urgent tasks, especially\nin the applications of remote sensing. Inspired by the ability of humans to\nquickly learn new visual concepts from very few examples, we propose a\ntraining-free, one-shot geospatial object detection framework for remote\nsensing images. It consists of (1) a feature extractor with remote sensing\ndomain knowledge, (2) a multi-level feature fusion method, (3) a novel\nsimilarity metric method, and (4) a 2-stage object detection pipeline.\nExperiments on sewage treatment plant and airport detections show that proposed\nmethod has achieved a certain effect. Our method can serve as a baseline for\ntraining-free, one-shot geospatial object detection.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1904.02302v1"}
{"entry_id": "http://arxiv.org/abs/1804.02335v1", "date": "2018-04-06", "title": "Free-space remote sensing of rotation at photon-counting level", "authors": "Wuhong Zhang, Jingsong Gao, Dongkai Zhang, Yilin He, Tianzhe Xu, Robert Fickler, Lixiang Chen", "abstract": "The rotational Doppler effect associated with light's orbital angular\nmomentum (OAM) has been found as a powerful tool to detect rotating bodies.\nHowever, this method was only demonstrated experimentally on the laboratory\nscale under well controlled conditions so far. And its real potential lies at\nthe practical applications in the field of remote sensing. We have established\na 120-meter long free-space link between the rooftops of two buildings and show\nthat both the rotation speed and the rotational symmetry of objects can be\nidentified from the detected rotational Doppler frequency shift signal at\nphoton count level. Effects of possible slight misalignments and atmospheric\nturbulences are quantitatively analyzed in terms of mode power spreading to the\nadjacent modes as well as the transfer of rotational frequency shifts.\nMoreover, our results demonstrate that with the preknowledge of the object's\nrotational symmetry one may always deduce the rotation speed no matter how\nstrong the coupling to neighboring modes is. Without any information of the\nrotating object, the deduction of the object's symmetry and rotational speed\nmay still be obtained as long as the mode spreading efficiency does not exceed\n50 %. Our work supports the feasibility of a practical sensor to remotely\ndetect both the speed and symmetry of rotating bodies.", "journal": "Phys. Rev. Applied 10, 044014 (2018)", "doi": "10.1103/PhysRevApplied.10.044014", "primary_category": "physics.optics", "categories": ["physics.optics", "physics.app-ph"], "pdf_url": "http://arxiv.org/pdf/1804.02335v1"}
{"entry_id": "http://arxiv.org/abs/2211.12994v1", "date": "2022-11-23", "title": "Connecting Solar Orbiter remote-sensing observations and Parker Solar Probe in-situ measurements with a numerical MHD reconstruction of the Parker spiral", "authors": "Ruggero Biondo, Alessandro Bemporad, Paolo Pagano, Daniele Telloni, Fabio Reale, Marco Romoli, Vincenzo Andretta, Ester Antonucci, Vania Da Deppo, Yara De Leo, Silvano Fineschi, Petr Heinzel, Daniel Moses, Giampiero Naletto, Gianalfredo Nicolini, Daniele Spadaro, Marco Stangalini, Luca Teriaca, Federico Landini, Clementina Sasso, Roberto Susino, Giovanna Jerse, Michela Uslenghi, Maurizio Pancrazzi", "abstract": "As a key feature, NASA's Parker Solar Probe (PSP) and ESA-NASA's Solar\nOrbiter (SO) missions cooperate to trace solar wind and transients from their\nsources on the Sun to the inner interplanetary space. The goal of this work is\nto accurately reconstruct the interplanetary Parker spiral and the connection\nbetween coronal features observed remotely by the Metis coronagraph on-board SO\nand those detected in situ by PSP at the time of the first PSP-SO quadrature of\nJanuary 2021. We use the Reverse In-situ and MHD Approach (RIMAP), a hybrid\nanalytical-numerical method performing data-driven reconstructions of the\nParker spiral. RIMAP solves the MHD equations on the equatorial plane with the\nPLUTO code, using the measurements collected by PSP between 0.1 and 0.2 AU as\nboundary conditions. Our reconstruction connects density and wind speed\nmeasurements provided by Metis (3-6 solar radii) to those acquired by PSP (21.5\nsolar radii) along a single streamline. The capability of our MHD model to\nconnect the inner corona observed by Metis and the super Alfv\\'enic wind\nmeasured by PSP, not only confirms the research pathways provided by\nmulti-spacecraft observations, but also the validity and accuracy of RIMAP\nreconstructions as a possible test bench to verify models of transient\nphenomena propagating across the heliosphere, such as coronal mass ejections,\nsolar energetic particles and solar wind switchbacks.", "journal": "A&A 668, A144 (2022)", "doi": "10.1051/0004-6361/202244535", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.plasm-ph", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2211.12994v1"}
{"entry_id": "http://arxiv.org/abs/2012.12864v1", "date": "2020-12-12", "title": "High-Entropy Rare Earth Tetraborides", "authors": "Mingde Qin, Qizhang Yan, Haoren Wang, Kenneth S. Vecchio, Jian Luo", "abstract": "Six high-entropy rare earth tetraborides of the tetragonal UB4-prototyped\nstructure have been successfully synthesized for the first time. The specimens\nare prepared from elemental precursors via high-energy ball mill and in-situ\nreactive spark plasma sintering. The sintered specimens are >98% in relative\ndensities without detectable oxide impurities (albeit the presence of minor\nhexaborides in some compositions). No detectable secondary phase is observed in\nthe composition (Y$_{0.2}$Nd$_{0.2}$Sm$_{0.2}$Gd$_{0.2}$Tb$_{0.2}$)B$_{4}$,\nwhich is proven homogeneous at both microscale and nanoscale. The Vickers\nmicrohardness are determined to be ~13-15 GPa at a standard indentation load of\n9.8 N. A scientifically interesting observation is represented by the\nanisotropic lattice distortion from the rule-of-mixture averages. This work\nexpands the family of high-entropy ceramics via fabricating a new class of\nhigh-entropy borides with a unique tetragonal quasi-layered crystal structure.", "journal": "Journal of the European Ceramic Society (12/8/2020)", "doi": null, "primary_category": "cond-mat.mtrl-sci", "categories": ["cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/2012.12864v1"}
{"entry_id": "http://arxiv.org/abs/1405.6133v1", "date": "2014-02-05", "title": "A review over the applicability of image entropy in analyses of remote sensing datasets", "authors": "S. K. Katiyar, P. V. Arun", "abstract": "Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1405.6133v1"}
{"entry_id": "http://arxiv.org/abs/1706.06093v1", "date": "2017-06-18", "title": "Extraterrestrial sedimentary rocks on Earth", "authors": "Yana Anfinogenova, John Anfinogenov, Larisa Budaeva, Dmitry Kuznetsov", "abstract": "This concept article discusses the possibilities for identifying\nsedimentary-origin meteorites. The paper concerns (i) the macroscopic candidate\nfor sedimentary meteorite in the epicenter of the 1908 Tunguska catastrophe;\n(ii) potential parent bodies for sedimentary meteorites; (iii) isotopic\nheterogeneity of unmixed silicate reservoirs on Mars; (iv) possible terrestrial\nloss or contamination in the noble gas signatures in new type meteorites that\nspent time in extreme weather conditions; (v) cosmogenic isotopes and\nshielding; and (vi) pseudo meteorites. We conclude that the list of candidate\nparent bodies for sedimentary meteorites includes, but is not limited by the\nEarth, Mars, Enceladus, Ganymede, Europa, and hypothetical planets that could\nexist between orbits of Mars and Jupiter in the past. A parent body for\nextraterrestrial sedimentary rocks on the Earth should be identified based on\nthe entire body of evidence which is not limited solely by tests of oxygen and\nnoble gas isotopes whose signatures may undergo terrestrial contamination and\nmay exhibit significant heterogeneity within the parent bodies. Observed fall\nof cosmic body, evidence of hypervelocity impact complying with the criteria of\nimpact structures, and the presence of fusion crust on the fragments should be\nconsidered as priority signs of meteoritic origin.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1706.06093v1"}
{"entry_id": "http://arxiv.org/abs/2008.08775v1", "date": "2020-08-20", "title": "Spatial--spectral FFPNet: Attention-Based Pyramid Network for Segmentation and Classification of Remote Sensing Images", "authors": "Qingsong Xu, Xin Yuan, Chaojun Ouyang, Yue Zeng", "abstract": "We consider the problem of segmentation and classification of high-resolution\nand hyperspectral remote sensing images. Unlike conventional natural (RGB)\nimages, the inherent large scale and complex structures of remote sensing\nimages pose major challenges such as spatial object distribution diversity and\nspectral information extraction when existing models are directly applied for\nimage classification. In this study, we develop an attention-based pyramid\nnetwork for segmentation and classification of remote sensing datasets.\nAttention mechanisms are used to develop the following modules: i) a novel and\nrobust attention-based multi-scale fusion method effectively fuses useful\nspatial or spectral information at different and same scales; ii) a region\npyramid attention mechanism using region-based attention addresses the target\ngeometric size diversity in large-scale remote sensing images; and iii\ncross-scale attention} in our adaptive atrous spatial pyramid pooling network\nadapts to varied contents in a feature-embedded space. Different forms of\nfeature fusion pyramid frameworks are established by combining these\nattention-based modules. First, a novel segmentation framework, called the\nheavy-weight spatial feature fusion pyramid network (FFPNet), is proposed to\naddress the spatial problem of high-resolution remote sensing images. Second,\nan end-to-end spatial--spectral FFPNet is presented for classifying\nhyperspectral images. Experiments conducted on ISPRS Vaihingen and ISPRS\nPotsdam high-resolution datasets demonstrate the competitive segmentation\naccuracy achieved by the proposed heavy-weight spatial FFPNet. Furthermore,\nexperiments on the Indian Pines and the University of Pavia hyperspectral\ndatasets indicate that the proposed spatial--spectral FFPNet outperforms the\ncurrent state-of-the-art methods in hyperspectral image classification.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.08775v1"}
{"entry_id": "http://arxiv.org/abs/2110.04494v1", "date": "2021-10-09", "title": "SGMNet: Scene Graph Matching Network for Few-Shot Remote Sensing Scene Classification", "authors": "Baoquan Zhang, Shanshan Feng, Xutao Li, Yunming Ye, Rui Ye", "abstract": "Few-Shot Remote Sensing Scene Classification (FSRSSC) is an important task,\nwhich aims to recognize novel scene classes with few examples. Recently,\nseveral studies attempt to address the FSRSSC problem by following few-shot\nnatural image classification methods. These existing methods have made\npromising progress and achieved superior performance. However, they all\noverlook two unique characteristics of remote sensing images: (i) object\nco-occurrence that multiple objects tend to appear together in a scene image\nand (ii) object spatial correlation that these co-occurrence objects are\ndistributed in the scene image following some spatial structure patterns. Such\nunique characteristics are very beneficial for FSRSSC, which can effectively\nalleviate the scarcity issue of labeled remote sensing images since they can\nprovide more refined descriptions for each scene class. To fully exploit these\ncharacteristics, we propose a novel scene graph matching-based meta-learning\nframework for FSRSSC, called SGMNet. In this framework, a scene graph\nconstruction module is carefully designed to represent each test remote sensing\nimage or each scene class as a scene graph, where the nodes reflect these\nco-occurrence objects meanwhile the edges capture the spatial correlations\nbetween these co-occurrence objects. Then, a scene graph matching module is\nfurther developed to evaluate the similarity score between each test remote\nsensing image and each scene class. Finally, based on the similarity scores, we\nperform the scene class prediction via a nearest neighbor classifier. We\nconduct extensive experiments on UCMerced LandUse, WHU19, AID, and\nNWPU-RESISC45 datasets. The experimental results show that our method obtains\nsuperior performance over the previous state-of-the-art methods.", "journal": "", "doi": "10.1109/TGRS.2022.3200056", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2110.04494v1"}
{"entry_id": "http://arxiv.org/abs/1206.4344v1", "date": "2012-06-19", "title": "Glancing views of the Earth. From a lunar eclipse to an exoplanetary transit", "authors": "A. Garc\u00eda Mu\u00f1oz, M. R. Zapatero Osorio, R. Barrena, P. Monta\u00f1\u00e9s-Rodr\u00edguez, E. L. Mart\u00edn, E. Pall\u00e9", "abstract": "It has been posited that lunar eclipse observations may help predict the\nin-transit signature of Earth-like extrasolar planets. However, a comparative\nanalysis of the two phenomena addressing in detail the transport of stellar\nlight through the planet's atmosphere has not yet been presented. Here, we\nproceed with the investigation of both phenomena by making use of a common\nformulation. Our starting point is a set of previously unpublished\nnear-infrared spectra collected at various phases during the August 2008 lunar\neclipse. We then take the formulation to the limit of an infinitely distant\nobserver in order to investigate the in-transit signature of the Earth-Sun\nsystem as being observed from outside our Solar System. The refraction-bending\nof sunlight rays that pass through the Earth's atmosphere is a critical factor\nin the illumination of the eclipsed Moon. Likewise, refraction will have an\nimpact on the in-transit transmission spectrum for specific planet-star systems\ndepending on the refractive properties of the planet's atmosphere, the stellar\nsize and the planet's orbital distance. For the Earth-Sun system, at\nmid-transit, refraction prevents the remote observer's access to the lower\n~12-14 km of the atmosphere and, thus, also to the bulk of the\nspectroscopically-active atmospheric gases. We demonstrate that the effective\noptical radius of the Earth in transit is modulated by refraction and varies by\n~12 km from mid-transit to 2nd contact. The refractive nature of atmospheres, a\nproperty which is rarely accounted for in published investigations, will pose\nadditional challenges to the characterization of Earth-like extrasolar planets.\nRefraction may have a lesser impact for Earth-like extrasolar planets within\nthe habitable zone of some M-type stars.", "journal": "", "doi": "10.1088/0004-637X/755/2/103", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1206.4344v1"}
{"entry_id": "http://arxiv.org/abs/1705.10450v3", "date": "2017-05-30", "title": "RSI-CB: A Large Scale Remote Sensing Image Classification Benchmark via Crowdsource Data", "authors": "Haifeng Li, Xin Dou, Chao Tao, Zhixiang Hou, Jie Chen, Jian Peng, Min Deng, Ling Zhao", "abstract": "In recent years, deep convolutional neural network (DCNN) has seen a\nbreakthrough progress in natural image recognition because of three points:\nuniversal approximation ability via DCNN, large-scale database (such as\nImageNet), and supercomputing ability powered by GPU. The remote sensing field\nis still lacking a large-scale benchmark compared to ImageNet and Place2. In\nthis paper, we propose a remote sensing image classification benchmark (RSI-CB)\nbased on massive, scalable, and diverse crowdsource data. Using crowdsource\ndata, such as Open Street Map (OSM) data, ground objects in remote sensing\nimages can be annotated effectively by points of interest, vector data from\nOSM, or other crowdsource data. The annotated images can be used in remote\nsensing image classification tasks. Based on this method, we construct a\nworldwide large-scale benchmark for remote sensing image classification. This\nbenchmark has two sub-datasets with 256 by 256 and 128 by 128 sizes because\ndifferent DCNNs require different image sizes. The former contains 6 categories\nwith 35 subclasses of more than 24,000 images. The latter contains 6 categories\nwith 45 subclasses of more than 36,000 images. This classification system of\nground objects is defined according to the national standard of land-use\nclassification in China and is inspired by the hierarchy mechanism of ImageNet.\nFinally, we conduct many experiments to compare RSI-CB with the SAT-4, SAT-6,\nand UC-Merced datasets on handcrafted features, such as scale-invariant feature\ntransform, color histogram, local binary patterns, and GIST, and classical DCNN\nmodels, such as AlexNet, VGGNet, GoogLeNet, and ResNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1705.10450v3"}
{"entry_id": "http://arxiv.org/abs/1912.09618v1", "date": "2019-12-20", "title": "Remote coronal dimmings related to a circular-ribbon flare", "authors": "Q. M. Zhang, R. S. Zheng", "abstract": "In this paper, multiwavelength observations of remote coronal dimmings\nrelated to an M1.1 circular-ribbon flare (CRF) in active region (AR) 12434 are\nreported. The confined flare without a CME was observed by AIA and HMI on board\nSDO on 2015 October 16. Global three-dimensional (3D) magnetic fields before\nflare were obtained using the potential field source surface modeling. A few\nminutes before the flare hard X-ray peak time (06:13:48 UT), small-scale, weak\ndimming appeared $\\sim$240$\\arcsec$ away from the flare site, which can be\nobserved by AIA only in 131 and 171 {\\AA}. Afterwards, long and narrow dimmings\nbecame evident in all AIA EUV passbands except 304 {\\AA}, while localized core\ndimming was not clearly observed near the flare site. The large-area dimmings\nextended southeastward and the areas increased gradually. The total area of\ndimmings reaches (1.2$\\pm0.4$)$\\times$10$^4$ Mm$^2$ in 193 {\\AA}. The maximal\nrelative intensity decreases in 171 and 193 {\\AA} reach 90\\% and 80\\%,\nrespectively. Subsequently, the dimmings began to replenish and the area\ndecreased slowly, lasting for $\\geq$3 hr. The remote dimmings and AR 12434 were\nconnected by large-scale coronal loops. The remote dimmings were associated\nwith the southwest footpoints of coronal loops with weak negative polarities.\nPossible origins of remote dimmings are discussed.", "journal": "A&A 633, A142 (2020)", "doi": "10.1051/0004-6361/201937126", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1912.09618v1"}
{"entry_id": "http://arxiv.org/abs/1909.03377v3", "date": "2019-09-08", "title": "Ultra-broadband local active noise control with remote acoustic sensing", "authors": "Tong Xiao, Xiaojun Qiu, Benjamin Halkon", "abstract": "One enduring challenge for controlling high frequency sound in local active\nnoise control (ANC) systems is to obtain the acoustic signal at the specific\nlocation to be controlled. In some applications such as in ANC headrest\nsystems, it is not practical to install error microphones in a person's ears to\nprovide the user a quiet or optimally acoustically controlled environment. Many\nvirtual error sensing approaches have been proposed to estimate the acoustic\nsignal remotely with the current state-of-the-art method using an array of four\nmicrophones and a head tracking system to yield sound reduction up to 1 kHz for\na single sound source. In the work reported in this paper, a novel approach of\nincorporating remote acoustic sensing using a laser Doppler vibrometer into an\nANC headrest system is investigated. In this 'virtual ANC headphone' system, a\nlightweight retro-reflective membrane pick-up is mounted in each synthetic ear\nof a head and torso simulator to determine the sound in the ear in real-time\nwith minimal invasiveness. The membrane design and the effects of its location\non the system performance are explored, the noise spectra in the ears without\nand with ANC for a variety of relevant primary sound fields are reported, and\nthe performance of the system during head movements is demonstrated. The test\nresults show that at least 10 dB sound attenuation can be realised in the ears\nover an extended frequency range from (500 Hz to 6 kHz) under a complex sound\nfield and for several common types of synthesised environmental noise, even in\nthe presence of head motion.", "journal": "Sci. Rep. 10 (2020)", "doi": "10.1038/s41598-020-77614-w", "primary_category": "eess.SY", "categories": ["eess.SY", "cs.SD", "cs.SY", "eess.AS", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/1909.03377v3"}
{"entry_id": "http://arxiv.org/abs/2209.05760v1", "date": "2022-09-13", "title": "CME Evolution in the Structured Heliosphere and Effects at Earth and Mars During Solar Minimum", "authors": "Erika Palmerio, Christina O. Lee, Ian G. Richardson, Teresa Nieves-Chinchilla, Luiz F. G. Dos Santos, Jacob R. Gruesbeck, Nariaki V. Nitta, M. Leila Mays, Jasper S. Halekas, Cary Zeitlin, Shaosui Xu, Mats Holmstr\u00f6m, Yoshifumi Futaana, Tamitha Mulligan, Benjamin J. Lynch, Janet G. Luhmann", "abstract": "The activity of the Sun alternates between a solar minimum and a solar\nmaximum, the former corresponding to a period of \"quieter\" status of the\nheliosphere. During solar minimum, it is in principle more straightforward to\nfollow eruptive events and solar wind structures from their birth at the Sun\nthroughout their interplanetary journey. In this paper, we report analysis of\nthe origin, evolution, and heliospheric impact of a series of solar transient\nevents that took place during the second half of August 2018, i.e. in the midst\nof the late declining phase of Solar Cycle 24. In particular, we focus on two\nsuccessive coronal mass ejections (CMEs) and a following high-speed stream\n(HSS) on their way towards Earth and Mars. We find that the first CME impacted\nboth planets, whilst the second caused a strong magnetic storm at Earth and\nwent on to miss Mars, which nevertheless experienced space weather effects from\nthe stream interacting region (SIR) preceding the HSS. Analysis of\nremote-sensing and in-situ data supported by heliospheric modelling suggests\nthat CME--HSS interaction resulted in the second CME rotating and deflecting in\ninterplanetary space, highlighting that accurately reproducing the ambient\nsolar wind is crucial even during \"simpler\" solar minimum periods. Lastly, we\ndiscuss the upstream solar wind conditions and transient structures responsible\nfor driving space weather effects at Earth and Mars.", "journal": "", "doi": "10.1029/2022SW003215", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "astro-ph.EP", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2209.05760v1"}
{"entry_id": "http://arxiv.org/abs/1511.08131v1", "date": "2015-11-25", "title": "Unsupervised Deep Feature Extraction for Remote Sensing Image Classification", "authors": "Adriana Romero, Carlo Gatta, Gustau Camps-Valls", "abstract": "This paper introduces the use of single layer and deep convolutional networks\nfor remote sensing data analysis. Direct application to multi- and\nhyper-spectral imagery of supervised (shallow or deep) convolutional networks\nis very challenging given the high input data dimensionality and the relatively\nsmall amount of available labeled data. Therefore, we propose the use of greedy\nlayer-wise unsupervised pre-training coupled with a highly efficient algorithm\nfor unsupervised learning of sparse features. The algorithm is rooted on sparse\nrepresentations and enforces both population and lifetime sparsity of the\nextracted features, simultaneously. We successfully illustrate the expressive\npower of the extracted representations in several scenarios: classification of\naerial scenes, as well as land-use classification in very high resolution\n(VHR), or land-cover classification from multi- and hyper-spectral images. The\nproposed algorithm clearly outperforms standard Principal Component Analysis\n(PCA) and its kernel counterpart (kPCA), as well as current state-of-the-art\nalgorithms of aerial classification, while being extremely computationally\nefficient at learning representations of data. Results show that single layer\nconvolutional networks can extract powerful discriminative features only when\nthe receptive field accounts for neighboring pixels, and are preferred when the\nclassification requires high resolution and detailed results. However, deep\narchitectures significantly outperform single layers variants, capturing\nincreasing levels of abstraction and complexity throughout the feature\nhierarchy.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, Volume:PP ,\n  Issue: 99, 2015", "doi": "10.1109/TGRS.2015.2478379", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1511.08131v1"}
{"entry_id": "http://arxiv.org/abs/1806.05824v1", "date": "2018-06-15", "title": "Three dimensional Deep Learning approach for remote sensing image classification", "authors": "Amina Ben Hamida, A Benoit, Patrick Lambert, Chokri Ben Amar", "abstract": "Recently, a variety of approaches has been enriching the field of Remote\nSensing (RS) image processing and analysis. Unfortunately, existing methods\nremain limited faced to the rich spatio-spectral content of today's large\ndatasets. It would seem intriguing to resort to Deep Learning (DL) based\napproaches at this stage with regards to their ability to offer accurate\nsemantic interpretation of the data. However, the specificity introduced by the\ncoexistence of spectral and spatial content in the RS datasets widens the scope\nof the challenges presented to adapt DL methods to these contexts. Therefore,\nthe aim of this paper is firstly to explore the performance of DL architectures\nfor the RS hyperspectral dataset classification and secondly to introduce a new\nthree-dimensional DL approach that enables a joint spectral and spatial\ninformation process. A set of three-dimensional schemes is proposed and\nevaluated. Experimental results based on well knownhyperspectral datasets\ndemonstrate that the proposed method is able to achieve a better classification\nrate than state of the art methods with lower computational costs.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, Institute of\n  Electrical and Electronics Engineers, 2018, pp.1 - 15", "doi": "10.1109/TGRS.2018.2818945", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1806.05824v1"}
{"entry_id": "http://arxiv.org/abs/2103.15463v2", "date": "2021-03-29", "title": "A Hierarchical Approach to Remote Sensing Scene Classification", "authors": "Ozlem Sen, Hacer Yalim Keles", "abstract": "Remote sensing scene classification deals with the problem of classifying\nland use/cover of a region from images. To predict the development and\nsocioeconomic structures of cities, the status of land use in regions is\ntracked by the national mapping agencies of countries. Many of these agencies\nuse land-use types that are arranged in multiple levels. In this paper, we\nexamined the efficiency of a hierarchically designed Convolutional Neural\nNetwork (CNN) based framework that is suitable for such arrangements. We use\nthe NWPU-RESISC45 dataset for our experiments and arranged this data set in a\ntwo-level nested hierarchy. Each node in the designed hierarchy is trained\nusing DenseNet-121 architectures. We provide detailed empirical analysis to\ncompare the performances of this hierarchical scheme and its non-hierarchical\ncounterpart, together with the individual model performances. We also evaluated\nthe performance of the hierarchical structure statistically to validate the\npresented empirical results. The results of our experiments show that although\nindividual classifiers for different sub-categories in the hierarchical scheme\nperform considerably well, the accumulation of the classification errors in the\ncascaded structure prevents its classification performance from exceeding that\nof the non-hierarchical deep model", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2103.15463v2"}
{"entry_id": "http://arxiv.org/abs/2104.07803v1", "date": "2021-04-15", "title": "Semisupervised Manifold Alignment of Multimodal Remote Sensing Images", "authors": "Devis Tuia, Michele Volpi, Maxime Trolliet, Gustau Camps-Valls", "abstract": "We introduce a method for manifold alignment of different modalities (or\ndomains) of remote sensing images. The problem is recurrent when a set of\nmultitemporal, multisource, multisensor and multiangular images is available.\nIn these situations, images should ideally be spatially coregistred, corrected\nand compensated for differences in the image domains. Such procedures require\nthe interaction of the user, involve tuning of many parameters and heuristics,\nand are usually applied separately. Changes of sensors and acquisition\nconditions translate into shifts, twists, warps and foldings of the image\ndistributions (or manifolds). The proposed semisupervised manifold alignment\n(SS-MA) method aligns the images working directly on their manifolds, and is\nthus not restricted to images of the same resolutions, either spectral or\nspatial. SS-MA pulls close together samples of the same class while pushing\nthose of different classes apart. At the same time, it preserves the geometry\nof each manifold along the transformation. The method builds a linear\ninvertible transformation to a latent space where all images are alike, and\nreduces to solving a generalized eigenproblem of moderate size. We study the\nperformance of SS-MA in toy examples and in real multiangular, multitemporal,\nand multisource image classification problems. The method performs well for\nstrong deformations and leads to accurate classification for all domains.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, 52(12): 7708 -\n  7720, 2014", "doi": "10.1109/TGRS.2014.2317499", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2104.07803v1"}
{"entry_id": "http://arxiv.org/abs/2208.03987v4", "date": "2022-08-08", "title": "Advancing Plain Vision Transformer Towards Remote Sensing Foundation Model", "authors": "Di Wang, Qiming Zhang, Yufei Xu, Jing Zhang, Bo Du, Dacheng Tao, Liangpei Zhang", "abstract": "Large-scale vision foundation models have made significant progress in visual\ntasks on natural images, with vision transformers being the primary choice due\nto their good scalability and representation ability. However, large-scale\nmodels in remote sensing (RS) have not yet been sufficiently explored. In this\npaper, we resort to plain vision transformers with about 100 million parameters\nand make the first attempt to propose large vision models tailored to RS tasks\nand investigate how such large models perform. To handle the large sizes and\nobjects of arbitrary orientations in RS images, we propose a new rotated\nvaried-size window attention to replace the original full attention in\ntransformers, which can significantly reduce the computational cost and memory\nfootprint while learning better object representation by extracting rich\ncontext from the generated diverse windows. Experiments on detection tasks show\nthe superiority of our model over all state-of-the-art models, achieving 81.24%\nmAP on the DOTA-V1.0 dataset. The results of our models on downstream\nclassification and segmentation tasks also show competitive performance\ncompared to existing advanced methods. Further experiments show the advantages\nof our models in terms of computational complexity and data efficiency in\ntransferring.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2208.03987v4"}
{"entry_id": "http://arxiv.org/abs/2209.07709v1", "date": "2022-09-16", "title": "LO-Det: Lightweight Oriented Object Detection in Remote Sensing Images", "authors": "Zhanchao Huang, Wei Li, Xiang-Gen Xia, Hao Wang, Feiran Jie, Ran Tao", "abstract": "A few lightweight convolutional neural network (CNN) models have been\nrecently designed for remote sensing object detection (RSOD). However, most of\nthem simply replace vanilla convolutions with stacked separable convolutions,\nwhich may not be efficient due to a lot of precision losses and may not be able\nto detect oriented bounding boxes (OBB). Also, the existing OBB detection\nmethods are difficult to constrain the shape of objects predicted by CNNs\naccurately. In this paper, we propose an effective lightweight oriented object\ndetector (LO-Det). Specifically, a channel separation-aggregation (CSA)\nstructure is designed to simplify the complexity of stacked separable\nconvolutions, and a dynamic receptive field (DRF) mechanism is developed to\nmaintain high accuracy by customizing the convolution kernel and its perception\nrange dynamically when reducing the network complexity. The CSA-DRF component\noptimizes efficiency while maintaining high accuracy. Then, a diagonal support\nconstraint head (DSC-Head) component is designed to detect OBBs and constrain\ntheir shapes more accurately and stably. Extensive experiments on public\ndatasets demonstrate that the proposed LO-Det can run very fast even on\nembedded devices with the competitive accuracy of detecting oriented objects.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, 2022", "doi": "10.1109/TGRS.2021.3067470", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2209.07709v1"}
{"entry_id": "http://arxiv.org/abs/1611.07175v2", "date": "2016-11-22", "title": "Optimal Local and Remote Controllers with Unreliable Uplink Channels", "authors": "Seyed Mohammad Asghari, Yi Ouyang, Ashutosh Nayyar", "abstract": "We consider a networked control system consisting of a remote controller and\na collection of linear plants, each associated with a local controller. Each\nlocal controller directly observes the state of its co-located plant and can\ninform the remote controller of the plant's state through an unreliable uplink\nchannel. We assume that the downlink channels from the remote controller to\nlocal controllers are perfect. The objective of the local controllers and the\nremote controller is to cooperatively minimize a quadratic performance cost. We\nprovide a dynamic program for this decentralized control problem using the\ncommon information approach. Although our problem is not a partially nested\nproblem, we obtain explicit optimal strategies for all controllers. In the\noptimal strategies, all controllers compute common estimates of the states of\nthe plants based on the common information obtained from the communication\nnetwork. The remote controller's action is linear in the common state\nestimates, and the action of each local controller is linear in both the actual\nstate of its co-located plant and the common state estimates. We illustrate our\nresults with numerical experiments using randomly generated models.", "journal": "", "doi": null, "primary_category": "cs.SY", "categories": ["cs.SY"], "pdf_url": "http://arxiv.org/pdf/1611.07175v2"}
{"entry_id": "http://arxiv.org/abs/1802.06183v1", "date": "2018-02-17", "title": "Towards Realisation of Heterogeneous Earth-Observation Sensor Database Framework for the Sensor Observation Service based on PostGIS", "authors": "Maduako N. Ikechukwu, Francis I. Okeke", "abstract": "Environmental monitoring and management systems in most cases deal with\nmodels and spatial analytics that involve the integration of in-situ and remote\nGeosensor observations. In-situ sensor observations and those gathered by\nremote sensors are usually provided by different databases and services in\nreal-time dynamic services such as the Geo-Web Services. Thus, data have to be\npulled from different databases and transferred over the network before they\nare fused and processed on the service middleware. This process is very massive\nand unnecessary communication-work load on the service middleware. Massive work\nload in large raster downloads from flat-file raster data sources each time a\nrequest is made and huge integration and geo-processing work load on the\nservice middleware which could actually be better leveraged at the database\nThis paper therefore proposes the realization of heterogeneous sensor database\nframework based on PostGIS for integration, geo-processing and spatial analysis\nof remote and in-situ sensor observations at the database level. Also discussed\nin this paper is how the framework can be integrated in the Sensor Observation\nService (SOS) to reduce communication and massive workload on the Geospatial\nWeb Services and as well make query request from the user end a lot more\nflexible. Keywords: Earth-Observation, Heterogeneous Earth-Observation Sensor\nDatabase, PostGIS , Sensor Observation Service.", "journal": "", "doi": null, "primary_category": "cs.DB", "categories": ["cs.DB"], "pdf_url": "http://arxiv.org/pdf/1802.06183v1"}
{"entry_id": "http://arxiv.org/abs/2203.02270v1", "date": "2022-03-04", "title": "Feature Transformation for Cross-domain Few-shot Remote Sensing Scene Classification", "authors": "Qiaoling Chen, Zhihao Chen, Wei Luo", "abstract": "Effectively classifying remote sensing scenes is still a challenge due to the\nincreasing spatial resolution of remote imaging and large variances between\nremote sensing images. Existing research has greatly improved the performance\nof remote sensing scene classification (RSSC). However, these methods are not\napplicable to cross-domain few-shot problems where target domain is with very\nlimited training samples available and has a different data distribution from\nsource domain. To improve the model's applicability, we propose the\nfeature-wise transformation module (FTM) in this paper. FTM transfers the\nfeature distribution learned on source domain to that of target domain by a\nvery simple affine operation with negligible additional parameters. Moreover,\nFTM can be effectively learned on target domain in the case of few training\ndata available and is agnostic to specific network structures. Experiments on\nRSSC and land-cover mapping tasks verified its capability to handle\ncross-domain few-shot problems. By comparison with directly finetuning, FTM\nachieves better performance and possesses better transferability and\nfine-grained discriminability. \\textit{Code will be publicly available.}", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2203.02270v1"}
{"entry_id": "http://arxiv.org/abs/2007.10636v1", "date": "2020-07-21", "title": "Effects of localized source currents on magnetotelluric responses of a flat earth and spherical earth", "authors": "Shinya Sato", "abstract": "Shifts in magnetotelluric (MT) responses owing to localized source currents\nshould be considered when visualizing deep subsurface resistivity structures\nsuch as the earth mantle. The earth is not flat but spherical; nevertheless,\nnon-uniform geomagnetic temporal variations arising from localized source\ncurrents are evaluated on the basis of components in a Cartesian coordinate\nsystem. To address this issue, this study assesses the difference in source\nbias within MT responses of a flat earth and spherical earth. Apparent\nresistivity and phases are calculated by setting the time period and\nconductivity of the earth interior to 200/2000 s and 0.001 S/m, respectively,\nand by changing the vertical and horizontal distances between the source\ncurrent and an observation station. A deviation in the biased MT responses of\nthe flat earth and spherical earth is not observed although both shift strongly\nfrom the true values. We can thus treat the source bias in a Cartesian\ncoordinate system although it originally arises in a spherical coordinate\nsystem.", "journal": "", "doi": null, "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "86A25"], "pdf_url": "http://arxiv.org/pdf/2007.10636v1"}
{"entry_id": "http://arxiv.org/abs/1909.11757v1", "date": "2019-08-30", "title": "Living Structure Down to Earth and Up to Heaven: Christopher Alexander", "authors": "Bin Jiang", "abstract": "Discovered by Christopher Alexander, living structure is a physical\nphenomenon, through which the quality of the built environment or artifacts can\nbe judged objectively. It bears two distinguished properties just like a tree:\n\"far more small things than large ones\" across all scales, and \"more or less\nsimilar things\" on each scale. As a physical phenomenon, and mathematical\nconcept, living structure is essentially empirical, discovered and developed\nfrom miniscule observation in nature- and human-made things, and it affects our\ndaily lives in some substantial ways, such as where to put a table or a flower\nvase in a room, helping us to make beautiful things and environments. Living\nstructure is not only empirical, but also philosophical and visionary, enabling\nus to see the world and space in more meaningful ways. This paper is intended\nto defend living structure as a physical phenomenon, clarifying some common\nquestions and misgivings surrounding Alexander's design thoughts, such as the\nobjective or structural nature of beauty, building styles advocated by\nAlexander, and mysterious nature of his concepts. We first illustrate living\nstructure - essentially organized complexity, as advocated by the late Jane\nJacobs (1916-2006) - that is governed by two fundamental laws (scaling law and\nTobler's law), and generated in some step by step fashion by two design\nprinciples (differentiation and adaptation) through the 15 structural\nproperties. We then verify why living structure is primarily empirical, drawing\nevidence from Alexander's own work, as well as our case studies applied to the\nEarth's surface including cities, streets, and buildings, and two logos. Before\nreaching conclusions, we concentrate on the most mysterious part of Alexander's\nwork - the hypothesized \"I\" - as a substance that pervasively exists\neverywhere, in order to make better sense of living structure in our minds.", "journal": "Urban Science, https://www.mdpi.com/2413-8851/3/3/96, 2019", "doi": "10.3390/urbansci3030096", "primary_category": "physics.soc-ph", "categories": ["physics.soc-ph"], "pdf_url": "http://arxiv.org/pdf/1909.11757v1"}
{"entry_id": "http://arxiv.org/abs/1909.13331v1", "date": "2019-09-29", "title": "Comet 66P/du Toit: not a near Earth main belt comet", "authors": "B. Yang, E. Jehin, F. J. Pozuelos, Y. Moulane, Y. Shinnaka, C. Opitom, H. H. Hsieh, D. Hutsem\u00e9kers, J. Manfroid", "abstract": "Main belt comets (MBCs) are a peculiar class of volatile-containing objects\nwith comet-like morphology and asteroid-like orbits. However, MBCs are\nchallenging targets to study remotely due to their small sizes and the\nrelatively large distance they are from the Sun and the Earth. Recently, a\nnumber of weakly active short-period comets have been identified that might\noriginate in the asteroid main belt. Among all of the known candidates, comet\n66P/du Toit has been suggested to have one of the highest probabilities of\ncoming from the main belt. We obtained medium and high-resolution spectra of\n66P from 300-2500 nm with the X-shooter/VLT and the UVES/VLT instruments in\nJuly 2018. We also obtained a series of narrow-band images of 66P to monitor\nthe gas and dust activity between May and July 2018 with TRAPPIST-South. In\naddition, we applied a dust model to characterize the dust coma of 66P and\nperformed dynamical simulations to study the orbital evolution of 66P. We\nderive the OPR of ammonia (NH$_3$) in 66P to be 1.08$\\pm$0.06, which\ncorresponds to a nuclear spin temperature of $\\sim$34 K. We computed the\nproduction rates of OH, NH, CN, C$_3,$ and C$_2$ radicals and measured the dust\nproxy, Af$\\rho$. The dust analysis reveals that the coma can be best-fit with\nan anisotropic model and the peak dust production rate is about 55 kg s$^{-1}$\nat the perihelion distance of 1.29 au. Dynamical simulations show that 66P is\nmoderately asteroidal with the capture time, t$_{cap} \\sim 10^4$ yr. Our\nobservations demonstrate that the measured physical properties of 66P are\nconsistent with other typical short-period comets and differ significantly from\nother MBCs. Therefore, 66P is unlikely to have a main belt origin.", "journal": "A&A 631, A168 (2019)", "doi": "10.1051/0004-6361/201936469", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1909.13331v1"}
{"entry_id": "http://arxiv.org/abs/1311.7033v4", "date": "2013-11-27", "title": "Mobile and remote inertial sensing with atom interferometers", "authors": "B. Barrett, P. -A. Gominet, E. Cantin, L. Antoni-Micollier, A. Bertoldi, B. Battelier, P. Bouyer, J. Lautier, A. Landragin", "abstract": "The past three decades have shown dramatic progress in the ability to\nmanipulate and coherently control the motion of atoms. This exquisite control\noffers the prospect of a new generation of inertial sensors with unprecedented\nsensitivity and accuracy, which will be important for both fundamental and\napplied science. In this article, we review some of our recent results\nregarding the application of atom interferometry to inertial measurements using\ncompact, mobile sensors. This includes some of the first interferometer\nmeasurements with cold $^{39}$K atoms, which is a major step toward achieving a\ntransportable, dual-species interferometer with rubidium and potassium for\nequivalence principle tests. We also discuss future applications of this\ntechnology, such as remote sensing of geophysical effects, gravitational wave\ndetection, and precise tests of the weak equivalence principle in Space.", "journal": "Proceedings of the International School of Physics \"Enrico Fermi\",\n  Volume 188: Atom Interferometry, pp. 493-555 (2014)", "doi": "10.3254/978-1-61499-448-0-493", "primary_category": "physics.atom-ph", "categories": ["physics.atom-ph", "physics.geo-ph", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1311.7033v4"}
{"entry_id": "http://arxiv.org/abs/2006.05180v1", "date": "2020-06-09", "title": "Breaking the Limits of Remote Sensing by Simulation and Deep Learning for Flood and Debris Flow Mapping", "authors": "Naoto Yokoya, Kazuki Yamanoi, Wei He, Gerald Baier, Bruno Adriano, Hiroyuki Miura, Satoru Oishi", "abstract": "We propose a framework that estimates inundation depth (maximum water level)\nand debris-flow-induced topographic deformation from remote sensing imagery by\nintegrating deep learning and numerical simulation. A water and debris flow\nsimulator generates training data for various artificial disaster scenarios. We\nshow that regression models based on Attention U-Net and LinkNet architectures\ntrained on such synthetic data can predict the maximum water level and\ntopographic deformation from a remote sensing-derived change detection map and\na digital elevation model. The proposed framework has an inpainting capability,\nthus mitigating the false negatives that are inevitable in remote sensing image\nanalysis. Our framework breaks the limits of remote sensing and enables rapid\nestimation of inundation depth and topographic deformation, essential\ninformation for emergency response, including rescue and relief activities. We\nconduct experiments with both synthetic and real data for two disaster events\nthat caused simultaneous flooding and debris flows and demonstrate the\neffectiveness of our approach quantitatively and qualitatively.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2006.05180v1"}
{"entry_id": "http://arxiv.org/abs/1902.05818v1", "date": "2019-02-15", "title": "Enhancing Remote Sensing Image Retrieval with Triplet Deep Metric Learning Network", "authors": "Rui Cao, Qian Zhang, Jiasong Zhu, Qing Li, Qingquan Li, Bozhi Liu, Guoping Qiu", "abstract": "With the rapid growing of remotely sensed imagery data, there is a high\ndemand for effective and efficient image retrieval tools to manage and exploit\nsuch data. In this letter, we present a novel content-based remote sensing\nimage retrieval method based on Triplet deep metric learning convolutional\nneural network (CNN). By constructing a Triplet network with metric learning\nobjective function, we extract the representative features of the images in a\nsemantic space in which images from the same class are close to each other\nwhile those from different classes are far apart. In such a semantic space,\nsimple metric measures such as Euclidean distance can be used directly to\ncompare the similarity of images and effectively retrieve images of the same\nclass. We also investigate a supervised and an unsupervised learning methods\nfor reducing the dimensionality of the learned semantic features. We present\ncomprehensive experimental results on two publicly available remote sensing\nimage retrieval datasets and show that our method significantly outperforms\nstate-of-the-art.", "journal": "International Journal of Remote Sensing, 2020, Vol. 41, No. 2, pp.\n  740-751", "doi": "10.1080/2150704X.2019.1647368", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1902.05818v1"}
{"entry_id": "http://arxiv.org/abs/1105.1140v2", "date": "2011-05-05", "title": "Earth's Energy Imbalance and Implications", "authors": "James Hansen, Makiko Sato, Pushker Kharecha, Karina von Schuckmann", "abstract": "Improving observations of ocean heat content show that Earth is absorbing\nmore energy from the sun than it is radiating to space as heat, even during the\nrecent solar minimum. The inferred planetary energy imbalance, 0.59 \\pm 0.15\nW/m2 during the 6-year period 2005-2010, confirms the dominant role of the\nhuman-made greenhouse effect in driving global climate change. Observed surface\ntemperature change and ocean heat gain together constrain the net climate\nforcing and ocean mixing rates. We conclude that most climate models mix heat\ntoo efficiently into the deep ocean and as a result underestimate the negative\nforcing by human-made aerosols. Aerosol climate forcing today is inferred to be\n1.6 \\pm 0.3 W/m2, implying substantial aerosol indirect climate forcing via\ncloud changes. Continued failure to quantify the specific origins of this large\nforcing is untenable, as knowledge of changing aerosol effects is needed to\nunderstand future climate change. We conclude that recent slowdown of ocean\nheat uptake was caused by a delayed rebound effect from Mount Pinatubo aerosols\nand a deep prolonged solar minimum. Observed sea level rise during the Argo\nfloat era is readily accounted for by ice melt and ocean thermal expansion, but\nthe ascendency of ice melt leads us to anticipate acceleration of the rate of\nsea level rise this decade.", "journal": "Atmos. Chem. Phys., 11 (2011), 13421-13449", "doi": "10.5194/acp-11-13421-2011", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1105.1140v2"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0305337v1", "date": "2003-05-19", "title": "The Search for Extrasolar Earth-like planets", "authors": "S. Seager", "abstract": "The search for extrasolar Earth-like planets is underway. Over 100 extrasolar\ngiant planets are known to orbit nearby sun-like stars, including several in\nmultiple-planet systems. These planetary systems are stepping stones for the\nsearch for Earth-like planets; the technology development, observational\nstrategies, and science results can all be applied to Earth-like planets. Stars\nmuch less massive than the sun the most common stars in our Galaxy are being\nmonitored for the gravitational influence of Earth-like planets. Although\nEarth-like planets orbiting sun-like stars are much more difficult to detect,\nspace missions are being built to detect them indirectly due to their effects\non the parent star and to quantify fundamental factors such as terrestrial\nplanet frequency, size distribution, and mass distribution. Extremely ambitious\nspace programs are being developed to directly detect Earth-like planets\norbiting sun-like stars, and must tackle the immense technological challenge of\nblocking out the light of the parent star, which is brighter than the planet by\nsix to ten orders of magnitude. Direct detection of radiation from the planet\nis necessary for the definitive goal of the search for Earth-like planets: the\nstudy of atmospheric spectral signatures for signs of severe disequilibrium\nchemistry that could be indicative of biological activity. In addition to\ntechnological development, a growing flurry of scientific activity has begun\nto: understand terrestrial planet formation and terrestrial planet frequency;\nmodel terrestrial-like planet atmospheres and evolution; articulate the\nbiological signatures of our own Earth; and even to study Earth as an\nextrasolar planet by observation and analysis of the spatially unresolved\nEarth.", "journal": "Earth Planet.Sci.Lett. 208 (2003) 113-124", "doi": "10.1016/S0012-821X(02)01151-2", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0305337v1"}
{"entry_id": "http://arxiv.org/abs/1706.03424v2", "date": "2017-06-11", "title": "PatternNet: A Benchmark Dataset for Performance Evaluation of Remote Sensing Image Retrieval", "authors": "Weixun Zhou, Shawn Newsam, Congmin Li, Zhenfeng Shao", "abstract": "Remote sensing image retrieval(RSIR), which aims to efficiently retrieve data\nof interest from large collections of remote sensing data, is a fundamental\ntask in remote sensing. Over the past several decades, there has been\nsignificant effort to extract powerful feature representations for this task\nsince the retrieval performance depends on the representative strength of the\nfeatures. Benchmark datasets are also critical for developing, evaluating, and\ncomparing RSIR approaches. Current benchmark datasets are deficient in that 1)\nthey were originally collected for land use/land cover classification and not\nimage retrieval, 2) they are relatively small in terms of the number of classes\nas well the number of sample images per class, and 3) the retrieval performance\nhas saturated. These limitations have severely restricted the development of\nnovel feature representations for RSIR, particularly the recent deep-learning\nbased features which require large amounts of training data. We therefore\npresent in this paper, a new large-scale remote sensing dataset termed\n\"PatternNet\" that was collected specifically for RSIR. PatternNet was collected\nfrom high-resolution imagery and contains 38 classes with 800 images per class.\nWe also provide a thorough review of RSIR approaches ranging from traditional\nhandcrafted feature based methods to recent deep learning based ones. We\nevaluate over 35 methods to establish extensive baseline results for future\nRSIR research using the PatternNet benchmark.", "journal": "", "doi": "10.1016/j.isprsjprs.2018.01.004", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1706.03424v2"}
{"entry_id": "http://arxiv.org/abs/1909.04614v1", "date": "2019-09-10", "title": "Deep Hashing Learning for Visual and Semantic Retrieval of Remote Sensing Images", "authors": "Weiwei Song, Shutao Li, Jon Atli Benediktsson", "abstract": "Driven by the urgent demand for managing remote sensing big data, large-scale\nremote sensing image retrieval (RSIR) attracts increasing attention in the\nremote sensing field. In general, existing retrieval methods can be regarded as\nvisual-based retrieval approaches which search and return a set of similar\nimages from a database to a given query image. Although retrieval methods have\nachieved great success, there is still a question that needs to be responded\nto: Can we obtain the accurate semantic labels of the returned similar images\nto further help analyzing and processing imagery? Inspired by the above\nquestion, in this paper, we redefine the image retrieval problem as visual and\nsemantic retrieval of images. Specifically, we propose a novel deep hashing\nconvolutional neural network (DHCNN) to simultaneously retrieve the similar\nimages and classify their semantic labels in a unified framework. In more\ndetail, a convolutional neural network (CNN) is used to extract\nhigh-dimensional deep features. Then, a hash layer is perfectly inserted into\nthe network to transfer the deep features into compact hash codes. In addition,\na fully connected layer with a softmax function is performed on hash layer to\ngenerate class distribution. Finally, a loss function is elaborately designed\nto simultaneously consider the label loss of each image and similarity loss of\npairs of images. Experimental results on two remote sensing datasets\ndemonstrate that the proposed method achieves the state-of-art retrieval and\nclassification performance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1909.04614v1"}
{"entry_id": "http://arxiv.org/abs/2010.00243v1", "date": "2020-10-01", "title": "MLRSNet: A Multi-label High Spatial Resolution Remote Sensing Dataset for Semantic Scene Understanding", "authors": "Xiaoman Qi, PanPan Zhu, Yuebin Wang, Liqiang Zhang, Junhuan Peng, Mengfan Wu, Jialong Chen, Xudong Zhao, Ning Zang, P. Takis Mathiopoulos", "abstract": "To better understand scene images in the field of remote sensing, multi-label\nannotation of scene images is necessary. Moreover, to enhance the performance\nof deep learning models for dealing with semantic scene understanding tasks, it\nis vital to train them on large-scale annotated data. However, most existing\ndatasets are annotated by a single label, which cannot describe the complex\nremote sensing images well because scene images might have multiple land cover\nclasses. Few multi-label high spatial resolution remote sensing datasets have\nbeen developed to train deep learning models for multi-label based tasks, such\nas scene classification and image retrieval. To address this issue, in this\npaper, we construct a multi-label high spatial resolution remote sensing\ndataset named MLRSNet for semantic scene understanding with deep learning from\nthe overhead perspective. It is composed of high-resolution optical satellite\nor aerial images. MLRSNet contains a total of 109,161 samples within 46 scene\ncategories, and each image has at least one of 60 predefined labels. We have\ndesigned visual recognition tasks, including multi-label based image\nclassification and image retrieval, in which a wide variety of deep learning\napproaches are evaluated with MLRSNet. The experimental results demonstrate\nthat MLRSNet is a significant benchmark for future research, and it complements\nthe current widely used datasets such as ImageNet, which fills gaps in\nmulti-label image research. Furthermore, we will continue to expand the\nMLRSNet. MLRSNet and all related materials have been made publicly available at\nhttps://data.mendeley.com/datasets/7j9bv9vwsx/2 and\nhttps://github.com/cugbrs/MLRSNet.git.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2010.00243v1"}
{"entry_id": "http://arxiv.org/abs/2111.03690v3", "date": "2021-11-05", "title": "Do we still need ImageNet pre-training in remote sensing scene classification?", "authors": "Vladimir Risojevi\u0107, Vladan Stojni\u0107", "abstract": "Due to the scarcity of labeled data, using supervised models pre-trained on\nImageNet is a de facto standard in remote sensing scene classification.\nRecently, the availability of larger high resolution remote sensing (HRRS)\nimage datasets and progress in self-supervised learning have brought up the\nquestions of whether supervised ImageNet pre-training is still necessary for\nremote sensing scene classification and would supervised pre-training on HRRS\nimage datasets or self-supervised pre-training on ImageNet achieve better\nresults on target remote sensing scene classification tasks. To answer these\nquestions, in this paper we both train models from scratch and fine-tune\nsupervised and self-supervised ImageNet models on several HRRS image datasets.\nWe also evaluate the transferability of learned representations to HRRS scene\nclassification tasks and show that self-supervised pre-training outperforms the\nsupervised one, while the performance of HRRS pre-training is similar to\nself-supervised pre-training or slightly lower. Finally, we propose using an\nImageNet pre-trained model combined with a second round of pre-training using\nin-domain HRRS images, i.e. domain-adaptive pre-training. The experimental\nresults show that domain-adaptive pre-training results in models that achieve\nstate-of-the-art results on HRRS scene classification benchmarks. The source\ncode and pre-trained models are available at\n\\url{https://github.com/risojevicv/RSSC-transfer}.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2111.03690v3"}
{"entry_id": "http://arxiv.org/abs/2202.05220v1", "date": "2022-02-10", "title": "Privacy Protection, Measurement Error, and the Integration of Remote Sensing and Socioeconomic Survey Data", "authors": "Jeffrey D. Michler, Anna Josephson, Talip Kilic, Siobhan Murray", "abstract": "When publishing socioeconomic survey data, survey programs implement a\nvariety of statistical methods designed to preserve privacy but which come at\nthe cost of distorting the data. We explore the extent to which spatial\nanonymization methods to preserve privacy in the large-scale surveys supported\nby the World Bank Living Standards Measurement Study - Integrated Surveys on\nAgriculture (LSMS-ISA) introduce measurement error in econometric estimates\nwhen that survey data is integrated with remote sensing weather data. Guided by\na pre-analysis plan, we produce 90 linked weather-household datasets that vary\nby the spatial anonymization method and the remote sensing weather product. By\nvarying the data along with the econometric model we quantify the magnitude and\nsignificance of measurement error coming from the loss of accuracy that results\nfrom protect privacy measures. We find that spatial anonymization techniques\ncurrently in general use have, on average, limited to no impact on estimates of\nthe relationship between weather and agricultural productivity. However, the\ndegree to which spatial anonymization introduces mismeasurement is a function\nof which remote sensing weather product is used in the analysis. We conclude\nthat care must be taken in choosing a remote sensing weather product when\nlooking to integrate it with publicly available survey data.", "journal": "", "doi": null, "primary_category": "econ.GN", "categories": ["econ.GN", "q-fin.EC"], "pdf_url": "http://arxiv.org/pdf/2202.05220v1"}
{"entry_id": "http://arxiv.org/abs/2301.00622v1", "date": "2023-01-02", "title": "Credible Remote Sensing Scene Classification Using Evidential Fusion on Aerial-Ground Dual-view Images", "authors": "Kun Zhao, Qian Gao, Siyuan Hao, Jie Sun, Lijian Zhou", "abstract": "Due to their ability to offer more comprehensive information than data from a\nsingle view, multi-view (multi-source, multi-modal, multi-perspective, etc.)\ndata are being used more frequently in remote sensing tasks. However, as the\nnumber of views grows, the issue of data quality becomes more apparent,\nlimiting the potential benefits of multi-view data. Although recent deep neural\nnetwork (DNN) based models can learn the weight of data adaptively, a lack of\nresearch on explicitly quantifying the data quality of each view when fusing\nthem renders these models inexplicable, performing unsatisfactorily and\ninflexible in downstream remote sensing tasks. To fill this gap, in this paper,\nevidential deep learning is introduced to the task of aerial-ground dual-view\nremote sensing scene classification to model the credibility of each view.\nSpecifically, the theory of evidence is used to calculate an uncertainty value\nwhich describes the decision-making risk of each view. Based on this\nuncertainty, a novel decision-level fusion strategy is proposed to ensure that\nthe view with lower risk obtains more weight, making the classification more\ncredible. On two well-known, publicly available datasets of aerial-ground\ndual-view remote sensing images, the proposed approach achieves\nstate-of-the-art results, demonstrating its effectiveness. The code and\ndatasets of this article are available at the following address:\nhttps://github.com/gaopiaoliang/Evidential.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2301.00622v1"}
{"entry_id": "http://arxiv.org/abs/2208.04451v1", "date": "2022-08-08", "title": "Augmented Chironomia for Presenting Data to Remote Audiences", "authors": "Brian D. Hall, Lyn Bartram, Matthew Brehmer", "abstract": "To facilitate engaging and nuanced conversations around data, we contribute a\ntouchless approach to interacting directly with visualization in remote\npresentations. We combine dynamic charts overlaid on a presenter's webcam feed\nwith continuous bimanual hand tracking, demonstrating interactions that\nhighlight and manipulate chart elements appearing in the foreground. These\ninteractions are simultaneously functional and deictic, and some allow for the\naddition of \"rhetorical flourish\", or expressive movement used when speaking\nabout quantities, categories, and time intervals. We evaluated our approach in\ntwo studies with professionals who routinely deliver and attend presentations\nabout data. The first study considered the presenter perspective, where 12\nparticipants delivered presentations to a remote audience using a presentation\nenvironment incorporating our approach. The second study considered the\naudience experience of 17 participants who attended presentations supported by\nour environment. Finally, we reflect on observations from these studies and\ndiscuss related implications for engaging remote audiences in conversations\nabout data.", "journal": "", "doi": "10.1145/3526113.3545614", "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/2208.04451v1"}
{"entry_id": "http://arxiv.org/abs/2007.03200v3", "date": "2020-07-07", "title": "ReMOTS: Self-Supervised Refining Multi-Object Tracking and Segmentation", "authors": "Fan Yang, Xin Chang, Chenyu Dang, Ziqiang Zheng, Sakriani Sakti, Satoshi Nakamura, Yang Wu", "abstract": "We aim to improve the performance of Multiple Object Tracking and\nSegmentation (MOTS) by refinement. However, it remains challenging for refining\nMOTS results, which could be attributed to that appearance features are not\nadapted to target videos and it is also difficult to find proper thresholds to\ndiscriminate them. To tackle this issue, we propose a self-supervised refining\nMOTS (i.e., ReMOTS) framework. ReMOTS mainly takes four steps to refine MOTS\nresults from the data association perspective. (1) Training the appearance\nencoder using predicted masks. (2) Associating observations across adjacent\nframes to form short-term tracklets. (3) Training the appearance encoder using\nshort-term tracklets as reliable pseudo labels. (4) Merging short-term\ntracklets to long-term tracklets utilizing adopted appearance features and\nthresholds that are automatically obtained from statistical information. Using\nReMOTS, we reached the $1^{st}$ place on CVPR 2020 MOTS Challenge 1, with an\nsMOTSA score of $69.9$.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2007.03200v3"}
{"entry_id": "http://arxiv.org/abs/2009.13364v1", "date": "2020-09-28", "title": "RS-MetaNet: Deep meta metric learning for few-shot remote sensing scene classification", "authors": "Haifeng Li, Zhenqi Cui, Zhiqing Zhu, Li Chen, Jiawei Zhu, Haozhe Huang, Chao Tao", "abstract": "Training a modern deep neural network on massive labeled samples is the main\nparadigm in solving the scene classification problem for remote sensing, but\nlearning from only a few data points remains a challenge. Existing methods for\nfew-shot remote sensing scene classification are performed in a sample-level\nmanner, resulting in easy overfitting of learned features to individual samples\nand inadequate generalization of learned category segmentation surfaces. To\nsolve this problem, learning should be organized at the task level rather than\nthe sample level. Learning on tasks sampled from a task family can help tune\nlearning algorithms to perform well on new tasks sampled in that family.\nTherefore, we propose a simple but effective method, called RS-MetaNet, to\nresolve the issues related to few-shot remote sensing scene classification in\nthe real world. On the one hand, RS-MetaNet raises the level of learning from\nthe sample to the task by organizing training in a meta way, and it learns to\nlearn a metric space that can well classify remote sensing scenes from a series\nof tasks. We also propose a new loss function, called Balance Loss, which\nmaximizes the generalization ability of the model to new samples by maximizing\nthe distance between different categories, providing the scenes in different\ncategories with better linear segmentation planes while ensuring model fit. The\nexperimental results on three open and challenging remote sensing datasets,\nUCMerced\\_LandUse, NWPU-RESISC45, and Aerial Image Data, demonstrate that our\nproposed RS-MetaNet method achieves state-of-the-art results in cases where\nthere are only 1-20 labeled samples.", "journal": "IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, 2020", "doi": "10.1109/TGRS.2020.3027387", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2009.13364v1"}
{"entry_id": "http://arxiv.org/abs/2005.07871v2", "date": "2020-05-16", "title": "Remote State Estimation with Smart Sensors over Markov Fading Channels", "authors": "Wanchun Liu, Daniel E. Quevedo, Yonghui Li, Karl Henrik Johansson, Branka Vucetic", "abstract": "We consider a fundamental remote state estimation problem of discrete-time\nlinear time-invariant (LTI) systems. A smart sensor forwards its local state\nestimate to a remote estimator over a time-correlated $M$-state Markov fading\nchannel, where the packet drop probability is time-varying and depends on the\ncurrent fading channel state. We establish a necessary and sufficient condition\nfor mean-square stability of the remote estimation error covariance as\n$\\rho^2(\\mathbf{A})\\rho(\\mathbf{DM})<1$, where $\\rho(\\cdot)$ denotes the\nspectral radius, $\\mathbf{A}$ is the state transition matrix of the LTI system,\n$\\mathbf{D}$ is a diagonal matrix containing the packet drop probabilities in\ndifferent channel states, and $\\mathbf{M}$ is the transition probability matrix\nof the Markov channel states. To derive this result, we propose a novel\nestimation-cycle based approach, and provide new element-wise bounds of matrix\npowers. The stability condition is verified by numerical results, and is shown\nmore effective than existing sufficient conditions in the literature. We\nobserve that the stability region in terms of the packet drop probabilities in\ndifferent channel states can either be convex or concave depending on the\ntransition probability matrix $\\mathbf{M}$. Our numerical results suggest that\nthe stability conditions for remote estimation may coincide for setups with a\nsmart sensor and with a conventional one (which sends raw measurements to the\nremote estimator), though the smart sensor setup achieves a better estimation\nperformance.", "journal": "", "doi": null, "primary_category": "eess.SY", "categories": ["eess.SY", "cs.IT", "cs.SY", "eess.SP", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2005.07871v2"}
{"entry_id": "http://arxiv.org/abs/1708.01494v3", "date": "2017-08-04", "title": "Hierarchical Metric Learning for Optical Remote Sensing Scene Categorization", "authors": "Akashdeep Goel, Biplab Banerjee, Aleksandra Pizurica", "abstract": "We address the problem of scene classification from optical remote sensing\n(RS) images based on the paradigm of hierarchical metric learning. Ideally,\nsupervised metric learning strategies learn a projection from a set of training\ndata points so as to minimize intra-class variance while maximizing inter-class\nseparability to the class label space. However, standard metric learning\ntechniques do not incorporate the class interaction information in learning the\ntransformation matrix, which is often considered to be a bottleneck while\ndealing with fine-grained visual categories. As a remedy, we propose to\norganize the classes in a hierarchical fashion by exploring their visual\nsimilarities and subsequently learn separate distance metric transformations\nfor the classes present at the non-leaf nodes of the tree. We employ an\niterative max-margin clustering strategy to obtain the hierarchical\norganization of the classes. Experiment results obtained on the large-scale\nNWPU-RESISC45 and the popular UC-Merced datasets demonstrate the efficacy of\nthe proposed hierarchical metric learning based RS scene recognition strategy\nin comparison to the standard approaches.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1708.01494v3"}
{"entry_id": "http://arxiv.org/abs/1806.08104v1", "date": "2018-06-21", "title": "Hypergraph p-Laplacian Regularization for Remote Sensing Image Recognition", "authors": "Xueqi Ma, Weifeng Liu, Shuying Li, Yicong Zhou", "abstract": "It is of great importance to preserve locality and similarity information in\nsemi-supervised learning (SSL) based applications. Graph based SSL and manifold\nregularization based SSL including Laplacian regularization (LapR) and\nHypergraph Laplacian regularization (HLapR) are representative SSL methods and\nhave achieved prominent performance by exploiting the relationship of sample\ndistribution. However, it is still a great challenge to exactly explore and\nexploit the local structure of the data distribution. In this paper, we present\nan effect and effective approximation algorithm of Hypergraph p-Laplacian and\nthen propose Hypergraph p-Laplacian regularization (HpLapR) to preserve the\ngeometry of the probability distribution. In particular, p-Laplacian is a\nnonlinear generalization of the standard graph Laplacian and Hypergraph is a\ngeneralization of a standard graph. Therefore, the proposed HpLapR provides\nmore potential to exploiting the local structure preserving. We apply HpLapR to\nlogistic regression and conduct the implementations for remote sensing image\nrecognition. We compare the proposed HpLapR to several popular manifold\nregularization based SSL methods including LapR, HLapR and HpLapR on UC-Merced\ndataset. The experimental results demonstrate the superiority of the proposed\nHpLapR.", "journal": "", "doi": "10.1109/TGRS.2018.2867570", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1806.08104v1"}
{"entry_id": "http://arxiv.org/abs/2101.01975v1", "date": "2021-01-06", "title": "Predicting Forest Fire Using Remote Sensing Data And Machine Learning", "authors": "Suwei Yang, Massimo Lupascu, Kuldeep S. Meel", "abstract": "Over the last few decades, deforestation and climate change have caused\nincreasing number of forest fires. In Southeast Asia, Indonesia has been the\nmost affected country by tropical peatland forest fires. These fires have a\nsignificant impact on the climate resulting in extensive health, social and\neconomic issues. Existing forest fire prediction systems, such as the Canadian\nForest Fire Danger Rating System, are based on handcrafted features and require\ninstallation and maintenance of expensive instruments on the ground, which can\nbe a challenge for developing countries such as Indonesia. We propose a novel,\ncost-effective, machine-learning based approach that uses remote sensing data\nto predict forest fires in Indonesia. Our prediction model achieves more than\n0.81 area under the receiver operator characteristic (ROC) curve, performing\nsignificantly better than the baseline approach which never exceeds 0.70 area\nunder ROC curve on the same tasks. Our model's performance remained above 0.81\narea under ROC curve even when evaluated with reduced data. The results support\nour claim that machine-learning based approaches can lead to reliable and\ncost-effective forest fire prediction systems.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2101.01975v1"}
{"entry_id": "http://arxiv.org/abs/2212.04869v1", "date": "2022-12-09", "title": "RCDT: Relational Remote Sensing Change Detection with Transformer", "authors": "Kaixuan Lu, Xiao Huang", "abstract": "Deep learning based change detection methods have received wide attentoion,\nthanks to their strong capability in obtaining rich features from images.\nHowever, existing AI-based CD methods largely rely on three\nfunctionality-enhancing modules, i.e., semantic enhancement, attention\nmechanisms, and correspondence enhancement. The stacking of these modules leads\nto great model complexity. To unify these three modules into a simple pipeline,\nwe introduce Relational Change Detection Transformer (RCDT), a novel and simple\nframework for remote sensing change detection tasks. The proposed RCDT consists\nof three major components, a weight-sharing Siamese Backbone to obtain\nbi-temporal features, a Relational Cross Attention Module (RCAM) that\nimplements offset cross attention to obtain bi-temporal relation-aware\nfeatures, and a Features Constrain Module (FCM) to achieve the final refined\npredictions with high-resolution constraints. Extensive experiments on four\ndifferent publically available datasets suggest that our proposed RCDT exhibits\nsuperior change detection performance compared with other competing methods.\nThe therotical, methodogical, and experimental knowledge of this study is\nexpected to benefit future change detection efforts that involve the cross\nattention mechanism.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2212.04869v1"}
{"entry_id": "http://arxiv.org/abs/2303.05240v1", "date": "2023-03-09", "title": "Intriguing Property of GAN for Remote Sensing Image Generation", "authors": "Xingzhe Su, Lingyu Si, Wenwen Qiang, Junzhi Yu, Fengge Wu, Changwen Zheng, Fuchun Sun", "abstract": "Generative adversarial networks (GANs) have achieved remarkable progress in\nthe natural image field. However, when applying GANs in the remote sensing (RS)\nimage generation task, we discover an extraordinary phenomenon: the GAN model\nis more sensitive to the size of training data for RS image generation than for\nnatural image generation. In other words, the generation quality of RS images\nwill change significantly with the number of training categories or samples per\ncategory. In this paper, we first analyze this phenomenon from two kinds of toy\nexperiments and conclude that the amount of feature information contained in\nthe GAN model decreases with reduced training data. Based on this discovery, we\npropose two innovative adjustment schemes, namely Uniformity Regularization\n(UR) and Entropy Regularization (ER), to increase the information learned by\nthe GAN model at the distributional and sample levels, respectively. We\ntheoretically and empirically demonstrate the effectiveness and versatility of\nour methods. Extensive experiments on the NWPU-RESISC45 and PatternNet datasets\nshow that our methods outperform the well-established models on RS image\ngeneration tasks.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2303.05240v1"}
{"entry_id": "http://arxiv.org/abs/1803.01275v2", "date": "2018-03-04", "title": "Generation of discord through a remote joint continuous variable measurement", "authors": "E. Zalys-Geller, A. Narla, S. Shankar, M. Hatridge, M. P. Silveri, K. Sliwa, Z. Leghtas, M. H. Devoret", "abstract": "In quantum mechanics, continuously measuring an observable steers the system\ninto one eigenstate of that observable. This property has interesting and\nuseful consequences when the observable is a joint property of two remotely\nseparated qubits. In particular, if the measurement of the two-qubit joint\nobservable is performed in a way that is blind to single-qubit information,\nquantum back-action generates correlation of the discord type even if the\nmeasurement is weak and inefficient. We demonstrate the ability to generate\nthese quantum correlations in a circuit-QED setup by performing a weak joint\nreadout of two remote, non-interacting, superconducting transmon qubits using\nthe two non-degenerate modes of a Josephson Parametric Converter (JPC).\nSingle-qubit information is erased from the output in the limit of large gain\nand with properly tailored cavity drive pulses. Our results of the measurement\nof discord are in quantitative agreement with theoretical predictions, and\ndemonstrate the utility of the JPC as a which-qubit information eraser.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1803.01275v2"}
{"entry_id": "http://arxiv.org/abs/1506.07888v1", "date": "2015-06-25", "title": "Deterministic generation of remote entanglement with active quantum feedback", "authors": "Leigh Martin, Felix Motzoi, Hanhan Li, Mohan Sarovar, Birgitta Whaley", "abstract": "We consider the task of deterministically entangling two remote qubits using\njoint measurement and feedback, but no directly entangling Hamiltonian. In\norder to formulate the most effective experimentally feasible protocol, we\nintroduce the notion of average sense locally optimal (ASLO) feedback\nprotocols, which do not require real-time quantum state estimation, a difficult\ncomponent of real-time quantum feedback control. We use this notion of\noptimality to construct two protocols which can deterministically create\nmaximal entanglement: a semiclassical feedback protocol for low efficiency\nmeasurements and a quantum feedback protocol for high efficiency measurements.\nThe latter reduces to direct feedback in the continuous-time limit, whose\ndynamics can be modeled by a Wiseman-Milburn feedback master equation which\nyields an analytic solution in the limit of unit measurement efficiency. Our\nformalism can smoothly interpolate between continuous-time and discrete-time\ndescriptions of feedback dynamics, and we exploit this feature to then derive a\nsuperior hybrid protocol for arbitrary non-unit measurement efficiency that\nswitches between quantum and semiclassical protocols. Finally, we show using\nsimulations incorporating experimental imperfections that deterministic\nentanglement of remote superconducting qubits may be achieved with current\ntechnology using the continuous-time feedback protocol alone.", "journal": "Phys. Rev. A 92, 062321 (2015)", "doi": "10.1103/PhysRevA.92.062321", "primary_category": "quant-ph", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/1506.07888v1"}
{"entry_id": "http://arxiv.org/abs/2105.04132v2", "date": "2021-05-10", "title": "An Attention-Fused Network for Semantic Segmentation of Very-High-Resolution Remote Sensing Imagery", "authors": "Xuan Yang, Shanshan Li, Zhengchao Chen, Jocelyn Chanussot, Xiuping Jia, Bing Zhang, Baipeng Li, Pan Chen", "abstract": "Semantic segmentation is an essential part of deep learning. In recent years,\nwith the development of remote sensing big data, semantic segmentation has been\nincreasingly used in remote sensing. Deep convolutional neural networks (DCNNs)\nface the challenge of feature fusion: very-high-resolution remote sensing image\nmultisource data fusion can increase the network's learnable information, which\nis conducive to correctly classifying target objects by DCNNs; simultaneously,\nthe fusion of high-level abstract features and low-level spatial features can\nimprove the classification accuracy at the border between target objects. In\nthis paper, we propose a multipath encoder structure to extract features of\nmultipath inputs, a multipath attention-fused block module to fuse multipath\nfeatures, and a refinement attention-fused block module to fuse high-level\nabstract features and low-level spatial features. Furthermore, we propose a\nnovel convolutional neural network architecture, named attention-fused network\n(AFNet). Based on our AFNet, we achieve state-of-the-art performance with an\noverall accuracy of 91.7% and a mean F1 score of 90.96% on the ISPRS Vaihingen\n2D dataset and an overall accuracy of 92.1% and a mean F1 score of 93.44% on\nthe ISPRS Potsdam 2D dataset.", "journal": "ISPRS Journal of Photogrammetry and Remote Sensing, 177: 238-262,\n  2021", "doi": "10.1016/j.isprsjprs.2021.05.004", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2105.04132v2"}
{"entry_id": "http://arxiv.org/abs/1210.2853v1", "date": "2012-10-10", "title": "Composition of Near-Earth Asteroid (4179) Toutatis", "authors": "Vishnu Reddy, Juan Andreas Sanchez, Michael Gaffey, Paul Abell, Lucille Le Corre, Paul Hardersen", "abstract": "Surface composition of near-Earth asteroid (4179) Toutatis is consistent with\nan undifferentiated L-chondrite composition. This is inconsistent with early\nobservations that suggested high pyroxene iron content and a differentiated\nbody.", "journal": "", "doi": "10.1016/j.icarus.2012.10.005", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.geo-ph", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1210.2853v1"}
{"entry_id": "http://arxiv.org/abs/1307.7517v1", "date": "2013-07-29", "title": "Physical Properties of Asteroid (308635) 2005 YU55 derived from multi-instrument infrared observations during a very close Earth-Approach", "authors": "T. G. Mueller, T. Miyata, C. Kiss, M. A. Gurwell, S. Hasegawa, E. Vilenius, S. Sako, T. Kamizuka, T. Nakamura, K. Asano, M. Uchiyama, M. Konishi, M. Yoneda, T. Ootsubo, F. Usui, Y. Yoshii, M. Kidger, B. Altieri, R. Lorente, A. Pal, L. O'Rourke, L. Metcalfe", "abstract": "The near-Earth asteroid (308635) 2005 YU55 is a potentially hazardous\nasteroid which was discovered in 2005 and passed Earth on November 8th 2011 at\n0.85 lunar distances. This was the closest known approach by an asteroid of\nseveral hundred metre diameter since 1976 when a similar size object passed at\n0.5 lunar distances. We observed 2005 YU55 from ground with a recently\ndeveloped mid-IR camera (miniTAO/MAX38) in N- and Q-band and with the\nSubmillimeter Array (SMA) at 1.3 mm. In addition, we obtained space\nobservations with Herschel/PACS at 70, 100, and 160 micron. Our thermal\nmeasurements cover a wide range of wavelengths from 8.9 micron to 1.3 mm and\nwere taken after opposition at phase angles between -97 deg and -18 deg. We\nperformed a radiometric analysis via a thermophysical model and combined our\nderived properties with results from radar, adaptive optics, lightcurve\nobservations, speckle and auxiliary thermal data. We find that (308635) 2005\nYU55 has an almost spherical shape with an effective diameter of 300 to 312 m\nand a geometric albedo pV of 0.055 to 0.075. Its spin-axis is oriented towards\ncelestial directions (lam_ecl, beta_ecl) = (60 deg +/- 30deg, -60 deg +/- 15\ndeg), which means it has a retrograde sense of rotation. The analysis of all\navailable data combined revealed a discrepancy with the radar-derived size. Our\nradiometric analysis of the thermal data together with the problem to find a\nunique rotation period might be connected to a non-principal axis rotation. A\nlow to intermediate level of surface roughness (r.m.s. of surface slopes in the\nrange 0.1 - 0.3) is required to explain the available thermal measurements. We\nfound a thermal inertia in the range 350-800 Jm^-2s^-0.5K^-1, very similar to\nthe rubble-pile asteroid (25143) Itokawa and indicating a mixture of low\nconductivity fine regolith with larger rocks and boulders of high thermal\ninertia on the surface.", "journal": "", "doi": "10.1051/0004-6361/201321664", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1307.7517v1"}
{"entry_id": "http://arxiv.org/abs/0806.0334v1", "date": "2008-06-02", "title": "A Possible Explanation of Anomalous Earth Flybys", "authors": "Walter Petry", "abstract": "Doppler shift observations of several spacecrafts during near Earth flybys\nshow an unexplained frequency shift. This shift is interpreted as an unexpected\nvelocity change called Earth flyby anomaly. A theory of non-privileged\nreference frames is used to study the Doppler shift in such frames which are\nexperimentally justified by the measured dipole anisotropy of the cosmic\nmicrowave background (CMB) in the solar system. The system in which the CMB is\nisotropic defines the privileged reference frame. The calculated frequency\nshift in non-privileged reference frames may give an explanation of the\nanomalous Earth flybys.", "journal": "", "doi": null, "primary_category": "physics.gen-ph", "categories": ["physics.gen-ph"], "pdf_url": "http://arxiv.org/pdf/0806.0334v1"}
{"entry_id": "http://arxiv.org/abs/1902.06042v3", "date": "2019-02-16", "title": "R$^2$-CNN: Fast Tiny Object Detection in Large-Scale Remote Sensing Images", "authors": "Jiangmiao Pang, Cong Li, Jianping Shi, Zhihai Xu, Huajun Feng", "abstract": "Recently, the convolutional neural network has brought impressive\nimprovements for object detection. However, detecting tiny objects in\nlarge-scale remote sensing images still remains challenging. First, the extreme\nlarge input size makes the existing object detection solutions too slow for\npractical use. Second, the massive and complex backgrounds cause serious false\nalarms. Moreover, the ultratiny objects increase the difficulty of accurate\ndetection. To tackle these problems, we propose a unified and self-reinforced\nnetwork called remote sensing region-based convolutional neural network\n($\\mathcal{R}^2$-CNN), composing of backbone Tiny-Net, intermediate global\nattention block, and final classifier and detector. Tiny-Net is a lightweight\nresidual structure, which enables fast and powerful features extraction from\ninputs. Global attention block is built upon Tiny-Net to inhibit false\npositives. Classifier is then used to predict the existence of targets in each\npatch, and detector is followed to locate them accurately if available. The\nclassifier and detector are mutually reinforced with end-to-end training, which\nfurther speed up the process and avoid false alarms. Effectiveness of\n$\\mathcal{R}^2$-CNN is validated on hundreds of GF-1 images and GF-2 images\nthat are 18 000 $\\times$ 18 192 pixels, 2.0-m resolution, and 27 620 $\\times$\n29 200 pixels, 0.8-m resolution, respectively. Specifically, we can process a\nGF-1 image in 29.4 s on Titian X just with single thread. According to our\nknowledge, no previous solution can detect the tiny object on such huge remote\nsensing images gracefully. We believe that it is a significant step toward\npractical real-time remote sensing systems.", "journal": "", "doi": "10.1109/TGRS.2019.2899955", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1902.06042v3"}
{"entry_id": "http://arxiv.org/abs/1906.07284v1", "date": "2019-06-17", "title": "Spitzer Albedos of Near-Earth Objects", "authors": "Annika Gustafsson, David E. Trilling, Michael Mommert, Andrew McNeill, Joseph L. Hora, Howard A. Smith, Stephan Hellmich, Stefano Mottola, Alan W. Harris", "abstract": "Thermal infrared observations are the most effective way to measure asteroid\ndiameter and albedo for a large number of near-Earth objects. Major surveys\nlike NEOWISE, NEOSurvey, ExploreNEOs, and NEOLegacy find a small fraction of\nhigh albedo objects that do not have clear analogs in the current meteorite\npopulation. About 8% of Spitzer-observed near-Earth objects have nominal albedo\nsolutions greater than 0.5. This may be a result of lightcurve variability\nleading to an incorrect estimate of diameter or inaccurate absolute visual\nmagnitudes. For a sample of 23 high albedo NEOs we do not find that their\nshapes are significantly different from the McNeill et al. (2019) near-Earth\nobject shape distribution. We performed a Monte Carlo analysis on 1505\nnear-Earth objects observed by Spitzer, sampling the visible and thermal fluxes\nof all targets to determine the likelihood of obtaining a high albedo\nerroneously. Implementing the McNeill shape distribution for near-Earth\nobjects, we provide an upper-limit on the geometric albedo of 0.5+/-0.1 for the\nnear-Earth population.", "journal": "", "doi": "10.3847/1538-3881/ab29ea", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1906.07284v1"}
{"entry_id": "http://arxiv.org/abs/1210.1711v1", "date": "2012-10-05", "title": "Search for Super Earths by Timing of Transits with CoRoT", "authors": "J. Cabrera", "abstract": "We explore the possibility of detecting Super Earths via transit timing\nvariations with the satellite CoRoT.", "journal": "", "doi": "10.1051/eas/1042009", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1210.1711v1"}
{"entry_id": "http://arxiv.org/abs/2012.03957v2", "date": "2020-12-07", "title": "Earth-bound Milli-charge Relics", "authors": "Maxim Pospelov, Harikrishnan Ramani", "abstract": "Dark sector particles with small electric charge, or millicharge, (mCPs) may\nlead to a variety of diverse phenomena in particle physics, astrophysics and\ncosmology. Assuming their possible existence, we investigate the accumulation\nand propagation of mCPs in matter, specifically inside the Earth. Even small\nvalues of millicharge lead to sizeable scattering cross sections on atoms,\nresulting in complete thermalization, and as a consequence, considerable\nbuild-up of number densities of mCPs, especially for the values of masses of\nGeV and higher when the evaporation becomes inhibited. Enhancement of mCP\ndensities compared to their galactic abundance, that can be as big as\n$10^{14}$, leads to the possibility of new experimental probes for this model.\nThe annihilation of pairs of mCPs will result in new signatures for the large\nvolume detectors (such as Super-Kamiokande). Formation of bound states of\nnegatively charged mCPs with nuclei can be observed by direct dark matter\ndetection experiments. A unique probe of mCP can be developed using underground\nelectrostatic accelerators that can directly accelerate mCPs above the\nexperimental thresholds of direct dark matter detection experiments.", "journal": "Phys. Rev. D 103, 115031 (2021)", "doi": "10.1103/PhysRevD.103.115031", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph.CO"], "pdf_url": "http://arxiv.org/pdf/2012.03957v2"}
{"entry_id": "http://arxiv.org/abs/1606.07215v1", "date": "2016-06-23", "title": "Optimal Local and Remote Controllers with Unreliable Communication", "authors": "Yi Ouyang, Seyed Mohammad Asghari, Ashutosh Nayyar", "abstract": "We consider a decentralized optimal control problem for a linear plant\ncontrolled by two controllers, a local controller and a remote controller. The\nlocal controller directly observes the state of the plant and can inform the\nremote controller of the plant state through a packet-drop channel. We assume\nthat the remote controller is able to send acknowledgments to the local\ncontroller to signal the successful receipt of transmitted packets. The\nobjective of the two controllers is to cooperatively minimize a quadratic\nperformance cost. We provide a dynamic program for this decentralized control\nproblem using the common information approach. Although our problem is not a\npartially nested LQG problem, we obtain explicit optimal strategies for the two\ncontrollers. In the optimal strategies, both controllers compute a common\nestimate of the plant state based on the common information. The remote\ncontroller's action is linear in the common estimated state, and the local\ncontroller's action is linear in both the actual state and the common estimated\nstate.", "journal": "", "doi": null, "primary_category": "cs.SY", "categories": ["cs.SY"], "pdf_url": "http://arxiv.org/pdf/1606.07215v1"}
{"entry_id": "http://arxiv.org/abs/1502.04930v1", "date": "2015-02-17", "title": "Spectrometry of the Earth using Neutrino Oscillations", "authors": "Carsten Rott, Akimichi Taketa, Debanjan Bose", "abstract": "The unknown constituents of the interior of our home planet have provoked the\nhuman imagination and driven scientific exploration. We herein demonstrate that\nlarge neutrino detectors could be used in the near future to significantly\nimprove our understanding of the Earth's inner chemical composition. Neutrinos,\nwhich are naturally produced in the atmosphere, traverse the Earth and undergo\noscillations that depend on the Earth's electron density. The Earth's chemical\ncomposition can be determined by combining observations from large neutrino\ndetectors with seismic measurements of the Earth's matter density. We present a\nmethod that will allow us to perform a measurement that can distinguish between\ncomposition models of the outer core. We show that the next-generation\nlarge-volume neutrino detectors can provide sufficient sensitivity to reject\nouter core models with large hydrogen content and thereby demonstrate the\npotential of this novel method. In the future, dedicated instruments could be\ncapable of distinguishing between specific Earth composition models and thereby\nreshape our understanding of the inner Earth in previously unimagined ways.", "journal": "Scientific Reports 5, Article number: 15225 (2015)", "doi": "10.1038/srep15225", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "astro-ph.EP", "hep-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/1502.04930v1"}
{"entry_id": "http://arxiv.org/abs/1809.00256v2", "date": "2018-09-01", "title": "Percolation Framework of the Earth's Topography", "authors": "Jingfang Fan, Jun Meng, Abbas Ali Saberi", "abstract": "Self-similarity and long-range correlations are the remarkable features of\nthe Earth's surface topography. Here we develop an approach based on\npercolation theory to study the geometrical features of Earth. Our analysis is\nbased on high-resolution, 1 arc min, ETOPO1 global relief records.We find some\nevidence for abrupt transitions that occurred during the evolution of the\nEarth's relief network, indicative of a continental/cluster aggregation. We\napply finite-size-scaling analysis based on a coarse-graining procedure to show\nthat the observed transition is most likely discontinuous. Furthermore, we\nstudy the percolation on two-dimensional fractional Brownian motion surfaces\nwith Hurst exponent $H$ as a model of long-range correlated topography, which\nsuggests that the long-range correlations may play a key role in the observed\ndiscontinuity on Earth. Our framework presented here provides a theoretical\nmodel to better understand the geometrical phase transition on Earth, and it\nalso identifies the critical nodes that will be more exposed to global climate\nchange in the Earth's relief network.", "journal": "Phys. Rev. E 99, 022304 (2019)", "doi": "10.1103/PhysRevE.99.022304", "primary_category": "physics.soc-ph", "categories": ["physics.soc-ph", "physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1809.00256v2"}
{"entry_id": "http://arxiv.org/abs/1506.08670v1", "date": "2015-06-29", "title": "Automatic Channel Network Extraction from Remotely Sensed Images by Singularity Analysis", "authors": "F. Isikdogan, A. C. Bovik, P. Passalacqua", "abstract": "Quantitative analysis of channel networks plays an important role in river\nstudies. To provide a quantitative representation of channel networks, we\npropose a new method that extracts channels from remotely sensed images and\nestimates their widths. Our fully automated method is based on a recently\nproposed Multiscale Singularity Index that responds strongly to curvilinear\nstructures but weakly to edges. The algorithm produces a channel map, using a\nsingle image where water and non-water pixels have contrast, such as a Landsat\nnear-infrared band image or a water index defined on multiple bands. The\nproposed method provides a robust alternative to the procedures that are used\nin remote sensing of fluvial geomorphology and makes classification and\nanalysis of channel networks easier. The source code of the algorithm is\navailable at: http://live.ece.utexas.edu/research/cne/.", "journal": "IEEE Geoscience and Remote Sensing Letters 12/11 (2015): 2218-2221", "doi": "10.1109/LGRS.2015.2458898", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1506.08670v1"}
{"entry_id": "http://arxiv.org/abs/1711.08681v1", "date": "2017-11-23", "title": "Beyond RGB: Very High Resolution Urban Remote Sensing With Multimodal Deep Networks", "authors": "Nicolas Audebert, Bertrand Le Saux, S\u00e9bastien Lef\u00e8vre", "abstract": "In this work, we investigate various methods to deal with semantic labeling\nof very high resolution multi-modal remote sensing data. Especially, we study\nhow deep fully convolutional networks can be adapted to deal with multi-modal\nand multi-scale remote sensing data for semantic labeling. Our contributions\nare threefold: a) we present an efficient multi-scale approach to leverage both\na large spatial context and the high resolution data, b) we investigate early\nand late fusion of Lidar and multispectral data, c) we validate our methods on\ntwo public datasets with state-of-the-art results. Our results indicate that\nlate fusion make it possible to recover errors steaming from ambiguous data,\nwhile early fusion allows for better joint-feature learning but at the cost of\nhigher sensitivity to missing data.", "journal": "", "doi": null, "primary_category": "cs.NE", "categories": ["cs.NE", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/1711.08681v1"}
{"entry_id": "http://arxiv.org/abs/1609.06861v1", "date": "2016-09-22", "title": "How Useful is Region-based Classification of Remote Sensing Images in a Deep Learning Framework?", "authors": "Nicolas Audebert, Bertrand Le Saux, S\u00e9bastien Lef\u00e8vre", "abstract": "In this paper, we investigate the impact of segmentation algorithms as a\npreprocessing step for classification of remote sensing images in a deep\nlearning framework. Especially, we address the issue of segmenting the image\ninto regions to be classified using pre-trained deep neural networks as feature\nextractors for an SVM-based classifier. An efficient segmentation as a\npreprocessing step helps learning by adding a spatially-coherent structure to\nthe data. Therefore, we compare algorithms producing superpixels with more\ntraditional remote sensing segmentation algorithms and measure the variation in\nterms of classification accuracy. We establish that superpixel algorithms allow\nfor a better classification accuracy as a homogenous and compact segmentation\nfavors better generalization of the training samples.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1609.06861v1"}
{"entry_id": "http://arxiv.org/abs/2010.00472v1", "date": "2020-10-01", "title": "High Quality Remote Sensing Image Super-Resolution Using Deep Memory Connected Network", "authors": "Wenjia Xu, Guangluan Xu, Yang Wang, Xian Sun, Daoyu Lin, Yirong Wu", "abstract": "Single image super-resolution is an effective way to enhance the spatial\nresolution of remote sensing image, which is crucial for many applications such\nas target detection and image classification. However, existing methods based\non the neural network usually have small receptive fields and ignore the image\ndetail. We propose a novel method named deep memory connected network (DMCN)\nbased on a convolutional neural network to reconstruct high-quality\nsuper-resolution images. We build local and global memory connections to\ncombine image detail with environmental information. To further reduce\nparameters and ease time-consuming, we propose downsampling units, shrinking\nthe spatial size of feature maps. We test DMCN on three remote sensing datasets\nwith different spatial resolution. Experimental results indicate that our\nmethod yields promising improvements in both accuracy and visual performance\nover the current state-of-the-art.", "journal": "", "doi": "10.1109/IGARSS.2018.8518855", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2010.00472v1"}
{"entry_id": "http://arxiv.org/abs/2101.05097v1", "date": "2021-01-13", "title": "Telecom-heralded entanglement between remote multimode solid-state quantum memories", "authors": "Dario Lago-Rivera, Samuele Grandi, Jelena V. Rakonjac, Alessandro Seri, Hugues de Riedmatten", "abstract": "Future quantum networks will enable the distribution of entanglement between\ndistant locations and allow applications in quantum communication, quantum\nsensing and distributed quantum computation. At the core of this network lies\nthe ability of generating and storing entanglement at remote, interconnected\nquantum nodes. While remote physical systems of various nature have been\nsuccessfully entangled, none of these realisations encompassed all of the\nrequirements for network operation, such as telecom-compatibility and multimode\noperation. Here we report the demonstration of heralded entanglement between\ntwo spatially separated quantum nodes, where the entanglement is stored in\nmultimode solid-state quantum memories. At each node a praseodymium-doped\ncrystal stores a photon of a correlated pair, with the second photon at\ntelecommunication wavelengths. Entanglement between quantum memories placed in\ndifferent labs is heralded by the detection of a telecom photon at a rate up to\n1.4 kHz and is stored in the crystals for a pre-determined storage time up to\n25 microseconds. We also show that the generated entanglement is robust against\nloss in the heralding path, and demonstrate temporally multiplexed operation,\nwith 62 temporal modes. Our realisation is extendable to entanglement over\nlonger distances and provides a viable route towards field-deployed,\nmultiplexed quantum repeaters based on solid-state resources.", "journal": "Nature 594, 37-40 (2021)", "doi": "10.1038/s41586-021-03481-8", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2101.05097v1"}
{"entry_id": "http://arxiv.org/abs/2201.08789v1", "date": "2022-01-21", "title": "AiTLAS: Artificial Intelligence Toolbox for Earth Observation", "authors": "Ivica Dimitrovski, Ivan Kitanovski, Pan\u010de Panov, Nikola Simidjievski, Dragi Kocev", "abstract": "The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation)\nincludes state-of-the-art machine learning methods for exploratory and\npredictive analysis of satellite imagery as well as repository of AI-ready\nEarth Observation (EO) datasets. It can be easily applied for a variety of\nEarth Observation tasks, such as land use and cover classification, crop type\nprediction, localization of specific objects (semantic segmentation), etc. The\nmain goal of AiTLAS is to facilitate better usability and adoption of novel AI\nmethods (and models) by EO experts, while offering easy access and standardized\nformat of EO datasets to AI experts which further allows benchmarking of\nvarious existing and novel AI methods tailored for EO data.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2201.08789v1"}
{"entry_id": "http://arxiv.org/abs/1101.3890v1", "date": "2011-01-20", "title": "Optical instability of the earth's atmosphere", "authors": "Pavel G. Kovadlo, Olga S. Kochetkova", "abstract": "Meteorological data have been used to calculate refractive index fluctuations\n- the indicator of optical instability of the Earth's atmosphere. The\ncalculations were made for standard pressure levels of the atmosphere in winter\nand summer. They are presented as distributions over the Earth's surface. The\nfindings enabled us to determine preferred areas for astronomical observations\nas well as to compare astroclimate conditions of the world's largest\nobservatories.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1101.3890v1"}
{"entry_id": "http://arxiv.org/abs/1406.1419v1", "date": "2014-05-29", "title": "Thermal Energy Generation in the Earth", "authors": "Frederick J. Mayer, John R. Reitz", "abstract": "We show that a recently introduced class of electromagnetic composite\nparticles can explain some discrepancies in observations involving heat and\nhelium released from the earth. Energy release during the formation of the\ncomposites and subsequent nuclear reactions involving the composites are\ndescribed that can quantitatively account for the discrepancies and are\nexpected to have implications in other areas of geophysics, for example, a new\npicture of heat production and volcanism in the earth is presented.", "journal": "Nonlinear Processes in Geophysics, 21, 367-378 (2014)", "doi": "10.5194/npg-21-367-2014", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "physics.chem-ph"], "pdf_url": "http://arxiv.org/pdf/1406.1419v1"}
{"entry_id": "http://arxiv.org/abs/1802.09367v1", "date": "2018-02-23", "title": "The Detectability of Earth's Biosignatures Across Time", "authors": "Enric Palle", "abstract": "Over the past two decades, enormous advances in the detection of exoplanets\nhave taken place. Currently, we have discovered hundreds of earth-sized\nplanets, several of them within the habitable zone of their star. In the coming\nyears, the efforts will concentrate in the characterization of these planets\nand their atmospheres to try to detect the presence of biosignatures. However,\neven if we discovered a second Earth, it is very unlikely that it would present\na stage of evolution similar to the present-day Earth. Our planet has been far\nfrom static since its formation about 4.5 Ga ago; on the contrary, during this\ntime, it has undergone multiple changes in it's atmospheric composition, it's\ntemperature structure, it's continental distribution, and even changes in the\nforms of life that inhabit it. All these changes have affected the global\nproperties of Earth as seen from an astronomical distance. Thus, it is of\ninterest not only to characterize the observables of the Earth as it is today,\nbut also at different epochs. Here we review the detectability of the Earth's\nglobally-averaged properties over time. This includes atmospheric composition\nand biosignatures, and surface properties that can be interpreted as sings of\nhabitability (bioclues). The resulting picture is that truly unambiguous\nbiosignatures are only detectable for about 1/4 of the Earth's history. The\nrest of the time we rely on detectable bioclues that can only establish an\nstatistical likelihood for the presence of life on a given planet.", "journal": "", "doi": "10.1007/978-3-319-55333-7_70", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1802.09367v1"}
{"entry_id": "http://arxiv.org/abs/1509.08438v2", "date": "2015-09-28", "title": "Remote preparation of $W$ states from imperfect bipartite sources", "authors": "M. G. M. Moreno, M\u00e1rcio M. Cunha, Fernando Parisio", "abstract": "Several proposals to produce {\\it tripartite} $W$-type entanglement are\nprobabilistic even if no imperfections are considered in the processes. We\nprovide a deterministic way to remotely create $W$ states out of an EPR source.\nThe proposal is made viable through measurements (which can be demolitive) in\nan appropriate three-qubit basis. The protocol becomes probabilistic only when\nsource flaws are considered. It turns out that, even in this situation, it is\nrobust against imperfections in two senses: (i) It is possible, after\npostselection, to create a pure ensemble of $W$ states out of an EPR source\ncontaining a systematic error; (ii) If no postselection is done, the resulting\nmixed state has a fidelity, with respect to a pure $|W\\rangle$, which is higher\nthan that of the imperfect source in comparison to an ideal EPR source. This\nsimultaneously amounts to entanglement concentration and {\\it lifting}.", "journal": "", "doi": "10.1007/s11128-016-1358-0", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1509.08438v2"}
{"entry_id": "http://arxiv.org/abs/2202.10974v3", "date": "2022-02-22", "title": "The Winning Solution to the iFLYTEK Challenge 2021 Cultivated Land Extraction from High-Resolution Remote Sensing Image", "authors": "Zhen Zhao, Yuqiu Liu, Gang Zhang, Liang Tang, Xiaolin Hu", "abstract": "Extracting cultivated land accurately from high-resolution remote images is a\nbasic task for precision agriculture. This report introduces our solution to\nthe iFLYTEK challenge 2021 cultivated land extraction from high-resolution\nremote sensing image. The challenge requires segmenting cultivated land objects\nin very high-resolution multispectral remote sensing images. We established a\nhighly effective and efficient pipeline to solve this problem. We first divided\nthe original images into small tiles and separately performed instance\nsegmentation on each tile. We explored several instance segmentation algorithms\nthat work well on natural images and developed a set of effective methods that\nare applicable to remote sensing images. Then we merged the prediction results\nof all small tiles into seamless, continuous segmentation results through our\nproposed overlap-tile fusion strategy. We achieved the first place among 486\nteams in the challenge.", "journal": "2022 14th International Conference on Advanced Computational\n  Intelligence (ICACI)", "doi": "10.1109/ICACI55529.2022.9837765", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2202.10974v3"}
{"entry_id": "http://arxiv.org/abs/1602.00970v5", "date": "2016-02-02", "title": "Visual descriptors for content-based retrieval of remote sensing images", "authors": "Paolo Napoletano", "abstract": "In this paper we present an extensive evaluation of visual descriptors for\nthe content-based retrieval of remote sensing (RS) images. The evaluation\nincludes global hand-crafted, local hand-crafted, and Convolutional Neural\nNetwork (CNNs) features coupled with four different Content-Based Image\nRetrieval schemes. We conducted all the experiments on two publicly available\ndatasets: the 21-class UC Merced Land Use/Land Cover (LandUse) dataset and\n19-class High-resolution Satellite Scene dataset (SceneSat). The content of RS\nimages might be quite heterogeneous, ranging from images containing fine\ngrained textures, to coarse grained ones or to images containing objects. It is\ntherefore not obvious in this domain, which descriptor should be employed to\ndescribe images having such a variability. Results demonstrate that CNN-based\nfeatures perform better than both global and and local hand-crafted features\nwhatever is the retrieval scheme adopted. Features extracted from SatResNet-50,\na residual CNN suitable fine-tuned on the RS domain, shows much better\nperformance than a residual CNN pre-trained on multimedia scene and object\nimages. Features extracted from NetVLAD, a CNN that considers both CNN and\nlocal features, works better than others CNN solutions on those images that\ncontain fine-grained textures and objects.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1602.00970v5"}
{"entry_id": "http://arxiv.org/abs/2112.00504v1", "date": "2021-12-01", "title": "Learning Oriented Remote Sensing Object Detection via Naive Geometric Computing", "authors": "Yanjie Wang, Xu Zou, Zhijun Zhang, Wenhui Xu, Liqun Chen, Sheng Zhong, Luxin Yan, Guodong Wang", "abstract": "Detecting oriented objects along with estimating their rotation information\nis one crucial step for analyzing remote sensing images. Despite that many\nmethods proposed recently have achieved remarkable performance, most of them\ndirectly learn to predict object directions under the supervision of only one\n(e.g. the rotation angle) or a few (e.g. several coordinates) groundtruth\nvalues individually. Oriented object detection would be more accurate and\nrobust if extra constraints, with respect to proposal and rotation information\nregression, are adopted for joint supervision during training. To this end, we\ninnovatively propose a mechanism that simultaneously learns the regression of\nhorizontal proposals, oriented proposals, and rotation angles of objects in a\nconsistent manner, via naive geometric computing, as one additional steady\nconstraint (see Figure 1). An oriented center prior guided label assignment\nstrategy is proposed for further enhancing the quality of proposals, yielding\nbetter performance. Extensive experiments demonstrate the model equipped with\nour idea significantly outperforms the baseline by a large margin to achieve a\nnew state-of-the-art result without any extra computational burden during\ninference. Our proposed idea is simple and intuitive that can be readily\nimplemented. Source codes and trained models are involved in supplementary\nfiles.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2112.00504v1"}
{"entry_id": "http://arxiv.org/abs/2203.14007v1", "date": "2022-03-26", "title": "EYNet: Extended YOLO for Airport Detection in Remote Sensing Images", "authors": "Hengameh Mirhajianmoghadam, Behrouz Bolourian Haghighi", "abstract": "Nowadays, airport detection in remote sensing images has attracted\nconsiderable attention due to its strategic role in civilian and military\nscopes. In particular, uncrewed and operated aerial vehicles must immediately\ndetect safe areas to land in emergencies. The previous schemes suffered from\nvarious aspects, including complicated backgrounds, scales, and shapes of the\nairport. Meanwhile, the rapid action and accuracy of the method are confronted\nwith significant concerns. Hence, this study proposes an effective scheme by\nextending YOLOV3 and ShearLet transform. In this way, MobileNet and ResNet18,\nwith fewer layers and parameters retrained on a similar dataset, are parallelly\ntrained as base networks. According to airport geometrical characteristics, the\nShearLet filters with different scales and directions are considered in the\nfirst convolution layers of ResNet18 as a visual attention mechanism. Besides,\nthe major extended in YOLOV3 concerns the detection Sub-Networks with novel\nstructures which boost object expression ability and training efficiency. In\naddition, novel augmentation and negative mining strategies are presented to\nsignificantly increase the localization phase's performance. The experimental\nresults on the DIOR dataset reveal that the framework reliably detects\ndifferent types of airports in a varied area and acquires robust results in\ncomplex scenes compared to traditional YOLOV3 and state-of-the-art schemes.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2203.14007v1"}
{"entry_id": "http://arxiv.org/abs/2204.08707v1", "date": "2022-04-19", "title": "Unsupervised Contrastive Hashing for Cross-Modal Retrieval in Remote Sensing", "authors": "Georgii Mikriukov, Mahdyar Ravanbakhsh, Beg\u00fcm Demir", "abstract": "The development of cross-modal retrieval systems that can search and retrieve\nsemantically relevant data across different modalities based on a query in any\nmodality has attracted great attention in remote sensing (RS). In this paper,\nwe focus our attention on cross-modal text-image retrieval, where queries from\none modality (e.g., text) can be matched to archive entries from another (e.g.,\nimage). Most of the existing cross-modal text-image retrieval systems in RS\nrequire a high number of labeled training samples and also do not allow fast\nand memory-efficient retrieval. These issues limit the applicability of the\nexisting cross-modal retrieval systems for large-scale applications in RS. To\naddress this problem, in this paper we introduce a novel unsupervised\ncross-modal contrastive hashing (DUCH) method for text-image retrieval in RS.\nTo this end, the proposed DUCH is made up of two main modules: 1) feature\nextraction module, which extracts deep representations of two modalities; 2)\nhashing module that learns to generate cross-modal binary hash codes from the\nextracted representations. We introduce a novel multi-objective loss function\nincluding: i) contrastive objectives that enable similarity preservation in\nintra- and inter-modal similarities; ii) an adversarial objective that is\nenforced across two modalities for cross-modal representation consistency; and\niii) binarization objectives for generating hash codes. Experimental results\nshow that the proposed DUCH outperforms state-of-the-art methods. Our code is\npublicly available at https://git.tu-berlin.de/rsim/duch.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.08707v1"}
{"entry_id": "http://arxiv.org/abs/1711.02549v3", "date": "2017-11-07", "title": "Remote Sensing Image Fusion Based on Two-stream Fusion Network", "authors": "Xiangyu Liu, Qingjie Liu, Yunhong Wang", "abstract": "Remote sensing image fusion (also known as pan-sharpening) aims at generating\nhigh resolution multi-spectral (MS) image from inputs of a high spatial\nresolution single band panchromatic (PAN) image and a low spatial resolution\nmulti-spectral image. Inspired by the astounding achievements of convolutional\nneural networks (CNNs) in a variety of computer vision tasks, in this paper, we\npropose a two-stream fusion network (TFNet) to address the problem of\npan-sharpening. Unlike previous CNN based methods that consider pan-sharpening\nas a super resolution problem and perform pan-sharpening in pixel level, the\nproposed TFNet aims to fuse PAN and MS images in feature level and reconstruct\nthe pan-sharpened image from the fused features. The TFNet mainly consists of\nthree parts. The first part is comprised of two networks extracting features\nfrom PAN and MS images, respectively. The subsequent network fuses them\ntogether to form compact features that represent both spatial and spectral\ninformation of PAN and MS images, simultaneously. Finally, the desired high\nspatial resolution MS image is recovered from the fused features through an\nimage reconstruction network. Experiments on Quickbird and \\mbox{GaoFen-1}\nsatellite images demonstrate that the proposed TFNet can fuse PAN and MS\nimages, effectively, and produce pan-sharpened images competitive with even\nsuperior to state of the arts.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1711.02549v3"}
{"entry_id": "http://arxiv.org/abs/1807.02700v3", "date": "2018-07-07", "title": "Towards Multi-class Object Detection in Unconstrained Remote Sensing Imagery", "authors": "Seyed Majid Azimi, Eleonora Vig, Reza Bahmanyar, Marco K\u00f6rner, Peter Reinartz", "abstract": "Automatic multi-class object detection in remote sensing images in\nunconstrained scenarios is of high interest for several applications including\ntraffic monitoring and disaster management. The huge variation in object scale,\norientation, category, and complex backgrounds, as well as the different camera\nsensors pose great challenges for current algorithms. In this work, we propose\na new method consisting of a novel joint image cascade and feature pyramid\nnetwork with multi-size convolution kernels to extract multi-scale strong and\nweak semantic features. These features are fed into rotation-based region\nproposal and region of interest networks to produce object detections. Finally,\nrotational non-maximum suppression is applied to remove redundant detections.\nDuring training, we minimize joint horizontal and oriented bounding box loss\nfunctions, as well as a novel loss that enforces oriented boxes to be\nrectangular. Our method achieves 68.16% mAP on horizontal and 72.45% mAP on\noriented bounding box detection tasks on the challenging DOTA dataset,\noutperforming all published methods by a large margin (+6% and +12% absolute\nimprovement, respectively). Furthermore, it generalizes to two other datasets,\nNWPU VHR-10 and UCAS-AOD, and achieves competitive results with the baselines\neven when trained on DOTA. Our method can be deployed in multi-class object\ndetection applications, regardless of the image and object scales and\norientations, making it a great choice for unconstrained aerial and satellite\nimagery.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.02700v3"}
{"entry_id": "http://arxiv.org/abs/2009.08337v2", "date": "2020-09-16", "title": "Histopathology for Mohs Micrographic Surgery with Photoacoustic Remote Sensing Microscopy", "authors": "Benjamin R. Ecclestone, Kevan Bell, Saad Abbasi, Deepak Dinakaran, Muba Taher, John R. Mackey, Parsin Haji Reza", "abstract": "Mohs micrographic surgery (MMS) is a precise oncological technique where\nlayers of tissue are resected and examined with intraoperative histopathology\nto minimize the removal of normal tissue while completely excising the cancer.\nTo achieve intraoperative pathology, the tissue is frozen, sectioned and\nstained over a 20- to 60-minute period, then analyzed by the MMS surgeon.\nSurgery is continued one layer at a time until no cancerous cells remain,\nmeaning MMS can take several hours to complete. Ideally, it would be desirable\nto circumvent or augment frozen sectioning methods and directly visualize\nsubcellular morphology on the unprocessed excised tissues. Employing\nphotoacoustic remote sensing (PARS) microscopy, we present a non-contact\nlabel-free reflection-mode method of performing such visualizations in frozen\nsections of human skin. PARS leverages endogenous optical absorption contrast\nwithin cell nuclei to provide visualizations reminiscent of histochemical\nstaining techniques. Presented here, is the first true one to one comparison\nbetween PARS microscopy and standard histopathological imaging in human\ntissues. We demonstrate the ability of PARS microscopy to provide large\ngrossing scans (>1 cm2, sufficient to visualize entire MMS sections) and\nregional scans with subcellular lateral resolution (~300 nm).", "journal": "", "doi": null, "primary_category": "physics.med-ph", "categories": ["physics.med-ph", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2009.08337v2"}
{"entry_id": "http://arxiv.org/abs/2105.08501v2", "date": "2021-05-18", "title": "Self-supervised Remote Sensing Images Change Detection at Pixel-level", "authors": "Yuxing Chen, Lorenzo Bruzzone", "abstract": "Deep learning techniques have achieved great success in remote sensing image\nchange detection. Most of them are supervised techniques, which usually require\nlarge amounts of training data and are limited to a particular application.\nSelf-supervised methods as an unsupervised approach are popularly used to solve\nthis problem and are widely used in unsupervised binary change detection tasks.\nHowever, the existing self-supervised methods in change detection are based on\npre-tasks or at patch-level, which may be sub-optimal for pixel-wise change\ndetection tasks. Therefore, in this work, a pixel-wise contrastive approach is\nproposed to overcome this limitation. This is achieved by using contrastive\nloss in pixel-level features on an unlabeled multi-view setting. In this\napproach, a Siamese ResUnet is trained to obtain pixel-wise representations and\nto align features from shifted positive pairs. Meanwhile, vector quantization\nis used to augment the learned features in two branches. The final binary\nchange map is obtained by subtracting features of one branch from features of\nthe other branch and using the Rosin thresholding method. To overcome the\neffects of regular seasonal changes in binary change maps, we also used an\nuncertainty method to enhance the temporal robustness of the proposed approach.\nTwo homogeneous (OSCD and MUDS) datasets and one heterogeneous (California\nFlood) dataset are used to evaluate the performance of the proposed approach.\nResults demonstrate improvements in both efficiency and accuracy over the\npatch-wise multi-view contrastive method.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2105.08501v2"}
{"entry_id": "http://arxiv.org/abs/2212.09937v1", "date": "2022-12-20", "title": "AI applications in forest monitoring need remote sensing benchmark datasets", "authors": "Emily R. Lines, Matt Allen, Carlos Cabo, Kim Calders, Amandine Debus, Stuart W. D. Grieve, Milto Miltiadou, Adam Noach, Harry J. F. Owen, Stefano Puliti", "abstract": "With the rise in high resolution remote sensing technologies there has been\nan explosion in the amount of data available for forest monitoring, and an\naccompanying growth in artificial intelligence applications to automatically\nderive forest properties of interest from these datasets. Many studies use\ntheir own data at small spatio-temporal scales, and demonstrate an application\nof an existing or adapted data science method for a particular task. This\napproach often involves intensive and time-consuming data collection and\nprocessing, but generates results restricted to specific ecosystems and sensor\ntypes. There is a lack of widespread acknowledgement of how the types and\nstructures of data used affects performance and accuracy of analysis\nalgorithms. To accelerate progress in the field more efficiently, benchmarking\ndatasets upon which methods can be tested and compared are sorely needed.\n  Here, we discuss how lack of standardisation impacts confidence in estimation\nof key forest properties, and how considerations of data collection need to be\naccounted for in assessing method performance. We present pragmatic\nrequirements and considerations for the creation of rigorous, useful\nbenchmarking datasets for forest monitoring applications, and discuss how tools\nfrom modern data science can improve use of existing data. We list a set of\nexample large-scale datasets that could contribute to benchmarking, and present\na vision for how community-driven, representative benchmarking initiatives\ncould benefit the field.", "journal": "", "doi": null, "primary_category": "cs.AI", "categories": ["cs.AI", "cs.CY"], "pdf_url": "http://arxiv.org/pdf/2212.09937v1"}
{"entry_id": "http://arxiv.org/abs/2301.01449v2", "date": "2023-01-04", "title": "Building Coverage Estimation with Low-resolution Remote Sensing Imagery", "authors": "Enci Liu, Chenlin Meng, Matthew Kolodner, Eun Jee Sung, Sihang Chen, Marshall Burke, David Lobell, Stefano Ermon", "abstract": "Building coverage statistics provide crucial insights into the urbanization,\ninfrastructure, and poverty level of a region, facilitating efforts towards\nalleviating poverty, building sustainable cities, and allocating infrastructure\ninvestments and public service provision. Global mapping of buildings has been\nmade more efficient with the incorporation of deep learning models into the\npipeline. However, these models typically rely on high-resolution satellite\nimagery which are expensive to collect and infrequently updated. As a result,\nbuilding coverage data are not updated timely especially in developing regions\nwhere the built environment is changing quickly. In this paper, we propose a\nmethod for estimating building coverage using only publicly available\nlow-resolution satellite imagery that is more frequently updated. We show that\nhaving a multi-node quantile regression layer greatly improves the model's\nspatial and temporal generalization. Our model achieves a coefficient of\ndetermination ($R^2$) as high as 0.968 on predicting building coverage in\nregions of different levels of development around the world. We demonstrate\nthat the proposed model accurately predicts the building coverage from raw\ninput images and generalizes well to unseen countries and continents,\nsuggesting the possibility of estimating global building coverage using only\nlow-resolution remote sensing data.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.01449v2"}
{"entry_id": "http://arxiv.org/abs/2112.11965v2", "date": "2021-12-22", "title": "Dense and long-term monitoring of Earth surface processes with passive RFID -- a review", "authors": "Mathieu Le Breton, Fr\u00e9d\u00e9ric Li\u00e9bault, Laurent Baillet, Arthur Charl\u00e9ty, \u00c9ric Larose, Smail Tedjini", "abstract": "Billions of Radio-Frequency Identification (RFID) passive tags are produced\nyearly to identify goods remotely. New research and business applications are\ncontinuously arising, including recently localization and sensing to monitor\nearth surface processes. Indeed, passive tags can cost 10 to 100 times less\nthan wireless sensors networks and require little maintenance, facilitating\nyears-long monitoring with ten's to thousands of tags. This study reviews the\nexisting and potential applications of RFID in geosciences. The most mature\napplication today is the study of coarse sediment transport in rivers or\ncoastal environments, using tags placed into pebbles. More recently, tag\nlocalization was used to monitor landslide displacement, with a centimetric\naccuracy. Sensing tags were used to detect a displacement threshold on unstable\nrocks, to monitor the soil moisture or temperature, and to monitor the snowpack\ntemperature and snow water equivalent. RFID sensors, available today, could\nmonitor other parameters, such as the vibration of structures, the tilt of\nunstable boulders, the strain of a material, or the salinity of water. Key\nchallenges for using RFID monitoring more broadly in geosciences include the\nuse of ground and aerial vehicles to collect data or localize tags, the\nincrease in reading range and duration, the ability to use tags placed under\nground, snow, water or vegetation, and the optimization of economical and\nenvironmental cost. As a pattern, passive RFID could fill a gap between\nwireless sensor networks and manual measurements, to collect data efficiently\nover large areas, during several years, at high spatial density and moderate\ncost.", "journal": "Earth-Science Reviews 234 (2022) 104225", "doi": "10.1016/j.earscirev.2022.104225", "primary_category": "physics.ins-det", "categories": ["physics.ins-det", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2112.11965v2"}
{"entry_id": "http://arxiv.org/abs/1803.09824v1", "date": "2018-03-26", "title": "Low-Shot Learning for the Semantic Segmentation of Remote Sensing Imagery", "authors": "Ronald Kemker, Ryan Luu, Christopher Kanan", "abstract": "Recent advances in computer vision using deep learning with RGB imagery\n(e.g., object recognition and detection) have been made possible thanks to the\ndevelopment of large annotated RGB image datasets. In contrast, multispectral\nimage (MSI) and hyperspectral image (HSI) datasets contain far fewer labeled\nimages, in part due to the wide variety of sensors used. These annotations are\nespecially limited for semantic segmentation, or pixel-wise classification, of\nremote sensing imagery because it is labor intensive to generate image\nannotations. Low-shot learning algorithms can make effective inferences despite\nsmaller amounts of annotated data. In this paper, we study low-shot learning\nusing self-taught feature learning for semantic segmentation. We introduce 1)\nan improved self-taught feature learning framework for HSI and MSI data and 2)\na semi-supervised classification algorithm. When these are combined, they\nachieve state-of-the-art performance on remote sensing datasets that have\nlittle annotated training data available. These low-shot learning frameworks\nwill reduce the manual image annotation burden and improve semantic\nsegmentation performance for remote sensing imagery.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1803.09824v1"}
{"entry_id": "http://arxiv.org/abs/1908.03809v1", "date": "2019-08-10", "title": "Conditional Generative Adversarial Networks for Data Augmentation and Adaptation in Remotely Sensed Imagery", "authors": "Jonathan Howe, Kyle Pula, Aaron A. Reite", "abstract": "The difficulty in obtaining labeled data relevant to a given task is among\nthe most common and well-known practical obstacles to applying deep learning\ntechniques to new or even slightly modified domains. The data volumes required\nby the current generation of supervised learning algorithms typically far\nexceed what a human needs to learn and complete a given task. We investigate\nways to expand a given labeled corpus of remote sensed imagery into a larger\ncorpus using Generative Adversarial Networks (GANs). We then measure how these\nadditional synthetic data affect supervised machine learning performance on an\nobject detection task.\n  Our data driven strategy is to train GANs to (1) generate synthetic\nsegmentation masks and (2) generate plausible synthetic remote sensing imagery\ncorresponding to these segmentation masks. Run sequentially, these GANs allow\nthe generation of synthetic remote sensing imagery complete with segmentation\nlabels. We apply this strategy to the data set from ISPRS' 2D Semantic Labeling\nContest - Potsdam, with a follow on vehicle detection task. We find that in\nscenarios with limited training data, augmenting the available data with such\nsynthetically generated data can improve detector performance.", "journal": "", "doi": "10.1117/12.2529586", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1908.03809v1"}
{"entry_id": "http://arxiv.org/abs/2104.07784v1", "date": "2021-04-15", "title": "A survey of active learning algorithms for supervised remote sensing image classification", "authors": "Devis Tuia, Michele Volpi, Loris Copa, Mikhail Kanevski, Jordi Munoz-Mari", "abstract": "Defining an efficient training set is one of the most delicate phases for the\nsuccess of remote sensing image classification routines. The complexity of the\nproblem, the limited temporal and financial resources, as well as the high\nintraclass variance can make an algorithm fail if it is trained with a\nsuboptimal dataset. Active learning aims at building efficient training sets by\niteratively improving the model performance through sampling. A user-defined\nheuristic ranks the unlabeled pixels according to a function of the uncertainty\nof their class membership and then the user is asked to provide labels for the\nmost uncertain pixels. This paper reviews and tests the main families of active\nlearning algorithms: committee, large margin and posterior probability-based.\nFor each of them, the most recent advances in the remote sensing community are\ndiscussed and some heuristics are detailed and tested. Several challenging\nremote sensing scenarios are considered, including very high spatial resolution\nand hyperspectral image classification. Finally, guidelines for choosing the\ngood architecture are provided for new and/or unexperienced user.", "journal": "IEEE Journal of Selected Topics in Signal Processing, 5(3): 606 -\n  617, 2011", "doi": "10.1109/JSTSP.2011.2139193", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2104.07784v1"}
{"entry_id": "http://arxiv.org/abs/2209.12621v1", "date": "2022-09-26", "title": "Improving Image Clustering through Sample Ranking and Its Application to remote--sensing images", "authors": "Qinglin Li, Guoping Qiu", "abstract": "Image clustering is a very useful technique that is widely applied to various\nareas, including remote sensing. Recently, visual representations by\nself-supervised learning have greatly improved the performance of image\nclustering. To further improve the well-trained clustering models, this paper\nproposes a novel method by first ranking samples within each cluster based on\nthe confidence in their belonging to the current cluster and then using the\nranking to formulate a weighted cross-entropy loss to train the model. For\nranking the samples, we developed a method for computing the likelihood of\nsamples belonging to the current clusters based on whether they are situated in\ndensely populated neighborhoods, while for training the model, we give a\nstrategy for weighting the ranked samples. We present extensive experimental\nresults that demonstrate that the new technique can be used to improve the\nState-of-the-Art image clustering models, achieving accuracy performance gains\nranging from $2.1\\%$ to $15.9\\%$. Performing our method on a variety of\ndatasets from remote sensing, we show that our method can be effectively\napplied to remote--sensing images.", "journal": "Remote Sens. 2022, 14, 3317", "doi": "10.3390/rs14143317", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2209.12621v1"}
{"entry_id": "http://arxiv.org/abs/2301.06874v1", "date": "2023-01-17", "title": "Training Methods of Multi-label Prediction Classifiers for Hyperspectral Remote Sensing Images", "authors": "Salma Haidar, Jos\u00e9 Oramas", "abstract": "With their combined spectral depth and geometric resolution, hyperspectral\nremote sensing images embed a wealth of complex, non-linear information that\nchallenges traditional computer vision techniques. Yet, deep learning methods\nknown for their representation learning capabilities prove more suitable for\nhandling such complexities. Unlike applications that focus on single-label,\npixel-level classification methods for hyperspectral remote sensing images, we\npropose a multi-label, patch-level classification method based on a\ntwo-component deep-learning network. We use patches of reduced spatial\ndimension and a complete spectral depth extracted from the remote sensing\nimages. Additionally, we investigate three training schemes for our network:\nIterative, Joint, and Cascade. Experiments suggest that the Joint scheme is the\nbest-performing scheme; however, its application requires an expensive search\nfor the best weight combination of the loss constituents. The Iterative scheme\nenables the sharing of features between the two parts of the network at the\nearly stages of training. It performs better on complex data with multi-labels.\nFurther experiments showed that methods designed with different architectures\nperformed well when trained on patches extracted and labeled according to our\nsampling method.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.06874v1"}
{"entry_id": "http://arxiv.org/abs/1805.00930v2", "date": "2018-05-02", "title": "Multi-Resolution Multi-Modal Sensor Fusion For Remote Sensing Data With Label Uncertainty", "authors": "Xiaoxiao Du, Alina Zare", "abstract": "In remote sensing, each sensor can provide complementary or reinforcing\ninformation. It is valuable to fuse outputs from multiple sensors to boost\noverall performance. Previous supervised fusion methods often require accurate\nlabels for each pixel in the training data. However, in many remote sensing\napplications, pixel-level labels are difficult or infeasible to obtain. In\naddition, outputs from multiple sensors often have different resolution or\nmodalities. For example, rasterized hyperspectral imagery presents data in a\npixel grid while airborne Light Detection and Ranging (LiDAR) generates dense\nthree-dimensional (3D) point clouds. It is often difficult to directly fuse\nsuch multi-modal, multi-resolution data. To address these challenges, we\npresent a novel Multiple Instance Multi-Resolution Fusion (MIMRF) framework\nthat can fuse multi-resolution and multi-modal sensor outputs while learning\nfrom automatically-generated, imprecisely-labeled data. Experiments were\nconducted on the MUUFL Gulfport hyperspectral and LiDAR data set and a\nremotely-sensed soybean and weed data set. Results show improved, consistent\nperformance on scene understanding and agricultural applications when compared\nto traditional fusion methods.", "journal": "", "doi": "10.1109/TGRS.2019.2955320", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1805.00930v2"}
{"entry_id": "http://arxiv.org/abs/2202.03501v1", "date": "2022-02-07", "title": "Scribble-based Boundary-aware Network for Weakly Supervised Salient Object Detection in Remote Sensing Images", "authors": "Zhou Huang, Tian-Zhu Xiang, Huai-Xin Chen, Hang Dai", "abstract": "Existing CNNs-based salient object detection (SOD) heavily depends on the\nlarge-scale pixel-level annotations, which is labor-intensive, time-consuming,\nand expensive. By contrast, the sparse annotations become appealing to the\nsalient object detection community. However, few efforts are devoted to\nlearning salient object detection from sparse annotations, especially in the\nremote sensing field. In addition, the sparse annotation usually contains\nscanty information, which makes it challenging to train a well-performing\nmodel, resulting in its performance largely lagging behind the fully-supervised\nmodels. Although some SOD methods adopt some prior cues to improve the\ndetection performance, they usually lack targeted discrimination of object\nboundaries and thus provide saliency maps with poor boundary localization. To\nthis end, in this paper, we propose a novel weakly-supervised salient object\ndetection framework to predict the saliency of remote sensing images from\nsparse scribble annotations. To implement it, we first construct the\nscribble-based remote sensing saliency dataset by relabelling an existing\nlarge-scale SOD dataset with scribbles, namely S-EOR dataset. After that, we\npresent a novel scribble-based boundary-aware network (SBA-Net) for remote\nsensing salient object detection. Specifically, we design a boundary-aware\nmodule (BAM) to explore the object boundary semantics, which is explicitly\nsupervised by the high-confidence object boundary (pseudo) labels generated by\nthe boundary label generation (BLG) module, forcing the model to learn features\nthat highlight the object structure and thus boosting the boundary localization\nof objects. Then, the boundary semantics are integrated with high-level\nfeatures to guide the salient object detection under the supervision of\nscribble labels.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2202.03501v1"}
{"entry_id": "http://arxiv.org/abs/1605.06148v1", "date": "2016-05-19", "title": "Remote Operations and Nightly Automation of The Red Buttes Observatory", "authors": "David H. Kasper, Tyler G. Ellis, Rex R. Yeigh, Henry A. Kobulnicky, Hannah Jang-Condell, Mark Kelley, Gerald J. Bucher, James S. Weger", "abstract": "We have implemented upgrades to the University of Wyoming's Red Buttes\nObservatory (RBO) to allow remote and autonomous operations using the 0.6 m\ntelescope. Detailed descriptions of hardware and software components provide\nsufficient information to guide upgrading similarly designed telescopes. We\nalso give a thorough description of the automated and remote operation modes\nwith intent to inform the construction of routines elsewhere. Because the\nupgrades were largely driven by the intent to perform exoplanet transit\nphotometry, we discuss how this science informed the automation process. A\nsample exoplanet transit observation serves to demonstrate RBO's capability to\nperform precision photometry. The successful upgrades have equipped a legacy\nobservatory for a new generation of automated and rapid-response observations.", "journal": "", "doi": "10.1088/1538-3873/128/968/105005", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1605.06148v1"}
{"entry_id": "http://arxiv.org/abs/1812.00645v2", "date": "2018-12-03", "title": "Unsupervised Deep Slow Feature Analysis for Change Detection in Multi-Temporal Remote Sensing Images", "authors": "Bo Du, Lixiang Ru, Chen Wu, Liangpei Zhang", "abstract": "Change detection has been a hotspot in remote sensing technology for a long\ntime. With the increasing availability of multi-temporal remote sensing images,\nnumerous change detection algorithms have been proposed. Among these methods,\nimage transformation methods with feature extraction and mapping could\neffectively highlight the changed information and thus has better change\ndetection performance. However, changes of multi-temporal images are usually\ncomplex, existing methods are not effective enough. In recent years, deep\nnetwork has shown its brilliant performance in many fields including feature\nextraction and projection. Therefore, in this paper, based on deep network and\nslow feature analysis (SFA) theory, we proposed a new change detection\nalgorithm for multi-temporal remotes sensing images called Deep Slow Feature\nAnalysis (DSFA). In DSFA model, two symmetric deep networks are utilized for\nprojecting the input data of bi-temporal imagery. Then, the SFA module is\ndeployed to suppress the unchanged components and highlight the changed\ncomponents of the transformed features. The CVA pre-detection is employed to\nfind unchanged pixels with high confidence as training samples. Finally, the\nchange intensity is calculated with chi-square distance and the changes are\ndetermined by threshold algorithms. The experiments are performed on two\nreal-world datasets and a public hyperspectral dataset. The visual comparison\nand quantitative evaluation have both shown that DSFA could outperform the\nother state-of-the-art algorithms, including other SFA-based and deep learning\nmethods.", "journal": "", "doi": "10.1109/TGRS.2019.2930682", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1812.00645v2"}
{"entry_id": "http://arxiv.org/abs/2007.08494v1", "date": "2020-07-16", "title": "Vehicle Detection of Multi-source Remote Sensing Data Using Active Fine-tuning Network", "authors": "Xin Wu, Wei Li, Danfeng Hong, Jiaojiao Tian, Ran Tao, Qian Du", "abstract": "Vehicle detection in remote sensing images has attracted increasing interest\nin recent years. However, its detection ability is limited due to lack of\nwell-annotated samples, especially in densely crowded scenes. Furthermore,\nsince a list of remotely sensed data sources is available, efficient\nexploitation of useful information from multi-source data for better vehicle\ndetection is challenging. To solve the above issues, a multi-source active\nfine-tuning vehicle detection (Ms-AFt) framework is proposed, which integrates\ntransfer learning, segmentation, and active classification into a unified\nframework for auto-labeling and detection. The proposed Ms-AFt employs a\nfine-tuning network to firstly generate a vehicle training set from an\nunlabeled dataset. To cope with the diversity of vehicle categories, a\nmulti-source based segmentation branch is then designed to construct additional\ncandidate object sets. The separation of high quality vehicles is realized by a\ndesigned attentive classifications network. Finally, all three branches are\ncombined to achieve vehicle detection. Extensive experimental results conducted\non two open ISPRS benchmark datasets, namely the Vaihingen village and Potsdam\ncity datasets, demonstrate the superiority and effectiveness of the proposed\nMs-AFt for vehicle detection. In addition, the generalization ability of Ms-AFt\nin dense remote sensing scenes is further verified on stereo aerial imagery of\na large camping site.", "journal": "ISPRS Journal of Photogrammetry and Remote Sensing,167:39-53,2020", "doi": "10.1016/j.isprsjprs.2020.06.016", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2007.08494v1"}
{"entry_id": "http://arxiv.org/abs/2101.06849v2", "date": "2021-01-18", "title": "CFC-Net: A Critical Feature Capturing Network for Arbitrary-Oriented Object Detection in Remote Sensing Images", "authors": "Qi Ming, Lingjuan Miao, Zhiqiang Zhou, Yunpeng Dong", "abstract": "Object detection in optical remote sensing images is an important and\nchallenging task. In recent years, the methods based on convolutional neural\nnetworks have made good progress. However, due to the large variation in object\nscale, aspect ratio, and arbitrary orientation, the detection performance is\ndifficult to be further improved. In this paper, we discuss the role of\ndiscriminative features in object detection, and then propose a Critical\nFeature Capturing Network (CFC-Net) to improve detection accuracy from three\naspects: building powerful feature representation, refining preset anchors, and\noptimizing label assignment. Specifically, we first decouple the classification\nand regression features, and then construct robust critical features adapted to\nthe respective tasks through the Polarization Attention Module (PAM). With the\nextracted discriminative regression features, the Rotation Anchor Refinement\nModule (R-ARM) performs localization refinement on preset horizontal anchors to\nobtain superior rotation anchors. Next, the Dynamic Anchor Learning (DAL)\nstrategy is given to adaptively select high-quality anchors based on their\nability to capture critical features. The proposed framework creates more\npowerful semantic representations for objects in remote sensing images and\nachieves high-performance real-time object detection. Experimental results on\nthree remote sensing datasets including HRSC2016, DOTA, and UCAS-AOD show that\nour method achieves superior detection performance compared with many\nstate-of-the-art approaches. Code and models are available at\nhttps://github.com/ming71/CFC-Net.", "journal": "", "doi": "10.1109/TGRS.2021.3095186", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2101.06849v2"}
{"entry_id": "http://arxiv.org/abs/0812.3911v2", "date": "2008-12-20", "title": "Sunsets, tall buildings and the Earth's radius", "authors": "P. K. Aravind", "abstract": "It is shown how repeated observations of the sunset from various points up a\ntall building can be used to determine the Earth's radius. The same\nobservations can also be used, at some latitudes, to deduce an approximate\nvalue for the amount of atmospheric refraction at the horizon.", "journal": "", "doi": null, "primary_category": "physics.pop-ph", "categories": ["physics.pop-ph", "physics.ed-ph"], "pdf_url": "http://arxiv.org/pdf/0812.3911v2"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0204093v1", "date": "2002-04-05", "title": "Microarcsecond Radio Imaging using Earth Orbit Synthesis", "authors": "J-P Macquart, D. L. Jauncey", "abstract": "The observed interstellar scintillation pattern of an intra-day variable\nradio source is influenced by its source structure. If the velocity of the\ninterstellar medium responsible for the scattering is comparable to the\nearth's, the vector sum of these allows an observer to probe the scintillation\npattern of a source in two dimensions and, in turn, to probe two-dimensional\nsource structure on scales comparable to the angular scale of the scintillation\npattern, typically $\\sim 10 \\mu$as for weak scattering. We review the theory on\nthe extraction of an ``image'' from the scintillation properties of a source,\nand show how earth's orbital motion changes a source's observed scintillation\nproperties during the course of a year. The imaging process, which we call\nEarth Orbit Synthesis, requires measurements of the statistical properties of\nthe scintillations at epochs spread throughout the course of a year.", "journal": "", "doi": "10.1086/340433", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0204093v1"}
{"entry_id": "http://arxiv.org/abs/2301.13325v1", "date": "2023-01-30", "title": "Hybrid-Vlasov simulation of soft X-ray emissions at the Earth's dayside magnetospheric boundaries", "authors": "Maxime Grandin, Hyunju K. Connor, Sanni Hoilijoki, Markus Battarbee, Yann Pfau-Kempf, Urs Ganse, Konstantinos Papadakis, Minna Palmroth", "abstract": "Solar wind charge exchange produces emissions in the soft X-ray energy range\nwhich can enable the study of near-Earth space regions such as the\nmagnetopause, the magnetosheath and the polar cusps by remote sensing\ntechniques. The Solar wind-Magnetosphere-Ionosphere Link Explorer (SMILE) and\nLunar Environment heliospheric X-ray Imager (LEXI) missions aim to obtain soft\nX-ray images of near-Earth space thanks to their Soft X-ray Imager (SXI)\ninstruments. While earlier modeling works have already simulated soft X-ray\nimages as might be obtained by SMILE SXI during its mission, the numerical\nmodels used so far are all based on the magnetohydrodynamics description of the\nspace plasma. To investigate the possible signatures of ion-kinetic-scale\nprocesses in soft X-ray images, we use for the first time a global\nhybrid-Vlasov simulation of the geospace from the Vlasiator model. The\nsimulation is driven by fast and tenuous solar wind conditions and purely\nsouthward interplanetary magnetic field. We first produce global X-ray images\nof the dayside near-Earth space by placing a virtual imaging satellite at two\ndifferent locations, providing meridional and equatorial views. We then analyze\nregional features present in the images and show that they correspond to\nsignatures in soft X-ray emissions of mirror-mode wave structures in the\nmagnetosheath and flux transfer events (FTEs) at the magnetopause. Our results\nsuggest that, although the time scales associated with the motion of those\ntransient phenomena will likely be significantly smaller than the integration\ntime of of the SMILE and LEXI imagers, mirror-mode structures and FTEs can\ncumulatively produce detectable signatures in the soft X-ray images. [...]", "journal": "", "doi": null, "primary_category": "physics.space-ph", "categories": ["physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2301.13325v1"}
{"entry_id": "http://arxiv.org/abs/1112.4550v1", "date": "2011-12-20", "title": "Two Earth-sized planets orbiting Kepler-20", "authors": "Francois Fressin, Guillermo Torres, Jason F. Rowe, David Charbonneau, Leslie A. Rogers, Sarah Ballard, Natalie M. Batalha, William J. Borucki, Stephen T. Bryson, Lars A. Buchhave, David R. Ciardi, Jean-Michel Desert, Courtney D. Dressing, Daniel C. Fabrycky, Eric B. Ford, Thomas N. Gautier III, Christopher E. Henze, Matthew J. Holman, Andrew W. Howard, Steve B. Howell, Jon M. Jenkins, David G. Koch, David W. Latham, Jack J. Lissauer, Geoffrey W. Marcy, Samuel N. Quinn, Darin Ragozzine, Dimitar D. Sasselov, Sara Seager, Thomas Barclay, Fergal Mullally, Shawn E. Seader, Martin Still, Joseph D. Twicken, Susan E. Thompson, Kamal Uddin", "abstract": "Since the discovery of the first extrasolar giant planets around Sun-like\nstars, evolving observational capabilities have brought us closer to the\ndetection of true Earth analogues. The size of an exoplanet can be determined\nwhen it periodically passes in front of (transits) its parent star, causing a\ndecrease in starlight proportional to its radius. The smallest exoplanet\nhitherto discovered has a radius 1.42 times that of the Earth's radius (R\nEarth), and hence has 2.9 times its volume. Here we report the discovery of two\nplanets, one Earth-sized (1.03R Earth) and the other smaller than the Earth\n(0.87R Earth), orbiting the star Kepler-20, which is already known to host\nthree other, larger, transiting planets. The gravitational pull of the new\nplanets on the parent star is too small to measure with current\ninstrumentation. We apply a statistical method to show that the likelihood of\nthe planetary interpretation of the transit signals is more than three orders\nof magnitude larger than that of the alternative hypothesis that the signals\nresult from an eclipsing binary star. Theoretical considerations imply that\nthese planets are rocky, with a composition of iron and silicate. The outer\nplanet could have developed a thick water vapour atmosphere.", "journal": "", "doi": "10.1038/nature10780", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1112.4550v1"}
{"entry_id": "http://arxiv.org/abs/1404.5842v1", "date": "2014-04-23", "title": "(25143) Itokawa: The Power of Radiometric Techniques for the Interpretation of Remote Thermal Observations in the Light of the Hayabusa Rendezvous Results", "authors": "T. G. M\u00fcller, S. Hasegawa, F. Usui", "abstract": "The near-Earth asteroid (25143) Itokawa was characterised in great detail by\nthe Japanese Hayabusa mission. We revisited the available thermal observations\nin the light of the true asteroid properties with the goal to evaluate the\npossibilities and limitations of thermal model techniques. In total, we used 25\npublished ground-based mid-infrared photometric observations and 5 so far\nunpublished measurements from the Japanese infrared astronomical satellite\nAKARI in combination with improved H-G values. Our thermophysical model (TPM)\napproach allowed us to determine correctly the sense of rotation, to estimate\nthe thermal inertia and to derive robust effective size and albedo values by\nonly using a simple spherical shape model. A more complex shape model, derived\nfrom light-curve inversion techniques, improved the quality of the predictions\nconsiderably and made the interpretation of thermal light-curve possible. The\nradiometrically derived effective diameter value agrees within 2% of the true\nItokawa size value. The combination of our TPM and the final Itokawa in-situ\nshape model was then used as a benchmark for deriving and testing radiometric\nsolutions. The consolidated value for the surface-averaged thermal inertia is\n700 $\\pm$ 200 Jm$^{-2}$s$^{-0.5}$K$^{-1}$. We found that even the high\nresolution shape models still require additional small-scale roughness in order\nto explain the disk-integrated infrared measurements. Our description of the\nthermal effects as a function of wavelengths, phase angle, and rotational phase\nfacilitates the planning of crucial thermal observations for sophisticated\ncharacterization of small bodies, including other potentially hazardous\nasteroids. Our analysis shows the power of radiometric techniques to derive the\nsize, albedo, thermal inertia, and also spin-axis orientation from small sets\nof measurements at thermal infrared wavelengths.", "journal": "", "doi": "10.1093/pasj/psu034", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1404.5842v1"}
{"entry_id": "http://arxiv.org/abs/1210.7479v2", "date": "2012-10-28", "title": "Objects orbiting the Earth in deep resonance", "authors": "J. C. Sampaio, E. Wnuk, R. Vilhena de Moraes, S. S. Fernandes", "abstract": "The increasing number of objects orbiting the Earth justifies the great\nattention and interest in the observation, spacecraft protection and collision\navoidance. These studies involve different disturbances and resonances in the\norbital motions of these objects distributed by the distinct altitudes. In this\nwork, the TLE (Two-Line Elements) of the NORAD are studied observing the\nresonant period of the objects orbiting the Earth and the main resonance in the\nLEO region. The time behavior of the semi-major axis, eccentricity and\ninclination of some space debris are studied. Possible irregular motions are\nobserved by the frequency analysis and by the presence of different resonant\nangles describing the orbital dynamics of these objects.", "journal": "", "doi": null, "primary_category": "physics.space-ph", "categories": ["physics.space-ph", "astro-ph.EP", "70F15"], "pdf_url": "http://arxiv.org/pdf/1210.7479v2"}
{"entry_id": "http://arxiv.org/abs/1905.01422v8", "date": "2019-05-04", "title": "An Adaptive Remote Stochastic Gradient Method for Training Neural Networks", "authors": "Yushu Chen, Hao Jing, Wenlai Zhao, Zhiqiang Liu, Ouyi Li, Liang Qiao, Wei Xue, Guangwen Yang", "abstract": "We present the remote stochastic gradient (RSG) method, which computes the\ngradients at configurable remote observation points, in order to improve the\nconvergence rate and suppress gradient noise at the same time for different\ncurvatures. RSG is further combined with adaptive methods to construct ARSG for\nacceleration. The method is efficient in computation and memory, and is\nstraightforward to implement. We analyze the convergence properties by modeling\nthe training process as a dynamic system, which provides a guideline to select\nthe configurable observation factor without grid search. ARSG yields\n$O(1/\\sqrt{T})$ convergence rate in non-convex settings, that can be further\nimproved to $O(\\log(T)/T)$ in strongly convex settings. Numerical experiments\ndemonstrate that ARSG achieves both faster convergence and better\ngeneralization, compared with popular adaptive methods, such as ADAM, NADAM,\nAMSGRAD, and RANGER for the tested problems. In particular, for training\nResNet-50 on ImageNet, ARSG outperforms ADAM in convergence speed and meanwhile\nit surpasses SGD in generalization.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1905.01422v8"}
{"entry_id": "http://arxiv.org/abs/0911.5233v1", "date": "2009-11-27", "title": "Where can we find Super-Earths?", "authors": "E. Podlewska-Gaca, E. Szuszkiewicz", "abstract": "In recent years we have been witnessing the discovery of one extrasolar gas\ngiant after another. Now the time has come to detect more low-mass planets like\nSuper-Earths and Earth-like objects. An interesting question to ask is: where\nshould we look for them? We have explored here the possibility of finding\nSuper-Earths in the close vicinity of gas giants, as a result of the early\nevolution of planetary systems. For this purpose, we have considered a young\nplanetary system containing a Super-Earth and a gas giant, both embedded in a\nprotoplanetary disc. We have shown that, if the Super-Earth is on the internal\norbit relative to the gas giant, the planets can easily become locked in a mean\nmotion resonance. This is no longer true, however, if the Super-Earth is on the\nexternal orbit. In this case we have obtained that the low-mass planet is\ncaptured in a trap at the outer edge of the gap opened by the giant planet and\nno first order mean motion commensurabilities are expected. Our investigations\nmight be particularly useful for the observational TTV (Transit Timing\nVariation) technique.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0911.5233v1"}
{"entry_id": "http://arxiv.org/abs/0901.3203v1", "date": "2009-01-21", "title": "Clock synchronization by remote detection of correlated photon pairs", "authors": "Caleb Ho, Antia Lamas-Linares, Christian Kurtsiefer", "abstract": "We present an algorithm to detect the time and frequency difference of\nindependent clocks based on observation of time-correlated photon pairs. This\nenables remote coincidence identification in entanglement-based quantum key\ndistribution schemes without dedicated coincidence hardware, pulsed sources\nwith a timing structure or very stable reference clocks. We discuss the method\nfor typical operating conditions, and show that the requirement in reference\nclock accuracy can be relaxed by about 5 orders of magnitude in comparison with\nprevious schemes.", "journal": "New J. Phys. 11, 045011 (2009)", "doi": "10.1088/1367-2630/11/4/045011", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/0901.3203v1"}
{"entry_id": "http://arxiv.org/abs/1307.5334v1", "date": "2013-07-18", "title": "Gold nanocrescents for remotely measuring and controlling local temperature", "authors": "Xuan Hoa Vu, Michael Levy, Thomas Barroca, Hong Nhung Tran, Emmanuel Fort", "abstract": "We present a novel technique to remotely measure and control the local\ntemperature within a medium. This technique is based on the observation of the\nrotational Brownian motion of gold nanocrescent particles, which possess a\nstrong anisotropic light interaction due to their plasmonic properties.\nRotational scattering correlation spectroscopy performed on a single\nnanoparticle is able to determine the local temperature with high accuracy.\nThese nano-thermometers can simultaneously play the role of nano-heaters when\nabsorbing the light of a focused laser beam.", "journal": "2013 Nanotechnology 24 325501", "doi": "10.1088/0957-4484/24/32/325501", "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/1307.5334v1"}
{"entry_id": "http://arxiv.org/abs/1907.09320v2", "date": "2019-07-22", "title": "An Efficient Target Detection and Recognition Method in Aerial Remote-sensing Images Based on Multiangle Regions-of-Interest", "authors": "Guangcun Shan, Hongyu Wang, Wei Liang, Congcong Liu, Qizi Ma, Quan Quan", "abstract": "Recently, deep learning technology have been extensively used in the field of\nimage recognition. However, its main application is the recognition and\ndetection of ordinary pictures and common scenes. It is challenging to\neffectively and expediently analyze remote-sensing images obtained by the image\nacquisition systems on unmanned aerial vehicles (UAVs), which includes the\nidentification of the target and calculation of its position. Aerial remote\nsensing images have different shooting angles and methods compared with\nordinary pictures or images, which makes remote-sensing images play an\nirreplaceable role in some areas. In this study, a new target detection and\nrecognition method in remote-sensing images is proposed based on deep\nconvolution neural network (CNN) for the provision of multilevel information of\nimages in combination with a region proposal network used to generate\nmultiangle regions-of-interest. The proposed method generated results that were\nmuch more accurate and precise than those obtained with traditional ways. This\ndemonstrated that the model proposed herein displays tremendous applicability\npotential in remote-sensing image recognition.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.NE", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1907.09320v2"}
{"entry_id": "http://arxiv.org/abs/2106.09485v4", "date": "2021-06-17", "title": "Secure Multi-Function Computation with Private Remote Sources", "authors": "Onur G\u00fcnl\u00fc, Matthieu Bloch, Rafael F. Schaefer", "abstract": "We consider a distributed function computation problem in which parties\nobserving noisy versions of a remote source facilitate the computation of a\nfunction of their observations at a fusion center through public communication.\nThe distributed function computation is subject to constraints, including not\nonly reliability and storage but also privacy and secrecy. Specifically, 1) the\nremote source should remain private from an eavesdropper and the fusion center,\nmeasured in terms of the information leaked about the remote source; 2) the\nfunction computed should remain secret from the eavesdropper, measured in terms\nof the information leaked about the arguments of the function, to ensure\nsecrecy regardless of the exact function used. We derive the exact rate regions\nfor lossless and lossy single-function computation and illustrate the lossy\nsingle-function computation rate region for an information bottleneck example,\nin which the optimal auxiliary random variables are characterized for\nbinary-input symmetric-output channels. We extend the approach to lossless and\nlossy asynchronous multiple-function computations with joint secrecy and\nprivacy constraints, in which case inner and outer bounds for the rate regions\ndiffering only in the Markov chain conditions imposed are characterized.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.LG", "eess.SP", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2106.09485v4"}
{"entry_id": "http://arxiv.org/abs/2302.11053v1", "date": "2023-02-21", "title": "ChameleonControl: Teleoperating Real Human Surrogates through Mixed Reality Gestural Guidance for Remote Hands-on Classrooms", "authors": "Mehrad Faridan, Bheesha Kumari, Ryo Suzuki", "abstract": "We present ChameleonControl, a real-human teleoperation system for scalable\nremote instruction in hands-on classrooms. In contrast to existing video or\nAR/VR-based remote hands-on education, ChameleonControl uses a real human as a\nsurrogate of a remote instructor. Building on existing human-based telepresence\napproaches, we contribute a novel method to teleoperate a human surrogate\nthrough synchronized mixed reality hand gestural navigation and verbal\ncommunication. By overlaying the remote instructor's virtual hands in the local\nuser's MR view, the remote instructor can guide and control the local user as\nif they were physically present. This allows the local user/surrogate to\nsynchronize their hand movements and gestures with the remote instructor,\neffectively teleoperating a real human. We deploy and evaluate our system in\nclassrooms of physiotherapy training, as well as other application domains such\nas mechanical assembly, sign language and cooking lessons. The study results\nconfirm that our approach can increase engagement and the sense of co-presence,\nshowing potential for the future of remote hands-on classrooms.", "journal": "", "doi": "10.1145/3544548.3581381", "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/2302.11053v1"}
{"entry_id": "http://arxiv.org/abs/1611.06859v2", "date": "2016-11-21", "title": "Two-photon interference from remote deterministic quantum dot microlenses", "authors": "Alexander Thoma, Peter Schnauber, Jonas B\u00f6hm, Manuel Gschrey, Jan-Hindrik Schulze, Andr\u00e9 Strittmatter, Sven Rodt, Tobias Heindel, Stephan Reitzenstein", "abstract": "We report on two-photon interference (TPI) experiments using remote\ndeterministic single-photon sources. Employing 3D in-situ electron-beam\nlithography, we fabricate quantum-light sources at specific target wavelengths\nby integrating pre-selected semiconductor quantum dots within monolithic\nmicrolenses. The individual single-photon sources show TPI visibilities of 49%\nand 22%, respectively, under pulsed p-shell excitation at 80 MHz. For the\nmutual TPI of the remote sources, we observe an uncorrected visibility of 29%,\nin quantitative agreement with the pure dephasing of the individual sources.\nDue to its efficient photon extraction within a broad spectral range (> 20 nm),\nour microlens-based approach is predestinated for future entanglement swapping\nexperiments utilizing entangled photon pairs emitted by distant\nbiexciton-exciton radiative cascades.", "journal": "Applied Physics Letters 110, 011104 (2017)", "doi": "10.1063/1.4973504", "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/1611.06859v2"}
{"entry_id": "http://arxiv.org/abs/1902.03339v1", "date": "2019-02-09", "title": "Worst-case Guarantees for Remote Estimation of an Uncertain Source", "authors": "Mukul Gagrani, Yi Ouyang, Mohammad Rasouli, Ashutosh Nayyar", "abstract": "Consider a remote estimation problem where a sensor wants to communicate the\nstate of an uncertain source to a remote estimator over a finite time horizon.\nThe uncertain source is modeled as an autoregressive process with bounded\nnoise. Given that the sensor has a limited communication budget, the sensor\nmust decide when to transmit the state to the estimator who has to produce\nreal-time estimates of the source state. In this paper, we consider the problem\nof finding a scheduling strategy for the sensor and an estimation strategy for\nthe estimator to jointly minimize the worst-case maximum instantaneous\nestimation error over the time horizon. This leads to a decentralized minimax\ndecision-making problem. We obtain a complete characterization of optimal\nstrategies for this decentralized minimax problem. In particular, we show that\nan open loop communication scheduling strategy is optimal and the optimal\nestimate depends only on the most recently received sensor observation.", "journal": "", "doi": null, "primary_category": "cs.SY", "categories": ["cs.SY", "math.OC"], "pdf_url": "http://arxiv.org/pdf/1902.03339v1"}
{"entry_id": "http://arxiv.org/abs/cond-mat/0307235v1", "date": "2003-07-10", "title": "Coulomb scattering with remote continuum states in quantum dot devices", "authors": "R. Wetzler, A. Wacker, E. Sch\"oll", "abstract": "Electron capture and emission by Coulomb scattering in self-assembled quantum\ndot (QD) devices is studied theoretically. While the dependence of the Coulomb\nscattering (Auger) rates on the local wetting layer electron density has been a\ntopic of intense research, we put special interest on the remote scattering\nbetween QD electrons and continuum electrons originating from a quantum well,\ndoped bulk layers or metal contacts. Numerical effort is made to include all\nmicroscopic transitions between the Fermi distributed continuum states. The\nremote Coulomb scattering is investigated as a function of the electron\ndensity, the distance from the QDs and the temperature. Our results are\ncompared with experimental observations, considering lifetime limitations in QD\nmemory structures as well as the electron emission in pn-diodes.", "journal": "", "doi": "10.1063/1.1739284", "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/cond-mat/0307235v1"}
{"entry_id": "http://arxiv.org/abs/1808.06194v8", "date": "2018-08-19", "title": "Fast and Robust Matching for Multimodal Remote Sensing Image Registration", "authors": "Yuanxin Ye, Lorenzo Bruzzone, Jie Shan, Francesca Bovolo, Qing Zhu", "abstract": "While image registration has been studied in remote sensing community for\ndecades, registering multimodal data [e.g., optical, LiDAR, SAR, and map]\nremains a challenging problem because of significant nonlinear intensity\ndifferences between such data. To address this problem, this paper presents a\nfast and robust matching framework integrating local descriptors for multimodal\nregistration. In the proposed framework, a local descriptor, such as Histogram\nof Oriented Gradient (HOG), Local Self Similarity (LSS), or Speeded-Up Robust\nFeature (SURF), is first extracted at each pixel to form a pixel-wise feature\nrepresentation of an image. Then we define a similarity measure based on the\nfeature representation in frequency domain using the 3 Dimensional Fast Fourier\nTransform (3DFFT) technique, followed by a template matching scheme to detect\ncontrol points between images. In this procedure, we also propose a novel\npixel-wise feature representation using orientated gradients of images, which\nis named channel features of orientated gradients (CFOG). This novel feature is\nan extension of the pixel-wise HOG descriptors, and outperforms that both in\nmatching performance and computational efficiency. The major advantage of the\nproposed framework includes: (1) structural similarity representation using the\npixel-wise feature description and (2) high computational efficiency due to the\nuse of 3DFFT. Experimental results on different types of multimodal images show\nthe superior matching performance of the proposed framework than the\nstate-of-the-art methods.The proposed matching framework have been used in the\nsoftware products of a Chinese listed company. The matlab code is available in\nthis manuscript.", "journal": "", "doi": "10.1109/TGRS.2019.2924684", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1808.06194v8"}
{"entry_id": "http://arxiv.org/abs/1405.0063v5", "date": "2014-05-01", "title": "Superoscillations underlying remote state preparation for relativistic fields", "authors": "Ran Ber, Oded Kenneth, Benni Reznik", "abstract": "We present a physical (gedanken) implementation of a generalized remote state\npreparation of relativistic quantum field states for an arbitrary set of\nobservers. The prepared states are created in regions that are outside the\nfuture light-cone of the generating region. The mechanism, which is based on\nutilizing the vacuum state of a relativistic quantum field as a resource, sheds\nlight on the well known Reeh-Schlieder theorem, indicating its strong\nconnection with the mathematical phenomenon of superoscillations.", "journal": "Phys. Rev. A 91, 052312 (2015)", "doi": "10.1103/PhysRevA.91.052312", "primary_category": "quant-ph", "categories": ["quant-ph", "hep-th"], "pdf_url": "http://arxiv.org/pdf/1405.0063v5"}
{"entry_id": "http://arxiv.org/abs/2102.10216v1", "date": "2021-02-20", "title": "Stability of Remote Synchronization in Star Networks of Kuramoto Oscillators", "authors": "Yuzhen Qin, Yu Kawano, Ming Cao", "abstract": "Synchrony of neuronal ensembles is believed to facilitate information\nexchange among cortical regions in the human brain. Recently, it has been\nobserved that distant brain areas which are not directly connected by neural\nlinks also experience synchronization. Such synchronization between remote\nregions is sometimes due to the presence of a mediating region connecting them,\ne.g., \\textit{the thalamus}. The underlying network structure of this\nphenomenon is star-like and motivates us to study the \\textit{remote\nsynchronization} of Kuramoto oscillators, {modeling neural dynamics}, coupled\nby a directed star network, for which peripheral oscillators get phase\nsynchronized, remaining the accommodating central mediator at a different\nphase. We show that the symmetry of the coupling strengths of the outgoing\nlinks from the central oscillator plays a crucial role in enabling stable\nremote synchronization. We also consider the case when there is a phase shift\nin the model which results from synaptic and conduction delays. Sufficient\nconditions on the coupling strengths are obtained to ensure the stability of\nremotely synchronized states. To validate our obtained results, numerical\nsimulations are also performed.", "journal": "in Proceedings of 57th IEEE Conference on Decision and Control,\n  2018", "doi": "10.1109/CDC.2018.8619257", "primary_category": "nlin.CD", "categories": ["nlin.CD", "math.OC"], "pdf_url": "http://arxiv.org/pdf/2102.10216v1"}
{"entry_id": "http://arxiv.org/abs/2204.02308v1", "date": "2022-04-05", "title": "CalmResponses: Displaying Collective Audience Reactions in Remote Communication", "authors": "Kiyosu Maeda, Riku Arakawa, Jun Rekimoto", "abstract": "We propose a system displaying audience eye gaze and nod reactions for\nenhancing synchronous remote communication. Recently, we have had increasing\nopportunities to speak to others remotely. In contrast to offline situations,\nhowever, speakers often have difficulty observing audience reactions at once in\nremote communication, which makes them feel more anxious and less confident in\ntheir speeches. Recent studies have proposed methods of presenting various\naudience reactions to speakers. Since these methods require additional devices\nto measure audience reactions, they are not appropriate for practical\nsituations. Moreover, these methods do not present overall audience reactions.\nIn contrast, we design and develop CalmResponses, a browser-based system which\nmeasures audience eye gaze and nod reactions only with a built-in webcam and\ncollectively presents them to speakers. The results of our two user studies\nindicated that the number of fillers in speaker's speech decreases when\naudiences' eye gaze is presented, and their self-rating score increases when\naudiences' nodding is presented. Moreover, comments from audiences suggested\nbenefits of CalmResponses for them in terms of co-presence and privacy\nconcerns.", "journal": "", "doi": null, "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/2204.02308v1"}
{"entry_id": "http://arxiv.org/abs/1808.08521v1", "date": "2018-08-26", "title": "DIFET: Distributed Feature Extraction Tool For High Spatial Resolution Remote Sensing Images", "authors": "Suleyman Eken, Eray Aydin, Ahmet Sayar", "abstract": "In this paper, we propose distributed feature extraction tool from high\nspatial resolution remote sensing images. Tool is based on Apache Hadoop\nframework and Hadoop Image Processing Interface. Two corner detection (Harris\nand Shi-Tomasi) algorithms and five feature descriptors (SIFT, SURF, FAST,\nBRIEF, and ORB) are considered. Robustness of the tool in the task of feature\nextraction from LandSat-8 imageries are evaluated in terms of horizontal\nscalability.", "journal": "", "doi": "10.5194/isprs-annals-IV-4-W4-209-2017", "primary_category": "cs.DC", "categories": ["cs.DC"], "pdf_url": "http://arxiv.org/pdf/1808.08521v1"}
{"entry_id": "http://arxiv.org/abs/2009.06088v1", "date": "2020-09-13", "title": "Label-free, non-contact, in-vivo ophthalmic imaging using photoacoustic remote sensing microscopy", "authors": "Zohreh Hosseinaee, Layla Khalili, James Alex Tummon Simmons, Kevan Bell, Parsin Haji Reza", "abstract": "We present the first label-free, non-contact, in-vivo imaging of the ocular\nvasculature using photoacoustic remote sensing (PARS) microscopy. Both anterior\nand posterior segments mouse eye were imaged. Vasculature of iris, sclera and\nretina tissues were clearly resolved. To best of our knowledge this the first\nstudy showing non-contact photoacoustic imaging conducted on in-vivo ocular\ntissue. We believe that PARS microscopy has the potential to advance the\ndiagnosis and treatment of ocular diseases.", "journal": "", "doi": "10.1364/OL.410171", "primary_category": "physics.med-ph", "categories": ["physics.med-ph"], "pdf_url": "http://arxiv.org/pdf/2009.06088v1"}
{"entry_id": "http://arxiv.org/abs/1808.06538v1", "date": "2018-08-16", "title": "Some New Results on l1-Minimizing Nullspace Kalman Filtering for Remote Sensing Applications", "authors": "Otmar Loffeld, Dunja Alexandra Hage, Miguel Heredia Conde, Ling Wang", "abstract": "This paper describes some new results on recursive l_1-minimizing by Kalman\nfiltering. We consider the l_1-norm as an explicit constraint, formulated as a\nnonlinear observation of the state to be estimated. Interpretiing a sparse\nvector to be estimated as a state which is observed from erroneous\n(undersampled) measurements we can address time- and space-variant sparsity,\nany kind of a priori information and also easily address nonstationary error\ninfluences in the measurements available. Inherently in our approach we move\nslightly away from the classical RIP-based approaches to a more intuitive\nunderstanding of the structure of the nullspace which is implicitly related to\nthe well understood engineering concepts of deterministic and stochastic\nobservability in estimation theory", "journal": "", "doi": null, "primary_category": "eess.SP", "categories": ["eess.SP"], "pdf_url": "http://arxiv.org/pdf/1808.06538v1"}
{"entry_id": "http://arxiv.org/abs/0805.0100v3", "date": "2008-05-01", "title": "Basic Mechanics of Planet-Satellite Interaction with special reference to Earth-Moon System", "authors": "Bijay Kumar Sharma", "abstract": "In1879 George Howard Darwin theoretically analyzed the outward spiraling\norbit of Moon and the subsequent lengthening of the Mean Solar Day. The author\nredid the same analysis based on the fact that Moon was receding at the rate of\n3.8 cm per annum. Basic Mechanics of Earth-Moon is worked out and various\nsystem parameters are optimized to fit the given boundary condition obtained by\nApollo Mission and other modern means of observations. Based on this\ntheoretical formulation the theoretical graph of the lengthening of the Mean\nSolar Day with respect to time is drawn and is compared with the observational\ngraph of the same based on pale ontological data, paleo tidal data and\niron-banded formation. The observational data on Mean Solar Day is found to\nfollow the theoretical smooth curve in post-Cambrian Era but is found to\ndeviate in the remote past. This deviation is corrected by taking the evolving\nform of Moment of Inertia of Earth. The deviation of the observed data prompts\nthe Author to suggest that the lengthening of the Mean Solar Day curve could\npossibly be used as an analytical seismograph for the impending earthquakes and\nsudden volcanic eruptions. The Basic Mechanics of E-M system is generalized to\nlay the foundation of simulation software for any Planet-Satellite pair in our\nSolar System.", "journal": "", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0805.0100v3"}
{"entry_id": "http://arxiv.org/abs/2110.01910v1", "date": "2021-10-05", "title": "Remote and Rural Connectivity: Infrastructure and Resource Sharing Principles", "authors": "Thembelihle Dlamini, Sifiso Vilakati", "abstract": "As Mobile Networks (MNs) are advancing towards meeting mobile users\nrequirements, the rural-urban divide still remains a major challenge. While\nareas within the urban space (metropolitan mobile space) are being developed,\nrural areas are left behind. Due to challenges of low population density, low\nincome, difficult terrain, non-existent infrastructure, lack of power grid,\nremote areas have low digital penetration. This situation makes remote areas\nless attractive towards investments and to operate connectivity networks, thus\nfailing to achieve universal access to the Internet. In addressing this issue,\nthis paper proposes a new BS deployment and resource management method for\nremote and rural areas. Here, two MN operators share their resources towards\nthe procurement and deployment of green energy-powered BSs equipped with\ncomputing capabilities. Then, the network infrastructure is shared between the\nmobile operators, with the main goal of enabling energy-efficient\ninfrastructure sharing, i.e., BS and its co-located computing platform. Using\nthis resource management strategy in rural communication sites guarantees a\nQuality of Service (QoS) comparable to that of urban communication sites. The\nperformance evaluation conducted through simulations validates our analysis as\nthe prediction variations observed shows greater accuracy between the harvested\nenergy and the traffic load. Also, the energy savings decrease as the number of\nmobile users (50 users in our case) connected to the remote site increases.\nLastly, the proposed algorithm achieves 51% energy savings when compared with\nthe 43% obtained by our benchmark algorithm. The proposed method demonstrates\nsuperior performance over the benchmark algorithm as it uses foresighted\noptimization where the harvested energy and the expected load are predicted\nover a given short-term horizon.", "journal": "", "doi": null, "primary_category": "cs.NI", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf_url": "http://arxiv.org/pdf/2110.01910v1"}
{"entry_id": "http://arxiv.org/abs/1912.10726v1", "date": "2019-12-23", "title": "Extracting urban water by combining deep learning and Google Earth Engine", "authors": "Y. D. Wang, Z. W. Li, C. Zeng, G. S. Xia, H. F. Shen", "abstract": "Urban water is important for the urban ecosystem. Accurate and efficient\ndetection of urban water with remote sensing data is of great significance for\nurban management and planning. In this paper, we proposed a new method to\ncombine Google Earth Engine (GEE) with multiscale convolutional neural network\n(MSCNN) to extract urban water from Landsat images, which is summarized as\noffline training and online prediction (OTOP). That is, the training of MSCNN\nwas completed offline, and the process of urban water extraction was\nimplemented on GEE with the trained parameters of MSCNN. The OTOP can give full\nplay to the respective advantages of GEE and CNN, and make the use of deep\nlearning method on GEE more flexible. It can process available satellite images\nwith high performance without data download and storage, and the overall\nperformance of urban water extraction is also higher than that of the modified\nnormalized difference water index (MNDWI) and random forest. The mean kappa,\nF1-score and intersection over union (IoU) of urban water extraction with the\nOTOP in Changchun, Wuhan, Kunming and Guangzhou reached 0.924, 0.930 and 0.869,\nrespectively. The results of the extended validation in the other major cities\nof China also show that the OTOP is robust and can be used to extract different\ntypes of urban water, which benefits from the structural design and training of\nthe MSCNN. Therefore, the OTOP is especially suitable for the study of\nlarge-scale and long-term urban water change detection in the background of\nurbanization.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1912.10726v1"}
{"entry_id": "http://arxiv.org/abs/1303.6619v1", "date": "2013-03-26", "title": "An N-dimensional approach towards object based classification of remotely sensed imagery", "authors": "Arun p V, S. K. Katiyar", "abstract": "Remote sensing techniques are widely used for land cover classification and\nurban analysis. The availability of high resolution remote sensing imagery\nlimits the level of classification accuracy attainable from pixel-based\napproach. In this paper object-based classification scheme based on a\nhierarchical support vector machine is introduced. By combining spatial and\nspectral information, the amount of overlap between classes can be decreased;\nthereby yielding higher classification accuracy and more accurate land cover\nmaps. We have adopted certain automatic approaches based on the advanced\ntechniques as Cellular automata and Genetic Algorithm for kernel and tuning\nparameter selection. Performance evaluation of the proposed methodology in\ncomparison with the existing approaches is performed with reference to the\nBhopal city study area.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1303.6619v1"}
{"entry_id": "http://arxiv.org/abs/1602.01517v1", "date": "2016-02-04", "title": "Towards Better Exploiting Convolutional Neural Networks for Remote Sensing Scene Classification", "authors": "Keiller Nogueira, Ot\u00e1vio A. B. Penatti, Jefersson A. dos Santos", "abstract": "We present an analysis of three possible strategies for exploiting the power\nof existing convolutional neural networks (ConvNets) in different scenarios\nfrom the ones they were trained: full training, fine tuning, and using ConvNets\nas feature extractors. In many applications, especially including remote\nsensing, it is not feasible to fully design and train a new ConvNet, as this\nusually requires a considerable amount of labeled data and demands high\ncomputational costs. Therefore, it is important to understand how to obtain the\nbest profit from existing ConvNets. We perform experiments with six popular\nConvNets using three remote sensing datasets. We also compare ConvNets in each\nstrategy with existing descriptors and with state-of-the-art baselines. Results\npoint that fine tuning tends to be the best performing strategy. In fact, using\nthe features from the fine-tuned ConvNet with linear SVM obtains the best\nresults. We also achieved state-of-the-art results for the three datasets used.", "journal": "", "doi": "10.1016/j.patcog.2016.07.001", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1602.01517v1"}
{"entry_id": "http://arxiv.org/abs/1704.02162v2", "date": "2017-04-07", "title": "Locally-adapted convolution-based super-resolution of irregularly-sampled ocean remote sensing data", "authors": "Manuel L\u00f3pez-Radcenco, Ronan Fablet, Abdeldjalil A\u00efssa-El-Bey, Pierre Ailliot", "abstract": "Super-resolution is a classical problem in image processing, with numerous\napplications to remote sensing image enhancement. Here, we address the\nsuper-resolution of irregularly-sampled remote sensing images. Using an optimal\ninterpolation as the low-resolution reconstruction, we explore locally-adapted\nmultimodal convolutional models and investigate different dictionary-based\ndecompositions, namely based on principal component analysis (PCA), sparse\npriors and non-negativity constraints. We consider an application to the\nreconstruction of sea surface height (SSH) fields from two information sources,\nalong-track altimeter data and sea surface temperature (SST) data. The reported\nexperiments demonstrate the relevance of the proposed model, especially\nlocally-adapted parametrizations with non-negativity constraints, to outperform\noptimally-interpolated reconstructions.", "journal": "", "doi": null, "primary_category": "stat.ML", "categories": ["stat.ML"], "pdf_url": "http://arxiv.org/pdf/1704.02162v2"}
{"entry_id": "http://arxiv.org/abs/1712.09809v1", "date": "2017-12-28", "title": "A Multi-Scale and Multi-Depth Convolutional Neural Network for Remote Sensing Imagery Pan-Sharpening", "authors": "Qiangqiang Yuan, Yancong Wei, Xiangchao Meng, Huanfeng Shen, Liangpei Zhang", "abstract": "Pan-sharpening is a fundamental and significant task in the field of remote\nsensing imagery processing, in which high-resolution spatial details from\npanchromatic images are employed to enhance the spatial resolution of\nmulti-spectral (MS) images. As the transformation from low spatial resolution\nMS image to high-resolution MS image is complex and highly non-linear, inspired\nby the powerful representation for non-linear relationships of deep neural\nnetworks, we introduce multi-scale feature extraction and residual learning\ninto the basic convolutional neural network (CNN) architecture and propose the\nmulti-scale and multi-depth convolutional neural network (MSDCNN) for the\npan-sharpening of remote sensing imagery. Both the quantitative assessment\nresults and the visual assessment confirm that the proposed network yields\nhigh-resolution MS images that are superior to the images produced by the\ncompared state-of-the-art methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1712.09809v1"}
{"entry_id": "http://arxiv.org/abs/1803.04048v2", "date": "2018-03-11", "title": "Multiple Instance Choquet Integral Classifier Fusion and Regression for Remote Sensing Applications", "authors": "Xiaoxiao Du, Alina Zare", "abstract": "In classifier (or regression) fusion the aim is to combine the outputs of\nseveral algorithms to boost overall performance. Standard supervised fusion\nalgorithms often require accurate and precise training labels. However,\naccurate labels may be difficult to obtain in many remote sensing applications.\nThis paper proposes novel classification and regression fusion models that can\nbe trained given ambiguosly and imprecisely labeled training data in which\ntraining labels are associated with sets of data points (i.e., \"bags\") instead\nof individual data points (i.e., \"instances\") following a multiple instance\nlearning framework. Experiments were conducted based on the proposed algorithms\non both synthetic data and applications such as target detection and crop yield\nprediction given remote sensing data. The proposed algorithms show effective\nclassification and regression performance.", "journal": "", "doi": "10.1109/TGRS.2018.2876687", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1803.04048v2"}
{"entry_id": "http://arxiv.org/abs/1804.00256v1", "date": "2018-04-01", "title": "One-Two-One Networks for Compression Artifacts Reduction in Remote Sensing", "authors": "Baochang Zhang, Jiaxin Gu, Chen Chen, Jungong Han, Xiangbo Su, Xianbin Cao, Jianzhuang Liu", "abstract": "Compression artifacts reduction (CAR) is a challenging problem in the field\nof remote sensing. Most recent deep learning based methods have demonstrated\nsuperior performance over the previous hand-crafted methods. In this paper, we\npropose an end-to-end one-two-one (OTO) network, to combine different deep\nmodels, i.e., summation and difference models, to solve the CAR problem.\nParticularly, the difference model motivated by the Laplacian pyramid is\ndesigned to obtain the high frequency information, while the summation model\naggregates the low frequency information. We provide an in-depth investigation\ninto our OTO architecture based on the Taylor expansion, which shows that these\ntwo kinds of information can be fused in a nonlinear scheme to gain more\ncapacity of handling complicated image compression artifacts, especially the\nblocking effect in compression. Extensive experiments are conducted to\ndemonstrate the superior performance of the OTO networks, as compared to the\nstate-of-the-arts on remote sensing datasets and other benchmark datasets.", "journal": "", "doi": "10.1016/j.isprsjprs.2018.01.003", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1804.00256v1"}
{"entry_id": "http://arxiv.org/abs/1905.06306v1", "date": "2019-05-01", "title": "A multiple-frame approach of crop yield estimation from satellite remotely sensed data", "authors": "Sumanta Kumar Das, Randhir Singh", "abstract": "Many studies have recently explored the information from the\nsatellite-remotely sensed data (SRSD) for estimating the crop production\nstatistics. The value of this information depends on the aerial and spatial\nresolutions of SRSD. The SRSD with fine spatial resolution is costly and the\naerial coverage is less. Use of multiple frames of SRSD in the estimation\nprocess of crop production can increase the precision. We propose an estimator\nfor the average yield of wheat for the state of Haryana, India. This estimator\nuses the information from the Wide Field Sensor (WiFS) and the Linear Imaging\nSelf Scanner (LISS-III) data from the Indian Remote Sensing satellite (IRS-1D)\nand the crop cutting experiment data collected by probability sampling design\nfrom a list frame of villages. We find that the relative efficiencies of the\nmultiple-frame estimators are high in comparison to the single frame\nestimators.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP", "stat.ME"], "pdf_url": "http://arxiv.org/pdf/1905.06306v1"}
{"entry_id": "http://arxiv.org/abs/1905.07877v1", "date": "2019-05-20", "title": "Procedural Synthesis of Remote Sensing Images for Robust Change Detection with Neural Networks", "authors": "Maria Kolos, Anton Marin, Alexey Artemov, Evgeny Burnaev", "abstract": "Data-driven methods such as convolutional neural networks (CNNs) are known to\ndeliver state-of-the-art performance on image recognition tasks when the\ntraining data are abundant. However, in some instances, such as change\ndetection in remote sensing images, annotated data cannot be obtained in\nsufficient quantities. In this work, we propose a simple and efficient method\nfor creating realistic targeted synthetic datasets in the remote sensing\ndomain, leveraging the opportunities offered by game development engines. We\nprovide a description of the pipeline for procedural geometry generation and\nrendering as well as an evaluation of the efficiency of produced datasets in a\nchange detection scenario. Our evaluations demonstrate that our pipeline helps\nto improve the performance and convergence of deep learning models when the\namount of real-world data is severely limited.", "journal": "16th International Symposium on Neural Networks, ISNN 2019", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1905.07877v1"}
{"entry_id": "http://arxiv.org/abs/2102.02531v1", "date": "2021-02-04", "title": "ABCNet: Attentive Bilateral Contextual Network for Efficient Semantic Segmentation of Fine-Resolution Remote Sensing Images", "authors": "Rui Li, Chenxi Duan", "abstract": "Semantic segmentation of remotely sensed images plays a crucial role in\nprecision agriculture, environmental protection, and economic assessment. In\nrecent years, substantial fine-resolution remote sensing images are available\nfor semantic segmentation. However, due to the complicated information caused\nby the increased spatial resolution, state-of-the-art deep learning algorithms\nnormally utilize complex network architectures for segmentation, which usually\nincurs high computational complexity. Specifically, the high-caliber\nperformance of the convolutional neural network (CNN) heavily relies on\nfine-grained spatial details (fine resolution) and sufficient contextual\ninformation (large receptive fields), both of which trigger high computational\ncosts. This crucially impedes their practicability and availability in\nreal-world scenarios that require real-time processing. In this paper, we\npropose an Attentive Bilateral Contextual Network (ABCNet), a convolutional\nneural network (CNN) with double branches, with prominently lower computational\nconsumptions compared to the cutting-edge algorithms, while maintaining a\ncompetitive accuracy. Code is available at https://github.com/lironui/ABCNet.", "journal": "", "doi": "10.1016/j.isprsjprs.2021.09.005", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2102.02531v1"}
{"entry_id": "http://arxiv.org/abs/2102.13392v3", "date": "2021-02-26", "title": "Unifying Remote Sensing Image Retrieval and Classification with Robust Fine-tuning", "authors": "Dimitri Gominski, Val\u00e9rie Gouet-Brunet, Liming Chen", "abstract": "Advances in high resolution remote sensing image analysis are currently\nhampered by the difficulty of gathering enough annotated data for training deep\nlearning methods, giving rise to a variety of small datasets and associated\ndataset-specific methods. Moreover, typical tasks such as classification and\nretrieval lack a systematic evaluation on standard benchmarks and training\ndatasets, which make it hard to identify durable and generalizable scientific\ncontributions. We aim at unifying remote sensing image retrieval and\nclassification with a new large-scale training and testing dataset, SF300,\nincluding both vertical and oblique aerial images and made available to the\nresearch community, and an associated fine-tuning method. We additionally\npropose a new adversarial fine-tuning method for global descriptors. We show\nthat our framework systematically achieves a boost of retrieval and\nclassification performance on nine different datasets compared to an ImageNet\npretrained baseline, with currently no other method to compare to.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.IR"], "pdf_url": "http://arxiv.org/pdf/2102.13392v3"}
{"entry_id": "http://arxiv.org/abs/2105.04951v2", "date": "2021-05-11", "title": "Task-Related Self-Supervised Learning for Remote Sensing Image Change Detection", "authors": "Zhinan Cai, Zhiyu Jiang, Yuan Yuan", "abstract": "Change detection for remote sensing images is widely applied for urban change\ndetection, disaster assessment and other fields. However, most of the existing\nCNN-based change detection methods still suffer from the problem of inadequate\npseudo-changes suppression and insufficient feature representation. In this\nwork, an unsupervised change detection method based on Task-related\nSelf-supervised Learning Change Detection network with smooth mechanism(TSLCD)\nis proposed to eliminate it. The main contributions include: (1) the\ntask-related self-supervised learning module is introduced to extract spatial\nfeatures more effectively. (2) a hard-sample-mining loss function is applied to\npay more attention to the hard-to-classify samples. (3) a smooth mechanism is\nutilized to remove some of pseudo-changes and noise. Experiments on four remote\nsensing change detection datasets reveal that the proposed TSLCD method\nachieves the state-of-the-art for change detection task.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2105.04951v2"}
{"entry_id": "http://arxiv.org/abs/2105.10459v1", "date": "2020-11-24", "title": "Research on Regional Urban Economic Development by Nightlight-time Remote Sensing", "authors": "Jiongyan Zhang", "abstract": "In order to study the phenomenon of regional economic development and urban\nexpansion from the perspective of night-light remote sensing images,\nresearchers use NOAA-provided night-light remote sensing image data (data from\n1992 to 2013) along with ArcGIS software to process image information, obtain\nthe basic pixel information data of specific areas of the image, and analyze\nthese data from the space-time domain for presentation of the trend of regional\neconomic development in China in recent years, and tries to explore the\nurbanization effect brought by the rapid development of China's economy.\nThrough the analysis and study of the data, the results show that the\nurbanization development speed in China is still at its peak, and has great\ndevelopment potential and space. But at the same time, people also need to pay\nattention to the imbalance of regional development.", "journal": "", "doi": null, "primary_category": "econ.GN", "categories": ["econ.GN", "eess.IV", "q-fin.EC"], "pdf_url": "http://arxiv.org/pdf/2105.10459v1"}
{"entry_id": "http://arxiv.org/abs/2108.07002v2", "date": "2021-08-16", "title": "Change is Everywhere: Single-Temporal Supervised Object Change Detection in Remote Sensing Imagery", "authors": "Zhuo Zheng, Ailong Ma, Liangpei Zhang, Yanfei Zhong", "abstract": "For high spatial resolution (HSR) remote sensing images, bitemporal\nsupervised learning always dominates change detection using many pairwise\nlabeled bitemporal images. However, it is very expensive and time-consuming to\npairwise label large-scale bitemporal HSR remote sensing images. In this paper,\nwe propose single-temporal supervised learning (STAR) for change detection from\na new perspective of exploiting object changes in unpaired images as\nsupervisory signals. STAR enables us to train a high-accuracy change detector\nonly using \\textbf{unpaired} labeled images and generalize to real-world\nbitemporal images. To evaluate the effectiveness of STAR, we design a simple\nyet effective change detector called ChangeStar, which can reuse any deep\nsemantic segmentation architecture by the ChangeMixin module. The comprehensive\nexperimental results show that ChangeStar outperforms the baseline with a large\nmargin under single-temporal supervision and achieves superior performance\nunder bitemporal supervision. Code is available at\nhttps://github.com/Z-Zheng/ChangeStar", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2108.07002v2"}
{"entry_id": "http://arxiv.org/abs/2109.11848v1", "date": "2021-09-24", "title": "How to find a good image-text embedding for remote sensing visual question answering?", "authors": "Christel Chappuis, Sylvain Lobry, Benjamin Kellenberger, Bertrand Le Saux, Devis Tuia", "abstract": "Visual question answering (VQA) has recently been introduced to remote\nsensing to make information extraction from overhead imagery more accessible to\neveryone. VQA considers a question (in natural language, therefore easy to\nformulate) about an image and aims at providing an answer through a model based\non computer vision and natural language processing methods. As such, a VQA\nmodel needs to jointly consider visual and textual features, which is\nfrequently done through a fusion step. In this work, we study three different\nfusion methodologies in the context of VQA for remote sensing and analyse the\ngains in accuracy with respect to the model complexity. Our findings indicate\nthat more complex fusion mechanisms yield an improved performance, yet that\nseeking a trade-of between model complexity and performance is worthwhile in\npractice.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2109.11848v1"}
{"entry_id": "http://arxiv.org/abs/2203.04445v1", "date": "2022-03-08", "title": "Self-Supervision, Remote Sensing and Abstraction: Representation Learning Across 3 Million Locations", "authors": "Sachith Seneviratne, Kerry A. Nice, Jasper S. Wijnands, Mark Stevenson, Jason Thompson", "abstract": "Self-supervision based deep learning classification approaches have received\nconsiderable attention in academic literature. However, the performance of such\nmethods on remote sensing imagery domains remains under-explored. In this work,\nwe explore contrastive representation learning methods on the task of\nimagery-based city classification, an important problem in urban computing. We\nuse satellite and map imagery across 2 domains, 3 million locations and more\nthan 1500 cities. We show that self-supervised methods can build a\ngeneralizable representation from as few as 200 cities, with representations\nachieving over 95\\% accuracy in unseen cities with minimal additional training.\nWe also find that the performance discrepancy of such methods, when compared to\nsupervised methods, induced by the domain discrepancy between natural imagery\nand abstract imagery is significant for remote sensing imagery. We compare all\nanalysis against existing supervised models from academic literature and\nopen-source our models for broader usage and further criticism.", "journal": "", "doi": "10.1109/DICTA52665.2021.9647061", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2203.04445v1"}
{"entry_id": "http://arxiv.org/abs/2204.00260v1", "date": "2022-04-01", "title": "MS-HLMO: Multi-scale Histogram of Local Main Orientation for Remote Sensing Image Registration", "authors": "Chenzhong Gao, Wei Li, Ran Tao, Qian Du", "abstract": "Multi-source image registration is challenging due to intensity, rotation,\nand scale differences among the images. Considering the characteristics and\ndifferences of multi-source remote sensing images, a feature-based registration\nalgorithm named Multi-scale Histogram of Local Main Orientation (MS-HLMO) is\nproposed. Harris corner detection is first adopted to generate feature points.\nThe HLMO feature of each Harris feature point is extracted on a Partial Main\nOrientation Map (PMOM) with a Generalized Gradient Location and Orientation\nHistogram-like (GGLOH) feature descriptor, which provides high intensity,\nrotation, and scale invariance. The feature points are matched through a\nmulti-scale matching strategy. Comprehensive experiments on 17 multi-source\nremote sensing scenes demonstrate that the proposed MS-HLMO and its simplified\nversion MS-HLMO$^+$ outperform other competitive registration algorithms in\nterms of effectiveness and generalization.", "journal": "", "doi": "10.1109/TGRS.2022.3193109", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.00260v1"}
{"entry_id": "http://arxiv.org/abs/2211.02820v2", "date": "2022-11-05", "title": "A Robust and Low Complexity Deep Learning Model for Remote Sensing Image Classification", "authors": "Cam Le, Lam Pham, Nghia NVN, Truong Nguyen, Le Hong Trang", "abstract": "In this paper, we present a robust and low complexity deep learning model for\nRemote Sensing Image Classification (RSIC), the task of identifying the scene\nof a remote sensing image. In particular, we firstly evaluate different low\ncomplexity and benchmark deep neural networks: MobileNetV1, MobileNetV2,\nNASNetMobile, and EfficientNetB0, which present the number of trainable\nparameters lower than 5 Million (M). After indicating best network\narchitecture, we further improve the network performance by applying attention\nschemes to multiple feature maps extracted from middle layers of the network.\nTo deal with the issue of increasing the model footprint as using attention\nschemes, we apply the quantization technique to satisfy the maximum of 20 MB\nmemory occupation. By conducting extensive experiments on the benchmark\ndatasets NWPU-RESISC45, we achieve a robust and low-complexity model, which is\nvery competitive to the state-of-the-art systems and potential for real-life\napplications on edge devices.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2211.02820v2"}
{"entry_id": "http://arxiv.org/abs/2211.04767v1", "date": "2022-11-09", "title": "Multimodal Remote Sensing Image Registration Based on Adaptive Multi-scale PIIFD", "authors": "Ning Li, Yuxuan Li, Jichao jiao", "abstract": "In recent years, due to the wide application of multi-sensor vision systems,\nmultimodal image acquisition technology has continued to develop, and the\nregistration problem based on multimodal images has gradually emerged. Most of\nthe existing multimodal image registration methods are only suitable for two\nmodalities, and cannot uniformly register multiple modal image data. Therefore,\nthis paper proposes a multimodal remote sensing image registration method based\non adaptive multi-scale PIIFD(AM-PIIFD). This method extracts KAZE features,\nwhich can effectively retain edge feature information while filtering noise.\nThen adaptive multi-scale PIIFD is calculated for matching. Finally, the\nmismatch is removed through the consistency of the feature main direction, and\nthe image alignment transformation is realized. The qualitative and\nquantitative comparisons with other three advanced methods shows that our\nmethod can achieve excellent performance in multimodal remote sensing image\nregistration.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2211.04767v1"}
{"entry_id": "http://arxiv.org/abs/2302.13028v1", "date": "2023-02-25", "title": "A Light-weight Deep Learning Model for Remote Sensing Image Classification", "authors": "Lam Pham, Cam Le, Dat Ngo, Anh Nguyen, Jasmin Lampert, Alexander Schindler, Ian McLoughlin", "abstract": "In this paper, we present a high-performance and light-weight deep learning\nmodel for Remote Sensing Image Classification (RSIC), the task of identifying\nthe aerial scene of a remote sensing image. To this end, we first valuate\nvarious benchmark convolutional neural network (CNN) architectures: MobileNet\nV1/V2, ResNet 50/151V2, InceptionV3/InceptionResNetV2, EfficientNet B0/B7,\nDenseNet 121/201, ConNeXt Tiny/Large. Then, the best performing models are\nselected to train a compact model in a teacher-student arrangement. The\nknowledge distillation from the teacher aims to achieve high performance with\nsignificantly reduced complexity. By conducting extensive experiments on the\nNWPU-RESISC45 benchmark, our proposed teacher-student models outperforms the\nstate-of-the-art systems, and has potential to be applied on a wide rage of\nedge devices.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2302.13028v1"}
{"entry_id": "http://arxiv.org/abs/1804.01982v1", "date": "2018-04-05", "title": "Multiparty quantum data hiding with enhanced security and remote deletion", "authors": "Xingyao Wu, Jianxin Chen", "abstract": "One of the applications of quantum technology is to use quantum states and\nmeasurements to communicate which offers more reliable security promises.\nQuantum data hiding, which gives the source party the ability of sharing data\namong multiple receivers and revealing it at a later time depending on his/her\nwill, is one of the promising information sharing schemes which may address\npractical security issues. In this work, we propose a novel quantum data hiding\nprotocol. By concatenating different subprotocols which apply to rather\nsymmetric hiding scenarios, we cover a variety of more general hiding\nscenarios. We provide the general requirements for constructing such protocols\nand give explicit examples of encoding states for five parties. We also proved\nthe security of the protocol in sense that the achievable information by\nunauthorized operations asymptotically goes to zero. In addition, due to the\ncapability of the sender to manipulate his/her subsystem, the sender is able to\nabort the protocol remotely at any time before he/she reveals the information.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1804.01982v1"}
{"entry_id": "http://arxiv.org/abs/1703.00121v1", "date": "2017-03-01", "title": "Remote Sensing Image Scene Classification: Benchmark and State of the Art", "authors": "Gong Cheng, Junwei Han, Xiaoqiang Lu", "abstract": "Remote sensing image scene classification plays an important role in a wide\nrange of applications and hence has been receiving remarkable attention. During\nthe past years, significant efforts have been made to develop various datasets\nor present a variety of approaches for scene classification from remote sensing\nimages. However, a systematic review of the literature concerning datasets and\nmethods for scene classification is still lacking. In addition, almost all\nexisting datasets have a number of limitations, including the small scale of\nscene classes and the image numbers, the lack of image variations and\ndiversity, and the saturation of accuracy. These limitations severely limit the\ndevelopment of new approaches especially deep learning-based methods. This\npaper first provides a comprehensive review of the recent progress. Then, we\npropose a large-scale dataset, termed \"NWPU-RESISC45\", which is a publicly\navailable benchmark for REmote Sensing Image Scene Classification (RESISC),\ncreated by Northwestern Polytechnical University (NWPU). This dataset contains\n31,500 images, covering 45 scene classes with 700 images in each class. The\nproposed NWPU-RESISC45 (i) is large-scale on the scene classes and the total\nimage number, (ii) holds big variations in translation, spatial resolution,\nviewpoint, object pose, illumination, background, and occlusion, and (iii) has\nhigh within-class diversity and between-class similarity. The creation of this\ndataset will enable the community to develop and evaluate various data-driven\nalgorithms. Finally, several representative methods are evaluated using the\nproposed dataset and the results are reported as a useful baseline for future\nresearch.", "journal": "Proceedings of the IEEE, 105 (10): 1865-1883, 2017", "doi": "10.1109/JPROC.2017.2675998", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1703.00121v1"}
{"entry_id": "http://arxiv.org/abs/1805.12219v3", "date": "2018-05-30", "title": "Tiling and Stitching Segmentation Output for Remote Sensing: Basic Challenges and Recommendations", "authors": "Bohao Huang, Daniel Reichman, Leslie M. Collins, Kyle Bradbury, Jordan M. Malof", "abstract": "In this work we consider the application of convolutional neural networks\n(CNNs) for pixel-wise labeling (a.k.a., semantic segmentation) of remote\nsensing imagery (e.g., aerial color or hyperspectral imagery). Remote sensing\nimagery is usually stored in the form of very large images, referred to as\n\"tiles\", which are too large to be segmented directly using most CNNs and their\nassociated hardware. As a result, during label inference, smaller sub-images,\ncalled \"patches\", are processed individually and then \"stitched\" (concatenated)\nback together to create a tile-sized label map. This approach suffers from\ncomputational ineffiency and can result in discontinuities at output\nboundaries. We propose a simple alternative approach in which the input size of\nthe CNN is dramatically increased only during label inference. This does not\navoid stitching altogether, but substantially mitigates its limitations. We\nevaluate the performance of the proposed approach against a vonventional\nstitching approach using two popular segmentation CNN models and two\nlarge-scale remote sensing imagery datasets. The results suggest that the\nproposed approach substantially reduces label inference time, while also\nyielding modest overall label accuracy increases. This approach contributed to\nour wining entry (overall performance) in the INRIA building labeling\ncompetition.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1805.12219v3"}
{"entry_id": "http://arxiv.org/abs/2007.03107v2", "date": "2020-07-06", "title": "Multi-image Super Resolution of Remotely Sensed Images using Residual Feature Attention Deep Neural Networks", "authors": "Francesco Salvetti, Vittorio Mazzia, Aleem Khaliq, Marcello Chiaberge", "abstract": "Convolutional Neural Networks (CNNs) have been consistently proved\nstate-of-the-art results in image Super-Resolution (SR), representing an\nexceptional opportunity for the remote sensing field to extract further\ninformation and knowledge from captured data. However, most of the works\npublished in the literature have been focusing on the Single-Image\nSuper-Resolution problem so far. At present, satellite based remote sensing\nplatforms offer huge data availability with high temporal resolution and low\nspatial resolution. In this context, the presented research proposes a novel\nresidual attention model (RAMS) that efficiently tackles the multi-image\nsuper-resolution task, simultaneously exploiting spatial and temporal\ncorrelations to combine multiple images. We introduce the mechanism of visual\nfeature attention with 3D convolutions in order to obtain an aware data fusion\nand information extraction of the multiple low-resolution images, transcending\nlimitations of the local region of convolutional operations. Moreover, having\nmultiple inputs with the same scene, our representation learning network makes\nextensive use of nestled residual connections to let flow redundant\nlow-frequency signals and focus the computation on more important\nhigh-frequency components. Extensive experimentation and evaluations against\nother available solutions, either for single or multi-image super-resolution,\nhave demonstrated that the proposed deep learning-based solution can be\nconsidered state-of-the-art for Multi-Image Super-Resolution for remote sensing\napplications.", "journal": "Remote Sens. 2020, 12(14), 2207", "doi": "10.3390/rs12142207", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2007.03107v2"}
{"entry_id": "http://arxiv.org/abs/2008.12470v1", "date": "2020-08-28", "title": "Counting from Sky: A Large-scale Dataset for Remote Sensing Object Counting and A Benchmark Method", "authors": "Guangshuai Gao, Qingjie Liu, Yunhong Wang", "abstract": "Object counting, whose aim is to estimate the number of objects from a given\nimage, is an important and challenging computation task. Significant efforts\nhave been devoted to addressing this problem and achieved great progress, yet\ncounting the number of ground objects from remote sensing images is barely\nstudied. In this paper, we are interested in counting dense objects from remote\nsensing images. Compared with object counting in a natural scene, this task is\nchallenging in the following factors: large scale variation, complex cluttered\nbackground, and orientation arbitrariness. More importantly, the scarcity of\ndata severely limits the development of research in this field. To address\nthese issues, we first construct a large-scale object counting dataset with\nremote sensing images, which contains four important geographic objects:\nbuildings, crowded ships in harbors, large-vehicles and small-vehicles in\nparking lots. We then benchmark the dataset by designing a novel neural network\nthat can generate a density map of an input image. The proposed network\nconsists of three parts namely attention module, scale pyramid module and\ndeformable convolution module to attack the aforementioned challenging factors.\nExtensive experiments are performed on the proposed dataset and one crowd\ncounting datset, which demonstrate the challenges of the proposed dataset and\nthe superiority and effectiveness of our method compared with state-of-the-art\nmethods.", "journal": "", "doi": "10.1109/TGRS.2020.3020555", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.12470v1"}
{"entry_id": "http://arxiv.org/abs/2010.00882v1", "date": "2020-10-02", "title": "Remote Sensing Image Scene Classification with Self-Supervised Paradigm under Limited Labeled Samples", "authors": "Chao Tao, Ji Qi, Weipeng Lu, Hao Wang, Haifeng Li", "abstract": "With the development of deep learning, supervised learning methods perform\nwell in remote sensing images (RSIs) scene classification. However, supervised\nlearning requires a huge number of annotated data for training. When labeled\nsamples are not sufficient, the most common solution is to fine-tune the\npre-training models using a large natural image dataset (e.g. ImageNet).\nHowever, this learning paradigm is not a panacea, especially when the target\nremote sensing images (e.g. multispectral and hyperspectral data) have\ndifferent imaging mechanisms from RGB natural images. To solve this problem, we\nintroduce new self-supervised learning (SSL) mechanism to obtain the\nhigh-performance pre-training model for RSIs scene classification from large\nunlabeled data. Experiments on three commonly used RSIs scene classification\ndatasets demonstrated that this new learning paradigm outperforms the\ntraditional dominant ImageNet pre-trained model. Moreover, we analyze the\nimpacts of several factors in SSL on RSIs scene classification tasks, including\nthe choice of self-supervised signals, the domain difference between the source\nand target dataset, and the amount of pre-training data. The insights distilled\nfrom our studies can help to foster the development of SSL in the remote\nsensing community. Since SSL could learn from unlabeled massive RSIs which are\nextremely easy to obtain, it will be a potentially promising way to alleviate\ndependence on labeled samples and thus efficiently solve many problems, such as\nglobal mapping.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2010.00882v1"}
{"entry_id": "http://arxiv.org/abs/2103.07935v4", "date": "2021-03-14", "title": "Scale-aware Neural Network for Semantic Segmentation of Multi-resolution Remote Sensing Images", "authors": "Libo Wang, Ce Zhang, Rui Li, Chenxi Duan, Xiaoliang Meng, Peter M. Atkinson", "abstract": "Assigning geospatial objects with specific categories at the pixel level is a\nfundamental task in remote sensing image analysis. Along with rapid development\nin sensor technologies, remotely sensed images can be captured at multiple\nspatial resolutions (MSR) with information content manifested at different\nscales. Extracting information from these MSR images represents huge\nopportunities for enhanced feature representation and characterisation.\nHowever, MSR images suffer from two critical issues: 1) increased scale\nvariation of geo-objects and 2) loss of detailed information at coarse spatial\nresolutions. To bridge these gaps, in this paper, we propose a novel\nscale-aware neural network (SaNet) for semantic segmentation of MSR remotely\nsensed imagery. SaNet deploys a densely connected feature network (DCFFM)\nmodule to capture high-quality multi-scale context, such that the scale\nvariation is handled properly and the quality of segmentation is increased for\nboth large and small objects. A spatial feature recalibration (SFRM) module is\nfurther incorporated into the network to learn intact semantic content with\nenhanced spatial relationships, where the negative effects of information loss\nare removed. The combination of DCFFM and SFRM allows SaNet to learn\nscale-aware feature representation, which outperforms the existing multi-scale\nfeature representation. Extensive experiments on three semantic segmentation\ndatasets demonstrated the effectiveness of the proposed SaNet in\ncross-resolution segmentation.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2103.07935v4"}
{"entry_id": "http://arxiv.org/abs/2204.04462v1", "date": "2022-04-09", "title": "A3CLNN: Spatial, Spectral and Multiscale Attention ConvLSTM Neural Network for Multisource Remote Sensing Data Classification", "authors": "Heng-Chao Li, Wen-Shuai Hu, Wei Li, Jun Li, Qian Du, Antonio Plaza", "abstract": "The problem of effectively exploiting the information multiple data sources\nhas become a relevant but challenging research topic in remote sensing. In this\npaper, we propose a new approach to exploit the complementarity of two data\nsources: hyperspectral images (HSIs) and light detection and ranging (LiDAR)\ndata. Specifically, we develop a new dual-channel spatial, spectral and\nmultiscale attention convolutional long short-term memory neural network\n(called dual-channel A3CLNN) for feature extraction and classification of\nmultisource remote sensing data. Spatial, spectral and multiscale attention\nmechanisms are first designed for HSI and LiDAR data in order to learn\nspectral- and spatial-enhanced feature representations, and to represent\nmultiscale information for different classes. In the designed fusion network, a\nnovel composite attention learning mechanism (combined with a three-level\nfusion strategy) is used to fully integrate the features in these two data\nsources. Finally, inspired by the idea of transfer learning, a novel stepwise\ntraining strategy is designed to yield a final classification result. Our\nexperimental results, conducted on several multisource remote sensing data\nsets, demonstrate that the newly proposed dual-channel A3CLNN exhibits better\nfeature representation ability (leading to more competitive classification\nperformance) than other state-of-the-art methods.", "journal": "IEEE Transactions on Neural Networks and Learning Systems, vol.\n  33, no. 2, pp. 747-761, Feb. 2022", "doi": "10.1109/TNNLS.2020.3028945", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2204.04462v1"}
{"entry_id": "http://arxiv.org/abs/2212.05752v1", "date": "2022-12-12", "title": "Scale-Semantic Joint Decoupling Network for Image-text Retrieval in Remote Sensing", "authors": "Chengyu Zheng, Ning song, Ruoyu Zhang, Lei Huang, Zhiqiang Wei, Jie Nie", "abstract": "Image-text retrieval in remote sensing aims to provide flexible information\nfor data analysis and application. In recent years, state-of-the-art methods\nare dedicated to ``scale decoupling'' and ``semantic decoupling'' strategies to\nfurther enhance the capability of representation. However, these previous\napproaches focus on either the disentangling scale or semantics but ignore\nmerging these two ideas in a union model, which extremely limits the\nperformance of cross-modal retrieval models. To address these issues, we\npropose a novel Scale-Semantic Joint Decoupling Network (SSJDN) for remote\nsensing image-text retrieval. Specifically, we design the Bidirectional Scale\nDecoupling (BSD) module, which exploits Salience Feature Extraction (SFE) and\nSalience-Guided Suppression (SGS) units to adaptively extract potential\nfeatures and suppress cumbersome features at other scales in a bidirectional\npattern to yield different scale clues. Besides, we design the Label-supervised\nSemantic Decoupling (LSD) module by leveraging the category semantic labels as\nprior knowledge to supervise images and texts probing significant\nsemantic-related information. Finally, we design a Semantic-guided Triple Loss\n(STL), which adaptively generates a constant to adjust the loss function to\nimprove the probability of matching the same semantic image and text and\nshorten the convergence time of the retrieval model. Our proposed SSJDN\noutperforms state-of-the-art approaches in numerical experiments conducted on\nfour benchmark remote sensing datasets.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2212.05752v1"}
{"entry_id": "http://arxiv.org/abs/2201.05421v1", "date": "2022-01-14", "title": "Rapid Variations of Earth's Core Magnetic Field", "authors": "V. Lesur, N. Gillet, M. D. Hammer, M. Mandea", "abstract": "Evidence of fast variations in the Earth's core field are seen both in\nmagnetic observatory and satellite records. We present here how they have been\nidentified at the Earth's surface from ground-based observatory records and how\ntheir spatio-temporal structure is now characterised by satellite data. It is\nshown how their properties at the core mantle boundary are extracted through\nlocalised and global modelling processes, paying particular attention to their\ntime scales. Finally are listed possible types of waves in the liquid outer\ncore, together with their main properties, that may give rise to these observed\nfast variations.", "journal": "Surveys in Geophysics 2022", "doi": "10.1007/s10712-021-09662-4", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2201.05421v1"}
{"entry_id": "http://arxiv.org/abs/1804.01709v1", "date": "2018-04-05", "title": "Observation-driven scheduling for remote estimation of two Gaussian sources", "authors": "Marcos M. Vasconcelos, Urbashi Mitra", "abstract": "Joint estimation and scheduling for sensor networks is considered in a system\nformed by two sensors, a scheduler and a remote estimator. Each sensor observes\na Gaussian source, which may be correlated. The scheduler observes the output\nof both sensors and chooses which of the two is revealed to the remote\nestimator. The goal is to jointly design scheduling and estimation policies\nthat minimize a mean-squared estimation error criterion. The person-by-person\noptimality of a policy pair called \"max-scheduling/mean-estimation\" is\nestablished, where the measurement with the largest absolute value is revealed\nto the estimator, which uses a corresponding conditional mean operator. This\nresult is obtained for independent sources, and in the case of correlated\nsources and symmetric variances. We also consider the joint design of\nscheduling and linear estimation policies for two correlated Gaussian sources\nwith an arbitrary correlation structure. In this case, the optimization problem\ncan be cast a difference-of-convex program, and locally optimal solutions can\nbe efficiently found using a simple numerical procedure.", "journal": "", "doi": null, "primary_category": "cs.SY", "categories": ["cs.SY"], "pdf_url": "http://arxiv.org/pdf/1804.01709v1"}
{"entry_id": "http://arxiv.org/abs/1910.03380v1", "date": "2019-10-08", "title": "Negative Space: Workspace Awareness in 3D Face-to-Face Remote Collaboration", "authors": "Maur\u00edcio Sousa, Daniel Mendes, Rafael Kuffner dos Anjos, Daniel Sim\u00f5es Lopes, Joaquim Jorge", "abstract": "Face-to-face telepresence promotes the sense of \"being there\" and can improve\ncollaboration by allowing immediate understanding of remote people's nonverbal\ncues. Several approaches successfully explored interactions with 2D content\nusing a see-through whiteboard metaphor. However, with 3D content, there is a\ndecrease in awareness due to ambiguities originated by participants' opposing\npoints-of-view. In this paper, we investigate how people and content should be\npresented for discussing 3D renderings within face-to-face collaborative\nsessions. To this end, we performed a user evaluation to compare four different\nconditions, in which we varied reflections of both workspace and remote people\nrepresentation. Results suggest potentially more benefits to remote\ncollaboration from workspace consistency rather than people's representation\nfidelity. We contribute a novel design space, the Negative Space, for remote\nface-to-face collaboration focusing on 3D content.", "journal": "", "doi": null, "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/1910.03380v1"}
{"entry_id": "http://arxiv.org/abs/1810.12448v1", "date": "2018-10-29", "title": "Incremental Learning for Semantic Segmentation of Large-Scale Remote Sensing Data", "authors": "Onur Tasar, Yuliya Tarabalka, Pierre Alliez", "abstract": "In spite of remarkable success of the convolutional neural networks on\nsemantic segmentation, they suffer from catastrophic forgetting: a significant\nperformance drop for the already learned classes when new classes are added on\nthe data, having no annotations for the old classes. We propose an incremental\nlearning methodology, enabling to learn segmenting new classes without\nhindering dense labeling abilities for the previous classes, although the\nentire previous data are not accessible. The key points of the proposed\napproach are adapting the network to learn new as well as old classes on the\nnew training data, and allowing it to remember the previously learned\ninformation for the old classes. For adaptation, we keep a frozen copy of the\npreviously trained network, which is used as a memory for the updated network\nin absence of annotations for the former classes. The updated network minimizes\na loss function, which balances the discrepancy between outputs for the\nprevious classes from the memory and updated networks, and the\nmis-classification rate between outputs for the new classes from the updated\nnetwork and the new ground-truth. For remembering, we either regularly feed\nsamples from the stored, little fraction of the previous data or use the memory\nnetwork, depending on whether the new data are collected from completely\ndifferent geographic areas or from the same city. Our experimental results\nprove that it is possible to add new classes to the network, while maintaining\nits performance for the previous classes, despite the whole previous training\ndata are not available.", "journal": "IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND\n  REMOTE SENSING, 12, 2019, 3524-3537", "doi": "10.1109/JSTARS.2019.2925416", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1810.12448v1"}
{"entry_id": "http://arxiv.org/abs/1707.01367v1", "date": "2017-07-05", "title": "The fast spin of near-Earth asteroid (455213) 2001 OE84, revisited after 14 years: constraints on internal structure", "authors": "David Polishook, Nicholas Moskovitz, Audrey Thirouin, Amanda Bosh, Stephen Levine, Carlos Zuluaga, Stephen Tegler, Oded Aharonson", "abstract": "At a mean diameter of ~650 m, the near-Earth asteroid (455213) 2001 OE84\n(OE84 for short) has a rapid rotation period of 0.486542+-0.000002 hours, which\nis uncommon for asteroids larger than ~200 m. We revisited OE84 14 years after\nit was first, and last, observed by Pravec et al. (2002) in order to measure\nagain its spin rate and to search for changes. We have confirmed the rapid\nrotation and, by fitting the photometric data from 2001 and 2016 using the\nlightcurve inversion technique, we determined a retrograde sense of rotation,\nwith the spin axis close to the ecliptic south pole; an oblate shape model of\na/b=1.32+-0.04 and b/c=1.8+-0.2; and no change in spin rate between 2001 and\n2016. Using these parameters we constrained the body's internal strength, and\nfound that current estimations of asteroid cohesion (up to ~80 Pa) are\ninsufficient to maintain an intact rubble pile at the measured spin rate of\nOE84. Therefore, we argue that a monolithic asteroid, that can rotate at the\nrate of OE84 without shedding mass and without slowing down its spin rate, is\nthe most plausible for OE84, and we give constraints on its age, since the time\nit was liberated from its parent body, between 2-10 million years.", "journal": "", "doi": "10.1016/j.icarus.2017.06.036", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1707.01367v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0507140v1", "date": "2005-07-06", "title": "Can Remote Observing be Good Observing? Reflections on Procrustes and Antaeus", "authors": "Felix J. Lockman", "abstract": "Remote observing seeks to simulate the presence of the astronomer at the\ntelescope. While this is useful, and necessary in some circumstances,\nsimulation is not reality. The drive to abstract the astronomer from the\ninstrument can have unpleasant consequences, some of which are prefigured in\nthe ancient tales of Procrustes and Antaeus. This article, written in 1992 for\na conference proceedings on remote observing, is reprinted here with only\nslight editorial changes and the addition of a short Afterword. I consider some\nof the human factors involved in remote observing, and suggest that our aim be\nto enhance rather than supplant the astronomer at the telescope.", "journal": "Observing at a Distance, (1993) eds. D.T. Emerson and R.G. Clowes,\n  World Scientific, p. 325", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0507140v1"}
{"entry_id": "http://arxiv.org/abs/2009.10010v1", "date": "2020-09-16", "title": "Reflection-mode virtual histology using photoacoustic remote sensing microscopy", "authors": "Kevan Bell, Saad Abbasi, Deepak Dinakaran, Muba Taher, Gilbert Bigras, Frank K. H. van Landeghem, John R. Mackey, Parsin Haji Reza", "abstract": "Histological visualizations are critical to clinical disease management and\nare fundamental to biological understanding. However, current approaches that\nrely on bright-field microscopy require extensive tissue preparation prior to\nimaging. These processes are labor intensive and contribute to delays in\nclinical feedback that can extend to two to three weeks for standard\nparaffin-embedded tissue preparation and interpretation. Here, we present a\nlabel-free reflection-mode imaging modality that reveals cellular-scale\nmorphology by detecting intrinsic endogenous contrast. We accomplish this with\nthe novel photoacoustic remote sensing (PARS) detection system that permits\nnon-contact optical absorption contrast to be extracted from thick and opaque\nbiological targets with optical resolution. PARS was examined both as a rapid\nassessment tool that is capable of managing large samples (>1 cm2) in under 10\nminutes, and as a high contrast imaging modality capable of extracting specific\nbiological contrast to simulate conventional histological stains such as\nhematoxylin and eosin (H&E). The capabilities of the proposed method are\ndemonstrated in a variety of human tissue preparations including formalin-fixed\nparaffin-embedded tissue blocks and unstained slides sectioned from these\nblocks, including normal and neoplastic human brain, and breast epithelium\ninvolved with breast cancer. Similarly, PARS images of human skin prepared by\nfrozen section clearly demonstrated basal cell carcinoma and normal human skin\ntissue. Finally, we imaged unprocessed murine kidney and achieved\nhistologically relevant subcellular morphology in fresh tissue. This represents\na vital step towards an effective real-time clinical microscope that overcomes\nthe limitations of standard histopathologic tissue preparations and enables\nreal-time pathology assessment.", "journal": "", "doi": null, "primary_category": "physics.med-ph", "categories": ["physics.med-ph", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2009.10010v1"}
{"entry_id": "http://arxiv.org/abs/1510.07103v2", "date": "2015-10-24", "title": "Propagation of GeV neutrinos through Earth", "authors": "Yaithd Daniel Olivas Arcos, Sarira Sahu", "abstract": "We have studied the Earth matter effect on the oscillation of upward going\nGeV neutrinos by taking into account the three active neutrino flavors. For\nneutrino energy in the range 3 to 12 GeV we observed three distinct resonant\npeaks for the oscillation process $\\nu_e\\leftrightarrow \\nu_{\\mu,\\tau}$ in\nthree \\textit{distinct} densities. However, according to the most realistic\ndensity profile of the Earth, the second peak at neutrino energy 6.18 GeV\ncorresponding to the density $6.6\\,g/cm^3$ does not exist. So the resonance at\nthis energy can not be of MSW-type. For the calculation of observed flux of\nthese GeV neutrinos on Earth, we considered two different flux ratios at the\nsource, the standard scenario with the flux ratio $1:2:0$ and the muon damped\nscenario with $0:1:0$. It is observed that at the detector while the standard\nscenario gives the observed flux ratio $1:1:1$, the muon damped scenario has a\ndifferent ratio. For muon damped case with $E_{\\nu} < 20$ GeV, we always get\nobserved neutrino fluxes as $\\Phi_{\\nu_e} < \\Phi_{\\nu_\\mu}\\simeq\n\\Phi_{\\nu_\\tau}$ and for $E_{\\nu} > 20$ GeV, we get the average\n$\\Phi_{\\nu_e}\\sim 0$ and $\\Phi_{\\nu_\\mu}\\simeq \\Phi_{\\nu_\\tau}\\simeq 0.45$. The\nupcoming PINGU will be able to shed more light on the nature of the resonance\nin these GeV neutrinos and hopefully will also be able to discriminate among\ndifferent processes of neutrino production at the source in GeV energy range.", "journal": "JHEAp 18 (2018) 35-42", "doi": "10.1016/j.jheap.2018.02.001", "primary_category": "hep-ph", "categories": ["hep-ph"], "pdf_url": "http://arxiv.org/pdf/1510.07103v2"}
{"entry_id": "http://arxiv.org/abs/0905.0704v1", "date": "2009-05-05", "title": "Earth's Heat Source - The Sun", "authors": "Oliver K. Manuel", "abstract": "The Sun encompasses planet Earth, supplies the heat that warms it, and even\nshakes it. The United Nation Intergovernmental Panel on Climate Change (IPCC)\nassumed that solar influence on our climate is limited to changes in solar\nirradiance and adopted the consensus opinion of a Hydrogen-filled Sun, the\nStandard Solar Model (SSM). They did not consider the alternative solar model\nand instead adopted another consensus opinion: Anthropogenic greenhouse gases\nplay a dominant role in climate change. The SSM fails to explain the solar\nwind, solar cycles, and the empirical link of solar surface activity with Earth\nchanging climate. The alternative solar model, that was molded from an\nembarrassingly large number of unexpected observations revealed by space-age\nmeasurements since 1959, explains not only these puzzles but also how closely\nlinked interactions between the Sun and its planets and other celestial bodies\ninduce turbulent cycles of secondary solar characteristics that significantly\naffect Earth climate.", "journal": "", "doi": null, "primary_category": "physics.gen-ph", "categories": ["physics.gen-ph"], "pdf_url": "http://arxiv.org/pdf/0905.0704v1"}
{"entry_id": "http://arxiv.org/abs/1904.09823v1", "date": "2019-04-22", "title": "Ship Instance Segmentation From Remote Sensing Images Using Sequence Local Context Module", "authors": "Yingchao Feng, Wenhui Diao, Zhonghan Chang, Menglong Yan, Xian Sun, Xin Gao", "abstract": "The performance of object instance segmentation in remote sensing images has\nbeen greatly improved through the introduction of many landmark frameworks\nbased on convolutional neural network. However, the object densely issue still\naffects the accuracy of such segmentation frameworks. Objects of the same class\nare easily confused, which is most likely due to the close docking between\nobjects. We think context information is critical to address this issue. So, we\npropose a novel framework called SLCMASK-Net, in which a sequence local context\nmodule (SLC) is introduced to avoid confusion between objects of the same\nclass. The SLC module applies a sequence of dilation convolution blocks to\nprogressively learn multi-scale context information in the mask branch.\nBesides, we try to add SLC module to different locations in our framework and\nexperiment with the effect of different parameter settings. Comparative\nexperiments are conducted on remote sensing images acquired by QuickBird with a\nresolution of $0.5m-1m$ and the results show that the proposed method achieves\nstate-of-the-art performance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1904.09823v1"}
{"entry_id": "http://arxiv.org/abs/2103.05569v2", "date": "2021-03-09", "title": "FAIR1M: A Benchmark Dataset for Fine-grained Object Recognition in High-Resolution Remote Sensing Imagery", "authors": "Xian Sun, Peijin Wang, Zhiyuan Yan, Feng Xu, Ruiping Wang, Wenhui Diao, Jin Chen, Jihao Li, Yingchao Feng, Tao Xu, Martin Weinmann, Stefan Hinz, Cheng Wang, Kun Fu", "abstract": "With the rapid development of deep learning, many deep learning-based\napproaches have made great achievements in object detection task. It is\ngenerally known that deep learning is a data-driven method. Data directly\nimpact the performance of object detectors to some extent. Although existing\ndatasets have included common objects in remote sensing images, they still have\nsome limitations in terms of scale, categories, and images. Therefore, there is\na strong requirement for establishing a large-scale benchmark on object\ndetection in high-resolution remote sensing images. In this paper, we propose a\nnovel benchmark dataset with more than 1 million instances and more than 15,000\nimages for Fine-grAined object recognItion in high-Resolution remote sensing\nimagery which is named as FAIR1M. All objects in the FAIR1M dataset are\nannotated with respect to 5 categories and 37 sub-categories by oriented\nbounding boxes. Compared with existing detection datasets dedicated to object\ndetection, the FAIR1M dataset has 4 particular characteristics: (1) it is much\nlarger than other existing object detection datasets both in terms of the\nquantity of instances and the quantity of images, (2) it provides more rich\nfine-grained category information for objects in remote sensing images, (3) it\ncontains geographic information such as latitude, longitude and resolution, (4)\nit provides better image quality owing to a careful data cleaning procedure. To\nestablish a baseline for fine-grained object recognition, we propose a novel\nevaluation method and benchmark fine-grained object detection tasks and a\nvisual classification task using several State-Of-The-Art (SOTA) deep\nlearning-based models on our FAIR1M dataset. Experimental results strongly\nindicate that the FAIR1M dataset is closer to practical application and it is\nconsiderably more challenging than existing datasets.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2103.05569v2"}
{"entry_id": "http://arxiv.org/abs/2107.06536v1", "date": "2021-07-14", "title": "Multi-Attention Generative Adversarial Network for Remote Sensing Image Super-Resolution", "authors": "Meng Xu, Zhihao Wang, Jiasong Zhu, Xiuping Jia, Sen Jia", "abstract": "Image super-resolution (SR) methods can generate remote sensing images with\nhigh spatial resolution without increasing the cost, thereby providing a\nfeasible way to acquire high-resolution remote sensing images, which are\ndifficult to obtain due to the high cost of acquisition equipment and complex\nweather. Clearly, image super-resolution is a severe ill-posed problem.\nFortunately, with the development of deep learning, the powerful fitting\nability of deep neural networks has solved this problem to some extent. In this\npaper, we propose a network based on the generative adversarial network (GAN)\nto generate high resolution remote sensing images, named the multi-attention\ngenerative adversarial network (MA-GAN). We first designed a GAN-based\nframework for the image SR task. The core to accomplishing the SR task is the\nimage generator with post-upsampling that we designed. The main body of the\ngenerator contains two blocks; one is the pyramidal convolution in the\nresidual-dense block (PCRDB), and the other is the attention-based upsample\n(AUP) block. The attentioned pyramidal convolution (AttPConv) in the PCRDB\nblock is a module that combines multi-scale convolution and channel attention\nto automatically learn and adjust the scaling of the residuals for better\nresults. The AUP block is a module that combines pixel attention (PA) to\nperform arbitrary multiples of upsampling. These two blocks work together to\nhelp generate better quality images. For the loss function, we design a loss\nfunction based on pixel loss and introduce both adversarial loss and feature\nloss to guide the generator learning. We have compared our method with several\nstate-of-the-art methods on a remote sensing scene image dataset, and the\nexperimental results consistently demonstrate the effectiveness of the proposed\nMA-GAN.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2107.06536v1"}
{"entry_id": "http://arxiv.org/abs/2111.03260v1", "date": "2021-11-05", "title": "Remote Sensing Image Super-resolution and Object Detection: Benchmark and State of the Art", "authors": "Yi Wang, Syed Muhammad Arsalan Bashir, Mahrukh Khan, Qudrat Ullah, Rui Wang, Yilin Song, Zhe Guo, Yilong Niu", "abstract": "For the past two decades, there have been significant efforts to develop\nmethods for object detection in Remote Sensing (RS) images. In most cases, the\ndatasets for small object detection in remote sensing images are inadequate.\nMany researchers used scene classification datasets for object detection, which\nhas its limitations; for example, the large-sized objects outnumber the small\nobjects in object categories. Thus, they lack diversity; this further affects\nthe detection performance of small object detectors in RS images. This paper\nreviews current datasets and object detection methods (deep learning-based) for\nremote sensing images. We also propose a large-scale, publicly available\nbenchmark Remote Sensing Super-resolution Object Detection (RSSOD) dataset. The\nRSSOD dataset consists of 1,759 hand-annotated images with 22,091 instances of\nvery high resolution (VHR) images with a spatial resolution of ~0.05 m. There\nare five classes with varying frequencies of labels per class. The image\npatches are extracted from satellite images, including real image distortions\nsuch as tangential scale distortion and skew distortion. We also propose a\nnovel Multi-class Cyclic super-resolution Generative adversarial network with\nResidual feature aggregation (MCGR) and auxiliary YOLOv5 detector to benchmark\nimage super-resolution-based object detection and compare with the existing\nstate-of-the-art methods based on image super-resolution (SR). The proposed\nMCGR achieved state-of-the-art performance for image SR with an improvement of\n1.2dB PSNR compared to the current state-of-the-art NLSN method. MCGR achieved\nbest object detection mAPs of 0.758, 0.881, 0.841, and 0.983, respectively, for\nfive-class, four-class, two-class, and single classes, respectively surpassing\nthe performance of the state-of-the-art object detectors YOLOv5, EfficientDet,\nFaster RCNN, SSD, and RetinaNet.", "journal": "Expert Systems with Applications, 2022", "doi": "10.1016/j.eswa.2022.116793", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2111.03260v1"}
{"entry_id": "http://arxiv.org/abs/2105.11726v2", "date": "2021-05-25", "title": "There is no data like more data -- current status of machine learning datasets in remote sensing", "authors": "Michael Schmitt, Seyed Ali Ahmadi, Ronny H\u00e4nsch", "abstract": "Annotated datasets have become one of the most crucial preconditions for the\ndevelopment and evaluation of machine learning-based methods designed for the\nautomated interpretation of remote sensing data. In this paper, we review the\nhistoric development of such datasets, discuss their features based on a few\nselected examples, and address open issues for future developments.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2105.11726v2"}
{"entry_id": "http://arxiv.org/abs/1804.04020v3", "date": "2018-04-11", "title": "Dynamic Multi-Context Segmentation of Remote Sensing Images based on Convolutional Networks", "authors": "Keiller Nogueira, Mauro Dalla Mura, Jocelyn Chanussot, William R. Schwartz, Jefersson A. dos Santos", "abstract": "Semantic segmentation requires methods capable of learning high-level\nfeatures while dealing with large volume of data. Towards such goal,\nConvolutional Networks can learn specific and adaptable features based on the\ndata. However, these networks are not capable of processing a whole remote\nsensing image, given its huge size. To overcome such limitation, the image is\nprocessed using fixed size patches. The definition of the input patch size is\nusually performed empirically (evaluating several sizes) or imposed (by network\nconstraint). Both strategies suffer from drawbacks and could not lead to the\nbest patch size. To alleviate this problem, several works exploited\nmulti-context information by combining networks or layers. This process\nincreases the number of parameters resulting in a more difficult model to\ntrain. In this work, we propose a novel technique to perform semantic\nsegmentation of remote sensing images that exploits a multi-context paradigm\nwithout increasing the number of parameters while defining, in training time,\nthe best patch size. The main idea is to train a dilated network with distinct\npatch sizes, allowing it to capture multi-context characteristics from\nheterogeneous contexts. While processing these varying patches, the network\nprovides a score for each patch size, helping in the definition of the best\nsize for the current scenario. A systematic evaluation of the proposed\nalgorithm is conducted using four high-resolution remote sensing datasets with\nvery distinct properties. Our results show that the proposed algorithm provides\nimprovements in pixelwise classification accuracy when compared to\nstate-of-the-art methods.", "journal": "", "doi": "10.1109/TGRS.2019.2913861", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1804.04020v3"}
{"entry_id": "http://arxiv.org/abs/2007.14428v1", "date": "2020-07-28", "title": "An Eruptive Circular-ribbon Flare with Extended Remote Brightenings", "authors": "Chang Liu, Avijeet Prasad, Jeongwoo Lee, Haimin Wang", "abstract": "We study an eruptive X1.1 circular-ribbon flare on 2013 November 10,\ncombining multiwavelength observations with a coronal field reconstruction\nusing a non-force-free field method. In the first stage, a filament forms via\nmagnetic reconnection between two mildly twisted sheared arcades, which are\nembedded under the fan dome associated with a null point. This reconnection\nseems to be driven by photospheric shearing and converging flows around the\ninner two arcade footpoints, consistent with the flare-related changes of\ntransverse field. The southern portion of the filament rises upward due to\ntorus instability and pushes against the null point. The induced null point\nreconnection then generates the circular ribbon and the initial remote\nbrightening in the west, as accelerated electrons precipitate along the fan and\npropagate outward along quasi-separatix surfaces with high values of the\nsquashing factor (Q) in the envelope fields, which have a curtain-like shape\nhere. In the second stage, the southern end of the flux rope breaks away from\nthe surface, sequentially disrupts the dome and overlying fields, and erupts in\na whipping-like fashion to become a partial halo coronal mass ejection. This\nleads to an enhanced flare emission and fast-moving remote brightenings at the\nfootpoints of the magnetic curtain, which span a remarkably broad region and\nare also associated with coronal dimmings. This is a rare example of eruptive\ncircular-ribbon flares, in which the evolution of a flux rope from its\nformation to successful eruption out of the dome and the resulting unusually\nextended remote brightenings are completely observed.", "journal": "", "doi": "10.3847/1538-4357/ab9cbe", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2007.14428v1"}
{"entry_id": "http://arxiv.org/abs/hep-ph/0006286v1", "date": "2000-06-26", "title": "Can cosmic strangelets reach the earth?", "authors": "Shibaji Banerjee, Sanjay K. Ghosh, Sibaji Raha, Debapriyo Syam", "abstract": "The mechanism for the propagation of strangelets with low baryon number\nthrough the atmosphere of the Earth has been explored. It has been shown that\nunder suitable initial conditions, such strangelets may indeed reach depths\nnear mountain altitudes with mass numbers and charges close to the observed\nvalues in cosmic ray experiments.", "journal": "Phys.Rev.Lett. 85 (2000) 1384-1387", "doi": "10.1103/PhysRevLett.85.1384", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph"], "pdf_url": "http://arxiv.org/pdf/hep-ph/0006286v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0502238v1", "date": "2005-02-11", "title": "Disk-averaged Spectra & light-curves of Earth", "authors": "G. Tinetti, V. S. Meadows, D. Crisp, W. Fong, N. Kiang, E. Fishbein, T. Velusamy, E. Bosc, M. Turnbull", "abstract": "We are using computer models to explore the observational sensitivity to\nchanges in atmospheric and surface properties, and the detectability of\nbiosignatures, in the globally averaged spectra and light-curves of the Earth.\nUsing AIRS (Atmospheric Infrared Sounder) data, as input for atmospheric and\nsurface properties, we have generated spatially resolved high-resolution\nsynthetic spectra using the SMART radiative transfer model, for a variety of\nconditions, from the UV to the far-IR (beyond the range of current Earth-based\nsatellite data). We have then averaged over the visible disk for a number of\ndifferent viewing geometries to quantify the sensitivity to surface types and\natmospheric features as a function of viewing geometry, and spatial and\nspectral resolution.\n  These results have been processed with an instrument simulator to improve our\nunderstanding of the detectable characteristics of Earth-like planets as viewed\nby the first generation extrasolar terrestrial planet detection and\ncharacterization missions (Terrestrial Planet Finder/Darwin and Life finder).\nThe wavelength range of our results are modelled over are applicable to both\nthe proposed visible coronograph and mid-infrared interferometer TPF\narchitectures.\n  We have validated this model against disk-averaged observations by the Mars\nGlobal Surveyor Thermal Emission Spectrometer (MGS TES).\n  This model was also used to analyze Earth-shine data for detectability of\nplanetary characteristics and biosignatures in disk-averaged spectra.", "journal": "", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0502238v1"}
{"entry_id": "http://arxiv.org/abs/1908.08199v1", "date": "2019-08-22", "title": "A Wearable Tactile Sensor Array for Large Area Remote Vibration Sensing in the Hand", "authors": "Yitian Shao, Hui Hu, Yon Visell", "abstract": "Tactile sensing is a essential for skilled manipulation and object\nperception, but existing devices are unable to capture mechanical signals in\nthe full gamut of regimes that are important for human touch sensing, and are\nunable to emulate the sensing abilities of the human hand. Recent research\nreveals that human touch sensing relies on the transmission of mechanical waves\nthroughout tissues of the hand. This provides the hand with remarkable\nabilities to remotely capture distributed vibration signatures of touch\ncontact. Little engineering attention has been given to important sensory\nsystem. Here, we present a wearable device inspired by the anatomy and function\nof the hand and by human sensory abilities. The device is based on a 126\nchannel sensor array capable of capturing high resolution tactile signals\nduring natural manual activities. It employs a network of miniature three-axis\nsensors mounted on a flexible circuit whose geometry and topology were designed\nmatch the anatomy of the hand, permitting data capture during natural\ninteractions, while minimizing artifacts. Each sensor possesses a frequency\nbandwidth matching the human tactile frequency range. Data is acquired in real\ntime via a custom FPGA and an I$^2$C network. We also present physiologically\ninformed signal processing methods for reconstructing whole hand tactile\nsignals using data from this system. We report experiments that demonstrate the\nability of this system to accurately capture remotely produced whole hand\ntactile signals during manual interactions.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO"], "pdf_url": "http://arxiv.org/pdf/1908.08199v1"}
{"entry_id": "http://arxiv.org/abs/1203.0209v1", "date": "2012-03-01", "title": "Observing the Earth as an exoplanet with LOUPE, the Lunar Observatory for Unresolved Polarimetry of Earth", "authors": "T. Karalidi, D. M. Stam, F. Snik, S. Bagnulo, W. B. Sparks, C. U. Keller", "abstract": "The detections of small, rocky exoplanets have surged in recent years and\nwill likely continue to do so. To know whether a rocky exoplanet is habitable,\nwe have to characterise its atmosphere and surface. A promising\ncharacterisation method for rocky exoplanets is direct detection using\nspectropolarimetry. This method will be based on single pixel signals, because\nspatially resolving exoplanets is impossible with current and near-future\ninstruments. Well-tested retrieval algorithms are essential to interpret these\nsingle pixel signals in terms of atmospheric composition, cloud and surface\ncoverage. Observations of Earth itself provide the obvious benchmark data for\ntesting such algorithms. The observations should provide signals that are\nintegrated over the Earth's disk, that capture day and night variations, and\nall phase angles. The Moon is a unique platform from where the Earth can be\nobserved as an exoplanet, undisturbed, all of the time. Here, we present LOUPE,\nthe Lunar Observatory for Unresolved Polarimetry of Earth, a small and robust\nspectropolarimeter to observe our Earth as an exoplanet.", "journal": "", "doi": "10.1016/j.pss.2012.05.017", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1203.0209v1"}
{"entry_id": "http://arxiv.org/abs/2211.16672v1", "date": "2022-11-30", "title": "Double layers in the Earth's bow shock", "authors": "Jiepu Sun, Ivan Y. Vasko, Stuart D. Bale, Rachel Wang, Forrest S. Mozer", "abstract": "We present Magnetospheric Multiscale observations of electrostatic double\nlayers in quasi-perpendicular Earth's bow shock. These double layers have\npredominantly parallel electric field with amplitudes up to 100 mV/m, spatial\nwidths of 50-700 m, and plasma frame speeds within 100 km/s. The potential drop\nacross a single double layer is 2-7% of the cross-shock potential in the de\nHoffmann-Teller frame and occurs over the spatial scale of ten Debye lengths or\none tenth of electron inertial length. Some double layers can have spatial\nwidth of 70 Debye lengths and potential drop up to 30% of the cross-shock\npotential. The electron temperature variation observed across double layers is\nroughly consistent with their potential drop. While electron heating in the\nEarth's bow shock occurs predominantly due to the quasi-static electric field\nin the de Hoffmann-Teller frame, these observations show that electron\ntemperature can also increase across Debye-scale electrostatic structures.", "journal": "", "doi": "10.1029/2022GL101348", "primary_category": "physics.space-ph", "categories": ["physics.space-ph", "physics.plasm-ph", "85-05", "J.2"], "pdf_url": "http://arxiv.org/pdf/2211.16672v1"}
{"entry_id": "http://arxiv.org/abs/0711.2584v1", "date": "2007-11-16", "title": "Remote Sensing of Chromospheric Magnetic Fields via the Hanle and Zeeman Effects", "authors": "J. Trujillo Bueno, R. Manso Sainz", "abstract": "The only way to obtain reliable empirical information on the intensity and\ntopology of the weak magnetic fields of the quiet solar chromosphere is via the\nmeasurement and rigorous physical interpretation of polarization signals in\nchromospheric spectral lines. The observed Stokes profiles reported here are\ndue to the Hanle and Zeeman effects operating in a weakly magnetized plasma\nthat is in a state far from local thermodynamic equilibrium. The physical\norigin of their enigmatic linear polarization Q and U components is the\nexistence of atomic polarization in their metastable lower-levels, which\npermits the action of a dichroism mechanism that has nothing to do with the\ntransverse Zeeman effect. It is also pointed out that the population imbalances\nand coherences among the Zeeman sublevels of such long-lived atomic levels can\nsurvive in the presence of horizontal magnetic fields having intensities in the\ngauss range, and produce significant polarization signals. Finally, it is shown\nhow the most recent developments in the observation and theoretical modelling\nof weak polarization signals are facilitating fundamental new advances in our\nability to investigate the magnetism of the outer solar atmosphere via\nspectropolarimetry.", "journal": "Nuovo Cim.C25:783-796,2002", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0711.2584v1"}
{"entry_id": "http://arxiv.org/abs/1712.04556v1", "date": "2017-12-12", "title": "Tracking Filament Evolution in the Low Solar Corona using Remote-Sensing and In-situ Observations", "authors": "Manan Kocher, Enrico Landi, Susan T. Lepri", "abstract": "In the present work, we analyze a filament eruption associated with an ICME\nthat arrived at L1 on August 5th, 2011. In multi-wavelength SDO/AIA images,\nthree plasma parcels within the filament were tracked at high-cadence along the\nsolar corona. A novel absorption diagnostic technique was applied to the\nfilament material travelling along the three chosen trajectories to compute the\ncolumn density and temperature evolution in time. Kinematics of the filamentary\nmaterial were estimated using STEREO/EUVI and STEREO/COR1 observations. The\nMichigan Ionization Code used inputs of these density, temperature, and speed\nprofiles for the computation of ionization profiles of the filament plasma.\nBased on these measurements we conclude the core plasma was in near ionization\nequilibrium, and the ionization states were not frozen-in at the altitudes\nwhere they were visible in absorption in AIA images. Additionally, we report\nthat the filament plasma was heterogeneous, and the filamentary material was\ncontinuously heated as it expanded in the low solar corona.", "journal": "", "doi": "10.3847/1538-4357/aac5f9", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1712.04556v1"}
{"entry_id": "http://arxiv.org/abs/quant-ph/0208154v1", "date": "2002-08-26", "title": "Altering the remote past", "authors": "Alexander Afriat", "abstract": "An abstract treatment of Bell inequalities is proposed, in which the\nparameters characterizing Bell's observable can be times rather than\ndirections. The violation of a Bell inequality might then be taken to mean that\na property of a system can be changed by the timing of a distant measurement,\nwhich could take place in the future.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/quant-ph/0208154v1"}
{"entry_id": "http://arxiv.org/abs/2008.08243v1", "date": "2020-08-19", "title": "Enabling Remote Whole-Body Control with 5G Edge Computing", "authors": "Huaijiang Zhu, Manali Sharma, Kai Pfeiffer, Marco Mezzavilla, Jia Shen, Sundeep Rangan, Ludovic Righetti", "abstract": "Real-world applications require light-weight, energy-efficient, fully\nautonomous robots. Yet, increasing autonomy is oftentimes synonymous with\nescalating computational requirements. It might thus be desirable to offload\nintensive computation--not only sensing and planning, but also low-level\nwhole-body control--to remote servers in order to reduce on-board computational\nneeds. Fifth Generation (5G) wireless cellular technology, with its low latency\nand high bandwidth capabilities, has the potential to unlock cloud-based high\nperformance control of complex robots. However, state-of-the-art control\nalgorithms for legged robots can only tolerate very low control delays, which\neven ultra-low latency 5G edge computing can sometimes fail to achieve. In this\nwork, we investigate the problem of cloud-based whole-body control of legged\nrobots over a 5G link. We propose a novel approach that consists of a standard\noptimization-based controller on the network edge and a local linear,\napproximately optimal controller that significantly reduces on-board\ncomputational needs while increasing robustness to delay and possible loss of\ncommunication. Simulation experiments on humanoid balancing and walking tasks\nthat includes a realistic 5G communication model demonstrate significant\nimprovement of the reliability of robot locomotion under jitter and delays\nlikely to experienced in 5G wireless links.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/2008.08243v1"}
{"entry_id": "http://arxiv.org/abs/2208.10001v2", "date": "2022-08-22", "title": "Nonreciprocal enhancement of remote entanglement between nonidentical mechanical oscillators", "authors": "Ya-Feng Jiao, Jing-Xue Liu, Ying Li, Ronghua Yang, Le-Man Kuang, Hui Jing", "abstract": "Entanglement between distant massive mechanical oscillators is of particular\ninterest in quantum-enabled devices due to its potential applications in\ndistributed quantum information processing. Here we propose how to achieve\nnonreciprocal remote entanglement between two spatially separated mechanical\noscillators within a cascaded optomechanical configuration, where the two\noptomechanical resonators are indirectly coupled through a telecommunication\nfiber. We show that by selectively spinning the optomechanical resonators, one\ncan break the time reversal symmetry of this compound system via Sagnac effect,\nand more excitingly, enhance the indirect couplings between the mechanical\noscillators via the individual optimizations of light-motion interaction in\neach optomechanical resonator. This ability allows us to generate and\nmanipulate nonreciprocal entanglement between distant mechanical oscillators,\nthat is, the entanglement could be achieved only through driving the system\nfrom one specific input direction but not the other. Moreover, in the case of\ntwo frequency-mismatched mechanical oscillators, it is also found that the\ndegree of the generated nonreciprocal entanglement is counterintuitively\nenhanced in comparison with its reciprocal counterparts, which are otherwise\nunattainable in static cascaded systems with a single-tone driving laser. Our\nwork, which is well within the feasibility of current experimental\ncapabilities, provides an enticing new opportunity to explore the nonclassical\ncorrelations between distant massive objects and facilitates a variety of\nemerging quantum technologies ranging from quantum information processing to\nquantum sensing.", "journal": "Phys. Rev. Applied 18, 064008 (2022)", "doi": "10.1103/PhysRevApplied.18.064008", "primary_category": "quant-ph", "categories": ["quant-ph", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/2208.10001v2"}
{"entry_id": "http://arxiv.org/abs/2004.08601v3", "date": "2020-04-18", "title": "Remote Empirical Coordination", "authors": "Michail Mylonakis, Photios A. Stavrou, Mikael Skoglund", "abstract": "We apply the framework of imperfect empirical coordination to a two-node\nsetup where the action $X$ of the first node is not observed directly but via\n$L$ agents who observe independently impaired measurements $\\hat X$ of the\naction. These $L$ agents, using a rate-limited communication that is available\nto all of them, help the second node to generate the action $Y$ in order to\nestablish the desired coordinated behaviour. When $L<\\infty$, we prove that it\nsuffices $R_i\\geq I\\left(\\hat X;\\hat{Y}\\right)$ for at least one agent whereas\nfor $L\\longrightarrow\\infty$, we show that it suffices $R_i\\geq I\\left(\\hat\nX;\\hat Y|X\\right)$ for all agents where $\\hat Y$ is a random variable such that\n$X-\\hat X-\\hat Y$ and $\\|p_{X,\\hat\nY}\\left(x,y\\right)-p_{X,Y}\\left(x,y\\right)\\|_{TV}\\leq \\Delta$ ( $\\Delta$ is the\npre-specified fidelity).", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2004.08601v3"}
{"entry_id": "http://arxiv.org/abs/2103.02374v1", "date": "2021-03-03", "title": "Hemispheric Tectonics on super-Earth LHS 3844b", "authors": "Tobias G. Meier, Dan J. Bower, Tim Lichtenberg, Paul J. Tackley, Brice-Olivier Demory", "abstract": "The tectonic regime of rocky planets fundamentally influences their long-term\nevolution and cycling of volatiles between interior and atmosphere. Earth is\nthe only known planet with active plate tectonics, but observations of\nexoplanets may deliver insights into the diversity of tectonic regimes beyond\nthe solar system. Observations of the thermal phase curve of super-Earth LHS\n3844b reveal a solid surface and lack of a substantial atmosphere, with a\ntemperature contrast between the substellar and antistellar point of around\n1000 K. Here, we use these constraints on the planet's surface to constrain the\ninterior dynamics and tectonic regimes of LHS 3844b using numerical models of\ninterior flow. We investigate the style of interior convection by assessing how\nupwellings and downwellings are organized and how tectonic regimes manifest. We\ndiscover three viable convective regimes with a mobile surface: (1) spatially\nuniform distribution of upwellings and downwellings, (2) prominent downwelling\non the dayside and upwellings on the nightside, and (3) prominent downwelling\non the nightside and upwellings on the dayside. Hemispheric tectonics is\nobserved for regimes (2) and (3) as a direct consequence of the day-to-night\ntemperature contrast. Such a tectonic mode is absent in the present-day solar\nsystem and has never been inferred from astrophysical observations of\nexoplanets. Our models offer distinct predictions for volcanism and outgassing\nlinked to the tectonic regime, which may explain secondary features in phase\ncurves and allow future observations to constrain the diversity of super-Earth\ninteriors.", "journal": "ApJL 908 L48 (2021)", "doi": "10.3847/2041-8213/abe400", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2103.02374v1"}
{"entry_id": "http://arxiv.org/abs/1806.01181v2", "date": "2018-06-04", "title": "Two planetary systems with transiting Earth-size and super-Earth planets orbiting late-type dwarf stars", "authors": "E. Diez Alonso, J. I. Gonzalez Hernandez, S. L. Suarez Gomez, D. S. Aguado, C. Gonzalez Gutierrez, A. Suarez Mascareno, A. Cabrera-Lavers, J. Gonzalez-Nuevo, B. Toledo Padron, J. Gracia, F. J. de Cos Juez, R. Rebolo", "abstract": "We present two new planetary systems found around cool dwarf stars with data\nfrom the K2 mission. The first system was found in K2-239 (EPIC 248545986),\nchar- acterized in this work as M3.0V and observed in the 14th campaign of K2.\nIt consists of three Earth-size transiting planets with radii of 1.1, 1.0 and\n1.1 R Earth, showing a compact configuration with orbital periods of 5.24, 7.78\nand 10.1 days, close to 2:3:4 resonance. The second was found in K2-240 (EPIC\n249801827), characterized in this work as M0.5V and observed in the 15th\ncampaign. It consists of two transiting super-Earths with radii 2.0 and 1.8 R\nEarth and orbital periods of 6.03 and 20.5 days. The equilibrium temperatures\nof the atmospheres of these planets are estimated to be in the range of 380-600\nK and the amplitudes of signals in transmission spectroscopy are estimated at\n~10 ppm.", "journal": "", "doi": "10.1093/mnrasl/sly102", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1806.01181v2"}
{"entry_id": "http://arxiv.org/abs/1901.05446v2", "date": "2019-01-16", "title": "A large scale passive laser gyroscope for Earth rotation sensing", "authors": "K. Liu, F. L. Zhang, Z. Y. Li, X. H. Feng, K. Li, Z. H. Lu, K. U. Schreiber, J. Luo, J. Zhang", "abstract": "Earth rotation sensing has many applications in different disciplines, such\nas for the monitoring of ground motions, the establishment of UT1 and the test\nof the relativistic Lense-Thirring effect on the ground. We report the\ndevelopment of a 1 m*1 m heterolithic passive resonant gyroscope (PRG). By\nlocking a pair of laser beams to adjacent modes of the square ring cavity in\nthe clockwise and counter-clockwise directions, we achieve a rotation\nresolution of about 2E-9 rad/s at an integration time of 1000 s. The\nsensitivity of the PRG for rotations reaches a level of 2E-9 rad/s/rtHz in the\n5-100~Hz region, currently limited by the detection noise, residual amplitude\nmodulation and the mechanical instability of the cavity. Our initial results\nimprove the reported rotation sensitivity of the PRGs and indicate that PRGs\nhave a great potential for high-resolution Earth rotation sensing.", "journal": "", "doi": "10.1364/OL.44.002732", "primary_category": "physics.ins-det", "categories": ["physics.ins-det", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/1901.05446v2"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0611782v1", "date": "2006-11-26", "title": "Empirical Earth rotation model: a consistent way to evaluate Earth orientation parameters", "authors": "L. Petrov", "abstract": "It is customary to perform analysis of the Earth's rotation in two steps:\nfirst, to present results of estimation of the Earth orientation parameters in\nthe form of time series based on a simplified model of variations of the\nEarth's rotation for a short period of time, and then to process this time\nseries of adjustments by applying smoothing, re-sampling and other numerical\nalgorithms. Although this approach saves computational time, it suffers from\nself-inconsistency: total Earth orientation parameters depend on a subjective\nchoice of the apriori Earth orientation model, cross-correlations between\npoints of time series are lost, and results of an operational analysis per se\nhave a limited use for end users. An alternative approach of direct estimation\nof the coefficients of expansion of Euler angle perturbations into basis\nfunctions is developed. These coefficients describe the Earth's rotation over\nentire period of observations and are evaluated simultaneously with station\npositions, source coordinates and other parameters in a single LSQ solution. In\nthe framework of this approach considerably larger errors in apriori EOP model\nare tolerated. This approach gives a significant conceptual simplification of\nrepresentation of the Earth's rotation.", "journal": "in Geodetic Reference Frames, ed. by H. Drewes, Springer-Verlag,\n  2009, p. 233", "doi": "10.1007/978-3-642-00860-3_36", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0611782v1"}
{"entry_id": "http://arxiv.org/abs/1608.03718v2", "date": "2016-08-12", "title": "Tidal Heating of Young Super-Earth Atmospheres", "authors": "Sivan Ginzburg, Re'em Sari", "abstract": "Short-period Earth to Neptune size exoplanets (super-Earths) with voluminous\ngas envelopes seem to be very common. These gas atmospheres are thought to have\noriginated from the protoplanetary disk in which the planets were embedded\nduring their first few Myr. The accretion rate of gas from the surrounding\nnebula is determined by the ability of the gas to cool and radiate away its\ngravitational energy. Here we demonstrate that heat from the tidal interaction\nbetween the star and the young (and therefore inflated) planet can inhibit the\ngas cooling and accretion. Quantitatively, we find that the growth of\nsuper-Earth atmospheres halts for planets with periods of about 10 days,\nprovided that their initial eccentricities are of the order of 0.2. Thus, tidal\nheating provides a robust and simple mechanism that can simultaneously explain\nwhy these planets did not become gas giants and account for the deficit of\nlow-density planets closer to the star, where the tides are even stronger. We\nsuggest that tidal heating may be as important as other factors (such as the\nnebula's lifetime and atmosphere evaporation) in shaping the observed\nsuper-Earth population.", "journal": "MNRAS (February 01, 2017) Vol. 464 3937-3944", "doi": "10.1093/mnras/stw2637", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1608.03718v2"}
{"entry_id": "http://arxiv.org/abs/2111.05058v2", "date": "2021-11-09", "title": "The Second Earth Trojan 2020 XL$_{5}$", "authors": "Man-To Hui, Paul A. Wiegert, David J. Tholen, Dora F\u00f6hring", "abstract": "The Earth Trojans are co-orbitals librating around the Lagrange points $L_4$\nor $L_5$ of the Sun-Earth system. Although many numerical studies suggest that\nthey can maintain their dynamical status and be stable on timescales up to a\nfew tens of thousands of years or even longer, they remain an elusive\npopulation. Thus far only one transient member (2010 TK$_7$) has been\ndiscovered serendipitously. Here, we present a dynamical study of asteroid 2020\nXL$_5$. With our meticulous followup astrometric observations of the object, we\nconfirmed that it is a new Earth Trojan. However, its eccentric orbit brings it\nclose encounters with Venus on a frequent basis. Based on our N-body\nintegration, we found that the asteroid was captured into the current Earth\nTrojan status in the 15th century, and then it has a likelihood of 99.5% to\nleave the $L_4$ region within the next $\\sim$10 kyr. Therefore, it is most\nlikely that 2020 XL$_5$ is dynamically unstable over this timescale.", "journal": "", "doi": "10.3847/2041-8213/ac37bf", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2111.05058v2"}
{"entry_id": "http://arxiv.org/abs/2212.02353v1", "date": "2022-12-05", "title": "Observation of night-time emissions of the Earth in the near UV range from the International Space Station with the Mini-EUSO detector", "authors": "M. Casolino, D. Barghini, M. Battisti, C. Blaksley, A. Belov, M. Bertaina, M. Bianciotto, F. Bisconti, S. Blin, K. Bolmgren, G. Cambi\u00e8, F. Capel, I. Churilo, M. Crisconio, C. De La Taille, T. Ebisuzaki, J. Eser, F. Fenu, M. A. Franceschi, C. Fuglesang, A. Golzio, P. Gorodetzky, H. Kasuga, F. Kajino, P. Klimov, V. Kuznetsov, M. Manfrin, L. Marcelli, G. Mascetti, W. Marsza, H. Miyamoto, A. Murashov, T. Napolitano, H. Ohmori, A. Olinto, E. Parizot, P. Picozza, L. W. Piotrowski, Z. Plebaniak, G. Pr\u00e9v\u00f4t, E. Reali, G. Romoli, M. Ricci, N. Sakaki, K. Shinozaki, J. Szabelski, Y. Takizawa, G. Valentini, M. Vrabel, L. Wiencke", "abstract": "Mini-EUSO (Multiwavelength Imaging New Instrument for the Extreme Universe\nSpace Observatory) is a telescope observing the Earth from the International\nSpace Station since 2019. The instrument employs a Fresnel-lens optical system\nand a focal surface composed of 36 multi-anode photomultiplier tubes, 64\nchannels each, for a total of 2304 channels with single photon counting\nsensitivity. Mini-EUSO also contains two ancillary cameras to complement\nmeasurements in the near infrared and visible ranges. The scientific objectives\nof the mission range from the search for extensive air showers generated by\nUltra-High Energy Cosmic Rays (UHECRs) with energies above 10$^{21}$ eV, the\nsearch for nuclearites and Strange Quark Matter (SQM), up to the study of\natmospheric phenomena such as Transient Luminous Events (TLEs), meteors and\nmeteoroids. Mini-EUSO can map the night-time Earth in the near UV range\n(between 290-430 nm) with a spatial resolution of about 6.3 km (full field of\nview of 44{\\deg}) and a maximum temporal resolution of 2.5 $\\mu$s, observing\nour planet through a nadir-facing UV-transparent window in the Russian Zvezda\nmodule. The detector saves triggered transient phenomena with a sampling rate\nof 2.5 $\\mu$s and 320 $\\mu$s, as well as continuous acquisition at 40.96 ms\nscale. In this paper we discuss the detector response and the flat-fielding and\ncalibration procedures. Using the 40.96 ms data, we present $\\simeq$6.3 km\nresolution night-time Earth maps in the UV band, and report on various\nemissions of anthropogenic and natural origin. We measure ionospheric airglow\nemissions of dark moonless nights over the sea and ground, studying the effect\nof clouds, moonlight, and artificial (towns, boats) lights. In addition to\npaving the way forward for the study of long-term variations of natural and\nartificial light, we also estimate the observation live-time of future UHECR\ndetectors.", "journal": "Remote Sensing of Environment, Volume 284, January 2023, 113336", "doi": "10.1016/j.rse.2022.113336", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2212.02353v1"}
{"entry_id": "http://arxiv.org/abs/0806.2191v1", "date": "2008-06-13", "title": "Remote hole-doping of Mott insulators on the nanometer scale", "authors": "M. Takizawa, Y. Hotta, T. Susaki, Y. Ishida, H. Wadati, Y. Takata, K. Horiba, M. Matsunami, S. Shin, M. Yabashi, K. Tamasaku, N. Nishino, T. Ishikawa, A. Fujimori, H. Y. Hwang", "abstract": "At interfaces between polar and nonpolar perovskite oxides, an unusual\nelectron-doping has been previously observed, due to electronic\nreconstructions. We report on remote hole-doping at an interface composed of\nonly polar layers, revealed by high-resolution hard x-ray core-level\nphotoemission spectroscopy. In LaAlO3/LaVO3/LaAlO3 trilayers, the vanadium\nvalence systematically evolves from the bulk value of V3+ to higher oxidation\nstates with decreasing LaAlO3 cap layer thickness. These results provide a\nsynthetic approach to hole-doping transition metal oxide heterointerfaces\nwithout invoking a polar discontinuity.", "journal": "Phys. Rev. Lett. 102, 236401 (2009)", "doi": null, "primary_category": "cond-mat.str-el", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/0806.2191v1"}
{"entry_id": "http://arxiv.org/abs/0911.2742v1", "date": "2009-11-14", "title": "Coupling Remote States through the Continuum: Multi-State Fano Resonances", "authors": "Y. Yoon, M. -G. Kang, T. Morimoto, M. Kida, N. Aoki, J. L. Reno, Y. Ochiai, L. Mourokh, J. P. Bird", "abstract": "We demonstrate a fully-tunable multi-state Fano system in which\nremotely-implemented quantum states interfere with each other through their\ncoupling to a mutual continuum. On tuning these resonances near coincidence a\nrobust avoided crossing is observed, with a distinctive character that confirms\nthe continuum as the source of the coupling. While the continuum often serves\nas a source of decoherence, our work therefore shows how its presence can\ninstead also be essential to mediate the interaction of quantum states, a\nresult that could allow new approaches to engineer the collective states of\nnanostructures.", "journal": "Phys. Rev. X 2, 021003 (2012)", "doi": null, "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/0911.2742v1"}
{"entry_id": "http://arxiv.org/abs/2003.09230v1", "date": "2020-03-20", "title": "Remote weak signal measurement via bound states in optomechanical system", "authors": "Xun Li, Biao Xiong, Shilei Chao, Chengsong Zhao, Hua-Tang Tan, Ling Zhou", "abstract": "A scheme for remote weak signal sensor is proposed in which a coupled\nresonator optical waveguide~(CROW), as a transmitter, couples to a hybrid\noptomechanical cavity and an observing cavity, respectively. The non-Markovian\ntheory is employed to study the weak force sensor by treating the CROW as a\nnon-Markovian reservoir of the cavity fields, and the\nnegative-effective-mass~(NEM) oscillator is introduced to cancel the\nback-action noise. Under certain conditions, dissipationless bound states can\nbe formed such that weak signal can be transferred in the CROW without\ndissipation. Our results show that ultrahigh sensitivity can be achieved with\nthe assistance of the bound states under certain parameters regime.", "journal": "", "doi": "10.1088/1572-9494/abd0e8", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2003.09230v1"}
{"entry_id": "http://arxiv.org/abs/2001.06531v1", "date": "2020-01-17", "title": "Forming Diverse Super-Earth Systems in Situ", "authors": "Mariah G. MacDonald, Rebekah I. Dawson, Sarah J. Morrison, Eve J. Lee, Arjun Khandelwal", "abstract": "Super-Earths and mini-Neptunes exhibit great diversity in their compositional\nand orbital properties. Their bulk densities span a large range, from those\ndense enough to be purely rocky to those needing a substantial contribution\nfrom volatiles to their volumes. Their orbital configurations range from\ncompact, circular multi-transiting systems like Kepler-11 to systems like our\nSolar System's terrestrial planets with wider spacings and modest but\nsignificant eccentricities and mutual inclinations. Here we investigate whether\na continuum of formation conditions resulting from variation in the amount of\nsolids available in the inner disk can account for the diversity of orbital and\ncompositional properties observed for super Earths, including the apparent\ndichotomy between single transiting and multiple transiting system. We simulate\nin situ formation of super-Earths via giant impacts and compare to the observed\nKepler sample. We find that intrinsic variations among disks in the amount of\nsolids available for in situ formation can account for the orbital and\ncompositional diversity observed among Kepler's transiting planets. Our\nsimulations can account for the planets' distributions of orbital period\nratios, transit duration ratios, and transit multiplicity; higher\neccentricities for single than multi transiting planets; smaller eccentricities\nfor larger planets; scatter in the mass-radius relation, including lower\ndensities for planets with masses measured with TTVs than RVs; and similarity\nin planets' sizes and spacings within each system. Our findings support the\ntheory that variation among super-Earth and mini-Neptune properties is\nprimarily locked in by different in situ formation conditions, rather than\narising stochastically through subsequent evolution.", "journal": "", "doi": "10.3847/1538-4357/ab6f04", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2001.06531v1"}
{"entry_id": "http://arxiv.org/abs/2208.13825v1", "date": "2022-08-29", "title": "Differentiable Programming for Earth System Modeling", "authors": "Maximilian Gelbrecht, Alistair White, Sebastian Bathiany, Niklas Boers", "abstract": "Earth System Models (ESMs) are the primary tools for investigating future\nEarth system states at time scales from decades to centuries, especially in\nresponse to anthropogenic greenhouse gas release. State-of-the-art ESMs can\nreproduce the observational global mean temperature anomalies of the last 150\nyears. Nevertheless, ESMs need further improvements, most importantly regarding\n(i) the large spread in their estimates of climate sensitivity, i.e., the\ntemperature response to increases in atmospheric greenhouse gases, (ii) the\nmodeled spatial patterns of key variables such as temperature and\nprecipitation, (iii) their representation of extreme weather events, and (iv)\ntheir representation of multistable Earth system components and their ability\nto predict associated abrupt transitions. Here, we argue that making ESMs\nautomatically differentiable has huge potential to advance ESMs, especially\nwith respect to these key shortcomings. First, automatic differentiability\nwould allow objective calibration of ESMs, i.e., the selection of optimal\nvalues with respect to a cost function for a large number of free parameters,\nwhich are currently tuned mostly manually. Second, recent advances in Machine\nLearning (ML) and in the amount, accuracy, and resolution of observational data\npromise to be helpful with at least some of the above aspects because ML may be\nused to incorporate additional information from observations into ESMs.\nAutomatic differentiability is an essential ingredient in the construction of\nsuch hybrid models, combining process-based ESMs with ML components. We\ndocument recent work showcasing the potential of automatic differentiation for\na new generation of substantially improved, data-informed ESMs.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2208.13825v1"}
{"entry_id": "http://arxiv.org/abs/1602.08358v1", "date": "2016-02-26", "title": "Remote Heart Rate Sensing and Projection to Renew Traditional Board Games and Foster Social Interactions", "authors": "J\u00e9r\u00e9my Frey", "abstract": "While physiological sensors enter the mass market and reach the general\npublic, they are still mainly employed to monitor health -- whether it is for\nmedical purpose or sports. We describe an application that uses heart rate\nfeedback as an incentive for social interactions. A traditional board game has\nbeen \"augmented\" through remote physiological sensing, using webcams.\nProjection helped to conceal the technological aspects from users. We detail\nhow players reacted -- stressful situations could emerge when users are\ndeprived from their own signals -- and we give directions for game designers to\nintegrate physiological sensors.", "journal": "CHI '16 Extended Abstracts, May 2016, San Jose, United States.\n  2016", "doi": "10.1145/2851581.2892391", "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/1602.08358v1"}
{"entry_id": "http://arxiv.org/abs/2102.03908v1", "date": "2021-02-07", "title": "A Generative Model Method for Unsupervised Multispectral Image Fusion in Remote Sensing", "authors": "Arian Azarang, Nasser Kehtarnavaz", "abstract": "This paper presents a generative model method for multispectral image fusion\nin remote sensing which is trained without supervision. This method eases the\nsupervision of learning and it also considers a multi-objective loss function\nto achieve image fusion. The loss function incorporates both spectral and\nspatial distortions. Two discriminators are designed to minimize the spectral\nand spatial distortions of the generative output. Extensive experimentations\nare conducted using three public domain datasets. The comparison results across\nfour reduced-resolution and three full-resolution objective metrics show the\nsuperiority of the developed method over several recently developed methods.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2102.03908v1"}
{"entry_id": "http://arxiv.org/abs/2210.16924v1", "date": "2022-10-30", "title": "OGInfra: Geolocating Oil & Gas Infrastructure using Remote Sensing based Active Fire Data", "authors": "Samyak Prajapati, Amrit Raj, Yash Chaudhari, Akhilesh Nandwal, Japman Singh Monga", "abstract": "Remote sensing has become a crucial part of our daily lives, whether it be\nfrom triangulating our location using GPS or providing us with a weather\nforecast. It has multiple applications in domains such as military,\nsocio-economical, commercial, and even in supporting humanitarian efforts. This\nwork proposes a novel technique for the automated geo-location of Oil & Gas\ninfrastructure with the use of Active Fire Data from the NASA FIRMS data\nrepository & Deep Learning techniques; achieving a top accuracy of 90.68% with\nthe use of ResNet101.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2210.16924v1"}
{"entry_id": "http://arxiv.org/abs/1805.02091v1", "date": "2018-05-05", "title": "RiFCN: Recurrent Network in Fully Convolutional Network for Semantic Segmentation of High Resolution Remote Sensing Images", "authors": "Lichao Mou, Xiao Xiang Zhu", "abstract": "Semantic segmentation in high resolution remote sensing images is a\nfundamental and challenging task. Convolutional neural networks (CNNs), such as\nfully convolutional network (FCN) and SegNet, have shown outstanding\nperformance in many segmentation tasks. One key pillar of these successes is\nmining useful information from features in convolutional layers for producing\nhigh resolution segmentation maps. For example, FCN nonlinearly combines\nhigh-level features extracted from last convolutional layers; whereas SegNet\nutilizes a deconvolutional network which takes as input only coarse, high-level\nfeature maps of the last convolutional layer. However, how to better fuse\nmulti-level convolutional feature maps for semantic segmentation of remote\nsensing images is underexplored. In this work, we propose a novel bidirectional\nnetwork called recurrent network in fully convolutional network (RiFCN), which\nis end-to-end trainable. It has a forward stream and a backward stream. The\nformer is a classification CNN architecture for feature extraction, which takes\nan input image and produces multi-level convolutional feature maps from shallow\nto deep; while in the later, to achieve accurate boundary inference and\nsemantic segmentation, boundary-aware high resolution feature maps in shallower\nlayers and high-level but low-resolution features are recursively embedded into\nthe learning framework (from deep to shallow) to generate a fused feature\nrepresentation that draws a holistic picture of not only high-level semantic\ninformation but also low-level fine-grained details. Experimental results on\ntwo widely-used high resolution remote sensing data sets for semantic\nsegmentation tasks, ISPRS Potsdam and Inria Aerial Image Labeling Data Set,\ndemonstrate competitive performance obtained by the proposed methodology\ncompared to other studied approaches.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1805.02091v1"}
{"entry_id": "http://arxiv.org/abs/1704.07917v1", "date": "2017-04-25", "title": "Lightning Chemistry on Earth-like Exoplanets", "authors": "Aleksandra Ardaseva, Paul B. Rimmer, Ingo Waldmann, Marco Rocchetto, Sergei N. Yurchenko, Christiane Helling, Jonathan Tennyson", "abstract": "We present a model for lightning shock induced chemistry that can be applied\nto atmospheres of arbitrary H/C/N/O chemistry, hence for extrasolar planets and\nbrown dwarfs. The model couples hydrodynamics and the STAND2015 kinetic\ngas-phase chemistry. For an exoplanet analogue to the contemporary Earth, our\nmodel predicts NO and NO2 yields in agreement with observation. We predict\nheight-dependent mixing ratios during a storm soon after a lightning shock of\nNO ~ 1e-3 at 40 km and NO2 ~ 1e-4 below 40 km, with O3 reduced to trace\nquantities (<< 1e-10). For an Earth-like exoplanet with a CO2/N2 dominated\natmosphere and with an extremely intense lightning storm over its entire\nsurface, we predict significant changes in the amount of NO, NO2, O3, H2O, H2,\nand predict significant abundance of C2N. We find that, for the Early Earth, O2\nis formed in large quantities by lightning but is rapidly processed by the\nphotochemistry, consistent with previous work on lightning. The effect of\npersistent global lightning storms are predicted to be significant, primarily\ndue to NO2, with the largest spectral features present at ~3.4 {\\mu}m and ~6.2\n{\\mu}m. The features within the transmission spectrum are on the order of 1 ppm\nand therefore are not likely detectable with JWST. Depending on its spectral\nproperties, C2N could be a key tracer for lightning on Earth-like exoplanets\nwith a N2/CO2 bulk atmosphere, unless destroyed by yet unknown chemical\nreactions.", "journal": "", "doi": "10.1093/mnras/stx1012", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1704.07917v1"}
{"entry_id": "http://arxiv.org/abs/1807.08118v2", "date": "2018-07-21", "title": "Coupled dictionary learning for unsupervised change detection between multi-sensor remote sensing images", "authors": "Vinicius Ferraris, Nicolas Dobigeon, Yanna Cavalcanti, Thomas Oberlin, Marie Chabert", "abstract": "Archetypal scenarios for change detection generally consider two images\nacquired through sensors of the same modality. However, in some specific cases\nsuch as emergency situations, the only images available may be those acquired\nthrough sensors of different modalities. This paper addresses the problem of\nunsupervisedly detecting changes between two observed images acquired by\nsensors of different modalities with possibly different resolutions. These\nsensor dissimilarities introduce additional issues in the context of\noperational change detection that are not addressed by most of the classical\nmethods. This paper introduces a novel framework to effectively exploit the\navailable information by modelling the two observed images as a sparse linear\ncombination of atoms belonging to a pair of coupled overcomplete dictionaries\nlearnt from each observed image. As they cover the same geographical location,\ncodes are expected to be globally similar, except for possible changes in\nsparse spatial locations. Thus, the change detection task is envisioned through\na dual code estimation which enforces spatial sparsity in the difference\nbetween the estimated codes associated with each image. This problem is\nformulated as an inverse problem which is iteratively solved using an efficient\nproximal alternating minimization algorithm accounting for nonsmooth and\nnonconvex functions. The proposed method is applied to real images with\nsimulated yet realistic and real changes. A comparison with state-of-the-art\nchange detection methods evidences the accuracy of the proposed strategy.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "physics.data-an"], "pdf_url": "http://arxiv.org/pdf/1807.08118v2"}
{"entry_id": "http://arxiv.org/abs/2207.12175v1", "date": "2022-07-25", "title": "Overview of the remote sensing observations from PSP solar encounter 10 with perihelion at 13.3 Rsun", "authors": "Russell A. Howard, Guillermo Stenborg, Angelos Vourlidas, Brendan M. Gallagher, Mark G. Linton, Phillip Hess, Nathan B. Rich, Paulett C. Liewer", "abstract": "The closest perihelion pass of Parker Solar Probe (PSP), so far, occurred\nbetween 16 and 26 of November 2021 and reached ~13.29 Rsun from Sun center.\nThis pass resulted in very unique observations of the solar corona by the\nWide-field Instrument for Solar PRobe (WISPR). WISPR observed at least ten\nCMEs, some of which were so close that the structures appear distorted. All of\nthe CMEs appeared to have a magnetic flux rope (MFR) structure and most were\noriented such that the view was along the axis orientation, revealing very\ncomplex interiors. Two CMEs had a small MFR develop in the interior, with a\nbright circular boundary surrounding a very dark interior. Trailing the larger\nCMEs were substantial outflows of small blobs and flux-rope like structures\nwithin striated ribbons, lasting for many hours. When the heliophysics plasma\nsheet (HPS) was inclined, as it was during the days around perihelion on\nNovember 21, 2021, the outflow was over a very wide latitude range. One CME was\novertaken by a faster one, with a resultant compression of the rear of the\nleading CME and an unusual expansion in the trailing CME. The small Thomson\nSurface creates brightness variations of structures as they pass through the\nfield of view. In addition to this dynamic activity, a brightness band from\nexcess dust along the orbit of asteroid/comet 3200 Phaethon is also seen for\nseveral days.", "journal": "", "doi": "10.3847/1538-4357/ac7ff5", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2207.12175v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0609398v2", "date": "2006-09-14", "title": "Spectral Evolution of an Earth-Like Planet", "authors": "L. Kaltenegger, W. A. Traub, K. W. Jucks", "abstract": "We have developed a characterization of the geological evolution of the\nEarths atmosphere and surface in order to model the observable spectra of an\nEarth-like planet through its geological history. These calculations are\ndesigned to guide the interpretation of an observed spectrum of such a planet\nby future instruments that will characterize exoplanets. Our models focus on\nspectral features that either imply habitability or are required for\nhabitability. These features are generated by H2O, CO2, CH4, O2, O3, N2O, and\nvegetation-like surface albedos. We chose six geological epochs to\ncharacterize. These epochs exhibit a wide range in abundance for these\nmolecules, ranging from a CO2 rich early atmosphere, to a CO2/CH4-rich\natmosphere around 2 billion years ago to a present-day atmosphere. We analyzed\nthe spectra to quantify the strength of each important spectral feature in both\nthe visible and thermal infrared spectral regions, and the resolutions required\nto unambiguously observe the features for each epoch. We find a wide range of\nspectral resolutions required for observing the different features. For\nexample, H2O and O3 can be observed with relatively low resolution, while O2\nand N2O require higher resolution. We also find that the inclusion of clouds in\nour models significantly affects both the strengths and resolutions required to\nobserve all spectral features.", "journal": "Astrophys.J.658:598-616,2007", "doi": "10.1086/510996", "primary_category": "astro-ph", "categories": ["astro-ph", "astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0609398v2"}
{"entry_id": "http://arxiv.org/abs/1410.7355v2", "date": "2014-10-27", "title": "Magnetic Interaction of a Super-CME with the Earth's Magnetosphere: Scenario for Young Earth", "authors": "Vladimir S. Airapetian, Alex Glocer, William Danchi", "abstract": "Solar eruptions, known as Coronal Mass Ejections (CMEs), are frequently\nobserved on our Sun. Recent Kepler observations of superflares on G-type stars\nhave implied that so called super-CMEs, possessing kinetic energies 10 times of\nthe most powerful CME event ever observed on the Sun, could be produced with a\nfrequency of 1 event per 800-2000 yr on solar-like slowly rotating stars. We\nhave performed a 3D time-dependent global magnetohydrodynamic simulation of the\nmagnetic interaction of such a CME cloud with the Earth's magnetosphere. We\ncalculated the global structure of the perturbed magnetosphere and derive the\nlatitude of the open-closed magnetic field boundary. We also estimated energy\nfluxes penetrating the Earth's ionosphere and discuss the consequences of\nenergetic particle fluxes on biological systems on early Earth.", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1410.7355v2"}
{"entry_id": "http://arxiv.org/abs/1512.07805v1", "date": "2015-12-24", "title": "RFP: A Remote Fetching Paradigm for RDMA-Accelerated Systems", "authors": "Maomeng Su, Mingxing Zhang, Kang Chen, Yongwei Wu, Guoliang Li", "abstract": "Remote Direct Memory Access (RDMA) is an efficient way to improve the\nperformance of traditional client-server systems. Currently, there are two main\ndesign paradigms for RDMA-accelerated systems. The first allows the clients to\ndirectly operate the server's memory and totally bypasses the CPUs at server\nside. The second follows the traditional server-reply paradigm, which asks the\nserver to write results back to the clients. However, the first method has to\nexpose server's memory and needs tremendous re-design of upper-layer software,\nwhich is complex, unsafe, error-prone, and inefficient. The second cannot\nachieve high input/output operations per second (IOPS), because it employs\nout-bound RDMA-write at server side which is not efficient.\n  We find that the performance of out-bound RDMA-write and in-bound RDMA-read\nis asymmetric and the latter is 5 times faster than the former. Based on this\nobservation, we propose a novel design paradigm named Remote Fetching Paradigm\n(RFP). In RFP, the server is still responsible for processing requests from the\nclients. However, counter-intuitively, instead of sending results back to the\nclients through out-bound RDMA-write, the server only writes the results in\nlocal memory buffers, and the clients use in-bound RDMA-read to remotely fetch\nthese results. Since in-bound RDMA-read achieves much higher IOPS than\nout-bound RDMA-write, our model is able to bring higher performance than the\ntraditional models.\n  In order to prove the effectiveness of RFP, we design and implement an\nRDMA-accelerated in-memory key-value store following the RFP model. To further\nimprove the IOPS, we propose an optimization mechanism that combines status\nchecking and result fetching. Experiment results show that RFP can improve the\nIOPS by 160%~310% against state-of-the-art models for in-memory key-value\nstores.", "journal": "", "doi": null, "primary_category": "cs.DC", "categories": ["cs.DC"], "pdf_url": "http://arxiv.org/pdf/1512.07805v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0510611v1", "date": "2005-10-20", "title": "Near-UV to near-IR disk-averaged Earth's reflectance spectra", "authors": "S. Hamdani, L. Arnold, C. Foellmi, J. Berthier, D. Briot, P. Francois, P. Riaud, J. Schneider", "abstract": "We report 320 to 1020nm disk-averaged Earth reflectance spectra obtained from\nMoon's Earthshine observations with the EMMI spectrograph on the NTT at ESO La\nSilla (Chile). The spectral signatures of Earth atmosphere and ground\nvegetation are observed. A vegetation red-edge of up to 9% is observed on\nEurope and Africa and ~2% upon Pacific Ocean. The spectra also show that Earth\nis a blue planet when Rayleigh scattering dominates, or totally white when the\ncloud cover is large.", "journal": "", "doi": "10.1017/S1743921306009136", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0510611v1"}
{"entry_id": "http://arxiv.org/abs/2009.02130v4", "date": "2020-09-03", "title": "Multi-Attention-Network for Semantic Segmentation of Fine Resolution Remote Sensing Images", "authors": "Rui Li, Shunyi Zheng, Chenxi Duan, Ce Zhang, Jianlin Su, P. M. Atkinson", "abstract": "Semantic segmentation of remote sensing images plays an important role in a\nwide range of applications including land resource management, biosphere\nmonitoring and urban planning. Although the accuracy of semantic segmentation\nin remote sensing images has been increased significantly by deep convolutional\nneural networks, several limitations exist in standard models. First, for\nencoder-decoder architectures such as U-Net, the utilization of multi-scale\nfeatures causes the underuse of information, where low-level features and\nhigh-level features are concatenated directly without any refinement. Second,\nlong-range dependencies of feature maps are insufficiently explored, resulting\nin sub-optimal feature representations associated with each semantic class.\nThird, even though the dot-product attention mechanism has been introduced and\nutilized in semantic segmentation to model long-range dependencies, the large\ntime and space demands of attention impede the actual usage of attention in\napplication scenarios with large-scale input. This paper proposed a\nMulti-Attention-Network (MANet) to address these issues by extracting\ncontextual dependencies through multiple efficient attention modules. A novel\nattention mechanism of kernel attention with linear complexity is proposed to\nalleviate the large computational demand in attention. Based on kernel\nattention and channel attention, we integrate local feature maps extracted by\nResNeXt-101 with their corresponding global dependencies and reweight\ninterdependent channel maps adaptively. Numerical experiments on three\nlarge-scale fine resolution remote sensing images captured by different\nsatellite sensors demonstrate the superior performance of the proposed MANet,\noutperforming the DeepLab V3+, PSPNet, FastFCN, DANet, OCRNet, and other\nbenchmark approaches.", "journal": "", "doi": "10.1109/TGRS.2021.3093977", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2009.02130v4"}
{"entry_id": "http://arxiv.org/abs/1911.04924v1", "date": "2019-11-12", "title": "O Peer, Where Art Thou? Uncovering Remote Peering Interconnections at IXPs", "authors": "George Nomikos, Vasileios Kotronis, Pavlos Sermpezis, Petros Gigis, Lefteris Manassakis, Christoph Dietzel, Stavros Konstantaras, Xenofontas Dimitropoulos, Vasileios Giotsas", "abstract": "Internet eXchange Points (IXPs) are Internet hubs that mainly provide the\nswitching infrastructure to interconnect networks and exchange traffic. While\nthe initial goal of IXPs was to bring together networks residing in the same\ncity or country, and thus keep local traffic local, this model is gradually\nshifting. Many networks connect to IXPs without having physical presence at\ntheir switching infrastructure. This practice, called Remote Peering, is\nchanging the Internet topology and economy, and has become the subject of a\ncontentious debate within the network operators' community. However, despite\nthe increasing attention it attracts, the understanding of the characteristics\nand impact of remote peering is limited. In this work, we introduce and\nvalidate a heuristic methodology for discovering remote peers at IXPs. We (i)\nidentify critical remote peering inference challenges, (ii) infer remote peers\nwith high accuracy (>95%) and coverage (93%) per IXP, and (iii) characterize\ndifferent aspects of the remote peering ecosystem by applying our methodology\nto 30 large IXPs. We observe that remote peering is a significantly common\npractice in all the studied IXPs; for the largest IXPs, remote peers account\nfor 40% of their member base. We also show that today, IXP growth is mainly\ndriven by remote peering, which contributes two times more than local peering.", "journal": "", "doi": "10.1145/3278532.3278556", "primary_category": "cs.NI", "categories": ["cs.NI"], "pdf_url": "http://arxiv.org/pdf/1911.04924v1"}
{"entry_id": "http://arxiv.org/abs/2301.12614v1", "date": "2023-01-30", "title": "RREx-BoT: Remote Referring Expressions with a Bag of Tricks", "authors": "Gunnar A. Sigurdsson, Jesse Thomason, Gaurav S. Sukhatme, Robinson Piramuthu", "abstract": "Household robots operate in the same space for years. Such robots\nincrementally build dynamic maps that can be used for tasks requiring remote\nobject localization. However, benchmarks in robot learning often test\ngeneralization through inference on tasks in unobserved environments. In an\nobserved environment, locating an object is reduced to choosing from among all\nobject proposals in the environment, which may number in the 100,000s. Armed\nwith this intuition, using only a generic vision-language scoring model with\nminor modifications for 3d encoding and operating in an embodied environment,\nwe demonstrate an absolute performance gain of 9.84% on remote object grounding\nabove state of the art models for REVERIE and of 5.04% on FAO. When allowed to\npre-explore an environment, we also exceed the previous state of the art\npre-exploration method on REVERIE. Additionally, we demonstrate our model on a\nreal-world TurtleBot platform, highlighting the simplicity and usefulness of\nthe approach. Our analysis outlines a \"bag of tricks\" essential for\naccomplishing this task, from utilizing 3d coordinates and context, to\ngeneralizing vision-language models to large 3d search spaces.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.12614v1"}
{"entry_id": "http://arxiv.org/abs/2104.08109v1", "date": "2021-04-16", "title": "Split Learning Meets Koopman Theory for Wireless Remote Monitoring and Prediction", "authors": "Abanoub M. Girgis, Hyowoon Seo, Jihong Park, Mehdi Bennis, Jinho Choi", "abstract": "Remote state monitoring over wireless is envisaged to play a pivotal role in\nenabling beyond 5G applications ranging from remote drone control to remote\nsurgery. One key challenge is to identify the system dynamics that is\nnon-linear with a large dimensional state. To obviate this issue, in this\narticle we propose to train an autoencoder whose encoder and decoder are split\nand stored at a state sensor and its remote observer, respectively. This\nautoencoder not only decreases the remote monitoring payload size by reducing\nthe state representation dimension, but also learns the system dynamics by\nlifting it via a Koopman operator, thereby allowing the observer to locally\npredict future states after training convergence. Numerical results under a\nnon-linear cart-pole environment demonstrate that the proposed split learning\nof a Koopman autoencoder can locally predict future states, and the prediction\naccuracy increases with the representation dimension and transmission power.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2104.08109v1"}
{"entry_id": "http://arxiv.org/abs/1911.03607v1", "date": "2019-11-09", "title": "DeepMask: an algorithm for cloud and cloud shadow detection in optical satellite remote sensing images using deep residual network", "authors": "Ke Xu, Kaiyu Guan, Jian Peng, Yunan Luo, Sibo Wang", "abstract": "Detecting and masking cloud and cloud shadow from satellite remote sensing\nimages is a pervasive problem in the remote sensing community. Accurate and\nefficient detection of cloud and cloud shadow is an essential step to harness\nthe value of remotely sensed data for almost all downstream analysis. DeepMask,\na new algorithm for cloud and cloud shadow detection in optical satellite\nremote sensing imagery, is proposed in this study. DeepMask utilizes ResNet, a\ndeep convolutional neural network, for pixel-level cloud mask generation. The\nalgorithm is trained and evaluated on the Landsat 8 Cloud Cover Assessment\nValidation Dataset distributed across 8 different land types. Compared with\nCFMask, the most widely used cloud detection algorithm, land-type-specific\nDeepMask models achieve higher accuracy across all land types. The average\naccuracy is 93.56%, compared with 85.36% from CFMask. DeepMask also achieves\n91.02% accuracy on all-land-type dataset. Compared with other CNN-based cloud\nmask algorithms, DeepMask benefits from the parsimonious architecture and the\nresidual connection of ResNet. It is compatible with input of any size and\nshape. DeepMask still maintains high performance when using only red, green,\nblue, and NIR bands, indicating its potential to be applied to other satellite\nplatforms that only have limited optical bands.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1911.03607v1"}
{"entry_id": "http://arxiv.org/abs/2212.08490v4", "date": "2022-12-16", "title": "LOCT: A Lightweight Network Using OC-Transformer for Extracting Buildings and Roads from UAV Aerial Remote Sensing Images", "authors": "Xiaoxiang Han, Yiman Liu, Gang Liu, Yuanjie Lin, Qiaohong Liu", "abstract": "Semantic segmentation for extracting buildings and roads, from unmanned\naerial vehicle (UAV) remote sensing images by deep learning becomes a more\nefficient and convenient method than traditional manual segmentation in\nsurveying and mapping field. In order to make the model lightweight and improve\nthe model accuracy, A Lightweight Network Using OC-Transformer (LOCT) for\nBuildings and Roads from UAV Aerial Remote Sensing Images is proposed. The\nproposed network adopts an encoder-decoder architecture in which a Lightweight\nDensely Connected Network (LDCNet) is developed as the encoder. In the decoder\npart, the dual multi-scale context modules which consist of the Atrous Spatial\nPyramid Pooling module (ASPP) and the Object Contextual Transformer module\n(OC-Transformer) are designed to capture more context information from feature\nmaps of UAV remote sensing images. Between ASPP and OC-Transformer, a Feature\nPyramid Network (FPN) module is used to and fuse multi-scale features\nextracting from ASPP. A private dataset of remote sensing images taken by UAV\nwhich contains 2431 training sets, 945 validation sets, and 475 test sets is\nconstructed. The proposed model performs well on this dataset, with only 1.4M\nparameters and 5.48G floating-point operations (FLOPs), achieving an mean\nintersection-over-union ratio (mIoU) of 71.12%. More extensive experiments on\nthe public LoveDA dataset and CITY-OSM dataset to further verify the\neffectiveness of the proposed model with excellent results on mIoU of 65.27%\nand 74.39%, respectively. The source code will be made available on\nhttps://github.com/GtLinyer/LOCT .", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2212.08490v4"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0609802v1", "date": "2006-09-28", "title": "Striated AKR Emission: A Remote Tracer of Ion Solitary Structures", "authors": "R. L. Mutel, J. D. Menietti, I. W. Christopher, D. A. Gurnett, J. M. Cook", "abstract": "We describe the statistical properties of narrowband drifting auroral\nkilometric radiation ('striated' AKR) based on observations from the Cluster\nwideband receiver during 2002-2005. We show that the observed characteristics,\nincluding frequency drift rate and direction, narrow bandwidth, observed\nintensity, and beaming angular sizes are all consistent with triggering by\nupward traveling ion solitary structures (`ion holes'). We calculate the\nexpected perturbation of a horseshoe electron distribution function by an ion\nhole by integrating the resonance condition for a cyclotron maser instability\n(CMI) using the perturbed velocity distribution. We find that the CMI growth\nrate can be strongly enhanced as the horseshoe velocity distribution contracts\ninside the passing ion hole, resulting in a power gain increase greater than\n100 dB. The gain curve is sharply peaked just above the R-mode cut-off\nfrequency, with an effective bandwidth ~50 Hz, consistent with the observed\nbandwidth of striated AKR emission. Ion holes are observed in situ in the\nacceleration region moving upward with spatial scales and speeds consistent\nwith the observed bandwidth and slopes of SAKR bursts. Hence, we suggest that\nSAKR bursts are a remote sensor of ion holes and can be used to determine the\nfrequency of occurrence, locations in the acceleration region, and lifetimes of\nthese structures.", "journal": "", "doi": "10.1029/2006JA011660", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0609802v1"}
{"entry_id": "http://arxiv.org/abs/1709.02611v2", "date": "2017-09-08", "title": "Likelihood informed dimension reduction for inverse problems in remote sensing of atmospheric constituent profiles", "authors": "Otto Lamminp\u00e4\u00e4, Marko Laine, Simo Tukiainen, Johanna Tamminen", "abstract": "We use likelihood informed dimension reduction (LIS) (T. Cui et al. 2014) for\ninverting vertical profile information of atmospheric methane from ground based\nFourier transform infrared (FTIR) measurements at Sodankyl\\\"a, Northern\nFinland. The measurements belong to the word wide TCCON network for greenhouse\ngas measurements and, in addition to providing accurate greenhouse gas\nmeasurements, they are important for validating satellite observations. LIS\nallows construction of an efficient Markov chain Monte Carlo sampling algorithm\nthat explores only a reduced dimensional space but still produces a good\napproximation of the original full dimensional Bayesian posterior distribution.\nThis in effect makes the statistical estimation problem independent of the\ndiscretization of the inverse problem. In addition, we compare LIS to a\ndimension reduction method based on prior covariance matrix truncation used\nearlier (S. Tukiainen et al. 2016).", "journal": "", "doi": "10.1007/978-3-030-04161-8_6", "primary_category": "stat.CO", "categories": ["stat.CO"], "pdf_url": "http://arxiv.org/pdf/1709.02611v2"}
{"entry_id": "http://arxiv.org/abs/2012.00402v2", "date": "2020-12-01", "title": "Use of Remote Sensing Data to Identify Air Pollution Signatures in India", "authors": "Sivaramakrishnan KN, Lipika Deka, Manik Gupta", "abstract": "Air quality has major impact on a country's socio-economic position and\nidentifying major air pollution sources is at the heart of tackling the issue.\nSpatially and temporally distributed air quality data acquisition across a\ncountry as varied as India has been a challenge to such analysis. The launch of\nthe Sentinel-5P satellite has helped in the observation of a wider variety of\nair pollutants than measured before at a global scale on a daily basis. In this\nchapter, spatio-temporal multi pollutant data retrieved from Sentinel-5P\nsatellite is used to cluster states as well as districts in India and\nassociated average monthly pollution signature and trends depicted by each of\nthe clusters are derived and presented.The clustering signatures can be used to\nidentify states and districts based on the types of pollutants emitted by\nvarious pollution sources.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CY"], "pdf_url": "http://arxiv.org/pdf/2012.00402v2"}
{"entry_id": "http://arxiv.org/abs/1205.1366v3", "date": "2012-05-07", "title": "Remote sensing via $\\ell_1$ minimization", "authors": "Max H\u00fcgel, Holger Rauhut, Thomas Strohmer", "abstract": "We consider the problem of detecting the locations of targets in the far\nfield by sending probing signals from an antenna array and recording the\nreflected echoes. Drawing on key concepts from the area of compressive sensing,\nwe use an $\\ell_1$-based regularization approach to solve this, in general\nill-posed, inverse scattering problem. As common in compressed sensing, we\nexploit randomness, which in this context comes from choosing the antenna\nlocations at random. With $n$ antennas we obtain $n^2$ measurements of a vector\n$x \\in \\C^{N}$ representing the target locations and reflectivities on a\ndiscretized grid. It is common to assume that the scene $x$ is sparse due to a\nlimited number of targets. Under a natural condition on the mesh size of the\ngrid, we show that an $s$-sparse scene can be recovered via\n$\\ell_1$-minimization with high probability if $n^2 \\geq C s \\log^2(N)$. The\nreconstruction is stable under noise and under passing from sparse to\napproximately sparse vectors. Our theoretical findings are confirmed by\nnumerical simulations.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT", "math.NA", "math.PR"], "pdf_url": "http://arxiv.org/pdf/1205.1366v3"}
{"entry_id": "http://arxiv.org/abs/1401.6136v2", "date": "2014-01-23", "title": "Distributed Remote Vector Gaussian Source Coding with Covariance Distortion Constraints", "authors": "Adel Zahedi, Jan Ostergaard, Soren Holdt Jensen, Patrick Naylor, Soren Bech", "abstract": "In this paper, we consider a distributed remote source coding problem, where\na sequence of observations of source vectors is available at the encoder. The\nproblem is to specify the optimal rate for encoding the observations subject to\na covariance matrix distortion constraint and in the presence of side\ninformation at the decoder. For this problem, we derive lower and upper bounds\non the rate-distortion function (RDF) for the Gaussian case, which in general\ndo not coincide. We then provide some cases, where the RDF can be derived\nexactly. We also show that previous results on specific instances of this\nproblem can be generalized using our results. We finally show that if the\ndistortion measure is the mean squared error, or if it is replaced by a certain\nmutual information constraint, the optimal rate can be derived from our main\nresult.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1401.6136v2"}
{"entry_id": "http://arxiv.org/abs/1706.01171v2", "date": "2017-06-05", "title": "Binary Patterns Encoded Convolutional Neural Networks for Texture Recognition and Remote Sensing Scene Classification", "authors": "Rao Muhammad Anwer, Fahad Shahbaz Khan, Joost van de Weijer, Matthieu Molinier, Jorma Laaksonen", "abstract": "Designing discriminative powerful texture features robust to realistic\nimaging conditions is a challenging computer vision problem with many\napplications, including material recognition and analysis of satellite or\naerial imagery. In the past, most texture description approaches were based on\ndense orderless statistical distribution of local features. However, most\nrecent approaches to texture recognition and remote sensing scene\nclassification are based on Convolutional Neural Networks (CNNs). The d facto\npractice when learning these CNN models is to use RGB patches as input with\ntraining performed on large amounts of labeled data (ImageNet). In this paper,\nwe show that Binary Patterns encoded CNN models, codenamed TEX-Nets, trained\nusing mapped coded images with explicit texture information provide\ncomplementary information to the standard RGB deep models. Additionally, two\ndeep architectures, namely early and late fusion, are investigated to combine\nthe texture and color information. To the best of our knowledge, we are the\nfirst to investigate Binary Patterns encoded CNNs and different deep network\nfusion architectures for texture recognition and remote sensing scene\nclassification. We perform comprehensive experiments on four texture\nrecognition datasets and four remote sensing scene classification benchmarks:\nUC-Merced with 21 scene categories, WHU-RS19 with 19 scene classes, RSSCN7 with\n7 categories and the recently introduced large scale aerial image dataset (AID)\nwith 30 aerial scene types. We demonstrate that TEX-Nets provide complementary\ninformation to standard RGB deep model of the same network architecture. Our\nlate fusion TEX-Net architecture always improves the overall performance\ncompared to the standard RGB network on both recognition problems. Our final\ncombination outperforms the state-of-the-art without employing fine-tuning or\nensemble of RGB network architectures.", "journal": "", "doi": "10.1016/j.isprsjprs.2018.01.023", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1706.01171v2"}
{"entry_id": "http://arxiv.org/abs/2106.10605v2", "date": "2021-06-20", "title": "Global and Local Contrastive Self-Supervised Learning for Semantic Segmentation of HR Remote Sensing Images", "authors": "Haifeng Li, Yi Li, Guo Zhang, Ruoyun Liu, Haozhe Huang, Qing Zhu, Chao Tao", "abstract": "Supervised learning for semantic segmentation requires a large number of\nlabeled samples, which is difficult to obtain in the field of remote sensing.\nSelf-supervised learning (SSL), can be used to solve such problems by\npre-training a general model with a large number of unlabeled images and then\nfine-tuning it on a downstream task with very few labeled samples. Contrastive\nlearning is a typical method of SSL that can learn general invariant features.\nHowever, most existing contrastive learning methods are designed for\nclassification tasks to obtain an image-level representation, which may be\nsuboptimal for semantic segmentation tasks requiring pixel-level\ndiscrimination. Therefore, we propose a global style and local matching\ncontrastive learning network (GLCNet) for remote sensing image semantic\nsegmentation. Specifically, 1) the global style contrastive learning module is\nused to better learn an image-level representation, as we consider that style\nfeatures can better represent the overall image features. 2) The local features\nmatching contrastive learning module is designed to learn representations of\nlocal regions, which is beneficial for semantic segmentation. The experimental\nresults show that our method mostly outperforms SOTA self-supervised methods\nand the ImageNet pre-training method. Specifically, with 1\\% annotation from\nthe original dataset, our approach improves Kappa by 6\\% on the ISPRS Potsdam\ndataset relative to the existing baseline. Moreover, our method outperforms\nsupervised learning methods when there are some differences between the\ndatasets of upstream tasks and downstream tasks. Since SSL could directly learn\nthe essential characteristics of data from unlabeled data, which is easy to\nobtain in the remote sensing field, this may be of great significance for tasks\nsuch as global mapping. The source code is available at\nhttps://github.com/GeoX-Lab/G-RSIM.", "journal": "IEEE Transactions on Geoscience and Remote Sensing. 2022", "doi": "10.1109/TGRS.2022.3147513", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2106.10605v2"}
{"entry_id": "http://arxiv.org/abs/physics/0401122v1", "date": "2004-01-24", "title": "Folded Pendulum Measurements of Earth's Free Oscillations", "authors": "Randall D. Peters", "abstract": "The nearly-incessant free oscillations of the Earth (not the larger,\nlong-lived normal modes seen following intense quakes) were first observed by\naccident in the record of a tilt-sensitive instrument designed to study surface\nphysics. Later tiltmeter studies demonstrated the usefulness of autocorrelation\nfor the routine study of these normally short-lived eigenmodes. More recent\nstudies suggest that many tilt-sensitive instruments are capable of observing\nthese oscillations--if the low-frequency response of their electronics is not\nsuppressed, as is customary with conventional designs.", "journal": "", "doi": null, "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/physics/0401122v1"}
{"entry_id": "http://arxiv.org/abs/hep-ph/0305128v4", "date": "2003-05-12", "title": "Upward Tau Air Showers from Earth", "authors": "D. Fargion, P. G. De Sanctis Lucentini, M. De Santis. M. Grossi", "abstract": "We estimate the rate of observable Horizontal and Upward Tau Air-Showers\n(HORTAUs, UPTAUS) considering both the Earth opacity and the finite size of the\nterrestrial atmosphere. We calculate the effective target volumes and masses\nfor Tau air-showers emerging from the Earth. The resulting model-independent\nmasses for satellite experiments such as EUSO may encompass at E_nu_tau = 10^19\neV a very large volume, V= 1020 km^3. Adopting simple power law neutrino\nfluxes, E^-2 and E^-1, calibrated to GZK-like and Z-Burst-like models, we\nestimate that at E= 10^19 eV nearly half a dozen horizontal shower events\nshould be detected by EUSO in three years of data collection by the\n\"guaranteed\" GZK neutrino flux. We also find that the equivalent mass for an\nEarth outer layer made of rock is dominant compared to the water, contrary to\nsimplified all-rock/all-water Earth models and previous Montecarlo simulations.\nTherefore we expect an enhancement of neutrino detection along continental\nshelves nearby the highest mountain chains, also given the better geometrical\nacceptance for Earth skimming neutrinos. The Auger experiment might reveal such\na signature at E_nu= 10^{18} eV (with 26 events in 3 yr) towards the Andes, if\nthe angular resolution at the horizon (both in azimuth and zenith) would reach\nan accuracy of nearly one degree needed to disentangle tau air showers from\ncommon UHECR. The number of events increases at lower energies; therefore we\nsuggest an extension of the EUSO and Auger sensitivity down to (or even below)\nE_nu = 10^19 eV and E_nu = 10^18 eV respectively.", "journal": "Astrophys.J. 613 (2004) 1285-1301", "doi": "10.1086/423124", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph", "nucl-th"], "pdf_url": "http://arxiv.org/pdf/hep-ph/0305128v4"}
{"entry_id": "http://arxiv.org/abs/1108.2302v1", "date": "2011-08-10", "title": "A Gaseous Group with Unusual Remote Star Formation", "authors": "Nitza Santiago-Figueroa, Mary E. Putman, Jessica Werk, Gerhardt R. Meurer, Emma Ryan-Weber", "abstract": "We present VLA 21-cm observations of the spiral galaxy ESO 481-G017 to\ndetermine the nature of remote star formation traced by an HII region found 43\nkpc and ~800 km s^-1 from the galaxy center (in projection). ESO 481-G017 is\nfound to have a 120 kpc HI disk with a mass of 1.2x10^10 Msun and UV GALEX\nimages reveal spiral arms extending into the gaseous disk. Two dwarf galaxies\nwith HI masses close to 10^8 Msun are detected at distances of ~200 kpc from\nESO 481-G017 and a HI cloud with a mass of 6x10^7 Msun is found near the\nposition and velocity of the remote HII region. The HII region is somewhat\noffset from the HI cloud spatially and there is no link to ESO 481-G017 or the\ndwarf galaxies. We consider several scenarios for the origin of the cloud and\nHII region and find the most likely is a dwarf galaxy that is undergoing ram\npressure stripping. The HI mass of the cloud and Halpha luminosity of the HII\nregion (10^38.1 erg s^-1) are consistent with dwarf galaxy properties, and the\nstripping can trigger the star formation as well as push the gas away from the\nstars.", "journal": "", "doi": "10.1071/AS11008", "primary_category": "astro-ph.CO", "categories": ["astro-ph.CO"], "pdf_url": "http://arxiv.org/pdf/1108.2302v1"}
{"entry_id": "http://arxiv.org/abs/1802.09380v2", "date": "2018-02-26", "title": "Apparent remote synchronization of amplitudes: a demodulation and interference effect", "authors": "Ludovico Minati, Luca Faes, Mattia Frasca, Pawel Oswiecimka, Stanislaw Drozdz", "abstract": "A form of \"remote synchronization\" was recently described wherein amplitude\nfluctuations across a ring of non-identical, non-linear electronic oscillators\nbecome entrained into spatially-structured patterns. According to linear models\nand mutual information, synchronization and causality dip at a certain\ndistance, then recover before eventually fading. Here, the underlying mechanism\nis finally elucidated through novel experiments and simulations. The system\nnon-linearity is found to have a dual role: it supports chaotic dynamics, and\nit enables energy exchange between the lower and higher sidebands of a\npredominant frequency. This frequency acts as carrier signal in an arrangement\nresembling standard amplitude modulation, wherein the lower sideband and the\ndemodulated baseband signals spectrally overlap. Due to a spatially-dependent\nphase relationship, at a certain distance near-complete destructive\ninterference occurs between them, causing the observed dip. Methods suitable\nfor detecting non-trivial entrainment, such as transfer entropy and the\nauxiliary system approach, nevertheless reveal that synchronization and\ncausality actually decrease with distance monotonically. Remoteness is,\ntherefore, arguably only apparent, as also reflected in the propagation of\nexternal perturbations. These results demonstrate a complex mechanism of\ndynamical interdependence, and exemplify how it can lead to incorrectly\ninferring synchronization and causality.", "journal": "Chaos 28, 063124 (2018)", "doi": "10.1063/1.5026980", "primary_category": "nlin.CD", "categories": ["nlin.CD"], "pdf_url": "http://arxiv.org/pdf/1802.09380v2"}
{"entry_id": "http://arxiv.org/abs/1612.06303v4", "date": "2016-12-19", "title": "Remote effects spatial process models for modeling teleconnections", "authors": "Joshua Hewitt, Jennifer A. Hoeting, James Done, Erin Towler", "abstract": "While most spatial data can be modeled with the assumption that distant\npoints are uncorrelated, some problems require dependence at both far and short\ndistances. We introduce a model to directly incorporate dependence in phenomena\nthat influence a distant response. Spatial climate problems often have such\nmodeling needs as data are influenced by local factors in addition to remote\nphenomena, known as teleconnections. Teleconnections arise from complex\ninteractions between the atmosphere and ocean, of which the El Nino--Southern\nOscillation teleconnection is a well-known example. Our model extends the\nstandard geostatistical modeling framework to account for effects of covariates\nobserved on a spatially remote domain. We frame our model as an extension of\nspatially varying coefficient models. Connections to existing methods are\nhighlighted and further modeling needs are addressed by additionally drawing on\nspatial basis functions and predictive processes. Notably, our approach allows\nusers to model teleconnected data without pre-specifying teleconnection\nindices, which other methods often require. We adopt a hierarchical Bayesian\nframework to conduct inference and make predictions. The method is demonstrated\nby predicting precipitation in Colorado while accounting for local factors and\nteleconnection effects with Pacific Ocean sea surface temperatures. We show how\nthe proposed model improves upon standard methods for estimating teleconnection\neffects and discuss its utility for climate applications.", "journal": "", "doi": null, "primary_category": "stat.ME", "categories": ["stat.ME"], "pdf_url": "http://arxiv.org/pdf/1612.06303v4"}
{"entry_id": "http://arxiv.org/abs/2204.09868v1", "date": "2022-04-21", "title": "Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval", "authors": "Zhiqiang Yuan, Wenkai Zhang, Kun Fu, Xuan Li, Chubo Deng, Hongqi Wang, Xian Sun", "abstract": "Remote sensing (RS) cross-modal text-image retrieval has attracted extensive\nattention for its advantages of flexible input and efficient query. However,\ntraditional methods ignore the characteristics of multi-scale and redundant\ntargets in RS image, leading to the degradation of retrieval accuracy. To cope\nwith the problem of multi-scale scarcity and target redundancy in RS multimodal\nretrieval task, we come up with a novel asymmetric multimodal feature matching\nnetwork (AMFMN). Our model adapts to multi-scale feature inputs, favors\nmulti-source retrieval methods, and can dynamically filter redundant features.\nAMFMN employs the multi-scale visual self-attention (MVSA) module to extract\nthe salient features of RS image and utilizes visual features to guide the text\nrepresentation. Furthermore, to alleviate the positive samples ambiguity caused\nby the strong intraclass similarity in RS image, we propose a triplet loss\nfunction with dynamic variable margin based on prior similarity of sample\npairs. Finally, unlike the traditional RS image-text dataset with coarse text\nand higher intraclass similarity, we construct a fine-grained and more\nchallenging Remote sensing Image-Text Match dataset (RSITMD), which supports RS\nimage retrieval through keywords and sentence separately and jointly.\nExperiments on four RS text-image datasets demonstrate that the proposed model\ncan achieve state-of-the-art performance in cross-modal RS text-image retrieval\ntask.", "journal": "in IEEE Transactions on Geoscience and Remote Sensing, vol. 60,\n  pp. 1-19, 2022, Art no. 4404119", "doi": "10.1109/TGRS.2021.3078451", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.MM"], "pdf_url": "http://arxiv.org/pdf/2204.09868v1"}
{"entry_id": "http://arxiv.org/abs/1409.7474v1", "date": "2014-09-26", "title": "Extracting man-made objects from remote sensing images via fast level set evolutions", "authors": "Zhongbin Li, Wenzhong Shi, Qunming Wang, Zelang Miao", "abstract": "Object extraction from remote sensing images has long been an intensive\nresearch topic in the field of surveying and mapping. Most existing methods are\ndevoted to handling just one type of object and little attention has been paid\nto improving the computational efficiency. In recent years, level set evolution\n(LSE) has been shown to be very promising for object extraction in the\ncommunity of image processing and computer vision because it can handle\ntopological changes automatically while achieving high accuracy. However, the\napplication of state-of-the-art LSEs is compromised by laborious parameter\ntuning and expensive computation. In this paper, we proposed two fast LSEs for\nman-made object extraction from high spatial resolution remote sensing images.\nThe traditional mean curvature-based regularization term is replaced by a\nGaussian kernel and it is mathematically sound to do that. Thus a larger time\nstep can be used in the numerical scheme to expedite the proposed LSEs. In\ncontrast to existing methods, the proposed LSEs are significantly faster. Most\nimportantly, they involve much fewer parameters while achieving better\nperformance. The advantages of the proposed LSEs over other state-of-the-art\napproaches have been verified by a range of experiments.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, Vol.53(2),\n  pp.883-899, 2015", "doi": "10.1109/TGRS.2015.2454251", "primary_category": "cs.CV", "categories": ["cs.CV", "68T10, 68T45", "B.2.4; I.4.6; I.4.8"], "pdf_url": "http://arxiv.org/pdf/1409.7474v1"}
{"entry_id": "http://arxiv.org/abs/2010.13106v1", "date": "2020-10-25", "title": "Scribble-based Weakly Supervised Deep Learning for Road Surface Extraction from Remote Sensing Images", "authors": "Yao Wei, Shunping Ji", "abstract": "Road surface extraction from remote sensing images using deep learning\nmethods has achieved good performance, while most of the existing methods are\nbased on fully supervised learning, which requires a large amount of training\ndata with laborious per-pixel annotation. In this paper, we propose a\nscribble-based weakly supervised road surface extraction method named\nScRoadExtractor, which learns from easily accessible scribbles such as\ncenterlines instead of densely annotated road surface ground-truths. To\npropagate semantic information from sparse scribbles to unlabeled pixels, we\nintroduce a road label propagation algorithm which considers both the\nbuffer-based properties of road networks and the color and spatial information\nof super-pixels. The proposal masks generated from the road label propagation\nalgorithm are utilized to train a dual-branch encoder-decoder network we\ndesigned, which consists of a semantic segmentation branch and an auxiliary\nboundary detection branch. We perform experiments on three diverse road\ndatasets that are comprised of highresolution remote sensing satellite and\naerial images across the world. The results demonstrate that ScRoadExtractor\nexceed the classic scribble-supervised segmentation method by 20% for the\nintersection over union (IoU) indicator and outperform the state-of-the-art\nscribble-based weakly supervised methods at least 4%.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2010.13106v1"}
{"entry_id": "http://arxiv.org/abs/1908.10695v1", "date": "2019-08-26", "title": "Remote sensing of exoplanetary atmospheres with ground-based high-resolution near-infrared spectroscopy", "authors": "D. Shulyak, M. Rengel, A. Reiners, U. Seemann, F. Yan", "abstract": "Thanks to the advances in modern instrumentation we have learned about many\nexoplanets that span a wide range of masses and composition. Studying their\natmospheres provides insight into planetary origin, evolution, dynamics, and\nhabitability. Present and future observing facilities will address these\nimportant topics in great detail by using more precise observations,\nhigh-resolution spectroscopy, and improved analysis methods. We investigate the\nfeasibility of retrieving the vertical temperature distribution and molecular\nnumber densities from expected exoplanet spectra in the near-infrared. We use\nthe test case of the CRIRES+, instrument at the Very Large Telescope which will\noperate in the near-infrared between 1 and 5 micron and resolving powers of\nR=100000 and R=50000. We also determine the optimal wavelength coverage and\nobservational strategies for increasing accuracy in the retrievals. We used the\noptimal estimation approach to retrieve the atmospheric parameters from the\nsimulated emission observations of the hot Jupiter HD~189733b. The radiative\ntransfer forward model is calculated using a public version of the tauREx\nsoftware package. Our simulations show that we can retrieve accurate\ntemperature distribution in a very wide range of atmospheric pressures between\n1 bar and $10^{-6}$ bar depending on the chosen spectral region. Retrieving\nmolecular mixing ratios is very challenging, but a simultaneous observations in\ntwo separate infrared regions around 1.6 micron and 2.3 micron helps to obtain\naccurate estimates; the exoplanetary spectra must be of relatively high\nsignal-to-noise ratio S/N>10, while the temperature can already be derived\naccurately with the lowest value that we considered in this study (S/N=5).", "journal": "A&A 629, A109 (2019)", "doi": "10.1051/0004-6361/201935691", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1908.10695v1"}
{"entry_id": "http://arxiv.org/abs/1811.03636v1", "date": "2018-11-08", "title": "Super-Earths in the TW Hya disc", "authors": "Daniel Mentiplay, Daniel J. Price, Christophe Pinte", "abstract": "We test the hypothesis that the sub-millimetre thermal emission and scattered\nlight gaps seen in recent observations of TW Hya are caused by planet-disc\ninteractions. We perform global three-dimensional dusty smoothed particle\nhydrodynamics simulations, comparing synthetic observations of our models with\ndust thermal emission, CO emission and scattered light observations. We find\nthat the dust gaps observed at 24 au and 41 au can be explained by two\nsuper-Earths ($\\sim 4 \\mathrm{M}_{\\oplus}$). A planet of approximately\nSaturn-mass can explain the CO emission and the depth and width of the gap seen\nin scattered light at 94 au. Our model produces a prominent spiral arm while\nthere are only hints of this in the data. To avoid runaway growth and migration\nof the planets we require a disc mass of $\\lesssim 10^{-2}\\,\\mathrm{M}_{\\odot}$\nin agreement with CO observations but 10$-$100 times lower than the estimate\nfrom HD line emission.", "journal": "", "doi": "10.1093/mnrasl/sly209", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1811.03636v1"}
{"entry_id": "http://arxiv.org/abs/2103.15743v1", "date": "2021-03-29", "title": "Roadmap for Rare-earth Quantum Computing", "authors": "Adam Kinos, David Hunger, Roman Kolesov, Klaus M\u00f8lmer, Hugues de Riedmatten, Philippe Goldner, Alexandre Tallaire, Loic Morvan, Perrine Berger, Sacha Welinski, Khaled Karrai, Lars Rippe, Stefan Kr\u00f6ll, Andreas Walther", "abstract": "Several platforms are being considered as hardware for quantum technologies.\nFor quantum computing (QC), superconducting qubits and artificially trapped\nions are among the leading platforms, but many others also show promise, e.g.\nphotons, cold atoms, defect centers including Rare-Earth (RE) ions. So far,\nresults are limited to the regime of noisy intermediate scale qubits (NISQ),\nwith a small number of qubits and a limited connectivity, and it is likely that\nfuture QC hardware will utilize several existing platforms in different ways.\nThus, it currently makes sense to invest resources broadly and explore the full\nrange of promising routes to quantum technology. Rare-earth ions in solids\nconstitute one of the most versatile platforms for future quantum technology.\nOne advantage is good coherence properties even when confined in strong natural\ntraps inside a solid-state matrix. This confinement allows very high qubit\ndensities and correspondingly strong ion-ion couplings. In addition, although\ntheir fluorescence is generally weak, cavity integration can enhance the\nemission greatly and enable very good connections to photonic circuits,\nincluding at the telecom wavelengths, making them promising systems for\nlong-term scalability. The primary aim of this roadmap is to provide a complete\npicture of what components a RE quantum computer would consist of, to describe\nthe details of all parts required to achieve a scalable system, and to discuss\nthe most promising paths to reach it. In brief, we find that clusters of 50-100\nsingle RE ions can act as high fidelity qubits in small processors, occupying\nonly about (10 nm)^3. Due to the high capacity for integration of the RE\nsystems, they be optically read out and connected to other such clusters for\nlarger scalability. We make suggestions for future improvements, which could\nallow the REQC platform to be a leading one.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2103.15743v1"}
{"entry_id": "http://arxiv.org/abs/1106.2141v3", "date": "2011-06-10", "title": "A Low Cost Remote Sensing System Using PC and Stereo Equipment", "authors": "Joel F. Campbell, Michael A. Flood, Narasimha S. Prasad, Wade D. Hodson", "abstract": "A system using a personal computer, speaker, and a microphone is used to\ndetect objects, and make crude measurements using a carrier modulated by a\npseudorandom noise (PN) code. This system can be constructed using a personal\ncomputer and audio equipment commonly found in the laboratory or at home, or\nmore sophisticated equipment that can be purchased at reasonable cost. We\ndemonstrate its value as an instructional tool for teaching concepts of remote\nsensing and digital signal processing.", "journal": "American Journal of Physics, Vol 79, Issue 12, Dec 2011", "doi": "10.1119/1.3643704", "primary_category": "physics.ed-ph", "categories": ["physics.ed-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/1106.2141v3"}
{"entry_id": "http://arxiv.org/abs/1903.05862v1", "date": "2019-03-14", "title": "Learning Orientation-Estimation Convolutional Neural Network for Building Detection in Optical Remote Sensing Image", "authors": "Yongliang Chen", "abstract": "Benefiting from the great success of deep learning in computer vision,\nCNN-based object detection methods have drawn significant attentions. Various\nframeworks have been proposed which show awesome and robust performance for a\nlarge range of datasets. However, for building detection in remote sensing\nimages, buildings always pose a diversity of orientations which makes it a\nchallenge for the application of off-the-shelf methods to building detection.\nIn this work, we aim to integrate orientation regression into the popular\naxis-aligned bounding-box detection method to tackle this problem. To adapt the\naxis-aligned bounding boxes to arbitrarily orientated ones, we also develop an\nalgorithm to estimate the Intersection over Union (IoU) overlap between any two\narbitrarily oriented boxes which is convenient to implement in Graphics\nProcessing Unit (GPU) for accelerating computation. The proposed method\nutilizes CNN for both robust feature extraction and rotated bounding box\nregression. We present our modelin an end-to-end fashion making it easy to\ntrain. The model is formulated and trained to predict orientation, location and\nextent simultaneously obtaining tighter bounding box and hence, higher mean\naverage precision (mAP). Experiments on remote sensing images of different\nscales shows a promising performance over the conventional one.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1903.05862v1"}
{"entry_id": "http://arxiv.org/abs/2006.05612v1", "date": "2020-06-10", "title": "Deep Learning for Change Detection in Remote Sensing Images: Comprehensive Review and Meta-Analysis", "authors": "Lazhar Khelifi, Max Mignotte", "abstract": "Deep learning (DL) algorithms are considered as a methodology of choice for\nremote-sensing image analysis over the past few years. Due to its effective\napplications, deep learning has also been introduced for automatic change\ndetection and achieved great success. The present study attempts to provide a\ncomprehensive review and a meta-analysis of the recent progress in this\nsubfield. Specifically, we first introduce the fundamentals of deep learning\nmethods which arefrequently adopted for change detection. Secondly, we present\nthe details of the meta-analysis conducted to examine the status of change\ndetection DL studies. Then, we focus on deep learning-based change detection\nmethodologies for remote sensing images by giving a general overview of the\nexisting methods. Specifically, these deep learning-based methods were\nclassified into three groups; fully supervised learning-based methods, fully\nunsupervised learning-based methods and transfer learning-based techniques. As\na result of these investigations, promising new directions were identified for\nfuture research. This study will contribute in several ways to our\nunderstanding of deep learning for change detection and will provide a basis\nfor further research.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2006.05612v1"}
{"entry_id": "http://arxiv.org/abs/2108.06073v1", "date": "2021-08-13", "title": "Coupling Model-Driven and Data-Driven Methods for Remote Sensing Image Restoration and Fusion", "authors": "Huanfeng Shen, Menghui Jiang, Jie Li, Chenxia Zhou, Qiangqiang Yuan, Liangpei Zhang", "abstract": "In the fields of image restoration and image fusion, model-driven methods and\ndata-driven methods are the two representative frameworks. However, both\napproaches have their respective advantages and disadvantages. The model-driven\nmethods consider the imaging mechanism, which is deterministic and\ntheoretically reasonable; however, they cannot easily model complicated\nnonlinear problems. The data-driven methods have a stronger prior knowledge\nlearning capability for huge data, especially for nonlinear statistical\nfeatures; however, the interpretability of the networks is poor, and they are\nover-dependent on training data. In this paper, we systematically investigate\nthe coupling of model-driven and data-driven methods, which has rarely been\nconsidered in the remote sensing image restoration and fusion communities. We\nare the first to summarize the coupling approaches into the following three\ncategories: 1) data-driven and model-driven cascading methods; 2) variational\nmodels with embedded learning; and 3) model-constrained network learning\nmethods. The typical existing and potential coupling methods for remote sensing\nimage restoration and fusion are introduced with application examples. This\npaper also gives some new insights into the potential future directions, in\nterms of both methods and applications.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2108.06073v1"}
{"entry_id": "http://arxiv.org/abs/2201.03686v1", "date": "2022-01-10", "title": "NFANet: A Novel Method for Weakly Supervised Water Extraction from High-Resolution Remote Sensing Imagery", "authors": "Ming Lu, Leyuan Fang, Muxing Li, Bob Zhang, Yi Zhang, Pedram Ghamisi", "abstract": "The use of deep learning for water extraction requires precise pixel-level\nlabels. However, it is very difficult to label high-resolution remote sensing\nimages at the pixel level. Therefore, we study how to utilize point labels to\nextract water bodies and propose a novel method called the neighbor feature\naggregation network (NFANet). Compared with pixellevel labels, point labels are\nmuch easier to obtain, but they will lose much information. In this paper, we\ntake advantage of the similarity between the adjacent pixels of a local\nwater-body, and propose a neighbor sampler to resample remote sensing images.\nThen, the sampled images are sent to the network for feature aggregation. In\naddition, we use an improved recursive training algorithm to further improve\nthe extraction accuracy, making the water boundary more natural. Furthermore,\nour method utilizes neighboring features instead of global or local features to\nlearn more representative features. The experimental results show that the\nproposed NFANet method not only outperforms other studied weakly supervised\napproaches, but also obtains similar results as the state-of-the-art ones.", "journal": "", "doi": "10.1109/TGRS.2022.3140323", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2201.03686v1"}
{"entry_id": "http://arxiv.org/abs/2209.14364v1", "date": "2022-09-28", "title": "Semantic Segmentation of Vegetation in Remote Sensing Imagery Using Deep Learning", "authors": "Alexandru Munteanu, Marian Neagul", "abstract": "In recent years, the geospatial industry has been developing at a steady\npace. This growth implies the addition of satellite constellations that produce\na copious supply of satellite imagery and other Remote Sensing data on a daily\nbasis. Sometimes, this information, even if in some cases we are referring to\npublicly available data, it sits unaccounted for due to the sheer size of it.\nProcessing such large amounts of data with the help of human labour or by using\ntraditional automation methods is not always a viable solution from the\nstandpoint of both time and other resources.\n  Within the present work, we propose an approach for creating a multi-modal\nand spatio-temporal dataset comprised of publicly available Remote Sensing data\nand testing for feasibility using state of the art Machine Learning (ML)\ntechniques. Precisely, the usage of Convolutional Neural Networks (CNN) models\nthat are capable of separating different classes of vegetation that are present\nin the proposed dataset. Popularity and success of similar methods in the\ncontext of Geographical Information Systems (GIS) and Computer Vision (CV) more\ngenerally indicate that methods alike should be taken in consideration and\nfurther analysed and developed.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2209.14364v1"}
{"entry_id": "http://arxiv.org/abs/1101.2987v1", "date": "2011-01-15", "title": "Support vector machines/relevance vector machine for remote sensing classification: A review", "authors": "Mahesh Pal", "abstract": "Kernel-based machine learning algorithms are based on mapping data from the\noriginal input feature space to a kernel feature space of higher dimensionality\nto solve a linear problem in that space. Over the last decade, kernel based\nclassification and regression approaches such as support vector machines have\nwidely been used in remote sensing as well as in various civil engineering\napplications. In spite of their better performance with different datasets,\nsupport vector machines still suffer from shortcomings such as\nvisualization/interpretation of model, choice of kernel and kernel specific\nparameter as well as the regularization parameter. Relevance vector machines\nare another kernel based approach being explored for classification and\nregression with in last few years. The advantages of the relevance vector\nmachines over the support vector machines is the availability of probabilistic\npredictions, using arbitrary kernel functions and not requiring setting of the\nregularization parameter. This paper presents a state-of-the-art review of SVM\nand RVM in remote sensing and provides some details of their use in other civil\nengineering application also.", "journal": "Proceeding of the Workshop on Application of advanced soft\n  computing Techniques in Geo-spatial Data Analysis. Department of Civil\n  Engineering, IIT Bombay, Sept. 22-23,2008, 211-227", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1101.2987v1"}
{"entry_id": "http://arxiv.org/abs/2210.12989v1", "date": "2022-10-24", "title": "Robust Object Detection in Remote Sensing Imagery with Noisy and Sparse Geo-Annotations (Full Version)", "authors": "Maximilian Bernhard, Matthias Schubert", "abstract": "Recently, the availability of remote sensing imagery from aerial vehicles and\nsatellites constantly improved. For an automated interpretation of such data,\ndeep-learning-based object detectors achieve state-of-the-art performance.\nHowever, established object detectors require complete, precise, and correct\nbounding box annotations for training. In order to create the necessary\ntraining annotations for object detectors, imagery can be georeferenced and\ncombined with data from other sources, such as points of interest localized by\nGPS sensors. Unfortunately, this combination often leads to poor object\nlocalization and missing annotations. Therefore, training object detectors with\nsuch data often results in insufficient detection performance. In this paper,\nwe present a novel approach for training object detectors with extremely noisy\nand incomplete annotations. Our method is based on a teacher-student learning\nframework and a correction module accounting for imprecise and missing\nannotations. Thus, our method is easy to use and can be combined with arbitrary\nobject detectors. We demonstrate that our approach improves standard detectors\nby 37.1\\% $AP_{50}$ on a noisy real-world remote-sensing dataset. Furthermore,\nour method achieves great performance gains on two datasets with synthetic\nnoise. Code is available at\n\\url{https://github.com/mxbh/robust_object_detection}.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.12989v1"}
{"entry_id": "http://arxiv.org/abs/1007.1850v3", "date": "2010-07-12", "title": "Comparing mesoscale chemistry-transport model and remote-sensed Aerosol Optical Depth", "authors": "C. Carnevale, G. Mannarini, E. Pisoni, M. Volta", "abstract": "A comparison of modeled and observed Aerosol Optical Depth (AOD) is\npresented. 3D Eulerian multiphase chemistry-transport model TCAM is employed\nfor simulating AOD at mesoscale. MODIS satellite sensor and AERONET photometer\nAOD are used for comparing spatial patterns and temporal timeseries. TCAM\nsimulations for year 2004 over a domain containing Po-Valley and nearly whole\nNorthern Italy are employed. For the computation of AOD, a configuration of\nexternal mixing of the chemical species is considered. Furthermore, a\nparametrization of the effect of moisture affecting both aerosol size and\ncomposition is used. An analysis of the contributions of the granulometric\nclasses to the extinction coefficient reveals the dominant role of the\ninorganic compounds of submicron size. For the analysis of spatial patterns,\nsummer and winter case study are considered. TCAM AOD reproduces spatial\npatterns similar to those retrieved from space, but AOD values are generally\nsmaller by an order of magnitude. However, accounting also for moisture, TCAM\nAOD significantly increases to values of the same magnitude of the observed\nones. The temporal performance of model AOD is tested in correspondence of\nAERONET site \"Venise\" and some temporal structures are reproduced. The results\nsuggest encouraging perspectives in view of satellite AOD assimilation also at\nthe mesoscale and not only at the global and regional scale as already tested\nin the literature.", "journal": "Atmospheric Environment 45 (2011) 289-295 2011", "doi": "10.1016/j.atmosenv.2010.10.029", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1007.1850v3"}
{"entry_id": "http://arxiv.org/abs/2212.02147v1", "date": "2022-12-05", "title": "Three-dimensional reconstruction of type U radio bursts: a novel remote sensing approach for coronal loops", "authors": "S. Mancuso, D. Barghini, A. Bemporad, D. Telloni, D. Gardiol, F. Frassati, I. Bizzarri, C. Taricco", "abstract": "Type U radio bursts are impulsive coherent radio emissions produced by the\nSun that indicate the presence of subrelativistic electron beams propagating\nalong magnetic loops in the solar corona. In this work, we present the analysis\nof a type U radio burst that was exceptionally imaged on 2011 March 22 by the\nNan\\c{c}ay Radioheliograph (NRH) at three different frequencies (298.7, 327.0,\nand 360.8 MHz). Using a novel modelling approach, we show for the first time\nthat the use of high-resolution radio heliograph images of type U radio bursts\ncan be sufficient to both accurately reconstruct the 3D morphology of coronal\nloops (without recurring to triangulation techniques) and to fully constrain\ntheir physical parameters. At the same time, we can obtain unique information\non the dynamics of the accelerated electron beams, which provides important\nclues as to the plasma mechanisms involved in their acceleration and as to why\ntype U radio bursts are not observed as frequently as type III radio bursts. We\nfinally present plausible explanations for a problematic aspect related to the\napparent lack of association between the modeled loop as inferred from radio\nimages and the extreme-ultraviolet (EUV) structures observed from space in the\nsame coronal region", "journal": "A&A 669, A28 (2023)", "doi": "10.1051/0004-6361/202243841", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2212.02147v1"}
{"entry_id": "http://arxiv.org/abs/2011.11344v1", "date": "2020-11-23", "title": "Characterization of Industrial Smoke Plumes from Remote Sensing Data", "authors": "Michael Mommert, Mario Sigel, Marcel Neuhausler, Linus Scheibenreif, Damian Borth", "abstract": "The major driver of global warming has been identified as the anthropogenic\nrelease of greenhouse gas (GHG) emissions from industrial activities. The\nquantitative monitoring of these emissions is mandatory to fully understand\ntheir effect on the Earth's climate and to enforce emission regulations on a\nlarge scale. In this work, we investigate the possibility to detect and\nquantify industrial smoke plumes from globally and freely available multi-band\nimage data from ESA's Sentinel-2 satellites. Using a modified ResNet-50, we can\ndetect smoke plumes of different sizes with an accuracy of 94.3%. The model\ncorrectly ignores natural clouds and focuses on those imaging channels that are\nrelated to the spectral absorption from aerosols and water vapor, enabling the\nlocalization of smoke. We exploit this localization ability and train a U-Net\nsegmentation model on a labeled sub-sample of our data, resulting in an\nIntersection-over-Union (IoU) metric of 0.608 and an overall accuracy for the\ndetection of any smoke plume of 94.0%; on average, our model can reproduce the\narea covered by smoke in an image to within 5.6%. The performance of our model\nis mostly limited by occasional confusion with surface objects, the inability\nto identify semi-transparent smoke, and human limitations to properly identify\nsmoke based on RGB-only images. Nevertheless, our results enable us to reliably\ndetect and qualitatively estimate the level of smoke activity in order to\nmonitor activity in industrial plants across the globe. Our data set and code\nbase are publicly available.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2011.11344v1"}
{"entry_id": "http://arxiv.org/abs/1810.08766v1", "date": "2018-10-20", "title": "Superionic hydrogen in Earth's deep interior", "authors": "Yu He, Duck Young Kim, Chris J. Pickard, Richard J. Needs, Qingyang Hu, Ho-kwang Mao", "abstract": "Superionic hydrogen was previously thought to be an exotic state predicted\nand confirmed only in pure H2O ice. In Earth's deep interior, H2O exists in the\nform of O-H groups in ultra-dense hydrous minerals, which have been proved to\nbe stable even at the conditions of the core-mantle boundary (CMB). However,\nthe superionic states of these hydrous minerals at high P-T have not been\ninvestigated. Using first-principles calculations, we found that pyrite\nstructured FeO2Hx (0 <= x <= 1) and d-AlOOH, which have been proposed to be\nmajor hydrogen-bearing phases in the deep lower mantle (DLM), contain\nsuperionic hydrogen at high P-T conditions. Our observations indicate a\nuniversal pathway of the hydroxyl O-H at low pressure transforming to\nsymmetrical O-H-O bonding at high-P low-T, and a superionic state at high-P\nhigh-T. The superionicity of hydrous minerals has a major impact on the\nelectrical conductivity and hydrogen transportation behaviors of Earth's lower\nmantle as well as the CMB.", "journal": "", "doi": null, "primary_category": "cond-mat.mtrl-sci", "categories": ["cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/1810.08766v1"}
{"entry_id": "http://arxiv.org/abs/0708.2649v2", "date": "2007-08-20", "title": "Quantization of neutron in Earth's gravity", "authors": "Pulak Ranjan Giri", "abstract": "Gravity is the weakest of all four known forces in the universe. Quantum\nstates of an elementary particle due to such a weak field is certainly very\nshallow and would therefore be an experimental challenge to detect. Recently an\nexperimental attempt was made by V. V. Nesvizhevsky et al., Nature 415, 297\n(2002), to measure the quantum states of a neutron, which shows that ground\nstate and few excited states are \\sim 10^{-12}eV. We show that the energy of\nthe ground state of a neutron confined above Earth's surface should be \\sim\n10^{-37}eV. The experimentally observed energy levels are 10^{25} times deeper\nthan the actual energy levels it should be and thus certainly not due to\ngravitational effect of Earth. Therefore the correct interpretation for the\npainstaking experimental results of Ref. \\cite{nes1} is due to the confinement\npotential of a one dimensional box of length L \\sim 50\\mu m, generated from the\nexperimental setup as commented before \\cite{hansoon}. Our results thus creates\na new challenge to the experimentalist to resolve the shallow energy levels of\nthe neutron in Earth's gravitational field in future.", "journal": "", "doi": null, "primary_category": "hep-th", "categories": ["hep-th", "quant-ph"], "pdf_url": "http://arxiv.org/pdf/0708.2649v2"}
{"entry_id": "http://arxiv.org/abs/2103.05326v1", "date": "2021-03-09", "title": "Near real-time precipitable water vapour monitoring for correcting near-infrared observations using satellite remote sensing", "authors": "E. A. Meier Vald\u00e9s, B. M. Morris, B. -O. Demory", "abstract": "In the search for small exoplanets orbiting cool stars whose spectral energy\ndistributions peak in the near infrared, the strong absorption of radiation in\nthis region due to water vapour in the atmosphere is a particularly adverse\neffect for the ground-based observations of cool stars. To achieve the\nphotometric precision required to detect exoplanets in the near infrared, it is\nnecessary to mitigate the impact of variable precipitable water vapour (PWV) on\nradial-velocity and photometric measurements. The aim is to enable global PWV\ncorrection by monitoring the amount of precipitable water vapour at zenith and\nalong the line of sight of any visible target. We developed an open source\nPython package that uses Geostationary Operational Environmental Satellites\n(GOES) imagery data, which provides temperature and relative humidity at\ndifferent pressure levels to compute near real-time PWV above any ground-based\nobservatory covered by GOES every 5 minutes or 10 minutes depending on the\nlocation. We computed PWV values on selected days above Cerro Paranal (Chile)\nand San Pedro M\\'artir (Mexico) to benchmark the procedure. We also simulated\ndifferent pointing at test targets as observed from the sites to compute the\nPWV along the line of sight. To asses the accuracy of our method, we compared\nour results with the on-site radiometer measurements obtained from Cerro\nParanal. Our results show that our publicly-available code proves to be a good\nsupporting tool for measuring the local PWV for any ground-based facility\nwithin the GOES coverage, which will help in reducing correlated noise\ncontributions in near-infrared ground-based observations that do not benefit\nfrom on-site PWV measurements.", "journal": "A&A 649, A132 (2021)", "doi": "10.1051/0004-6361/202039629", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2103.05326v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0106017v1", "date": "2001-06-01", "title": "Photometric observations of 9 Near-Earth Objects", "authors": "Gy. Szabo, B. Csak, K. Sarneczky, L. L. Kiss", "abstract": "We present new CCD observations of nine Near-Earth Asteroids carried out\nbetween February, 1999 and July, 2000. The bulk of the data was acquired\nthrough an R_C filter, while the minor planet 11405 was observed without\nfilter. We could determine synodic periods and amplitudes for 5 asteroids, 699:\n3.3 h, 0.18 mag; 1866: 2.7 h, 0.12 mag; 1999 JD6: 7.68 h, 1.2 mag; 2000 GK137:\n4.84 h, 0.27 mag; 2000 NM: 9.24 h, 0.30 mag. Based on observations taken at\ndifferent phases, we could infer a phase parameter m of 0.018+/-0.005 for 1865\nCerberus. An epoch-method yielded a sidereal period of 0.27024003(5) d for this\nobject with retrograde rotation. The remaining 3 objects have only partial\ncoverage, thus no firm conclusion on their synodic period is possible.", "journal": "", "doi": "10.1051/0004-6361:20010813", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0106017v1"}
{"entry_id": "http://arxiv.org/abs/2008.05590v1", "date": "2020-08-12", "title": "Machine Learning for Robust Identification of Complex Nonlinear Dynamical Systems: Applications to Earth Systems Modeling", "authors": "Nishant Yadav, Sai Ravela, Auroop R. Ganguly", "abstract": "Systems exhibiting nonlinear dynamics, including but not limited to chaos,\nare ubiquitous across Earth Sciences such as Meteorology, Hydrology, Climate\nand Ecology, as well as Biology such as neural and cardiac processes. However,\nSystem Identification remains a challenge. In climate and earth systems models,\nwhile governing equations follow from first principles and understanding of key\nprocesses has steadily improved, the largest uncertainties are often caused by\nparameterizations such as cloud physics, which in turn have witnessed limited\nimprovements over the last several decades. Climate scientists have pointed to\nMachine Learning enhanced parameter estimation as a possible solution, with\nproof-of-concept methodological adaptations being examined on idealized\nsystems. While climate science has been highlighted as a \"Big Data\" challenge\nowing to the volume and complexity of archived model-simulations and\nobservations from remote and in-situ sensors, the parameter estimation process\nis often relatively a \"small data\" problem. A crucial question for data\nscientists in this context is the relevance of state-of-the-art data-driven\napproaches including those based on deep neural networks or kernel-based\nprocesses. Here we consider a chaotic system - two-level Lorenz-96 - used as a\nbenchmark model in the climate science literature, adopt a methodology based on\nGaussian Processes for parameter estimation and compare the gains in predictive\nunderstanding with a suite of Deep Learning and strawman Linear Regression\nmethods. Our results show that adaptations of kernel-based Gaussian Processes\ncan outperform other approaches under small data constraints along with\nuncertainty quantification; and needs to be considered as a viable approach in\nclimate science and earth system modeling.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "nlin.CD"], "pdf_url": "http://arxiv.org/pdf/2008.05590v1"}
{"entry_id": "http://arxiv.org/abs/1412.2824v1", "date": "2014-12-09", "title": "Plan or not: Remote Human-robot Teaming with Incomplete Task Information", "authors": "Vignesh Narayanan, Yu Zhang, Nathaniel Mendoza, Subbarao Kambhampati", "abstract": "Human-robot interaction can be divided into two categories based on the\nphysical distance between the human and robot: remote and proximal. In proximal\ninteraction, the human and robot often engage in close coordination; in remote\ninteraction, the human and robot are less coupled due to communication\nconstraints. As a result, providing automation for the robot in remote\ninteraction becomes more important. Thus far, human factor studies on\nautomation in remote human-robot interaction have been restricted to various\nforms of supervision, in which the robot is essentially being used as a smart\nmobile manipulation platform with sensing capabilities. In this paper, we\ninvestigate the incorporation of general planning capability into the robot to\nfacilitate peer-to-peer human-robot teaming, in which the human and robot are\nviewed as teammates that are physically separated. The human and robot share\nthe same global goal and collaborate to achieve it. Note that humans may feel\nuncomfortable at such robot autonomy, which can potentially reduce teaming\nperformance. One important difference between peer-to-peer teaming and\nsupervised teaming is that an autonomous robot in peer-to-peer teaming can\nachieve the goal alone when the task information is completely specified.\nHowever, incompleteness often exists, which implies information asymmetry.\nWhile information asymmetry can be desirable sometimes, it may also lead to the\nrobot choosing improper actions that negatively influence the teaming\nperformance. We aim to investigate the various trade-offs, e.g., mental\nworkload and situation awareness, between these two types of remote human-robot\nteaming.", "journal": "", "doi": null, "primary_category": "cs.AI", "categories": ["cs.AI", "cs.RO"], "pdf_url": "http://arxiv.org/pdf/1412.2824v1"}
{"entry_id": "http://arxiv.org/abs/1704.05082v1", "date": "2017-04-17", "title": "The composition of Solar system asteroids and Earth/Mars moons, and the Earth-Moon composition similarity", "authors": "Alessandra Mastrobuono-Battisti, Hagai B. Perets", "abstract": "[abridged] In the typical giant-impact scenario for the Moon formation most\nof the Moon's material originates from the impactor. Any Earth-impactor\ncomposition difference should, therefore, correspond to a comparable Earth-Moon\ncomposition difference. Analysis of Moon rocks shows a close Earth-Moon\ncomposition similarity, posing a challenge for the giant-impact scenario, given\nthat impactors were thought to significantly differ in composition from the\nplanets they impact. Here we use a large set of 140 simulations to show that\nthe composition of impactors could be very similar to that of the planets they\nimpact; in $4.9\\%$-$18.2\\%$ ($1.9\\%$-$6.7\\%$) of the cases the resulting\ncomposition of the Moon is consistent with the observations of\n$\\Delta^{17}O<15$ ($\\Delta^{17}O<6$ ppm). These findings suggest that the\nEarth-Moon composition similarity could be resolved as to arise from the\nprimordial Earth-impactor composition similarity. Note that although we find\nthe likelihood for the suggested competing model of very high mass-ratio\nimpacts (producing significant Earth-impactor composition mixing) is comparable\n($<6.7\\%$), this scenario also requires additional fine-tuned requirements of a\nvery fast spinning Earth. Using the same simulations we also explore the\ncomposition of giant-impact formed Mars-moons as well as Vesta-like asteroids.\nWe find that the Mars-moon composition difference should be large, but smaller\nthan expected if the moons are captured asteroids. Finally, we find that the\nleft-over planetesimals ('asteroids') in our simulations are frequently\nscattered far away from their initial positions, thus potentially explaining\nthe mismatch between the current position and composition of the Vesta\nasteroid.", "journal": "", "doi": "10.1093/mnras/stx1054", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1704.05082v1"}
{"entry_id": "http://arxiv.org/abs/2007.02111v1", "date": "2020-07-04", "title": "Method to measure Earth missed by ancient Greeks?", "authors": "Fabio Falchi", "abstract": "I describe a simple method to calculate Earth dimensions using only local\nmeasurements and observations. I used modern technology (a digital photo camera\nand Google Earth) but the exact same method can be used without any aid, with\nnaked eye observations and distances measured by walking, and so it was\nperfectly accessible to Ancient Greek science.", "journal": "Physics Education, Volume 47, Number 6, November 2012", "doi": "10.1088/0031-9120/47/6/F01", "primary_category": "physics.pop-ph", "categories": ["physics.pop-ph", "physics.ed-ph", "physics.hist-ph"], "pdf_url": "http://arxiv.org/pdf/2007.02111v1"}
{"entry_id": "http://arxiv.org/abs/0812.4270v1", "date": "2008-12-22", "title": "MHD Remote Numerical Simulations: Evolution of Coronal Mass Ejections", "authors": "L. Hernandez-Cervantes, A. Santillan, A. R. Gonzalez-Ponce", "abstract": "Coronal mass ejections (CMEs) are solar eruptions into interplanetary space\nof as much as a few billion tons of plasma, with embedded magnetic fields from\nthe Sun's corona. These perturbations play a very important role in\nsolar--terrestrial relations, in particular in the spaceweather. In this work\nwe present some preliminary results of the software development at the\nUniversidad Nacional Autonoma de Mexico to perform Remote MHD Numerical\nSimulations. This is done to study the evolution of the CMEs in the\ninterplanetary medium through a Web-based interface and the results are store\ninto a database. The new astrophysical computational tool is called the Mexican\nVirtual Solar Observatory (MVSO) and is aimed to create theoretical models that\nmay be helpful in the interpretation of observational solar data.", "journal": "", "doi": "10.1017/S1743921309030567", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0812.4270v1"}
{"entry_id": "http://arxiv.org/abs/1709.02822v1", "date": "2017-09-08", "title": "A Remote Interface for Live Interaction with OMNeT++ Simulations", "authors": "Maximilian K\u00f6stler, Florian Kauer", "abstract": "Discrete event simulators, such as OMNeT++, provide fast and convenient\nmethods for the assessment of algorithms and protocols, especially in the\ncontext of wired and wireless networks. Usually, simulation parameters such as\ntopology and traffic patterns are predefined to observe the behaviour\nreproducibly. However, for learning about the dynamic behaviour of a system, a\nlive interaction that allows changing parameters on the fly is very helpful.\nThis is especially interesting for providing interactive demonstrations at\nconferences and fairs. In this paper, we present a remote interface to OMNeT++\nsimulations that can be used to control the simulations while visualising\nreal-time data merged from multiple OMNeT++ instances. We explain the software\narchitecture behind our framework and how it can be used to build\ndemonstrations on the foundation of OMNeT++.", "journal": "", "doi": null, "primary_category": "cs.SE", "categories": ["cs.SE", "I.6; I.6.6; I.6.7"], "pdf_url": "http://arxiv.org/pdf/1709.02822v1"}
{"entry_id": "http://arxiv.org/abs/1912.02411v1", "date": "2019-12-05", "title": "Data-driven sensor scheduling for remote estimation in wireless networks", "authors": "Marcos M. Vasconcelos, Urbashi Mitra", "abstract": "Sensor scheduling is a well studied problem in signal processing and control\nwith numerous applications. Despite its successful history, most of the related\nliterature assumes the knowledge of the underlying probabilistic model of the\nsensor measurements such as the correlation structure or the entire joint\nprobability density function. Herein, a framework for sensor scheduling for\nremote estimation is introduced in which the system design and the scheduling\ndecisions are based solely on observed data. Unicast and broadcast networks and\ncorresponding receivers are considered. In both cases, the empirical risk\nminimization can be posed as a difference-of-convex optimization problem and\nlocally optimal solutions are obtained efficiently by applying the\nconvex-concave procedure. Our results are independent of the data's probability\ndensity function, correlation structure and the number of sensors.", "journal": "", "doi": null, "primary_category": "eess.SY", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf_url": "http://arxiv.org/pdf/1912.02411v1"}
{"entry_id": "http://arxiv.org/abs/1312.1328v2", "date": "2013-12-04", "title": "Remote Life Detection Criteria, Habitable Zone Boundaries, and the Frequency of Earthlike Planets around M and Late-K Stars", "authors": "James F. Kasting, Ravi Kopparapu, Ramses M. Ramirez, Chester Harman", "abstract": "The habitable zone (HZ) around a star is typically defined as the region\nwhere a rocky planet can maintain liquid water on its surface. That definition\nis appropriate, because this allows for the possibility that carbon-based,\nphotosynthetic life exists on the planet in sufficient abundance to modify the\nplanet's atmosphere in a way that might be remotely detected. Exactly what\nconditions are needed, however, to maintain liquid water remains a topic for\ndebate. Historically, modelers have restricted themselves to water-rich planets\nwith CO2 and H2O as the only important greenhouse gases. More recently, some\nresearchers have suggested broadening the definition to include arid, 'Dune'\nplanets on the inner edge and planets with captured H2 atmospheres on the outer\nedge, thereby greatly increasing the HZ width. Such planets could exist, but we\ndemonstrate that an inner edge limit of 0.59 AU or less is physically\nunrealistic. We further argue that conservative HZ definitions should be used\nfor designing future space-based telescopes, but that optimistic definitions\nmay be useful in interpreting the data from such missions. In terms of\neffective solar flux, Seff, the recently recalculated HZ boundaries are: recent\nVenus-1.78, runaway greenhouse-1.04, moist greenhouse-1.01, maximum\ngreenhouse-0.35, early Mars-0.32. Based on a combination of different HZ\ndefinitions, the frequency of potentially Earth-like planets around late-K and\nM stars observed by Kepler is in the range of 0.4-0.5.", "journal": "", "doi": "10.1073/pnas.1309107110", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1312.1328v2"}
{"entry_id": "http://arxiv.org/abs/0905.2298v1", "date": "2009-05-14", "title": "A Super-Earth caught in a trap", "authors": "Edyta Podlewska, Ewa Szuszkiewicz", "abstract": "This paper is an extension of the work done by Pierens & Nelson (2008) in\nwhich they have investigated the behaviour of a two-planet system embedded in a\nprotoplanetary disc. They have put a Jupiter mass gas giant on the internal\norbit and a lower mass planet on the external one. We consider here a similar\nproblem taking into account a gas giant with masses in the range of 0.5 to 1\nJupiter mass and a Super-Earth as the outermost planet. By changing disc\nparameters and planet masses we have succeeded in getting the convergent\nmigration which allows for the possibility of their resonant locking. However,\nin the case in which the gas giant has the mass of Jupiter, before any mean\nmotion first order commensurability could be achieved, the Super-Earth is\ncaught in a trap when it is very close to the edge of the gap opened by the\ngiant planet. This confirms the result obtained by Pierens & Nelson (2008) in\ntheir simulations. Additionally, we have found that, in a very thin disc, an\napsidal resonance is observed in the system if the Super-Earth is captured in\nthe trap. Moreover, the eccentricity of the small planet remains low, while\nthat of the gas giant increases slightly due to the imbalance between Lindblad\nand corotational resonances. We have also studied analogous systems in which\nthe gas giant is allowed to take Sub-Jupiter masses. In this case, after\nperforming an extensive survey over all possible parameters, we have succeeded\nin getting the 1:2 mean motion resonant configuration only in a disc with low\naspect ratio and low surface density. However, the resonance is maintained just\nfor few thousand orbits. Thus, we conclude that for typical protoplanetary\ndiscs the mean motion commensurabilities are rare if the Super-Earth is located\non the external orbit relative to the gas giant. (abridged)", "journal": "", "doi": "10.1111/j.1365-2966.2009.15107.x", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0905.2298v1"}
{"entry_id": "http://arxiv.org/abs/1404.4460v1", "date": "2014-04-17", "title": "Earth-like Habitats in Planetary Systems", "authors": "J\u00f6rg Fritz, Bertram Bitsch, Ekkehard K\u00fchrt, Alessandro Morbidelli, Carmen Tornow, Kai W\u00fcnnemann, Vera A. Fernandes, Lee J. Grenfell, Heike Rauer, Roland Wagner, Stephanie C. Werner", "abstract": "Understanding the concept of habitability is related to an evolutionary\nknowledge of the particular planet-in-question. Additional indications\nso-called \"systemic aspects\" of the planetary system as a whole governs a\nparticular planet's claim on habitability. Here we focus on such systemic\naspects and discuss their relevance to the formation of an 'Earth-like'\nhabitable planet. We summarize our results obtained by lunar sample work and\nnumerical models within the framework of the Research Alliance \"Planetary\nEvolution and Life\". We consider various scenarios which simulate the dynamical\nevolution of the Solar System and discuss the likelihood of forming an\nEarth-like world orbiting another star. Our model approach is constrained by\nobservations of the modern Solar System and the knowledge of its history.\nResults suggest that the long-term presence of terrestrial planets is\njeopardized due to gravitational interactions if giant planets are present. But\nhabitability of inner rocky planets may be supported in those planetary systems\nhosting giant planets.\n  Gravitational interactions within a complex multiple-body structure including\ngiant planets may supply terrestrial planets with materials which formed in the\ncolder region of the proto-planetary disk. During these processes, water, the\nprime requisite for habitability, is delivered to the inner system. This may\noccur either during the main accretion phase of terrestrial planets or via\nimpacts during a post-accretion bombardment. Results for both processes are\nsummarized and discussed with reference to the lunar crater record.\n  Starting from a scenario involving migration of the giant planets this\ncontribution discusses the delivery of water to Earth, the modification of\natmospheres by impacts in a planetary system context and the likelihood of the\nexistence of extrasolar Earth-like habitable worlds.", "journal": "", "doi": "10.1016/j.pss.2014.03.003", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1404.4460v1"}
{"entry_id": "http://arxiv.org/abs/1805.10456v1", "date": "2018-05-26", "title": "Photometric survey of 67 near-Earth objects", "authors": "S. Ieva, E. Dotto, E. Mazzotta Epifani, D. Perna, A. Rossi, M. A. Barucci, A. Di Paola, R. Speziali, M. Micheli, E. Perozzi, M. Lazzarin, I. Bertini", "abstract": "The near-Earth object (NEO) population is a window into the original\nconditions of the protosolar nebula, and has the potential to provide a key\npathway for the delivery of water and organics to the early Earth. In addition\nto delivering the crucial ingredients for life, NEOs can pose a serious hazard\nto humanity since they can impact the Earth. To properly quantify the impact\nrisk, physical properties of the NEO population need to be studied.\nUnfortunately, NEOs have a great variation in terms of mitigation-relevant\nquantities (size, albedo, composition, etc.) and less than 15% of them have\nbeen characterized to date. There is an urgent need to undertake a\ncomprehensive characterization of smaller NEOs (D<300m) given that there are\nmany more of them than larger objects. One of the main aims of the NEOShield-2\nproject (2015--2017), financed by the European Community in the framework of\nthe Horizon 2020 program, is therefore to retrieve physical properties of a\nwide number of NEOs in order to design impact mitigation missions and assess\nthe consequences of an impact on Earth. We carried out visible photometry of\nNEOs, making use of the DOLORES instrument at the Telescopio Nazionale Galileo\n(TNG, La Palma, Spain) in order to derive visible color indexes and the\ntaxonomic classification for each target in our sample. We attributed for the\nfirst time the taxonomical complex of 67 objects obtained during the first year\nof the project. While the majority of our sample belong to the S-complex,\ncarbonaceous C-complex NEOs deserve particular attention. These NEOs can be\nlocated in orbits that are challenging from a mitigation point of view, with\nhigh inclination and low minimum orbit intersection distance (MOID). In\naddition, the lack of carbonaceous material we see in the small NEO population\nmight not be due to an observational bias alone.", "journal": "A&A 615, A127 (2018)", "doi": "10.1051/0004-6361/201732154", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1805.10456v1"}
{"entry_id": "http://arxiv.org/abs/2102.03830v1", "date": "2021-02-07", "title": "Deep Learning-Based Detail Map Estimation for MultiSpectral Image Fusion in Remote Sensing", "authors": "Arian Azarang, Nasser Kehtarnavaz", "abstract": "This paper presents a deep learning-based estimation of the intensity\ncomponent of MultiSpectral bands by considering joint multiplication of the\nneighbouring spectral bands. This estimation is conducted as part of the\ncomponent substitution approach for fusion of PANchromatic and MultiSpectral\nimages in remote sensing. After computing the band dependent intensity\ncomponents, a deep neural network is trained to learn the nonlinear\nrelationship between a PAN image and its nonlinear intensity components. Low\nResolution MultiSpectral bands are then fed into the trained network to obtain\nan estimate of High Resolution MultiSpectral bands. Experiments conducted on\nthree datasets show that the developed deep learning-based estimation approach\nprovides improved performance compared to the existing methods based on three\nobjective metrics.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2102.03830v1"}
{"entry_id": "http://arxiv.org/abs/1609.08018v1", "date": "2016-09-26", "title": "Small near-Earth asteroids in the Palomar Transient Factory survey: A real-time streak-detection system", "authors": "Adam Waszczak, Thomas A. Prince, Russ Laher, Frank Masci, Brian Bue, Umaa Rebbapragada, Tom Barlow, Jason Surace, George Helou, Shrinivas Kulkarni", "abstract": "Near-Earth asteroids (NEAs) in the 1-100 meter size range are estimated to be\n$\\sim$1,000 times more numerous than the $\\sim$15,000 currently-catalogued\nNEAs, most of which are in the 0.5-10 kilometer size range. Impacts from 10-100\nmeter size NEAs are not statistically life-threatening but may cause\nsignificant regional damage, while 1-10 meter size NEAs with low velocities\nrelative to Earth are compelling targets for space missions. We describe the\nimplementation and initial results of a real-time NEA-discovery system\nspecialized for the detection of small, high angular rate (visually-streaked)\nNEAs in Palomar Transient Factory (PTF) images. PTF is a 1.2-m aperture,\n7.3-deg$^2$ field-of-view optical survey designed primarily for the discovery\nof extragalactic transients (e.g., supernovae) in 60-second exposures reaching\n$\\sim$20.5 visual magnitude. Our real-time NEA discovery pipeline uses a\nmachine-learned classifier to filter a large number of false-positive streak\ndetections, permitting a human scanner to efficiently and remotely identify\nreal asteroid streaks during the night. Upon recognition of a streaked NEA\ndetection (typically within an hour of the discovery exposure), the scanner\ntriggers follow-up with the same telescope and posts the observations to the\nMinor Planet Center for worldwide confirmation. We describe our ten initial\nconfirmed discoveries, all small NEAs that passed 0.3-15 lunar distances from\nEarth. Lastly, we derive useful scaling laws for comparing\nstreaked-NEA-detection capabilities of different surveys as a function of their\nhardware and survey-pattern characteristics. This work most directly informs\nestimates of the streak-detection capabilities of the Zwicky Transient Facility\n(ZTF, planned to succeed PTF in 2017), which will apply PTF's current\nresolution and sensitivity over a 47-deg$^2$ field-of-view.", "journal": "", "doi": "10.1088/1538-3873/129/973/034402", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1609.08018v1"}
{"entry_id": "http://arxiv.org/abs/2003.02308v1", "date": "2020-03-04", "title": "Remote Quantum Sensing with Heisenberg Limited Sensitivity in Many Body Systems", "authors": "Gareth Si\u00f4n Jones, Sougato Bose, Abolfazl Bayat", "abstract": "Quantum sensors have been shown to be superior to their classical\ncounterparts in terms of resource efficiency. Such sensors have traditionally\nused the time evolution of special forms of initially entangled states,\nadaptive measurement basis change, or the ground state of many-body systems\ntuned to criticality. Here, we propose a different way of doing quantum sensing\nwhich exploits the dynamics of a many-body system, initialized in a product\nstate, along with a sequence of projective measurements in a specific basis.\nThe procedure has multiple practical advantages as it: (i) enables remote\nquantum sensing, protecting a sample from the potentially invasive readout\napparatus; and (ii) simplifies initialization by avoiding complex entangled or\ncritical ground states. From a fundamental perspective, it harnesses a resource\nso far unexploited for sensing, namely, the residual information from the\nunobserved part of the many-body system after the wave-function collapses\naccompanying the measurements. By increasing the number of measurement\nsequences, through the means of a Bayesian estimator, precision beyond the\nstandard limit, approaching the Heisenberg bound, is shown to be achievable.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph", "cond-mat.str-el", "physics.atom-ph"], "pdf_url": "http://arxiv.org/pdf/2003.02308v1"}
{"entry_id": "http://arxiv.org/abs/2008.04529v2", "date": "2020-08-11", "title": "Thick Cloud Removal of Remote Sensing Images Using Temporal Smoothness and Sparsity-Regularized Tensor Optimization", "authors": "Chenxi Duan, Jun Pan, Rui Li", "abstract": "In remote sensing images, the presence of thick cloud accompanying cloud\nshadow is a high probability event, which can affect the quality of subsequent\nprocessing and limit the scenarios of application. Hence, removing the thick\ncloud and cloud shadow as well as recovering the cloud-contaminated pixels is\nindispensable to make good use of remote sensing images. In this paper, a novel\nthick cloud removal method for remote sensing images based on temporal\nsmoothness and sparsity-regularized tensor optimization (TSSTO) is proposed.\nThe basic idea of TSSTO is that the thick cloud and cloud shadow are not only\nsparse but also smooth along the horizontal and vertical direction in images\nwhile the clean images are smooth along the temporal direction between images.\nTherefore, the sparsity norm is used to boost the sparsity of the cloud and\ncloud shadow, and unidirectional total variation (UTV) regularizers are applied\nto ensure the unidirectional smoothness. This paper utilizes alternation\ndirection method of multipliers to solve the presented model and generate the\ncloud and cloud shadow element as well as the clean element. The cloud and\ncloud shadow element is purified to get the cloud area and cloud shadow area.\nThen, the clean area of the original cloud-contaminated images is replaced to\nthe corresponding area of the clean element. Finally, the reference image is\nselected to reconstruct details of the cloud area and cloud shadow area using\nthe information cloning method. A series of experiments are conducted both on\nsimulated and real cloud-contaminated images from different sensors and with\ndifferent resolutions, and the results demonstrate the potential of the\nproposed TSSTO method for removing cloud and cloud shadow from both qualitative\nand quantitative viewpoints.", "journal": "", "doi": "10.3390/rs12203446", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.04529v2"}
{"entry_id": "http://arxiv.org/abs/2108.10054v1", "date": "2021-07-14", "title": "Remote Sensing and Machine Learning for Food Crop Production Data in Africa Post-COVID-19", "authors": "Racine Ly, Khadim Dia, Mariam Diallo", "abstract": "In the agricultural sector, the COVID-19 threatens to lead to a severe food\nsecurity crisis in the region, with disruptions in the food supply chain and\nagricultural production expected to contract between 2.6% and 7%. From the food\ncrop production side, the travel bans and border closures, the late reception\nand the use of agricultural inputs such as imported seeds, fertilizers, and\npesticides could lead to poor food crop production performances. Another layer\nof disruption introduced by the mobility restriction measures is the scarcity\nof agricultural workers, mainly seasonal workers. The lockdown measures and\nborder closures limit seasonal workers' availability to get to the farm on time\nfor planting and harvesting activities. Moreover, most of the imported\nagricultural inputs travel by air, which the pandemic has heavily impacted.\nSuch transportation disruptions can also negatively affect the food crop\nproduction system.\n  This chapter assesses food crop production levels in 2020 -- before the\nharvesting period -- in all African regions and four staples such as maize,\ncassava, rice, and wheat. The production levels are predicted using the\ncombination of biogeophysical remote sensing data retrieved from satellite\nimages and machine learning artificial neural networks (ANNs) technique. The\nremote sensing products are used as input variables and the ANNs as the\npredictive modeling framework. The input remote sensing products are the\nNormalized Difference Vegetation Index (NDVI), the daytime Land Surface\nTemperature (LST), rainfall data, and agricultural lands' Evapotranspiration\n(ET). The output maps and data are made publicly available on a web-based\nplatform, AAgWa (Africa Agriculture Watch, www.aagwa.org), to facilitate access\nto such information to policymakers, deciders, and other stakeholders.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI", "68T01, 68T05,", "I.2.1; I.6.5; I.6.3; E.0; G.1.2; H.1.0"], "pdf_url": "http://arxiv.org/pdf/2108.10054v1"}
{"entry_id": "http://arxiv.org/abs/2109.06094v2", "date": "2021-09-13", "title": "Single-stream CNN with Learnable Architecture for Multi-source Remote Sensing Data", "authors": "Yi Yang, Daoye Zhu, Tengteng Qu, Qiangyu Wang, Fuhu Ren, Chengqi Cheng", "abstract": "In this paper, we propose an efficient and generalizable framework based on\ndeep convolutional neural network (CNN) for multi-source remote sensing data\njoint classification. While recent methods are mostly based on multi-stream\narchitectures, we use group convolution to construct equivalent network\narchitectures efficiently within a single-stream network. We further adopt and\nimprove dynamic grouping convolution (DGConv) to make group convolution\nhyperparameters, and thus the overall network architecture, learnable during\nnetwork training. The proposed method therefore can theoretically adjust any\nmodern CNN models to any multi-source remote sensing data set, and can\npotentially avoid sub-optimal solutions caused by manually decided architecture\nhyperparameters. In the experiments, the proposed method is applied to ResNet\nand UNet, and the adjusted networks are verified on three very diverse\nbenchmark data sets (i.e., Houston2018 data, Berlin data, and MUUFL data).\nExperimental results demonstrate the effectiveness of the proposed\nsingle-stream CNNs, and in particular ResNet18-DGConv improves the\nstate-of-the-art classification overall accuracy (OA) on HS-SAR Berlin data set\nfrom $62.23\\%$ to $68.21\\%$. In the experiments we have two interesting\nfindings. First, using DGConv generally reduces test OA variance. Second,\nmulti-stream is harmful to model performance if imposed to the first few\nlayers, but becomes beneficial if applied to deeper layers. Altogether, the\nfindings imply that multi-stream architecture, instead of being a strictly\nnecessary component in deep learning models for multi-source remote sensing\ndata, essentially plays the role of model regularizer. Our code is publicly\navailable at https://github.com/yyyyangyi/Multi-source-RS-DGConv. We hope our\nwork can inspire novel research in the future.", "journal": "", "doi": "10.1109/TGRS.2022.3169163", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2109.06094v2"}
{"entry_id": "http://arxiv.org/abs/2210.12634v1", "date": "2022-10-23", "title": "RSVG: Exploring Data and Models for Visual Grounding on Remote Sensing Data", "authors": "Yang Zhan, Zhitong Xiong, Yuan Yuan", "abstract": "In this paper, we introduce the task of visual grounding for remote sensing\ndata (RSVG). RSVG aims to localize the referred objects in remote sensing (RS)\nimages with the guidance of natural language. To retrieve rich information from\nRS imagery using natural language, many research tasks, like RS image visual\nquestion answering, RS image captioning, and RS image-text retrieval have been\ninvestigated a lot. However, the object-level visual grounding on RS images is\nstill under-explored. Thus, in this work, we propose to construct the dataset\nand explore deep learning models for the RSVG task. Specifically, our\ncontributions can be summarized as follows. 1) We build the new large-scale\nbenchmark dataset of RSVG, termed RSVGD, to fully advance the research of RSVG.\nThis new dataset includes image/expression/box triplets for training and\nevaluating visual grounding models. 2) We benchmark extensive state-of-the-art\n(SOTA) natural image visual grounding methods on the constructed RSVGD dataset,\nand some insightful analyses are provided based on the results. 3) A novel\ntransformer-based Multi-Level Cross-Modal feature learning (MLCM) module is\nproposed. Remotely-sensed images are usually with large scale variations and\ncluttered backgrounds. To deal with the scale-variation problem, the MLCM\nmodule takes advantage of multi-scale visual features and multi-granularity\ntextual embeddings to learn more discriminative representations. To cope with\nthe cluttered background problem, MLCM adaptively filters irrelevant noise and\nenhances salient features. In this way, our proposed model can incorporate more\neffective multi-level and multi-modal features to boost performance.\nFurthermore, this work also provides useful insights for developing better RSVG\nmodels. The dataset and code will be publicly available at\nhttps://github.com/ZhanYang-nwpu/RSVG-pytorch.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.12634v1"}
{"entry_id": "http://arxiv.org/abs/1311.1145v1", "date": "2013-11-05", "title": "Characterizing the purple Earth: Modelling the globally-integrated spectral variability of the Archean Earth", "authors": "E. Sanrom\u00e1, E. Pall\u00e9, M. N. Parenteau, N. Y. Kiang, A. M. Guti\u00e9rrez-Navarro, R. L\u00f3pez, P. Monta\u00f1\u00e9s-Rodr\u00edguez", "abstract": "The ongoing searches for exoplanetary systems have revealed a wealth of\nplanets with diverse physical properties. Planets even smaller than the Earth\nhave already been detected, and the efforts of future missions are placed on\nthe discovery, and perhaps characterization, of small rocky exoplanets within\nthe habitable zone of their stars. Clearly what we know about our planet will\nbe our guideline for the characterization of such planets. But the Earth has\nbeen inhabited for at least 3.8 Ga, and its appearance has changed with time.\nHere, we have studied the Earth during the Archean eon, 3.0 Ga ago. At that\ntime one of the more widespread life forms on the planet were purple bacteria.\nThese bacteria are photosynthetic microorganisms and can inhabit both aquatic\nand terrestrial environments. Here, we used a radiative transfer model to\nsimulate the visible and near-IR radiation reflected by our planet, taking into\naccount several scenarios regarding the possible distribution of purple\nbacteria over continents and oceans. We find that purple bacteria have a\nreflectance spectrum which has a strong reflectivity increase, similar to the\nred edge of leafy plants, although shifted redwards. This feature produces a\ndetectable signal in the disk-averaged spectra of our planet, depending on\ncloud amount and on purple bacteria concentration/distribution. We conclude\nthat by using multi-color photometric observations, it is possible to\ndistinguish between an Archean Earth in which purple bacteria inhabit vast\nextensions of the planet, and a present-day Earth with continents covered by\ndeserts, vegetation or microbial mats.", "journal": "", "doi": "10.1088/0004-637X/780/1/52", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1311.1145v1"}
{"entry_id": "http://arxiv.org/abs/1906.06121v1", "date": "2019-06-14", "title": "A comparison of remotely-sensed and inventory datasets for burned area in Mediterranean Europe", "authors": "Marco Turco, Sixto Herrera, Etienne Tourigny, Emilio Chuvieco, Antonello Provenzale", "abstract": "Quantitative estimate of observational uncertainty is an essential ingredient\nto correctly interpret changes in climatic and environmental variables such as\nwildfires. In this work we compare four state-of-the-art satellite fire\nproducts with the gridded, ground-based EFFIS dataset for Mediterranean Europe\nand analyse their statistical differences. The data are compared for spatial\nand temporal similarities at different aggregations to identify a spatial scale\nat which most of the observations provide equivalent results. The results of\nthe analysis indicate that the datasets show high temporal correlation with\neach other (0.5/0.6) when aggregating the data at resolution of at least\n1.0{\\deg} or at NUTS3 level. However, burned area estimates vary widely between\ndatasets. Filtering out satellite fires located on urban and crop land cover\nclasses greatly improves the agreement with EFFIS data. Finally, in spite of\nthe differences found in the area estimates, the spatial pattern is similar for\nall the datasets, with spatial correlation increasing as the resolution\ndecreases. Also, the general reasonable agreement between satellite products\nbuilds confidence in using these datasets and in particular the most-recent\ndeveloped dataset, FireCCI51, shows the best agreement with EFFIS overall. As a\nresult, the main conclusion of the study is that users should carefully\nconsider the limitations of the satellite fire estimates currently available,\nas their uncertainties cannot be neglected in the overall uncertainty\nestimate/cascade that should accompany global or regional change studies and\nthat removing fires on human-dominated land areas is key to analyze forest\nfires estimation from satellite products.", "journal": "International Journal of Applied Earth Observation and\n  Geoinformation, Volume 82, October 2019, 101887", "doi": "10.1016/j.jag.2019.05.020", "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1906.06121v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0312627v1", "date": "2003-12-27", "title": "Neutrino induced showering from the Earth", "authors": "D. Fargion", "abstract": "Ultra High Energy, UHE, Neutrino Astronomy should be soon tested looking\ntoward the Earth. At present High Energy Neutrino Astronomy is searched by\nAMANDA, ANTARES underground detectors looking for its consequent unique muons\nsecondary track. We suggest a higher energy Tau Neutrino Astronomy based on\nHorizontal and Upward Tau Air-Showers escaping from the Earth. These Tau\nair-showers greatly amplifies the single tau track by an abundant secondary\ntail (billions of electron pairs, gamma and tens of millions muon bundles)\nspread in huge areas (kilometer size) easily observable (even partially) from\nhigh mountains, balloon or satellite array detectors. Possible early evidence\nof such a New Neutrino UPTAUs or HORTAUs (Upward or Horizontal Tau Air-Showers)\nAstronomy may be already found in rare BATSE gamma records of brief up-going\ngamma showers named Terrestrial Gamma Flashes (TGF). The TGF features, energy\nand arrival clustering are well tuned to upward tau air-showers. Future\nconfirmation of the Neutrino Tau Astronomy must be found in detectors as EUSO,\nseeking for Upward-Horizontal air-shower events: indeed even minimal,\nguaranteed, GZK neutrino fluxes may be observed if EUSO threshold reaches\n10^{19} eV or lower energies by enlarging its telescope size", "journal": "JHEP Proc.: PRHEP-AHEP2003/042", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0312627v1"}
{"entry_id": "http://arxiv.org/abs/1009.3540v1", "date": "2010-09-18", "title": "Simple system to measure the Earth's magnetic field", "authors": "R. Akoglu, M. Halilsoy, S. Habib Mazharimousavi", "abstract": "Our aim in this proposal is by using the Faraday's law of induction as a\nsimple lecture demonstration to measure the Earth's magnetic field (B). This\nwill also enable the students to learn about how electric power is generated\nfrom the rotational motion. Obviously the idea is not original, yet it may be\nattractive in the sense that no sophisticated devices are used.", "journal": "The Physics Teacher 48, November 2010, 549", "doi": "10.1119/1.3502512", "primary_category": "physics.pop-ph", "categories": ["physics.pop-ph", "physics.ed-ph"], "pdf_url": "http://arxiv.org/pdf/1009.3540v1"}
{"entry_id": "http://arxiv.org/abs/1912.09121v2", "date": "2019-12-19", "title": "SCAttNet: Semantic Segmentation Network with Spatial and Channel Attention Mechanism for High-Resolution Remote Sensing Images", "authors": "Haifeng Li, Kaijian Qiu, Li Chen, Xiaoming Mei, Liang Hong, Chao Tao", "abstract": "High-resolution remote sensing images (HRRSIs) contain substantial ground\nobject information, such as texture, shape, and spatial location. Semantic\nsegmentation, which is an important task for element extraction, has been\nwidely used in processing mass HRRSIs. However, HRRSIs often exhibit large\nintraclass variance and small interclass variance due to the diversity and\ncomplexity of ground objects, thereby bringing great challenges to a semantic\nsegmentation task. In this paper, we propose a new end-to-end semantic\nsegmentation network, which integrates lightweight spatial and channel\nattention modules that can refine features adaptively. We compare our method\nwith several classic methods on the ISPRS Vaihingen and Potsdam datasets.\nExperimental results show that our method can achieve better semantic\nsegmentation results. The source codes are available at\nhttps://github.com/lehaifeng/SCAttNet.", "journal": "IEEE Geoscience and Remote Sensing Letters 2020", "doi": "10.1109/LGRS.2020.2988294", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1912.09121v2"}
{"entry_id": "http://arxiv.org/abs/2103.15502v1", "date": "2021-03-29", "title": "Remote Sensing Image Translation via Style-Based Recalibration Module and Improved Style Discriminator", "authors": "Tiange Zhang, Feng Gao, Junyu Dong, Qian Du", "abstract": "Existing remote sensing change detection methods are heavily affected by\nseasonal variation. Since vegetation colors are different between winter and\nsummer, such variations are inclined to be falsely detected as changes. In this\nletter, we proposed an image translation method to solve the problem. A\nstyle-based recalibration module is introduced to capture seasonal features\neffectively. Then, a new style discriminator is designed to improve the\ntranslation performance. The discriminator can not only produce a decision for\nthe fake or real sample, but also return a style vector according to the\nchannel-wise correlations. Extensive experiments are conducted on\nseason-varying dataset. The experimental results show that the proposed method\ncan effectively perform image translation, thereby consistently improving the\nseason-varying image change detection performance. Our codes and data are\navailable at https://github.com/summitgao/RSIT_SRM_ISD.", "journal": "", "doi": "10.1109/LGRS.2021.3068558", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2103.15502v1"}
{"entry_id": "http://arxiv.org/abs/2109.05889v1", "date": "2021-09-13", "title": "Nonlocal Patch-Based Fully-Connected Tensor Network Decomposition for Remote Sensing Image Inpainting", "authors": "Wen-Jie Zheng, Xi-Le Zhao, Yu-Bang Zheng, Zhi-Feng Pang", "abstract": "Remote sensing image (RSI) inpainting plays an important role in real\napplications. Recently, fully-connected tensor network (FCTN) decomposition has\nbeen shown the remarkable ability to fully characterize the global correlation.\nConsidering the global correlation and the nonlocal self-similarity (NSS) of\nRSIs, this paper introduces the FCTN decomposition to the whole RSI and its NSS\ngroups, and proposes a novel nonlocal patch-based FCTN (NL-FCTN) decomposition\nfor RSI inpainting. Different from other nonlocal patch-based methods, the\nNL-FCTN decomposition-based method, which increases tensor order by stacking\nsimilar small-sized patches to NSS groups, cleverly leverages the remarkable\nability of FCTN decomposition to deal with higher-order tensors. Besides, we\npropose an efficient proximal alternating minimization-based algorithm to solve\nthe proposed NL-FCTN decomposition-based model with a theoretical convergence\nguarantee. Extensive experiments on RSIs demonstrate that the proposed method\nachieves the state-of-the-art inpainting performance in all compared methods.", "journal": "IEEE Geoscience and Remote Sensing Letters, 2021", "doi": "10.1109/LGRS.2021.3124804", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2109.05889v1"}
{"entry_id": "http://arxiv.org/abs/2009.13935v1", "date": "2020-09-29", "title": "A Comparative Study of Deep Learning Loss Functions for Multi-Label Remote Sensing Image Classification", "authors": "Hichame Yessou, Gencer Sumbul, Beg\u00fcm Demir", "abstract": "This paper analyzes and compares different deep learning loss functions in\nthe framework of multi-label remote sensing (RS) image scene classification\nproblems. We consider seven loss functions: 1) cross-entropy loss; 2) focal\nloss; 3) weighted cross-entropy loss; 4) Hamming loss; 5) Huber loss; 6)\nranking loss; and 7) sparseMax loss. All the considered loss functions are\nanalyzed for the first time in RS. After a theoretical analysis, an\nexperimental analysis is carried out to compare the considered loss functions\nin terms of their: 1) overall accuracy; 2) class imbalance awareness (for which\nthe number of samples associated to each class significantly varies); 3)\nconvexibility and differentiability; and 4) learning efficiency (i.e.,\nconvergence speed). On the basis of our analysis, some guidelines are derived\nfor a proper selection of a loss function in multi-label RS scene\nclassification problems.", "journal": "", "doi": "10.1109/IGARSS39084.2020.9323583", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2009.13935v1"}
{"entry_id": "http://arxiv.org/abs/2108.06103v4", "date": "2021-08-13", "title": "Bi-Temporal Semantic Reasoning for the Semantic Change Detection in HR Remote Sensing Images", "authors": "Lei Ding, Haitao Guo, Sicong Liu, Lichao Mou, Jing Zhang, Lorenzo Bruzzone", "abstract": "Semantic change detection (SCD) extends the multi-class change detection\n(MCD) task to provide not only the change locations but also the detailed\nland-cover/land-use (LCLU) categories before and after the observation\nintervals. This fine-grained semantic change information is very useful in many\napplications. Recent studies indicate that the SCD can be modeled through a\ntriple-branch Convolutional Neural Network (CNN), which contains two temporal\nbranches and a change branch. However, in this architecture, the communications\nbetween the temporal branches and the change branch are insufficient. To\novercome the limitations in existing methods, we propose a novel CNN\narchitecture for the SCD, where the semantic temporal features are merged in a\ndeep CD unit. Furthermore, we elaborate on this architecture to reason the\nbi-temporal semantic correlations. The resulting Bi-temporal Semantic Reasoning\nNetwork (Bi-SRNet) contains two types of semantic reasoning blocks to reason\nboth single-temporal and cross-temporal semantic correlations, as well as a\nnovel loss function to improve the semantic consistency of change detection\nresults. Experimental results on a benchmark dataset show that the proposed\narchitecture obtains significant accuracy improvements over the existing\napproaches, while the added designs in the Bi-SRNet further improves the\nsegmentation of both semantic categories and the changed areas. The codes in\nthis paper are accessible at: github.com/ggsDing/Bi-SRNet.", "journal": "", "doi": "10.1109/TGRS.2022.3154390", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2108.06103v4"}
{"entry_id": "http://arxiv.org/abs/1609.05233v1", "date": "2016-09-16", "title": "Inferring the interplanetary dust properties from remote observations and simulations", "authors": "Jeremie Lasue, Anny-Chantal Levasseur-Regourd, Nicolas Fray, Herv\u00e9 Cottin", "abstract": "Since in situ studies and interplanetary dust collections only provide a\nspatially limited amount of information about the interplanetary dust\nproperties, it is of major importance to complete these studies with properties\ninferred from remote observations of light scattered and emitted, with\ninterpretation through simulations. Physical properties of the interplanetary\ndust in the near-ecliptic symmetry surface, such as the local polarization,\ntemperature and composition, together with their heliocentric variations, may\nbe derived from scattered and emitted light observations, giving clues to the\nrespective contribution of the particles sources. A model of light scattering\nby a cloud of solid particles constituted by spheroidal grains and aggregates\nthereof is used to interpret the local light scattering data. Equilibrium\ntemperature of the same particles allows us to interpret the temperature\nheliocentric variations. A good fit of the local polarization phase curve,\n$P_{\\alpha}$, near 1.5~AU from the Sun is obtained for a mixture of silicates\nand more absorbing organics material ($\\approx$40 % in mass) and for a\nrealistic size distribution typical of the interplanetary dust in the 0.2 to\n200 micrometre size range. The contribution of dust particles of cometary\norigin is at least 20% in mass. The same size distribution of particles gives a\nsolar distance, $R$, dependence of the temperature in $R^{-0.45}$ different\nthan the typical black body behavior. The heliocentric dependence of\n$P_{\\alpha=90{\\deg}}$ is interpreted as a progressive disappearance of solid\norganics (such as HCN polymers or amorphous carbon) towards the Sun.", "journal": "Astronomy & Astrophysics, 473(2), 641-649 (2007)", "doi": "10.1051/0004-6361:20077623", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1609.05233v1"}
{"entry_id": "http://arxiv.org/abs/2005.07232v2", "date": "2020-05-14", "title": "DiResNet: Direction-aware Residual Network for Road Extraction in VHR Remote Sensing Images", "authors": "Lei Ding, Lorenzo Bruzzone", "abstract": "The binary segmentation of roads in very high resolution (VHR) remote sensing\nimages (RSIs) has always been a challenging task due to factors such as\nocclusions (caused by shadows, trees, buildings, etc.) and the intra-class\nvariances of road surfaces. The wide use of convolutional neural networks\n(CNNs) has greatly improved the segmentation accuracy and made the task\nend-to-end trainable. However, there are still margins to improve in terms of\nthe completeness and connectivity of the results. In this paper, we consider\nthe specific context of road extraction and present a direction-aware residual\nnetwork (DiResNet) that includes three main contributions: 1) An asymmetric\nresidual segmentation network with deconvolutional layers and a structural\nsupervision to enhance the learning of road topology (DiResSeg); 2) A\npixel-level supervision of local directions to enhance the embedding of linear\nfeatures; 3) A refinement network to optimize the segmentation results\n(DiResRef). Ablation studies on two benchmark datasets (the Massachusetts\ndataset and the DeepGlobe dataset) have confirmed the effectiveness of the\npresented designs. Comparative experiments with other approaches show that the\nproposed method has advantages in both overall accuracy and F1-score. The code\nis available at: https://github.com/ggsDing/DiResNet.", "journal": "Ding L, Bruzzone L. DiResNet: Direction-Aware Residual Network for\n  Road Extraction in VHR Remote Sensing Images[J]. IEEE Transactions on\n  Geoscience and Remote Sensing, 2020", "doi": "10.1109/TGRS.2020.3034011", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2005.07232v2"}
{"entry_id": "http://arxiv.org/abs/2205.04906v1", "date": "2022-05-10", "title": "Evaluating the Impact of Tiled User-Adaptive Real-Time Point Cloud Streaming on VR Remote Communication", "authors": "Shishir Subramanyam, Irene Viola, Jack Jansen, Evangelos Alexiou, Alan Hanjalic, Pablo Cesar", "abstract": "Remote communication has rapidly become a part of everyday life in both\nprofessional and personal contexts. However, popular video conferencing\napplications present limitations in terms of quality of communication,\nimmersion and social meaning. VR remote communication applications offer a\ngreater sense of co-presence and mutual sensing of emotions between remote\nusers. Previous research on these applications has shown that realistic point\ncloud user reconstructions offer better immersion and communication as compared\nto synthetic user avatars. However, photorealistic point clouds require a large\nvolume of data per frame and are challenging to transmit over bandwidth-limited\nnetworks. Recent research has demonstrated significant improvements to\nperceived quality by optimizing the usage of bandwidth based on the position\nand orientation of the user's viewport with user-adaptive streaming. In this\nwork, we developed a real-time VR communication application with an adaptation\nengine that features tiled user-adaptive streaming based on user behaviour. The\napplication also supports traditional network adaptive streaming. The\ncontribution of this work is to evaluate the impact of tiled user-adaptive\nstreaming on quality of communication, visual quality, system performance and\ntask completion in a functional live VR remote communication system. We perform\na subjective evaluation with 33 users to compare the different streaming\nconditions with a neck exercise training task. As a baseline, we use\nuncompressed streaming requiring ca. 300Mbps and our solution achieves similar\nvisual quality with tiled adaptive streaming at 14Mbps. We also demonstrate\nstatistically significant gains to the quality of interaction and improvements\nto system performance and CPU consumption with tiled adaptive streaming as\ncompared to the more traditional network adaptive streaming.", "journal": "", "doi": null, "primary_category": "cs.MM", "categories": ["cs.MM"], "pdf_url": "http://arxiv.org/pdf/2205.04906v1"}
{"entry_id": "http://arxiv.org/abs/1708.00813v1", "date": "2017-08-02", "title": "Land Cover Classification from Multi-temporal, Multi-spectral Remotely Sensed Imagery using Patch-Based Recurrent Neural Networks", "authors": "Atharva Sharma, Xiuwen Liu, Xiaojun Yang", "abstract": "Sustainability of the global environment is dependent on the accurate land\ncover information over large areas. Even with the increased number of satellite\nsystems and sensors acquiring data with improved spectral, spatial, radiometric\nand temporal characteristics and the new data distribution policy, most\nexisting land cover datasets were derived from a pixel-based single-date\nmulti-spectral remotely sensed image with low accuracy. To improve the\naccuracy, the bottleneck is how to develop an accurate and effective image\nclassification technique. By incorporating and utilizing the complete\nmulti-spectral, multi-temporal and spatial information in remote sensing images\nand considering their inherit spatial and sequential interdependence, we\npropose a new patch-based RNN (PB-RNN) system tailored for multi-temporal\nremote sensing data. The system is designed by incorporating distinctive\ncharacteristics in multi-temporal remote sensing data. In particular, it uses\nmulti-temporal-spectral-spatial samples and deals with pixels contaminated by\nclouds/shadow present in the multi-temporal data series. Using a Florida\nEverglades ecosystem study site covering an area of 771 square kilo-meters, the\nproposed PB-RNN system has achieved a significant improvement in the\nclassification accuracy over pixel-based RNN system, pixel-based single-imagery\nNN system, pixel-based multi-images NN system, patch-based single-imagery NN\nsystem and patch-based multi-images NN system. For example, the proposed system\nachieves 97.21% classification accuracy while a pixel-based single-imagery NN\nsystem achieves 64.74%. By utilizing methods like the proposed PB-RNN one, we\nbelieve that much more accurate land cover datasets can be produced over large\nareas efficiently.", "journal": "", "doi": "10.1016/j.neunet.2018.05.019", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1708.00813v1"}
{"entry_id": "http://arxiv.org/abs/1206.5250v1", "date": "2012-06-20", "title": "Probabilistic Models for Anomaly Detection in Remote Sensor Data Streams", "authors": "Ethan W. Dereszynski, Thomas G. Dietterich", "abstract": "Remote sensors are becoming the standard for observing and recording\necological data in the field. Such sensors can record data at fine temporal\nresolutions, and they can operate under extreme conditions prohibitive to human\naccess. Unfortunately, sensor data streams exhibit many kinds of errors ranging\nfrom corrupt communications to partial or total sensor failures. This means\nthat the raw data stream must be cleaned before it can be used by domain\nscientists. In our application environment|the H.J. Andrews Experimental\nForest|this data cleaning is performed manually. This paper introduces a\nDynamic Bayesian Network model for analyzing sensor observations and\ndistinguishing sensor failures from valid data for the case of air temperature\nmeasured at 15 minute time resolution. The model combines an accurate\ndistribution of long-term and short-term temperature variations with a single\ngeneralized fault model. Experiments with historical data show that the\nprecision and recall of the method is comparable to that of the domain expert.\nThe system is currently being deployed to perform real-time automated data\ncleaning.", "journal": "", "doi": null, "primary_category": "cs.AI", "categories": ["cs.AI", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/1206.5250v1"}
{"entry_id": "http://arxiv.org/abs/quant-ph/0510055v1", "date": "2005-10-07", "title": "Measurement-Induced Entanglement for Excitation Stored in Remote Atomic Ensembles", "authors": "C. W. Chou, H. de Riedmatten, D. Felinto, S. V. Polyakov, S. J. van Enk, H. J. Kimble", "abstract": "A critical requirement for diverse applications in Quantum Information\nScience is the capability to disseminate quantum resources over complex quantum\nnetworks. For example, the coherent distribution of entangled quantum states\ntogether with quantum memory to store these states can enable scalable\narchitectures for quantum computation, communication, and metrology. As a\nsignificant step toward such possibilities, here we report observations of\nentanglement between two atomic ensembles located in distinct apparatuses on\ndifferent tables. Quantum interference in the detection of a photon emitted by\none of the samples projects the otherwise independent ensembles into an\nentangled state with one joint excitation stored remotely in 10^5 atoms at each\nsite. After a programmable delay, we confirm entanglement by mapping the state\nof the atoms to optical fields and by measuring mutual coherences and photon\nstatistics for these fields. We thereby determine a quantitative lower bound\nfor the entanglement of the joint state of the ensembles. Our observations\nprovide a new capability for the distribution and storage of entangled quantum\nstates, including for scalable quantum communication networks .", "journal": "", "doi": "10.1038/nature04353", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/quant-ph/0510055v1"}
{"entry_id": "http://arxiv.org/abs/2003.09085v5", "date": "2020-03-20", "title": "Small-Object Detection in Remote Sensing Images with End-to-End Edge-Enhanced GAN and Object Detector Network", "authors": "Jakaria Rabbi, Nilanjan Ray, Matthias Schubert, Subir Chowdhury, Dennis Chao", "abstract": "The detection performance of small objects in remote sensing images is not\nsatisfactory compared to large objects, especially in low-resolution and noisy\nimages. A generative adversarial network (GAN)-based model called enhanced\nsuper-resolution GAN (ESRGAN) shows remarkable image enhancement performance,\nbut reconstructed images miss high-frequency edge information. Therefore,\nobject detection performance degrades for small objects on recovered noisy and\nlow-resolution remote sensing images. Inspired by the success of edge enhanced\nGAN (EEGAN) and ESRGAN, we apply a new edge-enhanced super-resolution GAN\n(EESRGAN) to improve the image quality of remote sensing images and use\ndifferent detector networks in an end-to-end manner where detector loss is\nbackpropagated into the EESRGAN to improve the detection performance. We\npropose an architecture with three components: ESRGAN, Edge Enhancement Network\n(EEN), and Detection network. We use residual-in-residual dense blocks (RRDB)\nfor both the ESRGAN and EEN, and for the detector network, we use the faster\nregion-based convolutional network (FRCNN) (two-stage detector) and single-shot\nmulti-box detector (SSD) (one stage detector). Extensive experiments on a\npublic (car overhead with context) and a self-assembled (oil and gas storage\ntank) satellite dataset show superior performance of our method compared to the\nstandalone state-of-the-art object detectors.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2003.09085v5"}
{"entry_id": "http://arxiv.org/abs/2202.03342v1", "date": "2022-02-07", "title": "A Review of Landcover Classification with Very-High Resolution Remotely Sensed Optical Images-Analysis Unit,Model Scalability and Transferability", "authors": "Rongjun Qin, Tao Liu", "abstract": "As an important application in remote sensing, landcover classification\nremains one of the most challenging tasks in very-high-resolution (VHR) image\nanalysis. As the rapidly increasing number of Deep Learning (DL) based\nlandcover methods and training strategies are claimed to be the\nstate-of-the-art, the already fragmented technical landscape of landcover\nmapping methods has been further complicated. Although there exists a plethora\nof literature review work attempting to guide researchers in making an informed\nchoice of landcover mapping methods, the articles either focus on the review of\napplications in a specific area or revolve around general deep learning models,\nwhich lack a systematic view of the ever advancing landcover mapping methods.\nIn addition, issues related to training samples and model transferability have\nbecome more critical than ever in an era dominated by data-driven approaches,\nbut these issues were addressed to a lesser extent in previous review articles\nregarding remote sensing classification. Therefore, in this paper, we present a\nsystematic overview of existing methods by starting from learning methods and\nvarying basic analysis units for landcover mapping tasks, to challenges and\nsolutions on three aspects of scalability and transferability with a remote\nsensing classification focus including (1) sparsity and imbalance of data; (2)\ndomain gaps across different geographical regions; and (3) multi-source and\nmulti-view fusion. We discuss in detail each of these categorical methods and\ndraw concluding remarks in these developments and recommend potential\ndirections for the continued endeavor.", "journal": "Remote Sensing, 14(3),646, 2022", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2202.03342v1"}
{"entry_id": "http://arxiv.org/abs/0710.5887v1", "date": "2007-10-31", "title": "A double resonance approach to submillimeter/terahertz remote sensing at atmospheric pressure", "authors": "Frank C. De Lucia, Douglas T. Petkie, Henry O. Everitt", "abstract": "The remote sensing of gases in complex mixtures at atmospheric pressure is a\nchallenging problem and much attention has been paid to it. The most\nfundamental difference between this application and highly successful\nastrophysical and upper atmospheric remote sensing is the line width associated\nwith atmospheric pressure broadening, ~ 5 GHz in all spectral regions. In this\npaper, we discuss quantitatively a new approach that would use a short pulse\ninfrared laser to modulate the submillimeter/terahertz (SMM/THz) spectral\nabsorptions on the time scale of atmospheric relaxation. We show that such a\nscheme has three important attributes: (1) The time resolved pump makes it\npossible and efficient to separate signal from atmospheric and system clutter,\nthereby gaining as much as a factor of 10^6 in sensitivity, (2) The 3-D\ninformation matrix (infrared pump laser frequency, SMM/THz probe frequency, and\ntime resolved SMM/THz relaxation) can provide orders of magnitude greater\nspecificity than a sensor that uses only one of these three dimensions, and (3)\nThe congested and relatively weak spectra associated with large molecules can\nactually be an asset because the usually deleterious effect of their\noverlapping spectra can be used to increase signal strength.", "journal": "", "doi": "10.1109/JQE.2008.912473", "primary_category": "physics.chem-ph", "categories": ["physics.chem-ph"], "pdf_url": "http://arxiv.org/pdf/0710.5887v1"}
{"entry_id": "http://arxiv.org/abs/1706.04719v2", "date": "2017-06-15", "title": "Effective Sequential Classifier Training for SVM-based Multitemporal Remote Sensing Image Classification", "authors": "Yiqing Guo, Xiuping Jia, David Paull", "abstract": "The explosive availability of remote sensing images has challenged supervised\nclassification algorithms such as Support Vector Machines (SVM), as training\nsamples tend to be highly limited due to the expensive and laborious task of\nground truthing. The temporal correlation and spectral similarity between\nmultitemporal images have opened up an opportunity to alleviate this problem.\nIn this study, a SVM-based Sequential Classifier Training (SCT-SVM) approach is\nproposed for multitemporal remote sensing image classification. The approach\nleverages the classifiers of previous images to reduce the required number of\ntraining samples for the classifier training of an incoming image. For each\nincoming image, a rough classifier is firstly predicted based on the temporal\ntrend of a set of previous classifiers. The predicted classifier is then\nfine-tuned into a more accurate position with current training samples. This\napproach can be applied progressively to sequential image data, with only a\nsmall number of training samples being required from each image. Experiments\nwere conducted with Sentinel-2A multitemporal data over an agricultural area in\nAustralia. Results showed that the proposed SCT-SVM achieved better\nclassification accuracies compared with two state-of-the-art model transfer\nalgorithms. When training data are insufficient, the overall classification\naccuracy of the incoming image was improved from 76.18% to 94.02% with the\nproposed SCT-SVM, compared with those obtained without the assistance from\nprevious images. These results demonstrate that the leverage of a priori\ninformation from previous images can provide advantageous assistance for later\nimages in multitemporal image classification.", "journal": "", "doi": "10.1109/TIP.2018.2808767", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1706.04719v2"}
{"entry_id": "http://arxiv.org/abs/1707.07321v3", "date": "2017-07-23", "title": "Exploiting Deep Features for Remote Sensing Image Retrieval: A Systematic Investigation", "authors": "Xin-Yi Tong, Gui-Song Xia, Fan Hu, Yanfei Zhong, Mihai Datcu, Liangpei Zhang", "abstract": "Remote sensing (RS) image retrieval is of great significant for geological\ninformation mining. Over the past two decades, a large amount of research on\nthis task has been carried out, which mainly focuses on the following three\ncore issues: feature extraction, similarity metric and relevance feedback. Due\nto the complexity and multiformity of ground objects in high-resolution remote\nsensing (HRRS) images, there is still room for improvement in the current\nretrieval approaches. In this paper, we analyze the three core issues of RS\nimage retrieval and provide a comprehensive review on existing methods.\nFurthermore, for the goal to advance the state-of-the-art in HRRS image\nretrieval, we focus on the feature extraction issue and delve how to use\npowerful deep representations to address this task. We conduct systematic\ninvestigation on evaluating correlative factors that may affect the performance\nof deep features. By optimizing each factor, we acquire remarkable retrieval\nresults on publicly available HRRS datasets. Finally, we explain the\nexperimental phenomenon in detail and draw conclusions according to our\nanalysis. Our work can serve as a guiding role for the research of\ncontent-based RS image retrieval.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1707.07321v3"}
{"entry_id": "http://arxiv.org/abs/1807.07327v1", "date": "2018-07-19", "title": "Deep Adaptive Proposal Network for Object Detection in Optical Remote Sensing Images", "authors": "Lin Cheng, Xu Liu, Lingling Li, Licheng Jiao, Xu Tang", "abstract": "Object detection is a fundamental and challenging problem in aerial and\nsatellite image analysis. More recently, a two-stage detector Faster R-CNN is\nproposed and demonstrated to be a promising tool for object detection in\noptical remote sensing images, while the sparse and dense characteristic of\nobjects in remote sensing images is complexity. It is unreasonable to treat all\nimages with the same region proposal strategy, and this treatment limits the\nperformance of two-stage detectors. In this paper, we propose a novel and\neffective approach, named deep adaptive proposal network (DAPNet), address this\ncomplexity characteristic of object by learning a new category prior network\n(CPN) on the basis of the existing Faster R-CNN architecture. Moreover, the\ncandidate regions produced by DAPNet model are different from the traditional\nregion proposal network (RPN), DAPNet predicts the detail category of each\ncandidate region. And these candidate regions combine the object number, which\ngenerated by the category prior network to achieve a suitable number of\ncandidate boxes for each image. These candidate boxes can satisfy detection\ntasks in sparse and dense scenes. The performance of the proposed framework has\nbeen evaluated on the challenging NWPU VHR-10 data set. Experimental results\ndemonstrate the superiority of the proposed framework to the state-of-the-art.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.07327v1"}
{"entry_id": "http://arxiv.org/abs/1910.03734v1", "date": "2019-10-09", "title": "Comparative study of panel and panelless-based reflectance conversion techniques for agricultural remote sensing", "authors": "Baabak Mamaghani, Carl Salvaggio", "abstract": "Small unmanned aircraft systems (sUAS) have allowed for thousands of aerial\nimages to be captured at a moments notice. The simplicity and relative low cost\nof flying a sUAS has provided remote sensing practitioners, both commercial and\nacademic, with a viable alternative to traditional remote sensing platforms\n(airplanes and satellites). This paper is an expanded follow-up study to an\ninitial work. Three radiance-to-reflectance conversion methods were tested to\ndetermine the optimal technique to use for converting raw digital count imagery\nto reflectance maps. The first two methods utilized in-scene reflectance\nconversion panels along with the empirical line method (ELM), while the final\nmethod used an upward looking sensor that recorded the band-effective spectral\ndownwelling irradiance. The methods employed were 2-Point ELM, 1-point ELM, and\nAt-altitude Radiance Ratio (AARR). The average signed reflectance factor errors\nproduced by these methods on real sUAS imagery were: -0.005, -0.0028, and\n-0.0244 respectively. These errors were produced across four altitudes (150,\n225, 300 and 375ft), six targets (grass, asphalt, concrete, blue felt, green\nfelt and red felt), five spectral bands (blue, green, red, red edge and near\ninfrared), and three weather conditions (cloudy, partly cloudy and sunny).\nFinally, data was simulated using the MODTRAN code to generate downwelling\nirradiance and sensor reaching radiance to compute the theoretical results of\nthe AARR technique. A multitude of variables were varied for these simulations\n(atmosphere, time, day, target, sensor height, and visibility), which resulted\nin an overall theoretically achievable signed reflectance factor error of\n0.0023.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/1910.03734v1"}
{"entry_id": "http://arxiv.org/abs/2012.03129v3", "date": "2020-12-05", "title": "Simultaneous Corn and Soybean Yield Prediction from Remote Sensing Data Using Deep Transfer Learning", "authors": "Saeed Khaki, Hieu Pham, Lizhi Wang", "abstract": "Large-scale crop yield estimation is, in part, made possible due to the\navailability of remote sensing data allowing for the continuous monitoring of\ncrops throughout their growth cycle. Having this information allows\nstakeholders the ability to make real-time decisions to maximize yield\npotential. Although various models exist that predict yield from remote sensing\ndata, there currently does not exist an approach that can estimate yield for\nmultiple crops simultaneously, and thus leads to more accurate predictions. A\nmodel that predicts the yield of multiple crops and concurrently considers the\ninteraction between multiple crop yields. We propose a new convolutional neural\nnetwork model called YieldNet which utilizes a novel deep learning framework\nthat uses transfer learning between corn and soybean yield predictions by\nsharing the weights of the backbone feature extractor. Additionally, to\nconsider the multi-target response variable, we propose a new loss function. We\nconduct our experiment using data from 1,132 counties for corn and 1,076\ncounties for soybean across the United States. Numerical results demonstrate\nthat our proposed method accurately predicts corn and soybean yield from one to\nfour months before the harvest with a MAE being 8.74% and 8.70% of the average\nyield, respectively, and is competitive to other state-of-the-art approaches.", "journal": "Scientific Reports, 11(1), 1-14 (2021)", "doi": "10.1038/s41598-021-89779-z", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV", "q-bio.QM", "stat.AP"], "pdf_url": "http://arxiv.org/pdf/2012.03129v3"}
{"entry_id": "http://arxiv.org/abs/2102.07997v3", "date": "2021-02-16", "title": "A2-FPN for Semantic Segmentation of Fine-Resolution Remotely Sensed Images", "authors": "Rui Li, Shunyi Zheng, Ce Zhang, Chenxi Duan, Libo Wang", "abstract": "Semantic segmentation using fine-resolution remotely sensed images plays a\ncritical role in many practical applications, such as urban planning,\nenvironmental protection, natural and anthropogenic landscape monitoring, etc.\nHowever, the automation of semantic segmentation, i.e., automatic\ncategorization/labeling and segmentation is still a challenging task,\nparticularly for fine-resolution images with huge spatial and spectral\ncomplexity. Addressing such a problem represents an exciting research field,\nwhich paves the way for scene-level landscape pattern analysis and decision\nmaking. In this paper, we propose an approach for automatic land segmentation\nbased on the Feature Pyramid Network (FPN). As a classic architecture, FPN can\nbuild a feature pyramid with high-level semantics throughout. However,\nintrinsic defects in feature extraction and fusion hinder FPN from further\naggregating more discriminative features. Hence, we propose an Attention\nAggregation Module (AAM) to enhance multi-scale feature learning through\nattention-guided feature aggregation. Based on FPN and AAM, a novel framework\nnamed Attention Aggregation Feature Pyramid Network (A2-FPN) is developed for\nsemantic segmentation of fine-resolution remotely sensed images. Extensive\nexperiments conducted on three datasets demonstrate the effectiveness of our A2\n-FPN in segmentation accuracy. Code is available at\nhttps://github.com/lironui/A2-FPN.", "journal": "", "doi": "10.1109/TGRS.2021.3093977", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2102.07997v3"}
{"entry_id": "http://arxiv.org/abs/2103.16871v1", "date": "2021-03-31", "title": "Robust Registration of Multimodal Remote Sensing Images Based on Structural Similarity", "authors": "Yuanxin Ye, Jie Shan, Lorenzo Bruzzone, Li Shen", "abstract": "Automatic registration of multimodal remote sensing data (e.g., optical,\nLiDAR, SAR) is a challenging task due to the significant non-linear radiometric\ndifferences between these data. To address this problem, this paper proposes a\nnovel feature descriptor named the Histogram of Orientated Phase Congruency\n(HOPC), which is based on the structural properties of images. Furthermore, a\nsimilarity metric named HOPCncc is defined, which uses the normalized\ncorrelation coefficient (NCC) of the HOPC descriptors for multimodal\nregistration. In the definition of the proposed similarity metric, we first\nextend the phase congruency model to generate its orientation representation,\nand use the extended model to build HOPCncc. Then a fast template matching\nscheme for this metric is designed to detect the control points between images.\nThe proposed HOPCncc aims to capture the structural similarity between images,\nand has been tested with a variety of optical, LiDAR, SAR and map data. The\nresults show that HOPCncc is robust against complex non-linear radiometric\ndifferences and outperforms the state-of-the-art similarities metrics (i.e.,\nNCC and mutual information) in matching performance. Moreover, a robust\nregistration method is also proposed in this paper based on HOPCncc, which is\nevaluated using six pairs of multimodal remote sensing images. The experimental\nresults demonstrate the effectiveness of the proposed method for multimodal\nimage registration.", "journal": "", "doi": "10.1109/TGRS.2017.2656380", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2103.16871v1"}
{"entry_id": "http://arxiv.org/abs/2107.05948v4", "date": "2021-07-13", "title": "Clustering-Based Representation Learning through Output Translation and Its Application to Remote--Sensing Images", "authors": "Qinglin Li, Bin Li, Jonathan M Garibaldi, Guoping Qiu", "abstract": "In supervised deep learning, learning good representations for\nremote--sensing images (RSI) relies on manual annotations. However, in the area\nof remote sensing, it is hard to obtain huge amounts of labeled data. Recently,\nself--supervised learning shows its outstanding capability to learn\nrepresentations of images, especially the methods of instance discrimination.\nComparing methods of instance discrimination, clustering--based methods not\nonly view the transformations of the same image as ``positive\" samples but also\nsimilar images. In this paper, we propose a new clustering-based method for\nrepresentation learning. We first introduce a quantity to measure\nrepresentations' discriminativeness and from which we show that even\ndistribution requires the most discriminative representations. This provides a\ntheoretical insight into why evenly distributing the images works well. We\nnotice that only the even distributions that preserve representations'\nneighborhood relations are desirable. Therefore, we develop an algorithm that\ntranslates the outputs of a neural network to achieve the goal of evenly\ndistributing the samples while preserving outputs' neighborhood relations.\nExtensive experiments have demonstrated that our method can learn\nrepresentations that are as good as or better than the state of the art\napproaches, and that our method performs computationally efficiently and\nrobustly on various RSI datasets.", "journal": "Remote Sens. 2022, 14, 3361", "doi": "10.3390/rs14143361", "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2107.05948v4"}
{"entry_id": "http://arxiv.org/abs/2201.01047v1", "date": "2022-01-04", "title": "DIAL: Deep Interactive and Active Learning for Semantic Segmentation in Remote Sensing", "authors": "Gaston Lenczner, Adrien Chan-Hon-Tong, Bertrand Le Saux, Nicola Luminari, Guy Le Besnerais", "abstract": "We propose in this article to build up a collaboration between a deep neural\nnetwork and a human in the loop to swiftly obtain accurate segmentation maps of\nremote sensing images. In a nutshell, the agent iteratively interacts with the\nnetwork to correct its initially flawed predictions. Concretely, these\ninteractions are annotations representing the semantic labels. Our\nmethodological contribution is twofold. First, we propose two interactive\nlearning schemes to integrate user inputs into deep neural networks. The first\none concatenates the annotations with the other network's inputs. The second\none uses the annotations as a sparse ground-truth to retrain the network.\nSecond, we propose an active learning strategy to guide the user towards the\nmost relevant areas to annotate. To this purpose, we compare different\nstate-of-the-art acquisition functions to evaluate the neural network\nuncertainty such as ConfidNet, entropy or ODIN. Through experiments on three\nremote sensing datasets, we show the effectiveness of the proposed methods.\nNotably, we show that active learning based on uncertainty estimation enables\nto quickly lead the user towards mistakes and that it is thus relevant to guide\nthe user interventions.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2201.01047v1"}
{"entry_id": "http://arxiv.org/abs/2202.13117v1", "date": "2022-02-26", "title": "An Unsupervised Cross-Modal Hashing Method Robust to Noisy Training Image-Text Correspondences in Remote Sensing", "authors": "Georgii Mikriukov, Mahdyar Ravanbakhsh, Beg\u00fcm Demir", "abstract": "The development of accurate and scalable cross-modal image-text retrieval\nmethods, where queries from one modality (e.g., text) can be matched to archive\nentries from another (e.g., remote sensing image) has attracted great attention\nin remote sensing (RS). Most of the existing methods assume that a reliable\nmulti-modal training set with accurately matched text-image pairs is existing.\nHowever, this assumption may not always hold since the multi-modal training\nsets may include noisy pairs (i.e., textual descriptions/captions associated to\ntraining images can be noisy), distorting the learning process of the retrieval\nmethods. To address this problem, we propose a novel unsupervised cross-modal\nhashing method robust to the noisy image-text correspondences (CHNR). CHNR\nconsists of three modules: 1) feature extraction module, which extracts feature\nrepresentations of image-text pairs; 2) noise detection module, which detects\npotential noisy correspondences; and 3) hashing module that generates\ncross-modal binary hash codes. The proposed CHNR includes two training phases:\ni) meta-learning phase that uses a small portion of clean (i.e., reliable) data\nto train the noise detection module in an adversarial fashion; and ii) the main\ntraining phase for which the trained noise detection module is used to identify\nnoisy correspondences while the hashing module is trained on the noisy\nmulti-modal training set. Experimental results show that the proposed CHNR\noutperforms state-of-the-art methods. Our code is publicly available at\nhttps://git.tu-berlin.de/rsim/chnr", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2202.13117v1"}
{"entry_id": "http://arxiv.org/abs/2204.00818v1", "date": "2022-04-02", "title": "RFVTM: A Recovery and Filtering Vertex Trichotomy Matching for Remote Sensing Image Registration", "authors": "Ming Zhao, Bowen An, Yongpeng Wu, Huynh Van Luong, Andr\u00e9 Kaup", "abstract": "Reliable feature point matching is a vital yet challenging process in\nfeature-based image registration. In this paper,a robust feature point matching\nalgorithm called Recovery and Filtering Vertex Trichotomy Matching (RFVTM) is\nproposed to remove outliers and retain sufficient inliers for remote sensing\nimages. A novel affine invariant descriptor called vertex trichotomy descriptor\nis proposed on the basis of that geometrical relations between any of vertices\nand lines are preserved after affine transformations, which is constructed by\nmapping each vertex into trichotomy sets. The outlier removals in Vertex\nTrichotomy Matching (VTM) are implemented by iteratively comparing the\ndisparity of corresponding vertex trichotomy descriptors. Some inliers\nmistakenly validated by a large amount of outliers are removed in VTM\niterations, and several residual outliers close to correct locations cannot be\nexcluded with the same graph structures. Therefore, a recovery and filtering\nstrategy is designed to recover some inliers based on identical vertex\ntrichotomy descriptors and restricted transformation errors. Assisted with the\nadditional recovered inliers, residual outliers can also be filtered out during\nthe process of reaching identical graph for the expanded vertex sets.\nExperimental results demonstrate the superior performance on precision and\nstability of this algorithm under various conditions, such as remote sensing\nimages with large transformations, duplicated patterns, or inconsistent\nspectral content.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.00818v1"}
{"entry_id": "http://arxiv.org/abs/2204.04716v1", "date": "2022-04-10", "title": "TOV: The Original Vision Model for Optical Remote Sensing Image Understanding via Self-supervised Learning", "authors": "Chao Tao, Ji Qia, Guo Zhang, Qing Zhu, Weipeng Lu, Haifeng Li", "abstract": "Do we on the right way for remote sensing image understanding (RSIU) by\ntraining models via supervised data-dependent and task-dependent way, instead\nof human vision in a label-free and task-independent way? We argue that a more\ndesirable RSIU model should be trained with intrinsic structure from data\nrather that extrinsic human labels to realize generalizability across a wide\nrange of RSIU tasks. According to this hypothesis, we proposed \\textbf{T}he\n\\textbf{O}riginal \\textbf{V}ision model (TOV) in remote sensing filed. Trained\nby massive unlabeled optical data along a human-like self-supervised learning\n(SSL) path that is from general knowledge to specialized knowledge, TOV model\ncan be easily adapted to various RSIU tasks, including scene classification,\nobject detection, and semantic segmentation, and outperforms dominant ImageNet\nsupervised pretrained method as well as two recently proposed SSL pretrained\nmethods on majority of 12 publicly available benchmarks. Moreover, we analyze\nthe influences of two key factors on the performance of building TOV model for\nRSIU, including the influence of using different data sampling methods and the\nselection of learning paths during self-supervised optimization. We believe\nthat a general model which is trained by a label-free and task-independent way\nmay be the next paradigm for RSIU and hope the insights distilled from this\nstudy can help to foster the development of an original vision model for RSIU.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.GT"], "pdf_url": "http://arxiv.org/pdf/2204.04716v1"}
{"entry_id": "http://arxiv.org/abs/2205.03147v1", "date": "2022-05-06", "title": "From Easy to Hard: Learning Language-guided Curriculum for Visual Question Answering on Remote Sensing Data", "authors": "Zhenghang Yuan, Lichao Mou, Qi Wang, Xiao Xiang Zhu", "abstract": "Visual question answering (VQA) for remote sensing scene has great potential\nin intelligent human-computer interaction system. Although VQA in computer\nvision has been widely researched, VQA for remote sensing data (RSVQA) is still\nin its infancy. There are two characteristics that need to be specially\nconsidered for the RSVQA task. 1) No object annotations are available in RSVQA\ndatasets, which makes it difficult for models to exploit informative region\nrepresentation; 2) There are questions with clearly different difficulty levels\nfor each image in the RSVQA task. Directly training a model with questions in a\nrandom order may confuse the model and limit the performance. To address these\ntwo problems, in this paper, a multi-level visual feature learning method is\nproposed to jointly extract language-guided holistic and regional image\nfeatures. Besides, a self-paced curriculum learning (SPCL)-based VQA model is\ndeveloped to train networks with samples in an easy-to-hard way. To be more\nspecific, a language-guided SPCL method with a soft weighting strategy is\nexplored in this work. The proposed model is evaluated on three public\ndatasets, and extensive experimental results show that the proposed RSVQA\nframework can achieve promising performance.", "journal": "", "doi": "10.1109/TGRS.2022.3173811", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2205.03147v1"}
{"entry_id": "http://arxiv.org/abs/2205.05369v1", "date": "2022-05-11", "title": "AutoLC: Search Lightweight and Top-Performing Architecture for Remote Sensing Image Land-Cover Classification", "authors": "Chenyu Zheng, Junjue Wang, Ailong Ma, Yanfei Zhong", "abstract": "Land-cover classification has long been a hot and difficult challenge in\nremote sensing community. With massive High-resolution Remote Sensing (HRS)\nimages available, manually and automatically designed Convolutional Neural\nNetworks (CNNs) have already shown their great latent capacity on HRS\nland-cover classification in recent years. Especially, the former can achieve\nbetter performance while the latter is able to generate lightweight\narchitecture. Unfortunately, they both have shortcomings. On the one hand,\nbecause manual CNNs are almost proposed for natural image processing, it\nbecomes very redundant and inefficient to process HRS images. On the other\nhand, nascent Neural Architecture Search (NAS) techniques for dense prediction\ntasks are mainly based on encoder-decoder architecture, and just focus on the\nautomatic design of the encoder, which makes it still difficult to recover the\nrefined mapping when confronting complicated HRS scenes.\n  To overcome their defects and tackle the HRS land-cover classification\nproblems better, we propose AutoLC which combines the advantages of two\nmethods. First, we devise a hierarchical search space and gain the lightweight\nencoder underlying gradient-based search strategy. Second, we meticulously\ndesign a lightweight but top-performing decoder that is adaptive to the\nsearched encoder of itself. Finally, experimental results on the LoveDA\nland-cover dataset demonstrate that our AutoLC method outperforms the\nstate-of-art manual and automatic methods with much less computational\nconsumption.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2205.05369v1"}
{"entry_id": "http://arxiv.org/abs/2206.13392v1", "date": "2022-06-20", "title": "Remote Sensing Image Classification using Transfer Learning and Attention Based Deep Neural Network", "authors": "Lam Pham, Khoa Tran, Dat Ngo, Jasmin Lampert, Alexander Schindler", "abstract": "The task of remote sensing image scene classification (RSISC), which aims at\nclassifying remote sensing images into groups of semantic categories based on\ntheir contents, has taken the important role in a wide range of applications\nsuch as urban planning, natural hazards detection, environment\nmonitoring,vegetation mapping, or geospatial object detection. During the past\nyears, research community focusing on RSISC task has shown significant effort\nto publish diverse datasets as well as propose different approaches to deal\nwith the RSISC challenges. Recently, almost proposed RSISC systems base on deep\nlearning models which prove powerful and outperform traditional approaches\nusing image processing and machine learning. In this paper, we also leverage\nthe power of deep learning technology, evaluate a variety of deep neural\nnetwork architectures, indicate main factors affecting the performance of a\nRSISC system. Given the comprehensive analysis, we propose a deep learning\nbased framework for RSISC, which makes use of the transfer learning technique\nand multihead attention scheme. The proposed deep learning framework is\nevaluated on the benchmark NWPU-RESISC45 dataset and achieves the best\nclassification accuracy of 94.7% which shows competitive to the\nstate-of-the-art systems and potential for real-life applications.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2206.13392v1"}
{"entry_id": "http://arxiv.org/abs/2207.01755v1", "date": "2022-07-05", "title": "Attention Guided Network for Salient Object Detection in Optical Remote Sensing Images", "authors": "Yuhan Lin, Han Sun, Ningzhong Liu, Yetong Bian, Jun Cen, Huiyu Zhou", "abstract": "Due to the extreme complexity of scale and shape as well as the uncertainty\nof the predicted location, salient object detection in optical remote sensing\nimages (RSI-SOD) is a very difficult task. The existing SOD methods can satisfy\nthe detection performance for natural scene images, but they are not well\nadapted to RSI-SOD due to the above-mentioned image characteristics in remote\nsensing images. In this paper, we propose a novel Attention Guided Network\n(AGNet) for SOD in optical RSIs, including position enhancement stage and\ndetail refinement stage. Specifically, the position enhancement stage consists\nof a semantic attention module and a contextual attention module to accurately\ndescribe the approximate location of salient objects. The detail refinement\nstage uses the proposed self-refinement module to progressively refine the\npredicted results under the guidance of attention and reverse attention. In\naddition, the hybrid loss is applied to supervise the training of the network,\nwhich can improve the performance of the model from three perspectives of\npixel, region and statistics. Extensive experiments on two popular benchmarks\ndemonstrate that AGNet achieves competitive performance compared to other\nstate-of-the-art methods. The code will be available at\nhttps://github.com/NuaaYH/AGNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2207.01755v1"}
{"entry_id": "http://arxiv.org/abs/2302.05109v1", "date": "2023-02-10", "title": "Adjacent-level Feature Cross-Fusion with 3D CNN for Remote Sensing Image Change Detection", "authors": "Yuanxin Ye, Mengmeng Wang, Liang Zhou, Guangyang Lei, Jianwei Fan, Yao Qin", "abstract": "Deep learning-based change detection using remote sensing images has received\nincreasing attention in recent years. However, how to effectively extract and\nfuse the deep features of bi-temporal images to improve the accuracy of change\ndetection is still a challenge. To address that, a novel adjacent-level feature\nfusion network with 3D convolution (named AFCF3D-Net) is proposed in this\narticle. First, through the inner fusion property of 3D convolution, we design\na new feature fusion way that can simultaneously extract and fuse the feature\ninformation from bi-temporal images. Then, in order to bridge the semantic gap\nbetween low-level features and high-level features, we propose an\nadjacent-level feature cross-fusion (AFCF) module to aggregate complementary\nfeature information between the adjacent-levels. Furthermore, the densely skip\nconnection strategy is introduced to improve the capability of pixel-wise\nprediction and compactness of changed objects in the results. Finally, the\nproposed AFCF3D-Net has been validated on the three challenging remote sensing\nchange detection datasets: Wuhan building dataset (WHU-CD), LEVIR building\ndataset (LEVIR-CD), and Sun Yat-Sen University (SYSU-CD). The results of\nquantitative analysis and qualitative comparison demonstrate that the proposed\nAFCF3D-Net achieves better performance compared to the other state-of-the-art\nchange detection methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2302.05109v1"}
{"entry_id": "http://arxiv.org/abs/2302.14835v1", "date": "2023-02-28", "title": "Novel Machine Learning Approach for Predicting Poverty using Temperature and Remote Sensing Data in Ethiopia", "authors": "Om Shah, Krti Tallam", "abstract": "In many developing nations, a lack of poverty data prevents critical\nhumanitarian organizations from responding to large-scale crises. Currently,\nsocioeconomic surveys are the only method implemented on a large scale for\norganizations and researchers to measure and track poverty. However, the\ninability to collect survey data efficiently and inexpensively leads to\nsignificant temporal gaps in poverty data; these gaps severely limit the\nability of organizational entities to address poverty at its root cause. We\npropose a transfer learning model based on surface temperature change and\nremote sensing data to extract features useful for predicting poverty rates.\nMachine learning, supported by data sources of poverty indicators, has the\npotential to estimate poverty rates accurately and within strict time\nconstraints. Higher temperatures, as a result of climate change, have caused\nnumerous agricultural obstacles, socioeconomic issues, and environmental\ndisruptions, trapping families in developing countries in cycles of poverty. To\nfind patterns of poverty relating to temperature that have the highest\ninfluence on spatial poverty rates, we use remote sensing data. The two-step\ntransfer model predicts the temperature delta from high resolution satellite\nimagery and then extracts image features useful for predicting poverty. The\nresulting model achieved 80% accuracy on temperature prediction. This method\ntakes advantage of abundant satellite and temperature data to measure poverty\nin a manner comparable to the existing survey methods and exceeds similar\nmodels of poverty prediction.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV", "68T99"], "pdf_url": "http://arxiv.org/pdf/2302.14835v1"}
{"entry_id": "http://arxiv.org/abs/2004.02428v2", "date": "2020-04-06", "title": "Contrast-weighted Dictionary Learning Based Saliency Detection for Remote Sensing Images", "authors": "Zhou Huang, Huai-Xin Chen, Tao Zhou, Yun-Zhi Yang, Chang-Yin Wang, Bi-Yuan Liu", "abstract": "Object detection is an important task in remote sensing image analysis. To\nreduce the computational complexity of redundant information and improve the\nefficiency of image processing, visual saliency models have been widely applied\nin this field. In this paper, a novel saliency detection model based on\nContrast-weighted Dictionary Learning (CDL) is proposed for remote sensing\nimages. Specifically, the proposed CDL learns salient and non-salient atoms\nfrom positive and negative samples to construct a discriminant dictionary, in\nwhich a contrast-weighted term is proposed to encourage the contrast-weighted\npatterns to be present in the learned salient dictionary while discouraging\nthem from being present in the non-salient dictionary. Then, we measure the\nsaliency by combining the coefficients of the sparse representation (SR) and\nreconstruction errors. Furthermore, by using the proposed joint saliency\nmeasure, a variety of saliency maps are generated based on the discriminant\ndictionary. Finally, a fusion method based on global gradient optimization is\nproposed to integrate multiple saliency maps. Experimental results on four\ndatasets demonstrate that the proposed model outperforms other state-of-the-art\nmethods.", "journal": "Pattern Recognition 2020", "doi": "10.1016/j.patcog.2020.107757", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2004.02428v2"}
{"entry_id": "http://arxiv.org/abs/0909.0434v2", "date": "2009-09-02", "title": "Unexpected Magnetism in Alkaline Earth Mono-Silicides", "authors": "Eduardo Cuervo-Reyes, Elizabeth Diane Stalder, Christian Mensing, Serhiy Budnyk, Reinhard Nesper", "abstract": "Alkaline earth mono-silicides ({\\AE}Si, {\\AE} $=$ Ca, Sr, Ba) are poor metals\nand their transport properties are not solely determined by the Zintl anion, in\ncontrast to their Zintl-type composition. Their conducting network is formed by\nthe depopulated ${}^{1}_{\\infty}$[Si$^{2-}$] $\\pi$-system and {\\AE}-$d$ states.\nThis justifies the special local coordination of the metal atoms and the\nplanarity of the silicon chains. The low density of carriers seems to be a\nplayground for magnetic instabilities and the triangular prismatic arrangement\nof {\\AE} atoms responsible for the observed weak glassy behavior.", "journal": "", "doi": null, "primary_category": "cond-mat.other", "categories": ["cond-mat.other"], "pdf_url": "http://arxiv.org/pdf/0909.0434v2"}
{"entry_id": "http://arxiv.org/abs/1808.07873v1", "date": "2018-08-23", "title": "Infrared Lightcurves of Near Earth Objects", "authors": "Joseph L. Hora, Amir Siraj, Michael Mommert, Andrew McNeill, David E. Trilling, Annika Gustafsson, Howard A. Smith, Giovanni G. Fazio, Steven Chesley, Joshua P. Emery, Alan Harris, Michael Mueller", "abstract": "We present lightcurves and derive periods and amplitudes for a subset of 38\nnear earth objects (NEOs) observed at 4.5 microns with the IRAC camera on the\nthe Spitzer Space Telescope, many of them having no previously reported\nrotation periods. This subset was chosen from about 1800 IRAC NEO observations\nas having obvious periodicity and significant amplitude. For objects where the\nperiod observed did not sample the full rotational period, we derived lower\nlimits to these parameters based on sinusoidal fits. Lightcurve durations\nranged from 42 to 544 minutes, with derived periods from 16 to 400 minutes. We\ndiscuss the effects of lightcurve variations on the thermal modeling used to\nderive diameters and albedos from Spitzer photometry. We find that both\ndiameters and albedos derived from the lightcurve maxima and minima agree with\nour previously published results, even for extreme objects, showing the\nconservative nature of the thermal model uncertainties. We also evaluate the\nNEO rotation rates, sizes, and their cohesive strengths.", "journal": "", "doi": "10.3847/1538-4365/aadcf5", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1808.07873v1"}
{"entry_id": "http://arxiv.org/abs/2012.06417v1", "date": "2020-12-11", "title": "A Methodology to Derive Global Maps of Leaf Traits Using Remote Sensing and Climate Data", "authors": "Alvaro Moreno-Martinez, Gustau Camps-Valls, Jens Kattge, Nathaniel Robinson, Markus Reichstein, Peter van Bodegom, Koen Kramer, J. Hans C. Cornelissen, Peter Reich, Michael Bahn, \u007fUlo Niinemets, Josep Pe\u00f1uelas, Joseph Craine, Bruno E. L. Cerabolini, Vanessa Minden, Daniel C. Laughlin, Lawren Sack, Brady Allred, Christopher Baraloto, Chaeho Byun, Nadejda A. Soudzilovskaia, Steven W. Running", "abstract": "This paper introduces a modular processing chain to derive global\nhigh-resolution maps of leaf traits. In particular, we present global maps at\n500 m resolution of specific leaf area, leaf dry matter content, leaf nitrogen\nand phosphorus content per dry mass, and leaf nitrogen/phosphorus ratio. The\nprocessing chain exploits machine learning techniques along with optical remote\nsensing data (MODIS/Landsat) and climate data for gap filling and up-scaling of\nin-situ measured leaf traits. The chain first uses random forests regression\nwith surrogates to fill gaps in the database ($> 45 \\% $ of missing entries)\nand maximize the global representativeness of the trait dataset. Along with the\nestimated global maps of leaf traits, we provide associated uncertainty\nestimates derived from the regression models. The process chain is modular, and\ncan easily accommodate new traits, data streams (traits databases and remote\nsensing data), and methods. The machine learning techniques applied allow\nattribution of information gain to data input and thus provide the opportunity\nto understand trait-environment relationships at the plant and ecosystem\nscales.", "journal": "Remote Sensing of Environment, Volume 218, 1 December 2018, Pages\n  69-88", "doi": "10.1016/j.rse.2018.09.006", "primary_category": "stat.AP", "categories": ["stat.AP", "physics.app-ph"], "pdf_url": "http://arxiv.org/pdf/2012.06417v1"}
{"entry_id": "http://arxiv.org/abs/2004.04209v1", "date": "2020-04-08", "title": "A single image deep learning approach to restoration of corrupted remote sensing products", "authors": "Anna Petrovskaia, Raghavendra B. Jana, Ivan V. Oseledets", "abstract": "Remote sensing images are used for a variety of analyses, from agricultural\nmonitoring, to disaster relief, to resource planning, among others. The images\ncan be corrupted due to a number of reasons, including instrument errors and\nnatural obstacles such as clouds. We present here a novel approach for\nreconstruction of missing information in such cases using only the corrupted\nimage as the input. The Deep Image Prior methodology eliminates the need for a\npre-trained network or an image database. It is shown that the approach easily\nbeats the performance of traditional single-image methods.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2004.04209v1"}
{"entry_id": "http://arxiv.org/abs/2010.07445v3", "date": "2020-10-15", "title": "Deep Learning Models for Predicting Wildfires from Historical Remote-Sensing Data", "authors": "Fantine Huot, R. Lily Hu, Matthias Ihme, Qing Wang, John Burge, Tianjian Lu, Jason Hickey, Yi-Fan Chen, John Anderson", "abstract": "Identifying regions that have high likelihood for wildfires is a key\ncomponent of land and forestry management and disaster preparedness. We create\na data set by aggregating nearly a decade of remote-sensing data and historical\nfire records to predict wildfires. This prediction problem is framed as three\nmachine learning tasks. Results are compared and analyzed for four different\ndeep learning models to estimate wildfire likelihood. The results demonstrate\nthat deep learning models can successfully identify areas of high fire\nlikelihood using aggregated data about vegetation, weather, and topography with\nan AUC of 83%.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2010.07445v3"}
{"entry_id": "http://arxiv.org/abs/2102.07004v1", "date": "2021-02-13", "title": "Weight Initialization Techniques for Deep Learning Algorithms in Remote Sensing: Recent Trends and Future Perspectives", "authors": "Wadii Boulila, Maha Driss, Mohamed Al-Sarem, Faisal Saeed, Moez Krichen", "abstract": "During the last decade, several research works have focused on providing\nnovel deep learning methods in many application fields. However, few of them\nhave investigated the weight initialization process for deep learning, although\nits importance is revealed in improving deep learning performance. This can be\njustified by the technical difficulties in proposing new techniques for this\npromising research field. In this paper, a survey related to weight\ninitialization techniques for deep algorithms in remote sensing is conducted.\nThis survey will help practitioners to drive further research in this promising\nfield. To the best of our knowledge, this paper constitutes the first survey\nfocusing on weight initialization for deep learning models.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2102.07004v1"}
{"entry_id": "http://arxiv.org/abs/2002.05925v2", "date": "2020-02-14", "title": "SemI2I: Semantically Consistent Image-to-Image Translation for Domain Adaptation of Remote Sensing Data", "authors": "Onur Tasar, S L Happy, Yuliya Tarabalka, Pierre Alliez", "abstract": "Although convolutional neural networks have been proven to be an effective\ntool to generate high quality maps from remote sensing images, their\nperformance significantly deteriorates when there exists a large domain shift\nbetween training and test data. To address this issue, we propose a new data\naugmentation approach that transfers the style of test data to training data\nusing generative adversarial networks. Our semantic segmentation framework\nconsists in first training a U-net from the real training data and then\nfine-tuning it on the test stylized fake training data generated by the\nproposed approach. Our experimental results prove that our framework\noutperforms the existing domain adaptation methods.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2002.05925v2"}
{"entry_id": "http://arxiv.org/abs/1308.1670v1", "date": "2013-08-07", "title": "Utility of the Weak Temperature Gradient Approximation for Earth-Like Tidally Locked Exoplanets", "authors": "Sean M. Mills, Dorian S. Abbot", "abstract": "Planets in M dwarf stars' habitable zones are likely to be tidally locked\nwith orbital periods of order tens of days. This means that the effects of\nrotation on atmospheric dynamics will be relatively weak, which requires small\nhorizontal temperature gradients above the boundary layer of terrestrial\natmospheres. An analytically solvable and dynamically consistent model for\nplanetary climate with only three free parameters can be constructed by making\nthe weak temperature gradient (WTG) approximation, which assumes temperatures\nare horizontally uniform aloft. The extreme numerical efficiency of a WTG model\ncompared to a 3D general circulation model (GCM) makes it an optimal tool for\nMonte Carlo fits to observables over parameter space. Additionally, such\nlow-order models are critical for developing physical intuition and coupling\natmospheric dynamics to models of other components of planetary climate. The\nobjective of this paper is to determine whether a WTG model provides an\nadequate approximation of the effect of atmospheric dynamics on quantities\nlikely to be observed over the next decade. To do this we first tune a WTG\nmodel to GCM output for an Earth-like tidally locked planet with a dry, 1 bar\natmosphere, then generate and compare the expected phase curves of both models.\nWe find that differences between the two models would be extremely difficult to\ndetect from phase curves using JWST. This result demonstrates the usefulness of\nthe WTG approximation when used in conjunction with GCMs as part of a modeling\nhierarchy to understand the climate of remote planets.", "journal": "", "doi": "10.1088/2041-8205/774/2/L17", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1308.1670v1"}
{"entry_id": "http://arxiv.org/abs/1807.09706v1", "date": "2018-07-25", "title": "Remote estimation over a packet-drop channel with Markovian state", "authors": "Jhelum Chakravorty, Aditya Mahajan", "abstract": "We investigate a remote estimation problem in which a transmitter observes a\nMarkov source and chooses the power level to transmit it over a time-varying\npacket-drop channel. The channel is modeled as a channel with Markovian state\nwhere the packet drop probability depends on the channel state and the transmit\npower. A receiver observes the channel output and the channel state and\nestimates the source realization. The receiver also feeds back the channel\nstate and an acknowledgment for successful reception to the transmitter. We\nconsider two models for the source---finite state Markov chains and first-order\nautoregressive processes. For the first model, using ideas from team theory, we\nestablish the structure of optimal transmission and estimation strategies and\nidentify a dynamic program to determine optimal strategies with that structure.\nFor the second model, we assume that the noise process has unimodal and\nsymmetric distribution. Using ideas from majorization theory, we show that the\noptimal transmission strategy is symmetric and monotonic and the optimal\nestimation strategy is like Kalman filter. Consequently, when there are a\nfinite number of power levels, the optimal transmission strategy may be\ndescribed using thresholds that depend on the channel state. Finally, we\npropose a simulation based approach (Renewal Monte Carlo) to compute the\noptimal thresholds and optimal performance and elucidate the algorithm with an\nexample.", "journal": "", "doi": "10.1109/TAC.2019.2926160", "primary_category": "cs.SY", "categories": ["cs.SY", "cs.IT", "math.IT", "math.OC"], "pdf_url": "http://arxiv.org/pdf/1807.09706v1"}
{"entry_id": "http://arxiv.org/abs/2012.02273v2", "date": "2020-12-03", "title": "A Distinct Population of Small Planets: Sub-Earths", "authors": "Yansong Qian, Yanqin Wu", "abstract": "The sizes of small planets have been known to be bi-modal, with a gap\nseparating planets that have lost their primordial atmospheres (super-Earths),\nand the ones that retain them (mini-Neptunes). Here, we report evidences for\nanother distinct population at smaller sizes. By focussing on planets orbiting\naround GK-dwarfs inward of 16 days, and correcting for observational\ncompleteness, we find that the number of super-Earths peak around 1.4 Earth\nradii and disappear shortly below this size. Instead, a new population of\nplanets (sub-Earths) appear to dominate at sizes below ~ 1 Earth radius, with\nan occurrence that rises with decreasing size. This pattern is also observed in\nultra-short-period planets.\n  The end of super-Earths supports earlier claims that super-Earths and\nmini-Neptunes, planets that likely form in gaseous proto-planetary disks, have\na narrow mass distribution. The sub-Earths, in contrast, can be described by a\npower-law mass distribution and may be explained by the theory of terrestrial\nplanet formation. We therefore speculate that they are formed well after the\ngaseous disks have dissipated. The extension of these sub-Earths towards longer\norbital periods, currently invisible, may be the true terrestrial analogues.\nThis strongly motivates new searches.", "journal": "", "doi": "10.3847/1538-3881/abe632", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2012.02273v2"}
{"entry_id": "http://arxiv.org/abs/1409.5398v1", "date": "2014-09-18", "title": "On the prospects of Near Earth Asteroid orbit triangulation using the Gaia satellite and Earth-based observations", "authors": "Siegfried Eggl, Hadrien Devillepoix", "abstract": "Accurate measurements of osculating orbital elements are essential in order\nto understand and model the complex dynamic behavior of Near Earth Asteroids\n(NEAs). ESA's Gaia mission promises to have great potential in this respect. In\nthis article we investigate the prospects of constraining orbits of newly\ndiscovered and known NEAs using nearly simultaneous observations from the Earth\nand Gaia. We find that observations performed simultaneously from two sites can\neffectively constrain preliminary orbits derived via statistical ranging. By\nlinking discoveries stored in the Minor Planet Center databases to Gaia\nastrometric alerts one can identify nearly simultaneous observations of Near\nEarth Objects and benefit from improved initial orbit solutions at no\nadditional observational cost.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1409.5398v1"}
{"entry_id": "http://arxiv.org/abs/2001.03550v1", "date": "2020-01-10", "title": "Debiased albedo distribution for Near Earth Objects", "authors": "Alessandro Morbidelli, Marco Delbo, Mikael Granvik, William F. Bottke, Robert Jedicke, Bryce Bolin, Patrick Michel, David Vokrouhlick\u00fd", "abstract": "We extend the most recent orbital and absolute magnitude Near Earth Object\n(NEO) model (Granvik et al., 2018) to provide a statistical description of NEO\ngeometric albedos. Our model is calibrated on NEOWISE albedo data for the NEO\npopulation and reproduces these data very well once a simple model for the\nNEOWISE observational biases is applied. The results are consistent with\nprevious estimates. There are about 1,000 NEOs with diameter D>1km and the mean\nalbedo to convert absolute magnitude into diameter is 0.147. We do not find any\nstatistically significant evidence that the albedo distribution of NEOs depends\non NEO size. Instead, we find evidence that the disruption of NEOs at small\nperihelion distances found in Granvik et al. (2016) occurs preferentially for\ndark NEOs. The interval between km-sized bodies striking the Earth should occur\non average once every 750,000 years. Low and high albedo NEOs are well mixed in\norbital space, but a trend remains with higher albedo objects being at smaller\nsemimajor axes and lower albedo objects more likely found at larger semimajor\naxes.", "journal": "", "doi": "10.1016/j.icarus.2020.113631", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2001.03550v1"}
{"entry_id": "http://arxiv.org/abs/1802.09264v1", "date": "2018-02-26", "title": "Outgassing on stagnant-lid super-Earths", "authors": "Caroline Dorn, Lena Noack, Antoine Rozel", "abstract": "We explore volcanic outgassing on purely rocky, stagnant-lid exoplanets of\ndifferent interior structures, compositions, thermal states, and age. We focus\non planets in the mass range of 1-8 ME (Earth masses). We derive scaling laws\nto quantify first- and second-order influences of these parameters on volcanic\noutgassing after 4.5 Gyrs of evolution. Given commonly observed astrophysical\ndata of super-Earths, we identify a range of possible interior structures and\ncompositions by employing Bayesian inference modelling. [..] The identified\ninteriors are subsequently used as input for two-dimensional (2-D) convection\nmodels to study partial melting, depletion, and outgassing rates of CO2. In\ntotal, we model depletion and outgassing for an extensive set of more than 2300\ndifferent super-Earth cases. We find that there is a mass range for which\noutgassing is most efficient (~2--3 ME, depending on thermal state) and an\nupper mass where outgassing becomes very inefficient (~5--7 \\ME, depending on\nthermal state). [..] In summary, depletion and outgassing are mainly influenced\nby planet mass and thermal state. Interior structure and composition only\nmoderately affect outgassing. The majority of outgassing occurs before 4.5\nGyrs, especially for planets below 3 ME. We conclude that for stagnant-lid\nplanets, (1) compositional and structural properties have secondary influence\non outgassing compared to planet mass and thermal state, and (2) confirm that\nthere is a mass range for which outgassing is most efficient and an upper mass\nlimit, above which no significant outgassing can occur. Our predicted trend of\nCO2-atmospheric masses can be observationally tested for exoplanets. These\nfindings and our provided scaling laws are an important step in order to\nprovide interpretative means for upcoming missions such as, e.g., JWST and\nE-ELT, that aim at characterizing exoplanet atmospheres.", "journal": "A&A 614, A18 (2018)", "doi": "10.1051/0004-6361/201731513", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1802.09264v1"}
{"entry_id": "http://arxiv.org/abs/2009.01465v1", "date": "2020-09-03", "title": "Understanding User Experience of COVID-19 Maps through Remote Elicitation Interviews", "authors": "Damla \u00c7ay, Till Nagel, As\u0131m Evren Yanta\u00e7", "abstract": "During the coronavirus pandemic, visualizations gained a new level of\npopularity and meaning for a wider audience. People were bombarded with a wide\nset of public health visualizations ranging from simple graphs to complex\ninteractive dashboards. In a pandemic setting, where large amounts of the world\npopulation are socially distancing themselves, it becomes an urgent need to\nrefine existing user experience evaluation methods for remote settings to\nunderstand how people make sense out of COVID-19 related visualizations. When\nevaluating visualizations aimed towards the general public with vastly\ndifferent socio-demographic backgrounds and varying levels of technical\nsavviness and data literacy, it is important to understand user feedback beyond\naspects such as speed, task accuracy, or usability problems. As a part of this\nwider evaluation perspective, micro-phenomenology has been used to evaluate\nstatic and narrative visualizations to reveal the lived experience in a\ndetailed way. Building upon these studies, we conducted a user study to\nunderstand how to employ Elicitation (aka Micro-phenomenological) interviews in\nremote settings. In a case study, we investigated what experiences the\nparticipants had with map-based interactive visualizations. Our findings reveal\npositive and negative aspects of conducting Elicitation interviews remotely.\nOur results can inform the process of planning and executing remote Elicitation\ninterviews to evaluate interactive visualizations. In addition, we share\nrecommendations regarding visualization techniques and interaction design about\npublic health data.", "journal": "", "doi": null, "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/2009.01465v1"}
{"entry_id": "http://arxiv.org/abs/1501.01921v1", "date": "2015-01-08", "title": "Remote optical sensing on the nanometer scale with a bowtie aperture nano-antenna on a SNOM fiber tip", "authors": "Elie M. Atie, Zhihua Xie, Ali El Eter, Roland Salut, Dusan Nedeljkovic, Tony Tannous, Fadi I. Baida, Thierry Grosjean", "abstract": "Plasmonic nano-antennas have proven the outstanding ability of sensing\nchemical and physical processes down to the nano-meter scale. Sensing is\nusually achieved within the highly confined optical fields generated resonantly\nby the nano-antennas, i.e. in contact to the nano-structures. In these paper,\nWe demonstrate the sensing capability of nano-antennas to their larger scale\nenvironment, well beyond their plasmonic confinement volume, leading to the\nconcept of 'remote' (non contact) sensing on the nano-meter scale. On the basis\nof a bowtie-aperture nano-antenna (BNA) integrated at the apex of a SNOM fiber\ntip, we introduce an ultra-compact, move-able and background-free optical\nnano-sensor for the remote sensing of a silicon surface (up to distance of 300\nnm). Sensitivity of the BNA to its large scale environment is high enough to\nexpect the monitoring and control of the spacing between the nano-antenna and a\nsilicon surface with sub-nano-meter accuracy. This work paves the way towards a\nnew class of nano-positionning technique, based on nano-antenna resonance\nmonitoring, that are alternative to nano-mechanical and optical\ninterference-based devices.", "journal": "", "doi": null, "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/1501.01921v1"}
{"entry_id": "http://arxiv.org/abs/2211.12387v2", "date": "2022-11-22", "title": "Magnetic resonance study of rare-earth titanates", "authors": "Ana Najev, Sajna Hameed, Alexey Alfonsov, Joseph Joe, Vladislav Kataev, Martin Greven, Miroslav Po\u017eek, Damjan Pelc", "abstract": "We present a nuclear magnetic resonance (NMR) and electron spin resonance\n(ESR) study of rare-earth titanates derived from the spin-1/2 Mott insulator\nYTiO$_3$. Measurements of single-crystalline samples of (Y,Ca,La)TiO$_3$ in a\nwide range of isovalent substitution (La) and hole doping (Ca) reveal several\nunusual features in the paramagnetic state of these materials. $^{89}$Y NMR\ndemonstrates a clear discrepancy between the static and dynamic local magnetic\nsusceptibilities, with deviations from Curie-Weiss behavior far above the Curie\ntemperature $T_C$. No significant changes are observed close to $T_C$, but a\nsuppression of fluctuations is detected in the NMR spin-lattice relaxation time\nat temperatures of about $3\\times T_C$. Additionally, the nuclear spin-spin\nrelaxation rate shows an unusual peak in dependence on temperature for all\nsamples. ESR of the unpaired Ti electron shows broad resonance lines at all\ntemperatures and substitution/doping levels, which we find to be caused by\nshort electronic spin-lattice relaxation times. We model the relaxation as an\nOrbach process that involves a low-lying electronic excited state, which\nenables the determination of the excited-state gap from the temperature\ndependence of the ESR linewidths. We ascribe the small gap to Jahn-Teller\nsplitting of the two lower Ti $t_{2g}$ orbitals. The value of the gap closely\nfollows $T_C$ and is consistent with the temperatures at which deviations from\nCurie-Weiss fluctuations are observed in NMR. These results provide insight\ninto the interplay between orbital and spin degrees of freedom in rare-earth\ntitanates and indicate that full orbital degeneracy lifting is associated with\nferromagnetic order.", "journal": "", "doi": null, "primary_category": "cond-mat.str-el", "categories": ["cond-mat.str-el"], "pdf_url": "http://arxiv.org/pdf/2211.12387v2"}
{"entry_id": "http://arxiv.org/abs/2210.02782v1", "date": "2022-10-06", "title": "Propagation of Coronal Mass Ejections from the Sun to Earth", "authors": "Wageesh Mishra, Luca Teriaca", "abstract": "Coronal Mass Ejections (CMEs), as they can inject a large amounts of mass and\nmagnetic flux into the interplanetary space, are the primary source of space\nweather phenomena on the Earth. The present review first briefly introduces the\nsolar surface signatures of the origins of CMEs and then focuses on the\nattempts to understand the kinematic evolution of CMEs from the Sun to the\nEarth. CMEs have been observed in the solar corona in white-light from a series\nof space missions over the last five decades. In particular, LASCO/SOHO has\nprovided almost continuous coverage of CMEs for more than two solar cycles\nuntil today. However, the observations from LASCO suffered from projection\neffects and limited field of view (within 30 Rs from the Sun). The launch in\n2006 of the twin STEREO spacecraft made possible multiple viewpoints imaging\nobservations, which enabled us to assess the projection effects on CMEs.\nMoreover, heliospheric imagers (HIs) onboard STEREO continuously observed the\nlarge and unexplored distance gap between the Sun and Earth. Finally, the\nEarth-directed CMEs that before have been routinely identified only near the\nEarth at 1 AU in in situ observations from ACE and WIND, could also be\nidentified at longitudes away from the Sun-Earth line using the in situ\ninstruments onboard STEREO. Our review presents the frequently used methods for\nestimation of the kinematics of CMEs and their arrival time at 1 AU using\nprimarily SOHO and STEREO observations. We emphasize the need of deriving the\nthree-dimensional (3D) properties of Earth-directed CMEs from the locations\naway from the Sun-Earth line. The results improving the CME arrival time\nprediction at Earth and the open issues holding back progress are also\ndiscussed. Finally, we summarize the importance of heliospheric imaging and\ndiscuss the path forward to achieve improved space weather forecasting.", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2210.02782v1"}
{"entry_id": "http://arxiv.org/abs/1604.05220v1", "date": "2016-04-18", "title": "Hot super-Earths stripped by their host stars", "authors": "M. S. Lundkvist, H. Kjeldsen, S. Albrecht, G. R. Davies, S. Basu, D. Huber, A. B. Justesen, C. Karoff, V. Silva Aguirre, V. Van Eylen, C. Vang, T. Arentoft, T. Barclay, T. R. Bedding, T. L. Campante, W. J. Chaplin, J. Christensen-Dalsgaard, Y. P. Elsworth, R. L. Gilliland, R. Handberg, S. Hekker, S. D. Kawaler, M. N. Lund, T. S. Metcalfe, A. Miglio, J. F. Rowe, D. Stello, B. Tingley, T. R. White", "abstract": "Simulations predict that hot super-Earth sized exoplanets can have their\nenvelopes stripped by photo-evaporation, which would present itself as a lack\nof these exoplanets. However, this absence in the exoplanet population has\nescaped a firm detection. Here we demonstrate, using asteroseismology on a\nsample of exoplanets and exoplanet candidates observed during the Kepler\nmission that, while there is an abundance of super-Earth sized exoplanets with\nlow incident fluxes, none are found with high incident fluxes. We do not find\nany exoplanets with radii between 2.2 and 3.8 Earth radii with incident flux\nabove 650 times the incident flux on Earth. This gap in the population of\nexoplanets is explained by evaporation of volatile elements and thus supports\nthe predictions. The confirmation of a hot-super-Earth desert caused by\nevaporation will add an important constraint on simulations of planetary\nsystems, since they must be able to reproduce the dearth of close-in\nsuper-Earths.", "journal": "Nature Communications, Volume 7, id. 11201 (2016)", "doi": "10.1038/ncomms11201", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1604.05220v1"}
{"entry_id": "http://arxiv.org/abs/2009.12136v1", "date": "2020-09-25", "title": "Sensitivity of Remote Focusing Microscopes to Magnification Mismatch", "authors": "Sharika Mohanan, Alexander D. Corbett", "abstract": "Remote focusing (RF) is a technique that greatly extends the aberration-free\naxial scan range of an optical microscope. To maximise the diffraction limited\ndepth range in an RF system, the magnification of the relay lenses should be\nsuch that the pupil planes of the objectives are accurately mapped on to each\nother. In this paper we study the tolerance of the RF system to magnification\nmismatch and quantify the amount of residual spherical aberration present at\ndifferent focusing depths. We observe that small deviations from ideal\nmagnification results in increased amounts of residual spherical aberration\nterms leading to a reduction in the dynamic range. For high numerical aperture\nobjectives, the simulation predicts a 50% decrease in the dynamic range for 1%\nmagnification mismatch. The simulation has been verified against an\nexperimental RF system with ideal and non-ideal magnifications. Experimentally\nconfirmed predictions also provide a valuable empirical method of determining\nwhen a system is close to the ideal phase matching condition, based on the sign\nof the spherical aberration on either side of focus.", "journal": "", "doi": "10.1111/jmi.12991", "primary_category": "physics.optics", "categories": ["physics.optics", "physics.bio-ph"], "pdf_url": "http://arxiv.org/pdf/2009.12136v1"}
{"entry_id": "http://arxiv.org/abs/2012.03297v1", "date": "2020-12-06", "title": "Remote sensing of vegetation dynamics in agro-ecosystems using SMAP vegetation optical depth and optical vegetation indices", "authors": "M. Piles, D. Chaparro, D. Entekhabi, A. G. Konings, T. Jagdhuber, G. Camps-Valls", "abstract": "The ESA's SMOS and the NASA's SMAP missions, launched in 2009 and 2015,\nrespectively, are the first two missions having on-board L-band microwave\nsensors, which are very sensitive to the water content in soils and vegetation.\nFocusing on the vegetation signal at L-band, we have implemented an inversion\napproach for SMAP that allows deriving vegetation optical depth (VOD, a\nmicrowave parameter related to biomass and plant water content) alongside soil\nmoisture, without reliance on ancillary optical information on vegetation. This\nwork aims at using this new observational data to monitor the phenology of\ncrops in major global agro-ecosystems and enhance present agricultural\nmonitoring and prediction capabilities. Core agricultural regions have been\nselected worldwide covering major crops (corn, soybean, wheat, rice). The\ncomplementarity and synergies between the microwave vegetation signal,\nsensitive to biomass water-uptake dynamics, and optical indices, sensitive to\ncanopy greenness, are explored. Results reveal the value of L-band VOD as an\nindependent ecological indicator for global terrestrial biosphere studies.", "journal": "", "doi": "10.1109/IGARSS.2017.8127964", "primary_category": "physics.app-ph", "categories": ["physics.app-ph"], "pdf_url": "http://arxiv.org/pdf/2012.03297v1"}
{"entry_id": "http://arxiv.org/abs/1004.0945v1", "date": "2010-04-06", "title": "Determining the azimuthal properties of coronal mass ejections from multi-spacecraft remote-sensing observations with stereo secchi", "authors": "N. Lugaz, J. N. Hernandez-Charpak, I. I. Roussev, C. J. Davis, A. Vourlidas, J. A. Davies", "abstract": "We discuss how simultaneous observations by multiple heliospheric imagers can\nprovide some important information about the azimuthal properties of Coronal\nMass Ejections (CMEs) in the heliosphere. We propose two simple models of CME\ngeometry that can be used to derive information about the azimuthal deflection\nand the azimuthal expansion of CMEs from SECCHI/HI observations. We apply these\ntwo models to four CMEs well-observed by both STEREO spacecraft during the year\n2008. We find that in three cases, the joint STEREO-A and B observations are\nconsistent with CMEs moving radially outward. In some cases, we are able to\nderive the azimuthal cross-section of the CME fronts, and we are able to\nmeasure the deviation from self-similar evolution. The results from this\nanalysis show the importance of having multiple satellites dedicated to space\nweather forecasting, for example in orbits at the Lagrangian L4 and L5 points.", "journal": "ApJ, 715 (2010) 493-499", "doi": "10.1088/0004-637X/715/1/493", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1004.0945v1"}
{"entry_id": "http://arxiv.org/abs/1501.03188v1", "date": "2015-01-13", "title": "Video Manipulation Techniques for the Protection of Privacy in Remote Presence Systems", "authors": "Alexander Hubers, Emily Andrulis, Levi Scott, Tanner Stirrat, Duc Tran, Ruonan Zhang, Ross Sowell, Cindy Grimm, William D. Smart", "abstract": "Systems that give control of a mobile robot to a remote user raise privacy\nconcerns about what the remote user can see and do through the robot. We aim to\npreserve some of that privacy by manipulating the video data that the remote\nuser sees. Through two user studies, we explore the effectiveness of different\nvideo manipulation techniques at providing different types of privacy. We\nsimultaneously examine task performance in the presence of privacy protection.\nIn the first study, participants were asked to watch a video captured by a\nrobot exploring an office environment and to complete a series of observational\ntasks under differing video manipulation conditions. Our results show that\nusing manipulations of the video stream can lead to fewer privacy violations\nfor different privacy types. Through a second user study, it was demonstrated\nthat these privacy-protecting techniques were effective without diminishing the\ntask performance of the remote user.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO", "cs.CR", "cs.CY", "H.5.2; I.2.9; I.4.3"], "pdf_url": "http://arxiv.org/pdf/1501.03188v1"}
{"entry_id": "http://arxiv.org/abs/1102.3625v3", "date": "2011-02-17", "title": "Colors of a Second Earth II: Effects of Clouds on Photometric Characterization of Earth-like Exoplanets", "authors": "Yuka Fujii, Hajime Kawahara, Yasushi Suto, Satoru Fukuda, Teruyuki Nakajima, Timothy A. Livengood, Edwin L. Turner", "abstract": "As a test-bed for future investigations of directly imaged terrestrial\nexoplanets, we present the recovery of the surface components of the Earth from\nmulti-band diurnal light curves obtained with the EPOXI spacecraft. We find\nthat the presence and longitudinal distribution of ocean, soil and vegetation\nare reasonably well reproduced by fitting the observed color variations with a\nsimplified model composed of a priori known albedo spectra of ocean, soil,\nvegetation, snow and clouds. The effect of atmosphere, including clouds, on\nlight scattered from surface components is modeled using a radiative transfer\ncode. The required noise levels for future observations of exoplanets are also\ndetermined. Our model-dependent approach allows us to infer the presence of\nmajor elements of the planet (in the case of the Earth, clouds and ocean) with\nobservations having S/N $\\gtrsim 10$ in most cases and with high confidence if\nS/N $\\gtrsim 20$. In addition, S/N $\\gtrsim 100$ enables us to detect the\npresence of components other than ocean and clouds in a fairly\nmodel-independent way. Degradation of our inversion procedure produced by cloud\ncover is also quantified. While cloud cover significantly dilutes the magnitude\nof color variations compared to the cloudless case, the pattern of color\nchanges remains. Therefore, the possibility of investigating surface features\nthrough light curve fitting remains even for exoplanets with cloud cover\nsimilar to the Earth's.", "journal": "", "doi": "10.1088/0004-637X/738/2/184", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1102.3625v3"}
{"entry_id": "http://arxiv.org/abs/2007.07699v2", "date": "2020-07-15", "title": "The Benefits of Very Low Earth Orbit for Earth Observation Missions", "authors": "N. H. Crisp, P. C. E. Roberts, S. Livadiotti, V. T. A. Oiko, S. Edmondson, S. J. Haigh, C. Huyton, L. Sinpetru, K. L. Smith, S. D. Worrall, J. Becedas, R. M. Dom\u00ednguez, D. Gonz\u00e1lez, V. Hanessian, A. M\u00f8lgaard, J. Nielsen, M. Bisgaard, Y. -A. Chan, S. Fasoulas, G. H. Herdrich, F. Romano, C. Traub, D. Garc\u00eda-Almi\u00f1ana, S. Rodr\u00edguez-Donaire, M. Sureda, D. Kataria, R. Outlaw, B. Belkouchi, A. Conte, J. S. Perez, R. Villain, B. Hei\u00dferer, A. Schwalber", "abstract": "Very low Earth orbits (VLEO), typically classified as orbits below\napproximately 450 km in altitude, have the potential to provide significant\nbenefits to spacecraft over those that operate in higher altitude orbits. This\npaper provides a comprehensive review and analysis of these benefits to\nspacecraft operations in VLEO, with parametric investigation of those which\napply specifically to Earth observation missions. The most significant benefit\nfor optical imaging systems is that a reduction in orbital altitude improves\nspatial resolution for a similar payload specification. Alternatively mass and\nvolume savings can be made whilst maintaining a given performance. Similarly,\nfor radar and lidar systems, the signal-to-noise ratio can be improved.\nAdditional benefits include improved geospatial position accuracy, improvements\nin communications link-budgets, and greater launch vehicle insertion\ncapability. The collision risk with orbital debris and radiation environment\ncan be shown to be improved in lower altitude orbits, whilst compliance with\nIADC guidelines for spacecraft post-mission lifetime and deorbit is also\nassisted. Finally, VLEO offers opportunities to exploit novel\natmosphere-breathing electric propulsion systems and aerodynamic attitude and\norbit control methods.\n  However, key challenges associated with our understanding of the lower\nthermosphere, aerodynamic drag, the requirement to provide a meaningful orbital\nlifetime whilst minimising spacecraft mass and complexity, and atomic oxygen\nerosion still require further research. Given the scope for significant\ncommercial, societal, and environmental impact which can be realised with\nhigher performing Earth observation platforms, renewed research efforts to\naddress the challenges associated with VLEO operations are required.", "journal": "Progress in Aerospace Sciences 117 (2020)", "doi": "10.1016/j.paerosci.2020.100619", "primary_category": "physics.space-ph", "categories": ["physics.space-ph", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2007.07699v2"}
{"entry_id": "http://arxiv.org/abs/1710.09342v2", "date": "2017-10-25", "title": "Ground Control to Major Tom: the importance of field surveys in remotely sensed data analysis", "authors": "Ian Bolliger, Tamma Carleton, Solomon Hsiang, Jonathan Kadish, Jonathan Proctor, Benjamin Recht, Esther Rolf, Vaishaal Shankar", "abstract": "In this project, we build a modular, scalable system that can collect, store,\nand process millions of satellite images. We test the relative importance of\nboth of the key limitations constraining the prevailing literature by applying\nthis system to a data-rich environment. To overcome classic data availability\nconcerns, and to quantify their implications in an economically meaningful\ncontext, we operate in a data rich environment and work with an outcome\nvariable directly correlated with key indicators of socioeconomic well-being.\nWe collect public records of sale prices of homes within the United States, and\nthen gradually degrade our rich sample in a range of different ways which mimic\nthe sampling strategies employed in actual survey-based datasets. Pairing each\nhouse with a corresponding set of satellite images, we use image-based features\nto predict housing prices within each of these degraded samples. To generalize\nbeyond any given featurization methodology, our system contains an independent\nfeaturization module, which can be interchanged with any preferred image\nclassification tool.\n  Our initial findings demonstrate that while satellite imagery can be used to\npredict housing prices with considerable accuracy, the size and nature of the\nground truth sample is a fundamental determinant of the usefulness of imagery\nfor this category of socioeconomic prediction. We quantify the returns to\nimproving the distribution and size of observed data, and show that the image\nclassification method is a second-order concern. Our results provide clear\nguidance for the development of adaptive sampling strategies in data-sparse\nlocations where satellite-based metrics may be integrated with standard survey\ndata, while also suggesting that advances from image classification techniques\nfor satellite imagery could be further augmented by more robust sampling\nstrategies.", "journal": "", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY"], "pdf_url": "http://arxiv.org/pdf/1710.09342v2"}
{"entry_id": "http://arxiv.org/abs/2011.06880v1", "date": "2020-11-13", "title": "Deriving CME density from remote sensing data and comparison to in-situ measurements", "authors": "M. Temmer, L. Holzknecht, M. Dumbovic, B. Vrsnak, N. Sachdeva, S. G. Heinemann, K. Dissauer, C. Scolini, E. Asvestari, A. M. Veronig, S. J. Hofmeister", "abstract": "We determine the 3D geometry and deprojected mass of 29 well-observed coronal\nmass ejections (CMEs) and their interplanetary counterparts (ICMEs) using\ncombined STEREO-SOHO white-light data. From the geometry parameters we\ncalculate the volume of the CME for the magnetic ejecta (flux-rope type\ngeometry) and sheath structure (shell-like geometry resembling the (I)CME\nfrontal rim). Working under the assumption that the CME mass is roughly equally\ndistributed within a specific volume, we expand the CME self-similarly and\ncalculate the CME density for distances close to the Sun (15-30 Rs) and at 1AU.\nSpecific trends are derived comparing calculated and in-situ measured proton\ndensities at 1AU, though large uncertainties are revealed due to the unknown\nmass and geometry evolution: i) a moderate correlation for the magnetic\nstructure having a mass that stays rather constant (~0.56-0.59), and ii) a weak\ncorrelation for the sheath density (~0.26) by assuming the sheath region is an\nextra mass - as expected for a mass pile-up process - that is in its amount\ncomparable to the initial CME deprojected mass. High correlations are derived\nbetween in-situ measured sheath density and the solar wind density (~ -0.73)\nand solar wind speed (~0.56) as measured 24 hours ahead of the arrival of the\ndisturbance. This gives additional confirmation that the sheath-plasma indeed\nstems from piled-up solar wind material. While the CME interplanetary\npropagation speed is not related to the sheath density, the size of the CME may\nplay some role in how much material could be piled up.", "journal": "", "doi": "10.1029/2020JA028380", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2011.06880v1"}
{"entry_id": "http://arxiv.org/abs/1801.06714v1", "date": "2018-01-20", "title": "Life Beyond the Solar System: Remotely Detectable Biosignatures", "authors": "Shawn Domagal-Goldman, Nancy Y. Kiang, Niki Parenteau, David C. Catling, Shiladitya DasSarma, Yuka Fujii, Chester E. Harman, Adrian Lenardic, Enric Pall\u00e9, Christopher T. Reinhard, Edward W. Schwieterman, Jean Schneider, Harrison B. Smith, Motohide Tamura, Daniel Angerhausen, Giada Arney, Vladimir S. Airapetian, Natalie M. Batalha, Charles S. Cockell, Leroy Cronin, Russell Deitrick, Anthony Del Genio, Theresa Fisher, Dawn M. Gelino, J. Lee Grenfell, Hilairy E. Hartnett, Siddharth Hegde, Yasunori Hori, Bet\u00fcl Ka\u00e7ar, Joshua Krissansen-Totten, Timothy Lyons, William B. Moore, Norio Narita, Stephanie L. Olson, Heike Rauer, Tyler D. Robinson, Sarah Rugheimer, Nick Siegler, Evgenya L. Shkolnik, Karl R. Stapelfeldt, Sara Walker", "abstract": "For the first time in human history, we will soon be able to apply the\nscientific method to the question \"Are We Alone?\" The rapid advance of\nexoplanet discovery, planetary systems science, and telescope technology will\nsoon allow scientists to search for life beyond our Solar System through direct\nobservation of extrasolar planets. This endeavor will occur alongside searches\nfor habitable environments and signs of life within our Solar System. While the\nsearches are thematically related and will inform each other, they will require\nseparate observational techniques. The search for life on exoplanets holds\npotential through the great diversity of worlds to be explored beyond our Solar\nSystem. However, there are also unique challenges related to the relatively\nlimited data this search will obtain on any individual world. This white paper\nreviews the scientific community's ability to use data from future telescopes\nto search for life on exoplanets. This material summarizes products from the\nExoplanet Biosignatures Workshop Without Walls (EBWWW). The EBWWW was\nconstituted by a series of online and in person activities, with participation\nfrom the international exoplanet and astrobiology communities, to assess state\nof the science and future research needs for the remote detection of life on\nplanets outside our Solar System.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1801.06714v1"}
{"entry_id": "http://arxiv.org/abs/1604.08680v1", "date": "2016-04-29", "title": "Infinite Horizon Optimal Transmission Power Control for Remote State Estimation over Fading Channels", "authors": "Xiaoqiang Ren, Junfeng Wu, Karl H. Johansson, Guodong Shi, Ling Shi", "abstract": "Jointly optimal transmission power control and remote estimation over an\ninfinite horizon is studied. A sensor observes a dynamic process and sends its\nobservations to a remote estimator over a wireless fading channel characterized\nby a time-homogeneous Markov chain. The successful transmission probability\ndepends on both the channel gains and the transmission power used by the\nsensor. The transmission power control rule and the remote estimator should be\njointly designed, aiming to minimize an infinite-horizon cost consisting of the\npower usage and the remote estimation error. A first question one may ask is:\nDoes this joint optimization problem have a solution? We formulate the joint\noptimization problem as an average cost belief-state Markov decision process\nand answer the question by proving that there exists an optimal deterministic\nand stationary policy. We then show that when the monitored dynamic process is\nscalar, the optimal remote estimates depend only on the most recently received\nsensor observation, and the optimal transmission power is symmetric and\nmonotonically increasing with respect to the innovation error.", "journal": "", "doi": null, "primary_category": "cs.SY", "categories": ["cs.SY"], "pdf_url": "http://arxiv.org/pdf/1604.08680v1"}
{"entry_id": "http://arxiv.org/abs/0707.2685v1", "date": "2007-07-18", "title": "The surface brightness profile of the remote cluster NGC 2419", "authors": "Michele Bellazzini", "abstract": "It is well known that the bright and remote Galactic globular cluster NGC2419\nhas a very peculiar structure. In particular its half-light radius is\nsignificantly larger than that of ordinary globular clusters of similar\nluminosity, being as large as that of the brightest nuclei of dwarf elliptical\ngalaxies. In this context it is particularly worth to check the reliability of\nthe existing surface brightness profiles for this cluster and of the available\nestimates of its structural parameters. Combining different datasets I derive\nthe surface brightness profile going from the cluster center out to ~ 480\narcsec, i.e. ~25 core radii. (Abridged). The newly obtained surface brightness\nprofile is in excellent agreement with that provided by Trager, King &\nDjorgovski for r>= 4 arcsec; it is best fitted by a King model having r_c=0.32\narcmin, mu_V(0)=19.55 and C=1.35. Also new independent estimates of the total\nintegrated V magnitude (V_t=10.47 +/- 0.07) and of the half-light radius\n(r_h=0.96 arcmin +/- 0.2 arcmin) have been obtained. (Abridged). The structure\nof NGC2419 is now reliably constrained by (at least) two fully independent\nobservational profiles that are in good agreement one with the other. Also the\noverall agreement between structural parameters independently obtained by\ndifferent authors is quite satisfying.", "journal": "", "doi": "10.1051/0004-6361:20078130", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0707.2685v1"}
{"entry_id": "http://arxiv.org/abs/2206.04399v1", "date": "2022-06-09", "title": "Depression Recognition using Remote Photoplethysmography from Facial Videos", "authors": "Constantino \u00c1lvarez Casado, Manuel Lage Ca\u00f1ellas, Miguel Bordallo L\u00f3pez", "abstract": "Depression is a mental illness that may be harmful to an individual's health.\nThe detection of mental health disorders in the early stages and a precise\ndiagnosis are critical to avoid social, physiological, or psychological side\neffects. This work analyzes physiological signals to observe if different\ndepressive states have a noticeable impact on the blood volume pulse (BVP) and\nthe heart rate variability (HRV) response. Although typically, HRV features are\ncalculated from biosignals obtained with contact-based sensors such as\nwearables, we propose instead a novel scheme that directly extracts them from\nfacial videos, just based on visual information, removing the need for any\ncontact-based device. Our solution is based on a pipeline that is able to\nextract complete remote photoplethysmography signals (rPPG) in a fully\nunsupervised manner. We use these rPPG signals to calculate over 60\nstatistical, geometrical, and physiological features that are further used to\ntrain several machine learning regressors to recognize different levels of\ndepression. Experiments on two benchmark datasets indicate that this approach\noffers comparable results to other audiovisual modalities based on voice or\nfacial expression, potentially complementing them. In addition, the results\nachieved for the proposed method show promising and solid performance that\noutperforms hand-engineered methods and is comparable to deep learning-based\napproaches.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.ET", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2206.04399v1"}
{"entry_id": "http://arxiv.org/abs/2211.15323v1", "date": "2022-11-28", "title": "Security Analysis of the Consumer Remote SIM Provisioning Protocol", "authors": "Abu Shohel Ahmed, Aleksi Peltonen, Mohit Sethi, Tuomas Aura", "abstract": "Remote SIM provisioning (RSP) for consumer devices is the protocol specified\nby the GSM Association for downloading SIM profiles into a secure element in a\nmobile device. The process is commonly known as eSIM, and it is expected to\nreplace removable SIM cards. The security of the protocol is critical because\nthe profile includes the credentials with which the mobile device will\nauthenticate to the mobile network. In this paper, we present a formal security\nanalysis of the consumer RSP protocol. We model the multi-party protocol in\napplied pi calculus, define formal security goals, and verify them in ProVerif.\nThe analysis shows that the consumer RSP protocol protects against a network\nadversary when all the intended participants are honest. However, we also model\nthe protocol in realistic partial compromise scenarios where the adversary\ncontrols a legitimate participant or communication channel. The security\nfailures in the partial compromise scenarios reveal weaknesses in the protocol\ndesign. The most important observation is that the security of RSP depends\nunnecessarily on it being encapsulated in a TLS tunnel. Also, the lack of\npre-established identifiers means that a compromised download server anywhere\nin the world or a compromised secure element can be used for attacks against\nRSP between honest participants. Additionally, the lack of reliable methods for\nverifying user intent can lead to serious security failures. Based on the\nfindings, we recommend practical improvements to RSP implementations, to future\nversions of the specification, and to mobile operator processes to increase the\nrobustness of eSIM security.", "journal": "", "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR"], "pdf_url": "http://arxiv.org/pdf/2211.15323v1"}
{"entry_id": "http://arxiv.org/abs/1005.4465v2", "date": "2010-05-25", "title": "Geo-neutrinos and Silicate Earth Enrichment of U and Th", "authors": "Steve Dye", "abstract": "The terrestrial distribution of U, Th, and K abundances governs the thermal\nevolution, traces the differentiation, and reflects the bulk composition of the\nearth. Comparing the bulk earth composition to chondritic meteorites estimates\nthe net amounts of these radiogenic heat-producing elements available for\npartitioning to the crust, mantle, and core. Core formation enriches the\nabundances of refractory lithophile elements, including U and Th, in the\nsilicate earth by ~1.5. Global removal of volatile elements potentially\nincreases this enrichment to ~2.8. The K content of the silicate earth follows\nfrom the ratio of K to U. Variable enrichment produces a range of possible\nheat-producing element abundances in the silicate earth. A model assesses the\nessentially fixed amounts of U, Th, and K in the approximately closed crust\nreservoir. Subtracting these sequestered crustal amounts from the variable\namounts in the silicate earth results in a range of possible mantle\nallocations, leaving global dynamics and thermal evolution poorly constrained.\nTerrestrial antineutrinos from {\\beta}-emitting daughter nuclei in the U and Th\ndecay series traverse the earth with negligible attenuation. The rate at which\nlarge subsurface instruments observe these geo-neutrinos depends on the\ndistribution of U and Th relative to the detector. Geo-neutrino observations\nwith sensitivity to U and Th in the mantle are able to estimate silicate earth\nenrichment, leading to a more complete understanding of the origin, accretion,\ndifferentiation, and thermal history of the planet.", "journal": "Earth Planet.Sci.Lett.297:1-9, 2010", "doi": "10.1016/j.epsl.2010.06.012", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "nucl-ex"], "pdf_url": "http://arxiv.org/pdf/1005.4465v2"}
{"entry_id": "http://arxiv.org/abs/2208.02987v1", "date": "2022-08-05", "title": "MIX-RS: A Multi-indexing System based on HDFS for Remote Sensing Data Storage", "authors": "Jiashu Wu, Jingpan Xiong, Hao Dai, Yang Wang, Chengzhong Xu", "abstract": "A large volume of remote sensing (RS) data has been generated with the\ndeployment of satellite technologies. The data facilitates research in\necological monitoring, land management and desertification, etc. The\ncharacteristics of RS data (e.g., enormous volume, large single-file size and\ndemanding requirement of fault tolerance) make the Hadoop Distributed File\nSystem (HDFS) an ideal choice for RS data storage as it is efficient, scalable\nand equipped with a data replication mechanism for failure resilience. To use\nRS data, one of the most important techniques is geospatial indexing. However,\nthe large data volume makes it time-consuming to efficiently construct and\nleverage. Considering that most modern geospatial data centres are equipped\nwith HDFS-based big data processing infrastructures, deploying multiple\ngeospatial indices becomes natural to optimise the efficacy. Moreover, because\nof the reliability introduced by high-quality hardware and the infrequently\nmodified property of the RS data, the use of multi-indexing will not cause\nlarge overhead. Therefore, we design a framework called Multi-IndeXing-RS\n(MIX-RS) that unifies the multi-indexing mechanism on top of the HDFS with data\nreplication enabled for both fault tolerance and geospatial indexing\nefficiency. Given the fault tolerance provided by the HDFS, RS data is\nstructurally stored inside for faster geospatial indexing. Additionally,\nmulti-indexing enhances efficiency. The proposed technique naturally sits on\ntop of the HDFS to form a holistic framework without incurring severe overhead\nor sophisticated system implementation efforts. The MIX-RS framework is\nimplemented and evaluated using real remote sensing data provided by the\nChinese Academy of Sciences, demonstrating excellent geospatial indexing\nperformance.", "journal": "", "doi": "10.26599/TST.2021.9010082", "primary_category": "cs.DB", "categories": ["cs.DB", "cs.CY"], "pdf_url": "http://arxiv.org/pdf/2208.02987v1"}
{"entry_id": "http://arxiv.org/abs/2301.05526v1", "date": "2023-01-13", "title": "Self-Training Guided Disentangled Adaptation for Cross-Domain Remote Sensing Image Semantic Segmentation", "authors": "Qi Zhao, Shuchang Lyu, Binghao Liu, Lijiang Chen, Hongbo Zhao", "abstract": "Deep convolutional neural networks (DCNNs) based remote sensing (RS) image\nsemantic segmentation technology has achieved great success used in many\nreal-world applications such as geographic element analysis. However, strong\ndependency on annotated data of specific scene makes it hard for DCNNs to fit\ndifferent RS scenes. To solve this problem, recent works gradually focus on\ncross-domain RS image semantic segmentation task. In this task, different\nground sampling distance, remote sensing sensor variation and different\ngeographical landscapes are three main factors causing dramatic domain shift\nbetween source and target images. To decrease the negative influence of domain\nshift, we propose a self-training guided disentangled adaptation network\n(ST-DASegNet). We first propose source student backbone and target student\nbackbone to respectively extract the source-style and target-style feature for\nboth source and target images. Towards the intermediate output feature maps of\neach backbone, we adopt adversarial learning for alignment. Then, we propose a\ndomain disentangled module to extract the universal feature and purify the\ndistinct feature of source-style and target-style features. Finally, these two\nfeatures are fused and served as input of source student decoder and target\nstudent decoder to generate final predictions. Based on our proposed domain\ndisentangled module, we further propose exponential moving average (EMA) based\ncross-domain separated self-training mechanism to ease the instability and\ndisadvantageous effect during adversarial optimization. Extensive experiments\nand analysis on benchmark RS datasets show that ST-DASegNet outperforms\nprevious methods on cross-domain RS image semantic segmentation task and\nachieves state-of-the-art (SOTA) results. Our code is available at\nhttps://github.com/cv516Buaa/ST-DASegNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.05526v1"}
{"entry_id": "http://arxiv.org/abs/2106.00506v1", "date": "2021-06-01", "title": "A Novel Graph-Theoretic Deep Representation Learning Method for Multi-Label Remote Sensing Image Retrieval", "authors": "Gencer Sumbul, Beg\u00fcm Demir", "abstract": "This paper presents a novel graph-theoretic deep representation learning\nmethod in the framework of multi-label remote sensing (RS) image retrieval\nproblems. The proposed method aims to extract and exploit multi-label\nco-occurrence relationships associated to each RS image in the archive. To this\nend, each training image is initially represented with a graph structure that\nprovides region-based image representation combining both local information and\nthe related spatial organization. Unlike the other graph-based methods, the\nproposed method contains a novel learning strategy to train a deep neural\nnetwork for automatically predicting a graph structure of each RS image in the\narchive. This strategy employs a region representation learning loss function\nto characterize the image content based on its multi-label co-occurrence\nrelationship. Experimental results show the effectiveness of the proposed\nmethod for retrieval problems in RS compared to state-of-the-art deep\nrepresentation learning methods. The code of the proposed method is publicly\navailable at https://git.tu-berlin.de/rsim/GT-DRL-CBIR .", "journal": "", "doi": "10.1109/IGARSS47720.2021.9554466", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2106.00506v1"}
{"entry_id": "http://arxiv.org/abs/2204.01439v1", "date": "2022-03-29", "title": "IoT with a Soft Touch: A Modular Remote Sensing Platform for STE(A)M Applications", "authors": "Jona Cappelle, Geoffrey Ottoy, Sarah Goossens, Hanne Deprez, Jarne Van Mulders, Guus Leenders, Gilles Callebaut", "abstract": "Besides wide attraction in the industry, IoT is being used to advance STEM\nand STEAM education across a range of education levels. This work presents a\nremote sensing platform, named IoT with a Soft Touch, developed to achieve two\ngoals. First, it aims to lower the technicality, stimulating the students to do\nSTE(A)M. Second, the technology is to be used in `softer' applications (e.g.,\nenvironmental and health care), thereby aiming to attract a more diverse set of\nstudent profiles. Students can easily build a wireless sensing device, with a\nspecific application in mind. The modular design of the platform and an\nintuitive graphical configurator tool allows them to tailor the device's\nfunctionality to their needs. The sensor's data is transmitted wirelessly with\nLoRaWAN. The data can be viewed and analyzed on a dashboard, or the raw data\ncan be extracted for further processing, e.g., as part of the school's STE(A)M\ncurriculum. This work elaborates on the low-power and modular design\nchallenges, and how the platform is used in education.", "journal": "", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY", "cs.NI"], "pdf_url": "http://arxiv.org/pdf/2204.01439v1"}
{"entry_id": "http://arxiv.org/abs/1902.05859v2", "date": "2019-02-15", "title": "Circular spectropolarimetric sensing of vegetation in the field; possibilities for the remote detection of extraterrestrial life", "authors": "C. H. Lucas Patty, Inge Loes ten Kate, Wybren Jan Buma, Rob J. M. van Spanning, G\u00e1bor Steinbach, Freek Ariese, Frans Snik", "abstract": "Homochirality is a generic and unique property of all biochemical life and\nthe fractional circular polarization of light it induces therefore constitutes\na potentially unambiguous biosignature.} However, while high-quality circular\npolarimetric spectra can be easily and quickly obtained in the laboratory,\naccurate measurements in the field are much more challenging due to large\nchanges in illumination and target movement. In this study we have measured\nvarious targets in the field, up to distances of a few kilometers, using the\ndedicated circular spectropolarimeter TreePol. We show how photosynthetic life\ncan readily be distinguished from abiotic matter. We underline the potential of\ncircular polarization signals as a remotely accessible means to characterize\nand monitor terrestrial vegetation, e.g. for agriculture and forestry.\nAdditionally, we discuss the potential of circular polarization for the remote\ndetection of extraterrestrial life.", "journal": "", "doi": "10.1089/ast.2019.2050", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.bio-ph", "q-bio.BM"], "pdf_url": "http://arxiv.org/pdf/1902.05859v2"}
{"entry_id": "http://arxiv.org/abs/2204.11978v1", "date": "2022-04-25", "title": "Remote laser-speckle sensing of heart sounds for health assessment and biometric identification", "authors": "Lucrezia Cester, Ilya Starshynov, Yola Jones, Pierpaolo Pellicori, John GF Cleland, Daniele Faccio", "abstract": "Assessment of heart sounds is the cornerstone of cardiac examination, but it\nrequires a stethoscope, skills and experience, and a direct contact with the\npatient. We developed a contactless, machine-learning assisted method for\nheart-sound identification and quantification based on the remote measurement\nof the reflected laser speckle from the neck skin surface in healthy\nindividuals. We compare the performance of this method to standard digital\nstethoscope recordings on an example task of heart-beat sound biometric\nidentification. We show that our method outperforms the stethoscope even\nallowing identification on the test data taken on different days. This method\nmight allow development of devices for remote monitoring of cardiovascular\nhealth in different settings.", "journal": "", "doi": null, "primary_category": "physics.med-ph", "categories": ["physics.med-ph"], "pdf_url": "http://arxiv.org/pdf/2204.11978v1"}
{"entry_id": "http://arxiv.org/abs/1110.5458v1", "date": "2011-10-25", "title": "Superconductivity in alkali-earth metals doped phenanthrene", "authors": "X. F. Wang, Y. J. Yan, Z. Gui, R. H. Liu, J. J. Ying, X. G. Luo, X. H. Chen", "abstract": "We discover superconductivity in alkali-earth metals doped phenanthrene. The\nsuperconducting critical temperatures \\emph{T}$_c$ are 5.6 K and 5.4 K for\nSr$_{1.5}$phenanthrene and Ba$_{1.5}$phenanthrene, respectively. The shielding\nfraction of Ba$_{1.5}$phenanthrene exceeds 65%. The Raman spectra show 8\ncm$^{-1}$/electron and 7 cm$^{-1}$/electron downshifts for the mode at 1441\ncm$^{-1}$ due to the charge transfer to organic molecules from the dopants of\nBa and Sr. Similar behavior has been observed in A$_3$phenanthrene and\nA$_3$C$_{60}$(A = K and Rb). The positive pressure effect in\nSr$_{1.5}$phenanthrene and Ba$_{1.5}$phenanthrene together with the lower $T_c$\nwith larger lattice indicates unconventional superconductivity in this organic\nsystem.", "journal": "Phys. Rev. B 84, 214523 (2011)", "doi": "10.1103/PhysRevB.84.214523", "primary_category": "cond-mat.supr-con", "categories": ["cond-mat.supr-con"], "pdf_url": "http://arxiv.org/pdf/1110.5458v1"}
{"entry_id": "http://arxiv.org/abs/2002.03729v2", "date": "2020-01-16", "title": "Renet: An improvement method for remote object detection based on Darknet", "authors": "Shengquan Wang, Ang Li", "abstract": "Recently, when we used this method to identify aircraft targets in remote\nsensing images, we found that there are some defects in our own YOLOv2 and\nDarknet-19 network. Characteristic in the images we identified are not very\nclear,thats why we couldn't get some much more good results. Then we replaced\nthe maxpooling in the yolov3 network as the global maxpooling.Under the same\ntest conditions, we got a higher It achieves the processing speed of a single\nimage is only 0.023 s on a GTX1050TI.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2002.03729v2"}
{"entry_id": "http://arxiv.org/abs/1904.00592v3", "date": "2019-04-01", "title": "ResUNet-a: a deep learning framework for semantic segmentation of remotely sensed data", "authors": "Foivos I. Diakogiannis, Fran\u00e7ois Waldner, Peter Caccetta, Chen Wu", "abstract": "Scene understanding of high resolution aerial images is of great importance\nfor the task of automated monitoring in various remote sensing applications.\nDue to the large within-class and small between-class variance in pixel values\nof objects of interest, this remains a challenging task. In recent years, deep\nconvolutional neural networks have started being used in remote sensing\napplications and demonstrate state of the art performance for pixel level\nclassification of objects. \\textcolor{black}{Here we propose a reliable\nframework for performant results for the task of semantic segmentation of\nmonotemporal very high resolution aerial images. Our framework consists of a\nnovel deep learning architecture, ResUNet-a, and a novel loss function based on\nthe Dice loss. ResUNet-a uses a UNet encoder/decoder backbone, in combination\nwith residual connections, atrous convolutions, pyramid scene parsing pooling\nand multi-tasking inference. ResUNet-a infers sequentially the boundary of the\nobjects, the distance transform of the segmentation mask, the segmentation mask\nand a colored reconstruction of the input. Each of the tasks is conditioned on\nthe inference of the previous ones, thus establishing a conditioned\nrelationship between the various tasks, as this is described through the\narchitecture's computation graph. We analyse the performance of several\nflavours of the Generalized Dice loss for semantic segmentation, and we\nintroduce a novel variant loss function for semantic segmentation of objects\nthat has excellent convergence properties and behaves well even under the\npresence of highly imbalanced classes.} The performance of our modeling\nframework is evaluated on the ISPRS 2D Potsdam dataset. Results show\nstate-of-the-art performance with an average F1 score of 92.9\\% over all\nclasses for our best model.", "journal": "", "doi": "10.1016/j.isprsjprs.2020.01.013", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1904.00592v3"}
{"entry_id": "http://arxiv.org/abs/2201.07030v2", "date": "2022-01-18", "title": "Cooperative Multi-UAV Coverage Mission Planning Platform for Remote Sensing Applications", "authors": "Savvas D. Apostolidis, Pavlos Ch. Kapoutsis, Athanasios Ch. Kapoutsis, Elias B. Kosmatopoulos", "abstract": "This paper proposes a novel mission planning platform, capable of efficiently\ndeploying a team of UAVs to cover complex-shaped areas, in various remote\nsensing applications. Under the hood lies a novel optimization scheme for\ngrid-based methods, utilizing Simulated Annealing algorithm, that significantly\nincreases the achieved percentage of coverage and improves the qualitative\nfeatures of the generated paths. Extensive simulated evaluation in comparison\nwith a state-of-the-art alternative methodology, for coverage path planning\n(CPP) operations, establishes the performance gains in terms of achieved\ncoverage and overall duration of the generated missions. On top of that, DARP\nalgorithm is employed to allocate sub-tasks to each member of the swarm, taking\ninto account each UAV's sensing and operational capabilities, their initial\npositions and any no-fly-zones possibly defined inside the operational area.\nThis feature is of paramount importance in real-life applications, as it has\nthe potential to achieve tremendous performance improvements in terms of time\ndemanded to complete a mission, while at the same time it unlocks a wide new\nrange of applications, that was previously not feasible due to the limited\nbattery life of UAVs. In order to investigate the actual efficiency gains that\nare introduced by the multi-UAV utilization, a simulated study is performed as\nwell. All of these capabilities are packed inside an end-to-end platform that\neases the utilization of UAVs' swarms in remote sensing applications. Its\nversatility is demonstrated via two different real-life applications: (i) a\nphotogrametry for precision agriculture and (ii) an indicative search and\nrescue for first responders missions, that were performed utilizing a swarm of\ncommercial UAVs. The source code can be found at:\nhttps://github.com/savvas-ap/mCPP-optimized-DARP", "journal": "Autonomous Robots, 1-28 (2022)", "doi": "10.1007/s10514-021-10028-3", "primary_category": "cs.RO", "categories": ["cs.RO"], "pdf_url": "http://arxiv.org/pdf/2201.07030v2"}
{"entry_id": "http://arxiv.org/abs/2204.09860v1", "date": "2022-04-21", "title": "Remote Sensing Cross-Modal Text-Image Retrieval Based on Global and Local Information", "authors": "Zhiqiang Yuan, Wenkai Zhang, Changyuan Tian, Xuee Rong, Zhengyuan Zhang, Hongqi Wang, Kun Fu, Xian Sun", "abstract": "Cross-modal remote sensing text-image retrieval (RSCTIR) has recently become\nan urgent research hotspot due to its ability of enabling fast and flexible\ninformation extraction on remote sensing (RS) images. However, current RSCTIR\nmethods mainly focus on global features of RS images, which leads to the\nneglect of local features that reflect target relationships and saliency. In\nthis article, we first propose a novel RSCTIR framework based on global and\nlocal information (GaLR), and design a multi-level information dynamic fusion\n(MIDF) module to efficaciously integrate features of different levels. MIDF\nleverages local information to correct global information, utilizes global\ninformation to supplement local information, and uses the dynamic addition of\nthe two to generate prominent visual representation. To alleviate the pressure\nof the redundant targets on the graph convolution network (GCN) and to improve\nthe model s attention on salient instances during modeling local features, the\nde-noised representation matrix and the enhanced adjacency matrix (DREA) are\ndevised to assist GCN in producing superior local representations. DREA not\nonly filters out redundant features with high similarity, but also obtains more\npowerful local features by enhancing the features of prominent objects.\nFinally, to make full use of the information in the similarity matrix during\ninference, we come up with a plug-and-play multivariate rerank (MR) algorithm.\nThe algorithm utilizes the k nearest neighbors of the retrieval results to\nperform a reverse search, and improves the performance by combining multiple\ncomponents of bidirectional retrieval. Extensive experiments on public datasets\nstrongly demonstrate the state-of-the-art performance of GaLR methods on the\nRSCTIR task. The code of GaLR method, MR algorithm, and corresponding files\nhave been made available at https://github.com/xiaoyuan1996/GaLR .", "journal": "in IEEE Transactions on Geoscience and Remote Sensing, vol. 60,\n  pp. 1-16, 2022, Art no. 5620616", "doi": "10.1109/TGRS.2022.3163706", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.IR", "cs.MM"], "pdf_url": "http://arxiv.org/pdf/2204.09860v1"}
{"entry_id": "http://arxiv.org/abs/0910.4750v2", "date": "2009-10-25", "title": "Investigation of particle and molecular extinction effects in remote sensing by ultraviolet DIAL in the lower atmosphere", "authors": "Gholamreza Shayeganrad, Leila Mashhadi, Davood Momeni", "abstract": "This study presents theoretical investigation of the effects of particle and\nmolecular extinction in horizontal remote sensing near the ground for several\nvisibilities at UV wavelengths by neglecting the spatial inhomogeneity of\naerosol in the atmosphere and taking into account the dependence of refracting\non air temperature and pressure. Due to weak attenuation of oxygen and other\ngaseous atmospheric constituents in this region, we have only considered the\neffect of ozone in calculation. The results are important to estimate\nsystematic errors in measuring gas concentration introduced by large wavelength\nseparation in UV-DIAL. The total attenuation (km-1) at wavelengths is listed in\nthe form of a table from 200 to 400 nm for several values of visibilities. It\nis found the aerosol attenuation in UV region varies quite smoothly with\nwavelength and therefore systematic error caused by aerosol scattering is\nnegligible in remote sensing by UV-DIAL even with large wavelength separation.\nMoreover, it has been found that only aerosol extinction is dominant in lidar\nremote sensing in the lower atmosphere in UV region. In large altitude that\naerosol concentration is lower; the molecular scattering is important\nespecially for wavelengths larger than 310 nm.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/0910.4750v2"}
{"entry_id": "http://arxiv.org/abs/1903.07224v1", "date": "2019-03-18", "title": "An End-to-End Joint Unsupervised Learning of Deep Model and Pseudo-Classes for Remote Sensing Scene Representation", "authors": "Zhiqiang Gong, Ping Zhong, Weidong Hu, Fang Liu, Bingwei Hui", "abstract": "This work develops a novel end-to-end deep unsupervised learning method based\non convolutional neural network (CNN) with pseudo-classes for remote sensing\nscene representation. First, we introduce center points as the centers of the\npseudo classes and the training samples can be allocated with pseudo labels\nbased on the center points. Therefore, the CNN model, which is used to extract\nfeatures from the scenes, can be trained supervised with the pseudo labels.\nMoreover, a pseudo-center loss is developed to decrease the variance between\nthe samples and the corresponding pseudo center point. The pseudo-center loss\nis important since it can update both the center points with the training\nsamples and the CNN model with the center points in the training process\nsimultaneously. Finally, joint learning of the pseudo-center loss and the\npseudo softmax loss which is formulated with the samples and the pseudo labels\nis developed for unsupervised remote sensing scene representation to obtain\ndiscriminative representations from the scenes. Experiments are conducted over\ntwo commonly used remote sensing scene datasets to validate the effectiveness\nof the proposed method and the experimental results show the superiority of the\nproposed method when compared with other state-of-the-art methods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1903.07224v1"}
{"entry_id": "http://arxiv.org/abs/2012.03597v3", "date": "2020-12-07", "title": "PSGCNet: A Pyramidal Scale and Global Context Guided Network for Dense Object Counting in Remote Sensing Images", "authors": "Guangshuai Gao, Qingjie Liu, Zhenghui Hu, Lu Li, Qi Wen, Yunhong Wang", "abstract": "Object counting, which aims to count the accurate number of object instances\nin images, has been attracting more and more attention. However, challenges\nsuch as large scale variation, complex background interference, and non-uniform\ndensity distribution greatly limit the counting accuracy, particularly striking\nin remote sensing imagery. To mitigate the above issues, this paper proposes a\nnovel framework for dense object counting in remote sensing images, which\nincorporates a pyramidal scale module (PSM) and a global context module (GCM),\ndubbed PSGCNet, where PSM is used to adaptively capture multi-scale information\nand GCM is to guide the model to select suitable scales generated from PSM.\nMoreover, a reliable supervision manner improved from Bayesian and Counting\nloss (BCL) is utilized to learn the density probability and then compute the\ncount expectation at each annotation. It can relieve non-uniform density\ndistribution to a certain extent. Extensive experiments on four remote sensing\ncounting datasets demonstrate the effectiveness of the proposed method and the\nsuperiority of it compared with state-of-the-arts. Additionally, experiments\nextended on four commonly used crowd counting datasets further validate the\ngeneralization ability of the model. Code is available at\nhttps://github.com/gaoguangshuai/PSGCNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2012.03597v3"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0605282v1", "date": "2006-05-11", "title": "X-Ray Emission from Jupiter, Saturn, and Earth: A Short Review", "authors": "Anil Bhardwaj", "abstract": "Jupiter, Saturn, and Earth - the three planets having dense atmosphere and a\nwell developed magnetosphere - are known to emit X-rays. Recently, Chandra\nX-ray Observatory has observed X-rays from these planets, and XMM-Newton has\nobserved them from Jupiter and Saturn. These observations have provided\nimproved morphological, temporal, and spectral characteristics of X-rays from\nthese planets. Both auroral and non-auroral (low-latitude) 'disk' X-ray\nemissions have been observed on Earth and Jupiter. X-rays have been detected\nfrom Saturn's disk, but no convincing evidence for X-ray aurora on Saturn has\nbeen observed. The non-auroral disk X-ray emissions from Jupiter, Saturn, and\nEarth, are mostly produced due to scattering of solar X-rays. X-ray aurora on\nEarth is mainly generated via bremsstrahlung from precipitating electrons and\non Jupiter via charge exchange of highlyionized energetic heavy ions\nprecipitating into the polar atmosphere. Recent unpublished work suggests that\nat higher (>2 keV) energies electron bremsstrahlung also plays a role in\nJupiter's X-ray aurora. This paper summarizes the recent results of X-ray\nobservations on Jupiter, Saturn, and Earth mainly in the soft energy (~0.1-2.0\nkeV) band and provides a comparative overview.", "journal": "", "doi": "10.1142/9789812707192_0021", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0605282v1"}
{"entry_id": "http://arxiv.org/abs/2207.13700v1", "date": "2022-07-26", "title": "Remote Medication Status Prediction for Individuals with Parkinson's Disease using Time-series Data from Smartphones", "authors": "Weijian Li, Wei Zhu, Ray Dorsey, Jiebo Luo", "abstract": "Medication for neurological diseases such as the Parkinson's disease usually\nhappens remotely at home, away from hospitals. Such out-of-lab environments\npose challenges in collecting timely and accurate health status data using the\nlimited professional care devices for health condition analysis, medication\nadherence measurement and future dose or treatment planning. Individual\ndifferences in behavioral signals collected from wearable sensors also lead to\ndifficulties in adopting current general machine learning analysis pipelines.\nTo address these challenges, we present a method for predicting medication\nstatus of Parkinson's disease patients using the public mPower dataset, which\ncontains 62,182 remote multi-modal test records collected on smartphones from\n487 patients. The proposed method shows promising results in predicting three\nmedication status objectively: Before Medication (AUC=0.95), After Medication\n(AUC=0.958), and Another Time (AUC=0.976) by examining patient-wise historical\nrecords with the attention weights learned through a Transformer model. We\nbelieve our method provides an innovative way for personalized remote health\nsensing in a timely and objective fashion which could benefit a broad range of\nsimilar applications.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2207.13700v1"}
{"entry_id": "http://arxiv.org/abs/2007.15624v1", "date": "2020-07-30", "title": "Colors of an Earth-like exoplanet -- Temporal flux and polarization signals of the Earth", "authors": "A. Groot, L. Rossi, V. J. H. Trees, J. C. Y. Cheung, D. M. Stam", "abstract": "Understanding the total flux and polarization signals of Earth-like planets\nand their spectral and temporal variability is essential for the future\ncharacterization of such exoplanets. We provide computed total (F) and linearly\n(Q and U) and circularly (V) polarized fluxes, and the degree of polarization P\nof sunlight that is reflected by a model Earth, to be used for instrument\ndesigns, optimizing observational strategies, and/or developing retrieval\nalgorithms. We modeled a realistic Earth-like planet using one year of daily\nEarth-observation data: cloud parameters (distribution, optical thickness, top\npressure, and particle effective radius), and surface parameters (distribution,\nsurface type, and albedo). The Stokes vector of the disk-averaged reflected\nsunlight was computed for phase angles alpha from 0 to 180 degrees, and for\nwavelengths lambda from 350 to 865 nm. The total flux F is one order of\nmagnitude higher than the polarized flux Q, and Q is two and four orders of\nmagnitude higher than U and V, respectively. Without clouds, the peak-to-peak\ndaily variations due to the planetary rotation increase with increasing lambda\nfor F, Q, and P, while they decrease for U and V. Clouds modify but do not\ncompletely suppress the variations that are due to rotating surface features.\nWith clouds, the variation in F increases with increasing lambda, while in Q,\nit decreases with increasing lambda, except at the largest phase angles. In\nearlier work, it was shown that with oceans, Q changes color from blue through\nwhite to red. The alpha where the color changes increases with increasing cloud\ncoverage. Here, we show that this unique color change in Q also occurs when the\noceans are partly replaced by continents, with or without clouds. The degree of\npolarization P shows a similar color change. Our computed fluxes and degree of\npolarization will be made publicly available.", "journal": "", "doi": "10.1051/0004-6361/202037569", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2007.15624v1"}
{"entry_id": "http://arxiv.org/abs/1910.12060v2", "date": "2019-10-26", "title": "MAP-Net: Multi Attending Path Neural Network for Building Footprint Extraction from Remote Sensed Imagery", "authors": "Qing Zhu, Cheng Liao, Han Hu, Xiaoming Mei, Haifeng Li", "abstract": "Accurately and efficiently extracting building footprints from a wide range\nof remote sensed imagery remains a challenge due to their complex structure,\nvariety of scales and diverse appearances. Existing convolutional neural\nnetwork (CNN)-based building extraction methods are complained that they cannot\ndetect the tiny buildings because the spatial information of CNN feature maps\nare lost during repeated pooling operations of the CNN, and the large buildings\nstill have inaccurate segmentation edges. Moreover, features extracted by a CNN\nare always partial which restricted by the size of the respective field, and\nlarge-scale buildings with low texture are always discontinuous and holey when\nextracted. This paper proposes a novel multi attending path neural network\n(MAP-Net) for accurately extracting multiscale building footprints and precise\nboundaries. MAP-Net learns spatial localization-preserved multiscale features\nthrough a multi-parallel path in which each stage is gradually generated to\nextract high-level semantic features with fixed resolution. Then, an attention\nmodule adaptively squeezes channel-wise features from each path for\noptimization, and a pyramid spatial pooling module captures global dependency\nfor refining discontinuous building footprints. Experimental results show that\nMAP-Net outperforms state-of-the-art (SOTA) algorithms in boundary localization\naccuracy as well as continuity of large buildings. Specifically, our method\nachieved 0.68\\%, 1.74\\%, 1.46\\% precision, and 1.50\\%, 1.53\\%, 0.82\\% IoU score\nimprovement without increasing computational complexity compared with the\nlatest HRNetv2 on the Urban 3D, Deep Globe and WHU datasets, respectively. The\nTensorFlow implementation is available at https://github.com/lehaifeng/MAPNet.", "journal": "IEEE Transactions on Geoscience and Remote Sensing 2020 IEEE\n  Transactions on Geoscience and Remote Sensing 2020 IEEE Transactions on\n  Geoscience and Remote Sensing 2020", "doi": "10.1109/TGRS.2020.3026051", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1910.12060v2"}
{"entry_id": "http://arxiv.org/abs/0909.4093v1", "date": "2009-09-22", "title": "Earth, Moon, Sun, and CV Accretion Disks", "authors": "M. M. Montgomery", "abstract": "Net tidal torque by the secondary on a misaligned accretion disk, like the\nnet tidal torque by the Moon and the Sun on the equatorial bulge of the\nspinning and tilted Earth, is suggested by others to be a source to retrograde\nprecession in non-magnetic, accreting Cataclysmic Variable (CV) Dwarf Novae\nsystems that show negative superhumps in their light curves. We investigate\nthis idea in this work. We generate a generic theoretical expression for\nretrograde precession in spinning disks that are misaligned with the orbital\nplane. Our generic theoretical expression matches that which describes the\nretrograde precession of Earths' equinoxes. By making appropriate assumptions,\nwe reduce our generic theoretical expression to those generated by others, or\nto those used by others, to describe retrograde precession in protostellar,\nprotoplanetary, X-ray binary, non-magnetic CV DN, quasar and black hole\nsystems. We find that differential rotation and effects on the disk by the\naccretion stream must be addressed. Our analysis indicates that the best\ndescription of a retrogradely precessing spinning, tilted, CV DN accretion disk\nis a differentially rotating, tilted disk with an attached rotating, tilted\nring located near the innermost disk annuli. Our final, reduced expression for\nretrograde precession agrees well with our numerical simulation results and\nwith selective observational systems that seem to have main sequence\nsecondaries. Our results suggest that tidal torques should be common to a\nvariety of systems where one member is spinning and tilted, regardless if\naccretion disks are present or not. Our results suggest that the accretion\ndisk's geometric shape directly affects the disk's precession rate.", "journal": "Astrophys.J.705:603-616,2009", "doi": "10.1088/0004-637X/705/1/603", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/0909.4093v1"}
{"entry_id": "http://arxiv.org/abs/2205.09220v1", "date": "2022-05-18", "title": "A Case Study of Building Shared Understanding of Non-Functional Requirements in a Remote Software Organization", "authors": "Laura Okpara, Colin Werner, Adam Murray, Daniela Damian", "abstract": "Building a shared understanding of non-functional requirements (NFRs) is a\nknown but understudied challenge in requirements engineering, especially in\norganizations that adopt continuous software engineering (CSE) practices.\nDuring the peak of the COVID-19 pandemic, many CSE organizations complied with\nworking remotely due to the imposed health restrictions; some continued to work\nremotely while implementing business processes to facilitate team communication\nand productivity. In remote CSE organizations, managing NFRs becomes more\nchallenging due to the limitations to team communication coupled with the\nincentive to deliver products quickly. While previous research has identified\nthe factors that lead to a lack of shared understanding of NFRs in CSE, we\nstill have a significant gap in understanding how CSE organizations,\nparticularly in remote work, build a shared understanding of NFRs in their\nsoftware development. We conduct a three-month ethnography-informed case study\nof a remote CSE organization. Through thematic analysis of our qualitative data\nfrom interviews and observations, we identify a number of practices in\ndeveloping a shared understanding of NFRs. The collaborative workspace the\norganization uses for remote interaction is Gather, which simulates physical\nworkspaces, and which our findings suggest allows for informal communications\ninstrumental for building shared understanding. As actionable insights, we\ndiscuss our findings in light of proactive practices that represent\nopportunities for software organizations to invest in building a shared\nunderstanding of NFRs in their development.", "journal": "", "doi": null, "primary_category": "cs.SE", "categories": ["cs.SE"], "pdf_url": "http://arxiv.org/pdf/2205.09220v1"}
{"entry_id": "http://arxiv.org/abs/1304.3777v1", "date": "2013-04-13", "title": "On Sun-to-Earth Propagation of Coronal Mass Ejections", "authors": "Ying D. Liu, Janet G. Luhmann, No\u00e9 Lugaz, Christian M\u00f6stl, Jackie A. Davies, Stuart D. Bale, Robert P. Lin", "abstract": "We investigate how coronal mass ejections (CMEs) propagate through, and\ninteract with, the inner heliosphere between the Sun and Earth, a key question\nin CME research and space weather forecasting. CME Sun-to-Earth kinematics are\nconstrained by combining wide-angle heliospheric imaging observations,\ninterplanetary radio type II bursts and in situ measurements from multiple\nvantage points. We select three events for this study, the 2012 January 19, 23,\nand March 7 CMEs. Different from previous event studies, this work attempts to\ncreate a general picture for CME Sun-to-Earth propagation and compare different\ntechniques for determining CME interplanetary kinematics. Key results are\nobtained concerning CME Sun-to-Earth propagation. Our comparison between\ndifferent techniques (and data sets) also has important implications for CME\nobservations and their interpretations. Future CME observations and space\nweather forecasting are discussed based on these results. See detail in the\nPDF.", "journal": "", "doi": "10.1088/0004-637X/769/1/45", "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1304.3777v1"}
{"entry_id": "http://arxiv.org/abs/1802.08369v1", "date": "2018-02-23", "title": "Missing Data Reconstruction in Remote Sensing image with a Unified Spatial-Temporal-Spectral Deep Convolutional Neural Network", "authors": "Qiang Zhang, Qiangqiang Yuan, Chao Zeng, Xinghua Li, Yancong Wei", "abstract": "Because of the internal malfunction of satellite sensors and poor atmospheric\nconditions such as thick cloud, the acquired remote sensing data often suffer\nfrom missing information, i.e., the data usability is greatly reduced. In this\npaper, a novel method of missing information reconstruction in remote sensing\nimages is proposed. The unified spatial-temporal-spectral framework based on a\ndeep convolutional neural network (STS-CNN) employs a unified deep\nconvolutional neural network combined with spatial-temporal-spectral\nsupplementary information. In addition, to address the fact that most methods\ncan only deal with a single missing information reconstruction task, the\nproposed approach can solve three typical missing information reconstruction\ntasks: 1) dead lines in Aqua MODIS band 6; 2) the Landsat ETM+ Scan Line\nCorrector (SLC)-off problem; and 3) thick cloud removal. It should be noted\nthat the proposed model can use multi-source data (spatial, spectral, and\ntemporal) as the input of the unified framework. The results of both simulated\nand real-data experiments demonstrate that the proposed model exhibits high\neffectiveness in the three missing information reconstruction tasks listed\nabove.", "journal": "", "doi": "10.1109/TGRS.2018.2810208", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1802.08369v1"}
{"entry_id": "http://arxiv.org/abs/1409.4459v1", "date": "2014-09-15", "title": "Optimal Measures for Characterizing Water-rich Super-Earths", "authors": "Nikku Madhusudhan, Seth Redfield", "abstract": "The detection and atmospheric characterization of super-Earths is one of the\nmajor frontiers of exoplanetary science. Currently, extensive efforts are\nunderway to detect molecules, particularly H2O, in super-Earth atmospheres. In\nthe present work, we develop a systematic set of strategies to identify and\nobserve potentially H2O-rich super-Earths that provide the best prospects for\ncharacterizing their atmospheres using existing instruments. Firstly, we\nprovide analytic prescriptions and discuss factors that need to be taken into\naccount while planning and interpreting observations of super-Earth radii and\nspectra. We discuss how observations in different spectral bandpasses constrain\ndifferent atmospheric properties of a super-Earth, including radius and\ntemperature of the planetary surface as well as the mean molecular mass, the\nchemical composition and thermal profile of the atmosphere. In particular, we\ncaution that radii measured in certain bandpasses can induce biases in the\ninterpretation of the interior compositions. Secondly, we investigate the\ndetectability of H2O-rich super-Earth atmospheres using the HST WFC3\nspectrograph as a function of the planetary properties and stellar brightness.\nWe find that highly irradiated super-Earths orbiting bright stars, such as 55\nCancri e, present better candidates for atmospheric characterization compared\nto cooler planets such as GJ 1214b even if the latter orbit lower-mass stars.\nBesides being better candidates for both transmission and emission\nspectroscopy, hotter planets offer higher likelihood of cloud-free atmospheres\nwhich aid tremendously in the observation and interpretation of spectra.\nFinally, we present case studies of two super-Earths, GJ 1214b and 55 Cancri e,\nusing available data and models of their interiors and atmospheres.", "journal": "", "doi": "10.1017/S1473550414000421", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1409.4459v1"}
{"entry_id": "http://arxiv.org/abs/1612.07921v1", "date": "2016-12-23", "title": "Understanding Non-optical Remote-sensed Images: Needs, Challenges and Ways Forward", "authors": "Amit Kumar Mishra", "abstract": "Non-optical remote-sensed images are going to be used more often in man-\naging disaster, crime and precision agriculture. With more small satellites and\nunmanned air vehicles planning to carry radar and hyperspectral image sensors\nthere is going to be an abundance of such data in the recent future.\nUnderstanding these data in real-time will be crucial in attaining some of the\nimportant sustain- able development goals. Processing non-optical images is, in\nmany ways, different from that of optical images. Most of the recent advances\nin the domain of image understanding has been using optical images. In this\narticle we shall explain the needs for image understanding in non-optical\ndomain and the typical challenges. Then we shall describe the existing\napproaches and how we can move from there to the desired goal of a reliable\nreal-time image understanding system.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1612.07921v1"}
{"entry_id": "http://arxiv.org/abs/1908.11799v1", "date": "2019-08-30", "title": "Dense Dilated Convolutions Merging Network for Semantic Mapping of Remote Sensing Images", "authors": "Qinghui Liu, Michael Kampffmeyer, Robert Jenssen, Arnt-B\u00f8rre Salberg", "abstract": "We propose a network for semantic mapping called the Dense Dilated\nConvolutions Merging Network (DDCM-Net) to provide a deep learning approach\nthat can recognize multi-scale and complex shaped objects with similar color\nand textures, such as buildings, surfaces/roads, and trees in very high\nresolution remote sensing images. The proposed DDCM-Net consists of dense\ndilated convolutions merged with varying dilation rates. This can effectively\nenlarge the kernels' receptive fields, and, more importantly, obtain fused\nlocal and global context information to promote surrounding discriminative\ncapability. We demonstrate the effectiveness of the proposed DDCM-Net on the\npublicly available ISPRS Potsdam dataset and achieve a performance of 92.3%\nF1-score and 86.0% mean intersection over union accuracy by only using the RGB\nbands, without any post-processing. We also show results on the ISPRS Vaihingen\ndataset, where the DDCM-Net trained with IRRG bands, also obtained better\nmapping accuracy (89.8% F1-score) than previous state-of-the-art approaches.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1908.11799v1"}
{"entry_id": "http://arxiv.org/abs/1512.01743v1", "date": "2015-12-06", "title": "Remote sensing of pressure inside deformable microchannels using light scattering in Scotch tape", "authors": "Kyungduk Kim, Hyeonseung Yu, Joonyoung Koh, Jung H. Shin, Wonhee Lee, Yongkeun Park", "abstract": "We present a simple but effective method to measure the pressure inside a\ndeformable micro-channel using laser scattering in a translucent Scotch tape.\nOur idea exploits the fact that the speckle pattern generated by a turbid layer\nis sensitive to the changes in an optical wavefront of an impinging beam. A\nchange in the internal pressure of a channel deforms the elastic channel, which\ncan be detected by measuring speckle patterns of a coherent laser that has\npassed through the channel and the Scotch tape. We demonstrate that internal\npressure can be remotely sensed with the resolution below 0.1 kPa within a\npressure range of 3 kPa after calibration. With its high sensitivity,\nreproducibility, and easy applicability, the present method will find direct\nand diverse applications.", "journal": "", "doi": "10.1364/OL.41.001837", "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/1512.01743v1"}
{"entry_id": "http://arxiv.org/abs/1807.09072v1", "date": "2018-07-24", "title": "Feature Fusion through Multitask CNN for Large-scale Remote Sensing Image Segmentation", "authors": "Shihao Sun, Lei Yang, Wenjie Liu, Ruirui Li", "abstract": "In recent years, Fully Convolutional Networks (FCN) has been widely used in\nvarious semantic segmentation tasks, including multi-modal remote sensing\nimagery. How to fuse multi-modal data to improve the segmentation performance\nhas always been a research hotspot. In this paper, a novel end-toend fully\nconvolutional neural network is proposed for semantic segmentation of natural\ncolor, infrared imagery and Digital Surface Models (DSM). It is based on a\nmodified DeepUNet and perform the segmentation in a multi-task way. The\nchannels are clustered into groups and processed on different task pipelines.\nAfter a series of segmentation and fusion, their shared features and private\nfeatures are successfully merged together. Experiment results show that the\nfeature fusion network is efficient. And our approach achieves good performance\nin ISPRS Semantic Labeling Contest (2D).", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.09072v1"}
{"entry_id": "http://arxiv.org/abs/1807.11573v1", "date": "2018-07-11", "title": "State-of-the-art and gaps for deep learning on limited training data in remote sensing", "authors": "John E. Ball, Derek T. Anderson, Pan Wei", "abstract": "Deep learning usually requires big data, with respect to both volume and\nvariety. However, most remote sensing applications only have limited training\ndata, of which a small subset is labeled. Herein, we review three\nstate-of-the-art approaches in deep learning to combat this challenge. The\nfirst topic is transfer learning, in which some aspects of one domain, e.g.,\nfeatures, are transferred to another domain. The next is unsupervised learning,\ne.g., autoencoders, which operate on unlabeled data. The last is generative\nadversarial networks, which can generate realistic looking data that can fool\nthe likes of both a deep learning network and human. The aim of this article is\nto raise awareness of this dilemma, to direct the reader to existing work and\nto highlight current gaps that need solving.", "journal": "IGARSS June 2018", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1807.11573v1"}
{"entry_id": "http://arxiv.org/abs/2002.00053v1", "date": "2020-01-31", "title": "Improving the Detection of Burnt Areas in Remote Sensing using Hyper-features Evolved by M3GP", "authors": "Jo\u00e3o E. Batista, Sara Silva", "abstract": "One problem found when working with satellite images is the radiometric\nvariations across the image and different images. Intending to improve remote\nsensing models for the classification of burnt areas, we set two objectives.\nThe first is to understand the relationship between feature spaces and the\npredictive ability of the models, allowing us to explain the differences\nbetween learning and generalization when training and testing in different\ndatasets. We find that training on datasets built from more than one image\nprovides models that generalize better. These results are explained by\nvisualizing the dispersion of values on the feature space. The second objective\nis to evolve hyper-features that improve the performance of different\nclassifiers on a variety of test sets. We find the hyper-features to be\nbeneficial, and obtain the best models with XGBoost, even if the hyper-features\nare optimized for a different method.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "eess.IV", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2002.00053v1"}
{"entry_id": "http://arxiv.org/abs/2003.09388v1", "date": "2020-03-17", "title": "Image Gravimetry: A New Remote Sensing Approach for Gravity Analysis in Geophysics", "authors": "M. Kiani", "abstract": "In this paper a new Geophysical gravimetry approach is presented, which is\nbased on satellite imagery in remote sensing. The method uses a satellite\nimage, together with a set of points in the image the gravity values of which\nare known. Template-based spheroidal spline method of interpolation is used to\nconstitute a system of equations to find the values of gravity at other points\nin the image. A real case study is presented for the Qom region in Iran. Values\nof gravity are determined from the Landsat satellite image for this region,\nusing 9 points in the image whose gravity values are known. Reference ellipsoid\ngravity values, which are based on coefficients derived from satellite\ngravimetry, are computed for this region, as well. Comparison between gravity\nvalues derived from Landsat image and those from reference ellipsoid shows that\nthe standard deviation of the results is around 6.71 milli Gal, with the\nmaximum of differences being 35 milli Gal.", "journal": "", "doi": null, "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "astro-ph.EP", "cs.NA", "eess.IV", "math.NA"], "pdf_url": "http://arxiv.org/pdf/2003.09388v1"}
{"entry_id": "http://arxiv.org/abs/2004.01613v2", "date": "2020-04-03", "title": "Deep Learning for Image Search and Retrieval in Large Remote Sensing Archives", "authors": "Gencer Sumbul, Jian Kang, Beg\u00fcm Demir", "abstract": "This chapter presents recent advances in content based image search and\nretrieval (CBIR) systems in remote sensing (RS) for fast and accurate\ninformation discovery from massive data archives. Initially, we analyze the\nlimitations of the traditional CBIR systems that rely on the hand-crafted RS\nimage descriptors. Then, we focus our attention on the advances in RS CBIR\nsystems for which deep learning (DL) models are at the forefront. In\nparticular, we present the theoretical properties of the most recent DL based\nCBIR systems for the characterization of the complex semantic content of RS\nimages. After discussing their strengths and limitations, we present the deep\nhashing based CBIR systems that have high time-efficient search capability\nwithin huge data archives. Finally, the most promising research directions in\nRS CBIR are discussed.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2004.01613v2"}
{"entry_id": "http://arxiv.org/abs/2008.00388v1", "date": "2020-08-02", "title": "Coherent synthetic aperture imaging for visible remote sensing via reflective Fourier ptychography", "authors": "Meng Xiang, An Pan, Yiyi Zhao, Xuewu Fan, Hui Zhao, Chuang Li, Baoli Yao", "abstract": "Synthetic aperture radar (SAR) can measure the phase with antenna and\nmicrowave, which cannot be directly extended to visible light imaging due to\nphase lost. In this letter, we reported an active remote sensing with visible\nlight via reflective Fourier ptychography (FP), termed coherent synthetic\naperture imaging (CSAI), achieving high resolution, wide field-of-view (FOV)\nand phase recovery. A proof-of-concept experiment was reported with laser\nscanning and a collimator for the infinite object. Both smooth and rough\nobjects are tested, and the spatial resolution increased from 15.6 um to 3.48\num with a factor of 4.5. The speckle noise can be suppressed by FP\nunexpectedly. Meanwhile, the CSAI method may replace the adaptive optics to\ntackle the aberration induced from atmospheric turbulence and optical system by\none-step deconvolution.", "journal": "", "doi": "10.1364/OL.409258", "primary_category": "physics.optics", "categories": ["physics.optics", "eess.IV", "physics.app-ph"], "pdf_url": "http://arxiv.org/pdf/2008.00388v1"}
{"entry_id": "http://arxiv.org/abs/2103.09699v1", "date": "2021-03-17", "title": "ShipSRDet: An End-to-End Remote Sensing Ship Detector Using Super-Resolved Feature Representation", "authors": "Shitian He, Huanxin Zou, Yingqian Wang, Runlin Li, Fei Cheng", "abstract": "High-resolution remote sensing images can provide abundant appearance\ninformation for ship detection. Although several existing methods use image\nsuper-resolution (SR) approaches to improve the detection performance, they\nconsider image SR and ship detection as two separate processes and overlook the\ninternal coherence between these two correlated tasks. In this paper, we\nexplore the potential benefits introduced by image SR to ship detection, and\npropose an end-to-end network named ShipSRDet. In our method, we not only feed\nthe super-resolved images to the detector but also integrate the intermediate\nfeatures of the SR network with those of the detection network. In this way,\nthe informative feature representation extracted by the SR network can be fully\nused for ship detection. Experimental results on the HRSC dataset validate the\neffectiveness of our method. Our ShipSRDet can recover the missing details from\nthe input image and achieves promising ship detection performance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2103.09699v1"}
{"entry_id": "http://arxiv.org/abs/2104.08899v1", "date": "2021-04-18", "title": "Texture Based Classification of High Resolution Remotely Sensed Imagery using Weber Local Descriptor", "authors": "Decky Aspandi-Latif, Sally Goldin, Preesan Rakwatin, Kurt Rudahl", "abstract": "Traditional image classification techniques often produce unsatisfactory\nresults when applied to high spatial resolution data because classes in high\nresolution images are not spectrally homogeneous. Texture offers an alternative\nsource of information for classifying these images. This paper evaluates a\nrecently developed, computationally simple texture metric called Weber Local\nDescriptor (WLD) for use in classifying high resolution QuickBird panchromatic\ndata. We compared WLD with state-of-the art texture descriptors (TD) including\nLocal Binary Pattern (LBP) and its rotation-invariant version LBPRIU. We also\ninvestigated whether incorporating VAR, a TD that captures brightness\nvariation, would improve the accuracy of LBPRIU and WLD. We found that WLD\ngenerally produces more accurate classification results than the other TD we\nexamined, and is also more robust to varying parameters. We have implemented an\noptimised algorithm for calculating WLD which makes the technique practical in\nterms of computation time. Overall, our results indicate that WLD is a\npromising approach for classifying high resolution remote sensing data.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2104.08899v1"}
{"entry_id": "http://arxiv.org/abs/2105.10050v1", "date": "2021-05-20", "title": "Wildfires vegetation recovery through satellite remote sensing and Functional Data Analysis", "authors": "Feliu Serra-Burriel, Pedro Delicado, Fernando M. Cucchietti", "abstract": "In recent years wildfires have caused havoc across the world, especially\naggravated in certain regions, due to climate change. Remote sensing has become\na powerful tool for monitoring fires, as well as for measuring their effects on\nvegetation over the following years. We aim to explain the dynamics of\nwildfires' effects on a vegetation index (previously estimated by causal\ninference through synthetic controls) from pre-wildfire available information\n(mainly proceeding from satellites). For this purpose, we use regression models\nfrom Functional Data Analysis, where wildfire effects are considered functional\nresponses, depending on elapsed time after each wildfire, while pre-wildfire\ninformation acts as scalar covariates. Our main findings show that vegetation\nrecovery after wildfires is a slow process, affected by many pre-wildfire\nconditions, among which the richness and diversity of vegetation is one of the\nbest predictors for the recovery.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP"], "pdf_url": "http://arxiv.org/pdf/2105.10050v1"}
{"entry_id": "http://arxiv.org/abs/2112.02991v1", "date": "2021-12-06", "title": "Cross-Modality Attentive Feature Fusion for Object Detection in Multispectral Remote Sensing Imagery", "authors": "Qingyun Fang, Zhaokui Wang", "abstract": "Cross-modality fusing complementary information of multispectral remote\nsensing image pairs can improve the perception ability of detection algorithms,\nmaking them more robust and reliable for a wider range of applications, such as\nnighttime detection. Compared with prior methods, we think different features\nshould be processed specifically, the modality-specific features should be\nretained and enhanced, while the modality-shared features should be\ncherry-picked from the RGB and thermal IR modalities. Following this idea, a\nnovel and lightweight multispectral feature fusion approach with joint\ncommon-modality and differential-modality attentions are proposed, named\nCross-Modality Attentive Feature Fusion (CMAFF). Given the intermediate feature\nmaps of RGB and IR images, our module parallel infers attention maps from two\nseparate modalities, common- and differential-modality, then the attention maps\nare multiplied to the input feature map respectively for adaptive feature\nenhancement or selection. Extensive experiments demonstrate that our proposed\napproach can achieve the state-of-the-art performance at a low computation\ncost.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2112.02991v1"}
{"entry_id": "http://arxiv.org/abs/2201.09156v1", "date": "2022-01-23", "title": "LSNet: Extremely Light-Weight Siamese Network For Change Detection in Remote Sensing Image", "authors": "Biyuan Liu, Huaixin Chen, Zhixi Wang", "abstract": "The Siamese network is becoming the mainstream in change detection of remote\nsensing images (RSI). However, in recent years, the development of more\ncomplicated structure, module and training processe has resulted in the\ncumbersome model, which hampers their application in large-scale RSI\nprocessing. To this end, this paper proposes an extremely lightweight Siamese\nnetwork (LSNet) for RSI change detection, which replaces standard convolution\nwith depthwise separable atrous convolution, and removes redundant dense\nconnections, retaining only valid feature flows while performing Siamese\nfeature fusion, greatly compressing parameters and computation amount. Compared\nwith the first-place model on the CCD dataset, the parameters and the\ncomputation amount of LSNet is greatly reduced by 90.35\\% and 91.34\\%\nrespectively, with only a 1.5\\% drops in accuracy.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2201.09156v1"}
{"entry_id": "http://arxiv.org/abs/2203.04316v2", "date": "2022-03-08", "title": "Time-domain feature extraction for target-specificity in Photoacoustic Remote Sensing Microscopy", "authors": "Nicholas Pellegrino, Benjamin R. Ecclestone, Paul Fieguth, Parsin Haji Reza", "abstract": "Photoacoustic Remote Sensing (PARS) microscopy is an emerging label-free\noptical absorption imaging modality. PARS operates by capturing\nnanosecond-scale optical perturbations generated by photoacoustic pressures.\nThese time-domain (TD) modulations are usually projected by amplitude to\ndetermine absorption magnitude. However, significant information on the\ntarget's material properties is contained within the TD signals. This work\nproposes a novel clustering method to learn TD features which relate to\nunderlying biomolecule characteristics. This technique identifies features\nrelated to constituent biomolecules, enabling single-acquisition virtual tissue\nlabelling. Colorized visualizations of tissue are produced, highlighting\nspecific tissue components. This is demonstrated on freshly resected murine\nbrain tissue, clearly discerning structures including myelinated and\nunmyelinated neurons (white and gray matter) and nuclear structures.", "journal": "", "doi": "10.1364/OL.457142", "primary_category": "physics.med-ph", "categories": ["physics.med-ph", "q-bio.QM"], "pdf_url": "http://arxiv.org/pdf/2203.04316v2"}
{"entry_id": "http://arxiv.org/abs/2203.14476v1", "date": "2022-03-28", "title": "A Novel Remote Sensing Approach to Recognize and Monitor Red Palm Weevil in Date Palm Trees", "authors": "Yashu Kang, Chunlei Chen, Fujian Cheng, Jianyong Zhang", "abstract": "The spread of the Red Pal Weevil (RPW) has become an existential threat for\npalm trees around the world. In the Middle East, RPW is causing wide-spread\ndamage to date palm Phoenix dactylifera L., having both agricultural impacts on\nthe palm production and environmental impacts. Early detection of RPW is very\nchallenging, especially at large scale. This research proposes a novel remote\nsensing approach to recognize and monitor red palm weevil in date palm trees,\nusing a combination of vegetation indices, object detection and semantic\nsegmentation techniques. The study area consists of date palm trees with three\nclasses, including healthy palms, smallish palms and severely infected palms.\nThis proposed method achieved a promising 0.947 F1 score on test data set. This\nwork paves the way for deploying artificial intelligence approaches to monitor\nRPW in large-scale as well as provide guidance for practitioners.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2203.14476v1"}
{"entry_id": "http://arxiv.org/abs/2204.01736v1", "date": "2022-04-04", "title": "Tracking Urbanization in Developing Regions with Remote Sensing Spatial-Temporal Super-Resolution", "authors": "Yutong He, William Zhang, Chenlin Meng, Marshall Burke, David B. Lobell, Stefano Ermon", "abstract": "Automated tracking of urban development in areas where construction\ninformation is not available became possible with recent advancements in\nmachine learning and remote sensing. Unfortunately, these solutions perform\nbest on high-resolution imagery, which is expensive to acquire and infrequently\navailable, making it difficult to scale over long time spans and across large\ngeographies. In this work, we propose a pipeline that leverages a single\nhigh-resolution image and a time series of publicly available low-resolution\nimages to generate accurate high-resolution time series for object tracking in\nurban construction. Our method achieves significant improvement in comparison\nto baselines using single image super-resolution, and can assist in extending\nthe accessibility and scalability of building construction tracking across the\ndeveloping world.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2204.01736v1"}
{"entry_id": "http://arxiv.org/abs/2210.07601v1", "date": "2022-10-14", "title": "MCTNet: A Multi-Scale CNN-Transformer Network for Change Detection in Optical Remote Sensing Images", "authors": "Weiming Li, Lihui Xue, Xueqian Wang, Gang Li", "abstract": "For the task of change detection (CD) in remote sensing images, deep\nconvolution neural networks (CNNs)-based methods have recently aggregated\ntransformer modules to improve the capability of global feature extraction.\nHowever, they suffer degraded CD performance on small changed areas due to the\nsimple single-scale integration of deep CNNs and transformer modules. To\naddress this issue, we propose a hybrid network based on multi-scale\nCNN-transformer structure, termed MCTNet, where the multi-scale global and\nlocal information are exploited to enhance the robustness of the CD performance\non changed areas with different sizes. Especially, we design the ConvTrans\nblock to adaptively aggregate global features from transformer modules and\nlocal features from CNN layers, which provides abundant global-local features\nwith different scales. Experimental results demonstrate that our MCTNet\nachieves better detection performance than existing state-of-the-art CD\nmethods.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.07601v1"}
{"entry_id": "http://arxiv.org/abs/2210.09743v1", "date": "2022-10-18", "title": "A Dashboard to Analysis and Synthesis of Dimensionality Reduction Methods in Remote Sensing", "authors": "Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine", "abstract": "Hyperspectral images (HSI) classification is a high technical remote sensing\nsoftware. The purpose is to reproduce a thematic map . The HSI contains more\nthan a hundred hyperspectral measures, as bands (or simply images), of the\nconcerned region. They are taken at neighbors frequencies. Unfortunately, some\nbands are redundant features, others are noisily measured, and the high\ndimensionality of features made classification accuracy poor. The problematic\nis how to find the good bands to classify the regions items. Some methods use\nMutual Information (MI) and thresholding, to select relevant images, without\nprocessing redundancy. Others control and avoid redundancy. But they process\nthe dimensionality reduction, some times as selection, other times as wrapper\nmethods without any relationship . Here , we introduce a survey on all scheme\nused, and after critics and improvement, we synthesize a dashboard, that helps\nuser to analyze an hypothesize features selection and extraction softwares.", "journal": "IJET Vol 5 No 3 Jun-Jul 2013 -\n  http://www.scopus.com/inward/record.url?eid=2-s2.0-84880952006&partnerID=MN8TOARS", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2210.09743v1"}
{"entry_id": "http://arxiv.org/abs/2211.08129v1", "date": "2022-11-15", "title": "Self-supervised remote sensing feature learning: Learning Paradigms, Challenges, and Future Works", "authors": "Chao Tao, Ji Qi, Mingning Guo, Qing Zhu, Haifeng Li", "abstract": "Deep learning has achieved great success in learning features from massive\nremote sensing images (RSIs). To better understand the connection between\nfeature learning paradigms (e.g., unsupervised feature learning (USFL),\nsupervised feature learning (SFL), and self-supervised feature learning\n(SSFL)), this paper analyzes and compares them from the perspective of feature\nlearning signals, and gives a unified feature learning framework. Under this\nunified framework, we analyze the advantages of SSFL over the other two\nlearning paradigms in RSIs understanding tasks and give a comprehensive review\nof the existing SSFL work in RS, including the pre-training dataset,\nself-supervised feature learning signals, and the evaluation methods. We\nfurther analyze the effect of SSFL signals and pre-training data on the learned\nfeatures to provide insights for improving the RSI feature learning. Finally,\nwe briefly discuss some open problems and possible research directions.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2211.08129v1"}
{"entry_id": "http://arxiv.org/abs/2301.05858v1", "date": "2023-01-14", "title": "Robust Remote Sensing Scene Classification with Multi-View Voting and Entropy Ranking", "authors": "Jinyang Wang, Tao Wang, Min Gan, George Hadjichristofi", "abstract": "Deep convolutional neural networks have been widely used in scene\nclassification of remotely sensed images. In this work, we propose a robust\nlearning method for the task that is secure against partially incorrect\ncategorization of images. Specifically, we remove and correct errors in the\nlabels progressively by iterative multi-view voting and entropy ranking. At\neach time step, we first divide the training data into disjoint parts for\nseparate training and voting. The unanimity in the voting reveals the\ncorrectness of the labels, so that we can train a strong model with only the\nimages with unanimous votes. In addition, we adopt entropy as an effective\nmeasure for prediction uncertainty, in order to partially recover labeling\nerrors by ranking and selection. We empirically demonstrate the superiority of\nthe proposed method on the WHU-RS19 dataset and the AID dataset.", "journal": "", "doi": "10.1007/978-3-031-20096-0_7", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.05858v1"}
{"entry_id": "http://arxiv.org/abs/2302.08046v1", "date": "2023-02-16", "title": "Continuous Remote Sensing Image Super-Resolution based on Context Interaction in Implicit Function Space", "authors": "Keyan Chen, Wenyuan Li, Sen Lei, Jianqi Chen, Xiaolong Jiang, Zhengxia Zou, Zhenwei Shi", "abstract": "Despite its fruitful applications in remote sensing, image super-resolution\nis troublesome to train and deploy as it handles different resolution\nmagnifications with separate models. Accordingly, we propose a\nhighly-applicable super-resolution framework called FunSR, which settles\ndifferent magnifications with a unified model by exploiting context interaction\nwithin implicit function space. FunSR composes a functional representor, a\nfunctional interactor, and a functional parser. Specifically, the representor\ntransforms the low-resolution image from Euclidean space to multi-scale\npixel-wise function maps; the interactor enables pixel-wise function expression\nwith global dependencies; and the parser, which is parameterized by the\ninteractor's output, converts the discrete coordinates with additional\nattributes to RGB values. Extensive experimental results demonstrate that FunSR\nreports state-of-the-art performance on both fixed-magnification and\ncontinuous-magnification settings, meanwhile, it provides many friendly\napplications thanks to its unified nature.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2302.08046v1"}
{"entry_id": "http://arxiv.org/abs/1803.01336v1", "date": "2018-03-04", "title": "Control for Networked Control Systems with Remote and Local Controllers over Unreliable Communication Channel", "authors": "Xiao Liang, Juanjuan Xu", "abstract": "This paper is concerned with the problems of optimal control and\nstabilization for networked control systems (NCSs), where the remote controller\nand the local controller operate the linear plant simultaneously. The main\ncontributions are two-fold. Firstly, a necessary and sufficient condition for\nthe finite horizon optimal control problem is given in terms of the two Riccati\nequations. Secondly, it is shown that the system without the additive noise is\nstabilizable in the mean square sense if and only if the two algebraic Riccati\nequations admit the unique solutions, and a sufficient condition is given for\nthe boundedness in the mean square sense of the system with the additive noise.\nNumerical examples about the unmanned aerial vehicle model are shown to\nillustrate the effectiveness of the proposed algorithm.", "journal": "Automatica, 98: 86-94, 2018", "doi": "10.1016/j.automatica.2018.09.015", "primary_category": "math.OC", "categories": ["math.OC", "65K10, 93D20"], "pdf_url": "http://arxiv.org/pdf/1803.01336v1"}
{"entry_id": "http://arxiv.org/abs/1810.05782v1", "date": "2018-10-13", "title": "Cloud Detection Algorithm for Remote Sensing Images Using Fully Convolutional Neural Networks", "authors": "Sorour Mohajerani, Thomas A. Krammer, Parvaneh Saeedi", "abstract": "This paper presents a deep-learning based framework for addressing the\nproblem of accurate cloud detection in remote sensing images. This framework\nbenefits from a Fully Convolutional Neural Network (FCN), which is capable of\npixel-level labeling of cloud regions in a Landsat 8 image. Also, a\ngradient-based identification approach is proposed to identify and exclude\nregions of snow/ice in the ground truths of the training set. We show that\nusing the hybrid of the two methods (threshold-based and deep-learning)\nimproves the performance of the cloud identification process without the need\nto manually correct automatically generated ground truths. In average the\nJaccard index and recall measure are improved by 4.36% and 3.62%, respectively.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1810.05782v1"}
{"entry_id": "http://arxiv.org/abs/2003.08874v1", "date": "2020-03-19", "title": "On the Detectability of Conflict: a Remote Sensing Study of the Rohingya Conflict", "authors": "Christopher X. Ren, Matthew T. Calef, Alice M. S. Durieux, A. Ziemann, J. Theiler", "abstract": "The detection and quantification of conflict through remote sensing\nmodalities represents a challenging but crucial aspect of human rights\nmonitoring. In this work we demonstrate how utilizing multi-modal data sources\ncan help build a comprehensive picture of conflict and human displacement,\nusing the Rohingya conflict in the state of Rakhine, Myanmar as a case study.\nWe show that time series analysis of fire detections from the Moderate\nResolution Imaging Spectroradiometer (MODIS) and Visible Infrared Imaging\nRadiometer Suite (VIIRS) can reveal anomalous spatial and temporal\ndistributions of fires related to conflict. This work also shows that Synthetic\nAperture Radar (SAR) backscatter and coherence data can detect the razing and\nburning of buildings and villages, even in cloudy conditions. These techniques\nmay be further developed in the future to enable the monitoring and detection\nof signals originating from these types of conflict.", "journal": "", "doi": null, "primary_category": "stat.AP", "categories": ["stat.AP"], "pdf_url": "http://arxiv.org/pdf/2003.08874v1"}
{"entry_id": "http://arxiv.org/abs/2006.05015v1", "date": "2020-06-09", "title": "Can Synthetic Data Improve Object Detection Results for Remote Sensing Images?", "authors": "Weixing Liu, Jun Liu, Bin Luo", "abstract": "Deep learning approaches require enough training samples to perform well, but\nit is a challenge to collect enough real training data and label them manually.\nIn this letter, we propose the use of realistic synthetic data with a wide\ndistribution to improve the performance of remote sensing image aircraft\ndetection. Specifically, to increase the variability of synthetic data, we\nrandomly set the parameters during rendering, such as the size of the instance\nand the class of background images. In order to make the synthetic images more\nrealistic, we then refine the synthetic images at the pixel level using\nCycleGAN with real unlabeled images. We also fine-tune the model with a small\namount of real data, to obtain a higher accuracy. Experiments on NWPU VHR-10,\nUCAS-AOD and DIOR datasets demonstrate that the proposed method can be applied\nfor augmenting insufficient real data.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2006.05015v1"}
{"entry_id": "http://arxiv.org/abs/2006.11767v1", "date": "2020-06-21", "title": "Patch Based Classification of Remote Sensing Data: A Comparison of 2D-CNN, SVM and NN Classifiers", "authors": "Mahesh Pal, Akshay, Himanshu Rohilla, B. Charan Teja", "abstract": "Pixel based algorithms including back propagation neural networks (NN) and\nsupport vector machines (SVM) have been widely used for remotely sensed image\nclassifications. Within last few years, deep learning based image classifier\nlike convolution neural networks (2D-CNN) are becoming popular alternatives to\nthese classifiers. In this paper, we compare performance of patch based SVM and\nNN with that of a deep learning algorithms comprising of 2D-CNN and fully\nconnected layers. Similar to CNN which utilise image patches to derive features\nfor further classification, we propose to use patches as an input in place of\nindividual pixel with both SVM and NN classifiers. Two datasets, one\nmultispectral and other hyperspectral data was used to compare the performance\nof different classifiers. Results with both datasets suggest the effectiveness\nof patch based SVM and NN classifiers in comparison to state of art 2D-CNN\nclassifier.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2006.11767v1"}
{"entry_id": "http://arxiv.org/abs/2205.08959v1", "date": "2022-05-18", "title": "A lightweight multi-scale context network for salient object detection in optical remote sensing images", "authors": "Yuhan Lin, Han Sun, Ningzhong Liu, Yetong Bian, Jun Cen, Huiyu Zhou", "abstract": "Due to the more dramatic multi-scale variations and more complicated\nforegrounds and backgrounds in optical remote sensing images (RSIs), the\nsalient object detection (SOD) for optical RSIs becomes a huge challenge.\nHowever, different from natural scene images (NSIs), the discussion on the\noptical RSI SOD task still remains scarce. In this paper, we propose a\nmulti-scale context network, namely MSCNet, for SOD in optical RSIs.\nSpecifically, a multi-scale context extraction module is adopted to address the\nscale variation of salient objects by effectively learning multi-scale\ncontextual information. Meanwhile, in order to accurately detect complete\nsalient objects in complex backgrounds, we design an attention-based pyramid\nfeature aggregation mechanism for gradually aggregating and refining the\nsalient regions from the multi-scale context extraction module. Extensive\nexperiments on two benchmarks demonstrate that MSCNet achieves competitive\nperformance with only 3.26M parameters. The code will be available at\nhttps://github.com/NuaaYH/MSCNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2205.08959v1"}
{"entry_id": "http://arxiv.org/abs/2206.02331v1", "date": "2022-06-06", "title": "MASNet:Improve Performance of Siamese Networks with Mutual-attention for Remote Sensing Change Detection Tasks", "authors": "Hongbin Zhou, Yupeng Ren, Qiankun Li, Jun Yin, Yonggang Lin", "abstract": "Siamese networks are widely used for remote sensing change detection tasks. A\nvanilla siamese network has two identical feature extraction branches which\nshare weights, these two branches work independently and the feature maps are\nnot fused until about to be sent to a decoder head. However we find that it is\ncritical to exchange information between two feature extraction branches at\nearly stage for change detection task. In this work we present Mutual-Attention\nSiamese Network (MASNet), a general siamese network with mutual-attention\nplug-in, so to exchange information between the two feature extraction\nbranches. We show that our modification improve the performance of siamese\nnetworks on multi change detection datasets, and it works for both\nconvolutional neural network and visual transformer.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2206.02331v1"}
{"entry_id": "http://arxiv.org/abs/1304.2386v1", "date": "2013-04-07", "title": "Percolation description of the global topography of Earth and Moon", "authors": "Abbas Ali Saberi", "abstract": "Remarkable global correlations exist between geometrical features of\nterrestrial surface on the Earth, current mean sea level and its geological\ninternal processes whose origins have remained an essential goal in the Earth\nsciences. Theoretical modeling of the ubiquitous self-similar fractal patterns\nobserved on the Earth and their underlying rules is indeed of great importance.\nHere I present a percolation description of the global topography of the Earth\nin which the present mean sea level is automatically singled out as a critical\nlevel in the model. This finding elucidates the origins of the appearance of\nscale invariant patterns on the Earth. The criticality is shown to be\naccompanied by a continental aggregation, unraveling an important correlation\nbetween the water and long-range topographic evolution. To have a comparison\npoint in hand, I apply such analysis onto the lunar topography which reveals\nvarious characteristic features of the Moon.", "journal": "Phys. Rev. Lett. 110, 178501 (2013)", "doi": "10.1103/PhysRevLett.110.178501", "primary_category": "cond-mat.stat-mech", "categories": ["cond-mat.stat-mech", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/1304.2386v1"}
{"entry_id": "http://arxiv.org/abs/1908.04350v1", "date": "2019-08-12", "title": "Earth as an Exoplanet: A Two-dimensional Alien Map", "authors": "Siteng Fan, Cheng Li, Jia-Zheng Li, Stuart Bartlett, Jonathan H. Jiang, Vijay Natraj, David Crisp, Yuk L. Yung", "abstract": "Resolving spatially-varying exoplanet features from single-point light curves\nis essential for determining whether Earth-like worlds harbor geological\nfeatures and/or climate systems that influence habitability. To evaluate the\nfeasibility and requirements of this spatial feature resolving problem, we\npresent an analysis of multi-wavelength single-point light curves of Earth,\nwhere it plays the role of a proxy exoplanet. Here, ~10,000 DSCOVR/EPIC frames\ncollected over a two-year period were integrated over the Earth's disk to yield\na spectrally-dependent point source and analyzed using singular value\ndecomposition. We found that, between the two dominant principal components\n(PCs), the second PC contains surface-related features of the planet, while the\nfirst PC mainly includes cloud information. We present the first\ntwo-dimensional (2D) surface map of Earth reconstructed from light curve\nobservations without any assumptions of its spectral properties. This study\nserves as a baseline for reconstructing the surface features of Earth-like\nexoplanets in the future.", "journal": "", "doi": "10.3847/2041-8213/ab3a49", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1908.04350v1"}
{"entry_id": "http://arxiv.org/abs/1610.05385v3", "date": "2016-10-18", "title": "Laser remote magnetometry using mesospheric sodium", "authors": "Thomas J. Kane, Paul D. Hillman, Craig A. Denman, Michael Hart, R. Phillip Scott, Michael E. Purucker, Stephen J. Potashnik", "abstract": "We have demonstrated a remote magnetometer based on sodium atoms in the\nEarth's mesosphere, at a 106-kilometer distance from our instrument. A\n1.33-watt laser illuminated the atoms, and the magnetic field was inferred from\nback-scattered light collected by a telescope with a 1.55-meter-diameter\naperture. The measurement sensitivity was 162 nT/$\\sqrt{Hz}$. The value of\nmagnetic field inferred from our measurement is consistent with an estimate\nbased on the Earth's known field shape to within a fraction of a percent.\nProjected improvements in optics could lead to sensitivity of 20\nnT/$\\sqrt{Hz}$, and the use of advanced lasers or a large telescope could\napproach 1-nT/$\\sqrt{Hz}$ sensitivity. All experimental and theoretical\nsensitivity values are based on a 60$^\\circ$ angle between the laser beam axis\nand the magnetic field vector; at the optimal 90$^\\circ$ angle sensitivity\nwould be improved by about a factor of two.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP", "physics.atom-ph", "physics.ins-det", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/1610.05385v3"}
{"entry_id": "http://arxiv.org/abs/1801.06819v1", "date": "2018-01-21", "title": "A Next-Best-Smell Approach for Remote Gas Detection with a Mobile Robot", "authors": "Riccardo Polvara, Marco Trabattoni, Tomasz Piotr Kucner, Erik Schaffernicht, Francesco Amigoni, Achim J. Lilienthal", "abstract": "The problem of gas detection is relevant to many real-world applications,\nsuch as leak detection in industrial settings and landfill monitoring. Using\nmobile robots for gas detection has several advantages and can reduce danger\nfor humans. In our work, we address the problem of planning a path for a mobile\nrobotic platform equipped with a remote gas sensor, which minimizes the time to\ndetect all gas sources in a given environment. We cast this problem as a\ncoverage planning problem by defining a basic sensing operation -- a scan with\nthe remote gas sensor -- as the field of \"view\" of the sensor. Given the\ncomputing effort required by previously proposed offline approaches, in this\npaper we suggest a online coverage algorithm, called Next-Best-Smell, adapted\nfrom the Next-Best-View class of exploration algorithms. Our algorithm\nevaluates candidate locations with a global utility function, which combines\nutility values for travel distance, information gain, and sensing time, using\nMulti-Criteria Decision Making. In our experiments, conducted both in\nsimulation and with a real robot, we found the performance of the\nNext-Best-Smell approach to be comparable with that of the state-of-the-art\noffline algorithm, at much lower computational cost.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO"], "pdf_url": "http://arxiv.org/pdf/1801.06819v1"}
{"entry_id": "http://arxiv.org/abs/hep-ph/0005125v1", "date": "2000-05-12", "title": "Geophysical constraints on mirror matter within the Earth", "authors": "A. Yu. Ignatiev, R. R. Volkas", "abstract": "We have performed a detailed investigation of geophysical constraints on the\npossible admixture of mirror matter inside the Earth. On the basis of the\nPreliminary Reference Earth Model (PREM) -- the `Standard Model' of the Earth's\ninterior -- we have developed a method which allows one to compute changes in\nvarious quantities characterising the Earth (mass, moment of inertia, normal\nmode frequencies etc.)due to the presence of mirror matter. As a result we have\nbeen able to obtain for the first time the direct upper bounds on the possible\nconcentration of the mirror matter in the Earth. In terms of the ratio of the\nmirror mass to the Earth mass a conservative upper bound is $3.8\\times\n10^{-3}$. We then analysed possible mechanisms (such as lunar and solar tidal\nforces, meteorite impacts and earthquakes) of exciting mirror matter\noscillations around the Earth centre. Such oscillations could manifest\nthemselves through global variations of the gravitational acceleration at the\nEarth's surface. We conclude that such variations are too small to be observed.\nOur results are valid for other types of hypothetical matter coupled to\nordinary matter by gravitation only (e.g. the shadow matter of superstring\ntheories).", "journal": "Phys.Rev. D62 (2000) 023508", "doi": "10.1103/PhysRevD.62.023508", "primary_category": "hep-ph", "categories": ["hep-ph"], "pdf_url": "http://arxiv.org/pdf/hep-ph/0005125v1"}
{"entry_id": "http://arxiv.org/abs/1907.05245v1", "date": "2019-07-10", "title": "Expanding the Timeline for Earth's Photosynthetic Red Edge Biosignature", "authors": "Jack T. O'Malley-James, Lisa Kaltenegger", "abstract": "When Carl Sagan observed the Earth during a Gallileo fly-by in 1993, he found\na widely distributed surface pigment with a sharp reflection edge in the red\npart of the spectrum, which, together with the abundance of gaseous oxygen and\nmethane in extreme thermodynamic disequilibrium, were strongly suggestive of\nthe presence of life on Earth. This widespread pigmentation that could not be\nexplained by geological processes alone, is caused by the cellular structure of\nvegetation - a mechanism for potentially limiting damage to chlorophyll and/or\nlimiting water loss. The distinctive increase in the red portion of Earth's\nglobal reflectance spectrum is called the vegetation red edge in astrobiology\nliterature and is one of the proposed surface biosignatures to search for on\nexoplanets and exomoons. Earth's surface vegetation has only been widespread\nfor about half a billion years, providing a surface biosignature for\napproximately 1/9th our planet's lifetime. However, as chlorophyll is present\nin many forms of life on Earth, like cyanobacteria, algae, lichen, corals, as\nwell as leafy vegetation, such a spectral red edge feature could indicate a\nwide range of life, expanding its use for the search for surface biosignatures\nbeyond vegetation alone to a time long before vegetation became widespread on\nEarth. We show how lichens could extend the presence of Earth's red edge\nsurface biofeature to 1.2 Gyr ago, while ocean surface algae and cyanobacteria\ncould extend it to over 2 Gyr ago, expanding the use of a photosynthetic red\nedge to earlier times in Earth's history.", "journal": "The Astrophysical Journal Letters, 879:L20 (5pp), 2019 July 10", "doi": "10.3847/2041-8213/ab2769", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1907.05245v1"}
{"entry_id": "http://arxiv.org/abs/1604.05507v1", "date": "2016-04-19", "title": "The young centre of the Earth", "authors": "Ulrik I. Uggerhoj, Rune E. Mikkelsen, Jan Faye", "abstract": "We treat, as an illustrative example of gravitational time dilation in\nrelativity, the observation that the center of the Earth is younger than the\nsurface by an appreciable amount. Richard Feynman first made this insightful\npoint and presented an estimate of the size of the effect in a talk; a\ntranscription was later published in which the time difference is quoted as\n'one or two days'. However, a back-of-the-envelope calculation shows that the\nresult is in fact a few years. In this paper we present this estimate alongside\na more elaborate analysis yielding a difference of two and a half years. The\naim is to provide a fairly complete solution to the relativity of the 'aging'\nof an object due to differences in the gravitational potential. This solution -\naccessible at the undergraduate level - can be used for educational purposes,\nas an example in the classroom. Finally, we also briefly discuss why exchanging\n'years' for 'days' - which in retrospect is a quite simple, but significant,\nmistake - has been repeated seemingly uncritically, albeit in a few cases only.\nThe pedagogical value of this discussion is to show students that any number or\nobservation, no matter who brought it forward, must be critically examined.", "journal": "Eur.J.Phys. vol. 37, 035602 (2016)", "doi": "10.1088/0143-0807/37/3/035602", "primary_category": "physics.ed-ph", "categories": ["physics.ed-ph", "physics.pop-ph"], "pdf_url": "http://arxiv.org/pdf/1604.05507v1"}
{"entry_id": "http://arxiv.org/abs/1606.07421v1", "date": "2016-06-23", "title": "The Albedo Distribution of Near Earth Asteroids", "authors": "Edward L. Wright, Amy Mainzer, Joseph Masiero, Tommy Grav, James Bauer", "abstract": "The cryogenic WISE mission in 2010 was extremely sensitive to asteroids and\nnot biased against detecting dark objects. The albedos of 428 Near Earth\nAsteroids (NEAs) observed by WISE during its fully cryogenic mission can be fit\nquite well by a 3 parameter function that is the sum of two Rayleigh\ndistributions. The Rayleigh distribution is zero for negative values, and\nfollows $f(x) = x \\exp[-x^2/(2\\sigma^2)]/\\sigma^2$ for positive x. The peak\nvalue is at x=\\sigma, so the position and width are tied together. The three\nparameters are the fraction of the objects in the dark population, the position\nof the dark peak, and the position of the brighter peak. We find that 25.3% of\nthe NEAs observed by WISE are in a very dark population peaking at $p_V =\n0.03$, while the other 74.7% of the NEAs seen by WISE are in a moderately dark\npopulation peaking at $p_V = 0.168$. A consequence of this bimodal distribution\nis that the Congressional mandate to find 90% of all NEAs larger than 140 m\ndiameter cannot be satisfied by surveying to H=22 mag, since a 140 m diameter\nasteroid at the very dark peak has H=23.7 mag, and more than 10% of NEAs are\ndarker than p_V = 0.03.", "journal": "", "doi": "10.3847/0004-6256/152/4/79", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1606.07421v1"}
{"entry_id": "http://arxiv.org/abs/2001.05405v1", "date": "2020-01-15", "title": "Heterogeneous accretion of Earth inferred from Mo-Ru isotope systematics", "authors": "Timo Hopp, Gerrit Budde, Thorsten Kleine", "abstract": "The Mo and Ru isotopic compositions of meteorites and the bulk silicate Earth\n(BSE) hold important clues about the provenance of Earth's building material.\nPrior studies have argued that non-carbonaceous (NC) and carbonaceous (CC)\nmeteorite groups together define a Mo-Ru 'cosmic' correlation, and that the BSE\nplots on the extension of this correlation. These observations were taken as\nevidence that the final 10-15% of Earth's accreted material derived from a\nhomogeneous inner disk reservoir with an enstatite chondrite-like isotopic\ncomposition. Here, using new Mo and Ru isotopic data for previously\nuninvestigated meteorite groups, we show that the Mo-Ru correlation only exists\nfor NC meteorites, and that both the BSE and CC meteorites fall off this Mo-Ru\ncorrelation. These observations indicate that the final stages of Earth's\naccretion were heterogeneous and consisted of a mixture of NC and CC materials.\nThe Mo-Ru isotope systematics are best accounted for by either an NC heritage\nof the late veneer combined with a CC heritage of the Moon-forming giant\nimpactor, or by mixed NC-CC compositions for both components. The involvement\nof CC bodies in the late-stage accretionary assemblage of Earth is consistent\nwith chemical models for core-mantle differentiation, which argue for the\naddition of more oxidized and volatile-rich material toward the end of Earth's\nformation. As such, this study resolves the inconsistencies between homogeneous\naccretion models based on prior interpretations of the Mo-Ru systematics of\nmeteorites and the chemical evidence for heterogeneous accretion of Earth.", "journal": "", "doi": "10.1016/j.epsl.2020.116065", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2001.05405v1"}
{"entry_id": "http://arxiv.org/abs/2302.10712v1", "date": "2023-02-21", "title": "AOTF based spectro-polarimeter for observing Earth as an Exoplanet", "authors": "Bhavesh Jaiswal, Swapnil Singh, Anand Jain, K Sankarasubramanian, Anuj Nandi", "abstract": "Earth is the only known habitable planet and it serves as a testbed to\nbenchmark the observations of temperate and more Earth-like exoplanets. It is\nrequired to observe the disc-integrated signatures of Earth for a large range\nof phase angles, resembling the observations of an exoplanet. In this work, an\nAOTF (Acousto-Optic Tunable Filter) based experiment is designed to observe the\nspectro-polarimetric signatures of Earth. The results of spectroscopic and\npolarimetric laboratory calibration are presented here along with a brief\noverview of a possible instrument configuration. Based on the results of the\nspectro-polarimetric calibration, simulations are carried out to optimize the\ninstrument design for the expected signal levels for various observing\nconditions. The usefulness of an AOTF based spectro-polarimeter is established\nfrom this study and it is found that, in the present configuration, the\ninstrument can achieve a polarimetric accuracy of $<0.3$\\% for linear\npolarization for an integration time of 100 ms or larger. The design\nconfiguration of the instrument and the planning of conducting such\nobservations from Lunar orbit are discussed.", "journal": "Journal of Astronomical Telescopes, Instruments, and Systems,\n  Volume 8, id. 044007 (2022)", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2302.10712v1"}
{"entry_id": "http://arxiv.org/abs/2006.08723v1", "date": "2020-06-11", "title": "Threats and Countermeasures of Cyber Security in Direct and Remote Vehicle Communication Systems", "authors": "Subrato Bharati, Prajoy Podder, M. Rubaiyat Hossain Mondal, Md. Robiul Alam Robel", "abstract": "Traffic management, road safety, and environmental impact are important\nissues in the modern world. These challenges are addressed by the application\nof sensing, control and communication methods of intelligent transportation\nsystems (ITS). A part of ITS is a vehicular ad-hoc network (VANET) which means\na wireless network of vehicles. However, communication among vehicles in a\nVANET exposes several security threats which need to be studied and addressed.\nIn this review, firstly, the basic flow of VANET is illustrated focusing on its\ncommunication methods, architecture, characteristics, standards, and security\nfacilities. Next, the attacks and threats for VANET are discussed. Moreover,\nthe authentication systems are described by which vehicular networks can be\nprotected from fake messages and malicious nodes. Security threats and counter\nmeasures are discussed for different remote vehicle communication methods\nnamely, remote keyless entry system, dedicated short range communication,\ncellular scheme, Zigbee, Bluetooth, radio frequency identification, WiFi,\nWiMAX, and different direct vehicle communication methods namely on-board\ndiagnosis and universal serial bus.", "journal": "Journal of Information Assurance and Security (ISSN 1554-1010),\n  Volume 15 (2020), pp. 153-164, MIR Labs, www.mirlabs.net/jias/index.html", "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR", "cs.IT", "eess.SP", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2006.08723v1"}
{"entry_id": "http://arxiv.org/abs/1606.04180v2", "date": "2016-06-14", "title": "From order to chaos in Earth satellite orbits", "authors": "Ioannis Gkolias, Jerome Daquin, Fabien Gachet, Aaron J. Rosengren", "abstract": "We consider Earth satellite orbits in the range of semi-major axes where the\nperturbing effects of Earth's oblateness and lunisolar gravity are of\ncomparable order. This range covers the medium-Earth orbits (MEO) of the Global\nNavigation Satellite Systems and the geosynchronous orbits (GEO) of the\ncommunication satellites. We recall a secular and quadrupolar model, based on\nthe Milankovitch vector formulation of perturbation theory, which governs the\nlong-term orbital evolution subject to the predominant gravitational\ninteractions. We study the global dynamics of this two-and-a-half\ndegrees-of-freedom Hamiltonian system by means of the fast Lyapunov indicator\n(FLI), used in a statistical sense. Specifically, we characterize the degree of\nchaoticity of the action space using angle-averaged normalized FLI maps,\nthereby overcoming the angle dependencies of the conventional stability maps.\nEmphasis is placed upon the phase-space structures near secular resonances,\nwhich are of first importance to the space debris community. We confirm and\nquantify the transition from order to chaos in MEO, stemming from the critical\ninclinations, and find that highly inclined GEO orbits are particularly\nunstable. Despite their reputed normality, Earth satellite orbits can possess\nan extraordinarily rich spectrum of dynamical behaviors, and, from a\nmathematical perspective, have all the complications that make them very\ninteresting candidates for testing the modern tools of chaos theory.", "journal": "", "doi": "10.3847/0004-6256/152/5/119", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "nlin.CD"], "pdf_url": "http://arxiv.org/pdf/1606.04180v2"}
{"entry_id": "http://arxiv.org/abs/2111.06013v1", "date": "2021-11-11", "title": "The Other Side of Black Screen: Rethinking Interaction in Synchronous Remote Learning for Collaborative Programming", "authors": "Tahiya Chowdhury", "abstract": "Collaborative learning environments such as programming labs are crucial for\nlearning experiential hands-on skills such as critical thinking and problem\nsolving, and peer discussion. In a traditional laboratory setting, many of\nthese skills can be practiced through natural interaction (verbal, facial) and\nphysical co-location. However, during and after a global pandemic, these\nlearning practices cannot be exercised safely in in-person settings any longer\nand thus need to be re-imagined for a remote learning environment. As\ndiscussions spur about effective remote learning practices, there is an urgency\nfor identifying the unique needs demanded by both students and instructors\nunder different learning environments. How can we design remote learning to\noffer broadly accessible learning, by drawing in-person practices and combining\nthem with the power of remote learning solutions? In this case study, we\npresent observations of in-person and online versions of 2 introductory\nprogramming courses offered before and during the COVID-19 pandemic. Our\nobservations reveal certain user needs and interaction practices under 5 themes\nthat are unique to students' prior experience with the curriculum and academic\nlevel. We find that the current online video-conferencing platforms cannot\nfoster collaborative learning among peers, lacks learning ambiance and\nspontaneous engagement between students and instructors. Based on our findings,\nwe propose design recommendations and intervention strategies to improve\ncurrent practices in synchronous remote learning that can facilitate a better\nlearning environment, particularly for introductory lab courses.", "journal": "", "doi": null, "primary_category": "cs.CY", "categories": ["cs.CY", "K.3.2"], "pdf_url": "http://arxiv.org/pdf/2111.06013v1"}
{"entry_id": "http://arxiv.org/abs/2303.04931v1", "date": "2023-03-08", "title": "An Observer-Based Key Agreement Scheme for Remotely Controlled Mobile Robots", "authors": "Amir Mohammad Naseri, Walter Lucia, Amr Youssef", "abstract": "Remotely controlled mobile robots are important examples of Cyber-Physical\nSystems (CPSs). Recently, these robots are being deployed in many safety\ncritical applications. Therefore, ensuring their cyber-security is of paramount\nimportance. Different control schemes that have been proposed to secure such\nsystems against sophisticated cyber-attacks require the exchange of secret\nmessages between their smart actuators and the remote controller. Thus, these\nschemes require pre-shared secret keys, or an established Public Key\nInfrastructure (PKI) that allows for key agreement. Such cryptographic\napproaches might not always be suitable for the deployment environments of such\nremotely mobile robots. To address this problem, in this paper, we consider a\ncontrol theoretic approach for establishing a secret key between the remotely\ncontrolled robot and the networked controller without resorting to traditional\ncryptographic techniques. Our key agreement scheme leverages a nonlinear\nunknown input observer and an error correction code mechanism to allow the\nrobot to securely agree on a secret key with its remote controller. To validate\nthe proposed scheme, we implement it using a Khepera-IV differential drive\nrobot and evaluate its efficiency and the additional control cost acquired by\nit. Our experimental results confirm the effectiveness of the proposed key\nestablishment scheme.", "journal": "", "doi": null, "primary_category": "eess.SY", "categories": ["eess.SY", "cs.CR", "cs.RO", "cs.SY"], "pdf_url": "http://arxiv.org/pdf/2303.04931v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0505084v1", "date": "2005-05-04", "title": "Globally integrated measurements of the Earth's visible spectral albedo", "authors": "P. Montanes-Rodriguez, E. Palle, P. R. Goode, J. Hickey, S. E. Koonin", "abstract": "We report spectroscopic observations of the earthshine reflected from the\nMoon. By applying our photometry methodology to spectroscopy, we were able to\nprecisely determine the Earth's reflectance, and its variation as a function of\nwavelength through a single night as the Earth rotates. These data imply that\nplanned regular monitoring of earthshine spectra will yield valuable, new\ninputs for climate models, which would be complementary to those from the more\nstandard broadband measurements of satellite platforms. The mean spectroscopic\nalbedo over the visible is consistent with simultaneous broadband photometric\nmeasurements. We found no evidence for an appreciable \"red\" or \"vegetation\nedge\" in the Earth's spectral albedo, and no evidence for changes in this\nspectral region (700 -740 nm) over the 40 degrees of Earth's rotation covered\nby our observations.", "journal": "Astrophys.J. 629 (2005) 1175-1182", "doi": "10.1086/431420", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0505084v1"}
{"entry_id": "http://arxiv.org/abs/0908.1825v1", "date": "2009-08-13", "title": "Empiric Models of the Earth's Free Core Nutation", "authors": "Zinovy Malkin", "abstract": "Free core nutation (FCN) is the main factor that limits the accuracy of the\nmodeling of the motion of Earth's rotational axis in the celestial coordinate\nsystem. Several FCN models have been proposed. A comparative analysis is made\nof the known models including the model proposed by the author. The use of the\nFCN model is shown to substantially increase the accuracy of the modeling of\nEarth's rotation. Furthermore, the FCN component extracted from the observed\nmotion of Earth's rotational axis is an important source for the study of the\nshape and rotation of the Earth's core. A comparison of different FCN models\nhas shown that the proposed model is better than other models if used to\nextract the geophysical signal (the amplitude and phase of FCN) from\nobservational data.", "journal": "Solar System Research, 2007, Vol. 41, No. 6, pp. 492-497", "doi": "10.1134/S0038094607060044", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0908.1825v1"}
{"entry_id": "http://arxiv.org/abs/1103.1846v1", "date": "2011-03-09", "title": "Hot Super Earths: disrupted young jupiters?", "authors": "Sergei Nayakshin", "abstract": "Recent {\\em Kepler} observations revealed an unexpected abundance of \"hot\"\nEarth-size to Neptune-size planets in the inner $0.02-0.2$ AU from their parent\nstars. We propose that these smaller planets are the remnants of massive giant\nplanets that migrated inward quicker than they could contract. We show that\nsuch disruptions naturally occur in the framework of the Tidal Downsizing\nhypothesis for planet formation. We find that the characteristic planet-star\nseparation at which such \"hot disruptions\" occur is $R \\approx 0.03-0.2$ AU.\nThis result is independent of the planet's embryo mass but is dependent on the\naccretion rate in the disc. At high accretion rates, $\\dot M \\simgt\n10^{-6}\\msun$ yr$^{-1}$, the embryo is unable to contract quickly enough and is\ndisrupted. At late times, when the accretion rate drops to $\\dot M \\simlt\n10^{-8} \\msun$ yr$^{-1}$, the embryos migrate sufficiently slow to not be\ndisrupted. These \"late arrivals\" may explain the well known population of hot\njupiters. If type I migration regime is inefficient, then our model predicts a\npile-up of planets at $R\\sim 0.1$ AU as the migration rate suddenly switches\nfrom the type II to type I in that region.", "journal": "", "doi": "10.1111/j.1365-2966.2011.19246.x", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1103.1846v1"}
{"entry_id": "http://arxiv.org/abs/1608.08959v2", "date": "2016-08-31", "title": "On the Origin of Earth's Moon", "authors": "Amy C. Barr", "abstract": "The Giant Impact is currently accepted as the leading theory for the\nformation of Earth's Moon. Successful scenarios for lunar origin should be able\nto explain the chemical composition of the Moon (volatile content and stable\nisotope ratios), the Moon's initial thermal state, and the system's bulk\nphysical and dynamical properties. Hydrocode simulations of the formation of\nthe Moon have long been able to match the bulk properties, but recent, more\ndetailed work on the evolution of the protolunar disk has yielded great insight\ninto the origin of the Moon's chemistry, and its early thermal history. Here, I\nshow that the community has constructed the elements of an end-to-end theory\nfor lunar origin that matches the overwhelming majority of observational\nconstraints. In spite of the great progress made in recent years, new samples\nof the Moon, clarification of processes in the impact-generated disk, and a\nbroader exploration of impact parameter space could yield even more insights\ninto this fundamental and uniquely challenging geophysical problem.", "journal": "Journal of Geophysical Research, v. 121, p. 1573-1601, 2016", "doi": "10.1002/2016JE005098", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1608.08959v2"}
{"entry_id": "http://arxiv.org/abs/0707.3905v1", "date": "2007-07-26", "title": "Spectropolarimetric signatures of Earth-like extrasolar planets", "authors": "D. M. Stam", "abstract": "We present results of numerical simulations of the flux (irradiance), F, and\nthe degree of polarization (i.e. the ratio of polarized to total flux), P, of\nlight that is reflected by Earth-like extrasolar planets orbiting solar-type\nstars, as functions of the wavelength (from 0.3 to 1.0 micron, with 0.001\nmicron spectral resolution) and as functions of the planetary phase angle. We\nuse different surface coverages for our model planets, including vegetation and\na Fresnel reflecting ocean, and clear and cloudy atmospheres. Our\nadding-doubling radiative transfer algorithm, which fully includes multiple\nscattering and polarization, handles horizontally homogeneous planets only; we\nsimulate fluxes and polarization of horizontally inhomogeneous planets by\nweighting results for homogeneous planets. Like the flux, F, the degree of\npolarization, P, of the reflected starlight is shown to depend strongly on the\nphase angle, on the composition and structure of the planetary atmosphere, on\nthe reflective properties of the underlying surface, and on the wavelength, in\nparticular in wavelength regions with gaseous absorption bands. The sensitivity\nof P to a planet's physical properties appears to be different than that of F.\nCombining flux with polarization observations thus makes for a strong tool for\ncharacterizing extrasolar planets. The calculated total and polarized fluxes\nwill be made available through the CDS.", "journal": "", "doi": "10.1051/0004-6361:20078358", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0707.3905v1"}
{"entry_id": "http://arxiv.org/abs/1801.03667v2", "date": "2018-01-11", "title": "A Conception of Engineering Design for Remote Unattended Operation Public Observatory", "authors": "Jun Han, Dongwei Fan, Chenzhou Cui, Chuanzhong Wang, Shanshan Li, Linying Mi, Zheng Li, Yunfei Xu, Boliang He, Changhua Li, Yihan Tao, Sisi Yang", "abstract": "Public observatory project is playing more and more important role in science\npopularization education and scientific research, and many amateur astronomers\nalso have began to build their own observatories in remote areas. As a result\nof the limitation of technical condition and construction funds for amateur\nastronomers, their system often breaks down, and then a stable remote\nunattended operation system becomes very critical. Hardware connection and\ncontrol is the basic and core part in observatory design. Here we propose a\nconception of engineering hardware design for public observatory operation as a\nbridge between observatory equipment and observation software. It can not only\nsatisfy multiple observation mode requirement, but also save cost.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1801.03667v2"}
{"entry_id": "http://arxiv.org/abs/1903.04462v1", "date": "2019-03-11", "title": "Viewing Earth's surface as a soft matter landscape", "authors": "Douglas J. Jerolmack, Karen E. Daniels", "abstract": "The Earth's surface is composed of a staggering diversity of\nparticulate-fluid mixtures: dry to wet, dilute to dense, colloidal to granular,\nand attractive to repulsive particles. This material variety is matched by the\nrange of relevant stresses and strain rates, from laminar to turbulent flows,\nand steady to intermittent forcing, leading to anything from rapid and\ncatastrophic landslides to the slow relaxation of soil and rocks over geologic\ntimescales. Geophysical flows sculpt landscapes, but also threaten human lives\nand infrastructure. From a physics point of view, virtually all Earth and\nplanetary landscapes are composed of soft matter, in the sense they are both\ndeformable and sensitive to collective effects. Geophysical materials, however,\noften involve compositions and flow geometries that have not yet been examined\nin physics. In this review we explore how a soft-matter perspective has helped\nto illuminate, and even predict, the rich dynamics of Earth materials and their\nassociated landscapes. We also highlight some novel phenomena of geophysical\nflows that challenge, and will hopefully inspire, more fundamental work in soft\nmatter.", "journal": "", "doi": null, "primary_category": "cond-mat.soft", "categories": ["cond-mat.soft", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/1903.04462v1"}
{"entry_id": "http://arxiv.org/abs/1202.5870v1", "date": "2012-02-27", "title": "Consistent modeling of the geodetic precession in Earth rotation", "authors": "E. Gerlach, S. Klioner, M. Soffel", "abstract": "A highly precise model for the motion of a rigid Earth is indispensable to\nreveal the effects of non-rigidity in the rotation of the Earth from\nobservations. To meet the accuracy goal of modern theories of Earth rotation of\n1 microarcsecond (muas) it is clear, that for such a model also relativistic\neffects have to be taken into account. The largest of these effects is the so\ncalled geodetic precession.\n  In this paper we will describe this effect and the standard procedure to deal\nwith it in modeling Earth rotation up to now. With our relativistic model of\nEarth rotation Klioner et al. (2001) we are able to give a consistent\npost-Newtonian treatment of the rotational motion of a rigid Earth in the\nframework of General Relativity. Using this model we show that the currently\napplied standard treatment of geodetic precession is not correct. The\ninconsistency of the standard treatment leads to errors in all modern theories\nof Earth rotation with a magnitude of up to 200 muas for a time span of one\ncentury.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "gr-qc", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/1202.5870v1"}
{"entry_id": "http://arxiv.org/abs/2001.01521v1", "date": "2020-01-06", "title": "Can the earth be flat ? A physical oceanographer's perspective", "authors": "Charly de Marez, Mathieu Le Corre", "abstract": "According to a recent survey, 2% of the U.S. population is convinced that the\nearth is flat. This idea is heralded by members of the Flat Earth Society, and\npromulgated through Internet forums and other public media channels. Children\nand young students are easy targets. As a science teacher confronted by these\nideas, it can be a challenge to firmly confront their fundamentally flawed\nfoundation while still remaining compassionate towards those who espouse such\nbeliefs. While we do not purport to have the answer for such difficult\nsituations, as two scientists studying ocean physics, we attempt to lend a\nhelping hand to the interested instructor. Here, we use the most advanced\ncomputational tools of the physical oceanography community to show that the\nproperties of the ocean that we observe from ships, satellites, and autonomous\nobserving platforms should not exist if the earth were flat. In particular,\nusing the first realistic simulation of the ocean on a flat Earth, we show that\nthe North Atlantic gyre, appears entirely different on a flat Earth. For\nmembers of the physical oceanography community, the results presented here are\nobvious; however, for the Flat Earth Society community, it may present an\nintellectual challenge.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2001.01521v1"}
{"entry_id": "http://arxiv.org/abs/1807.05713v3", "date": "2018-07-16", "title": "Land-Cover Classification with High-Resolution Remote Sensing Images Using Transferable Deep Models", "authors": "Xin-Yi Tong, Gui-Song Xia, Qikai Lu, Huanfeng Shen, Shengyang Li, Shucheng You, Liangpei Zhang", "abstract": "In recent years, large amount of high spatial-resolution remote sensing\n(HRRS) images are available for land-cover mapping. However, due to the complex\ninformation brought by the increased spatial resolution and the data\ndisturbances caused by different conditions of image acquisition, it is often\ndifficult to find an efficient method for achieving accurate land-cover\nclassification with high-resolution and heterogeneous remote sensing images. In\nthis paper, we propose a scheme to apply deep model obtained from labeled\nland-cover dataset to classify unlabeled HRRS images. The main idea is to rely\non deep neural networks for presenting the contextual information contained in\ndifferent types of land-covers and propose a pseudo-labeling and sample\nselection scheme for improving the transferability of deep models. More\nprecisely, a deep Convolutional Neural Networks is first pre-trained with a\nwell-annotated land-cover dataset, referred to as the source data. Then, given\na target image with no labels, the pre-trained CNN model is utilized to\nclassify the image in a patch-wise manner. The patches with high confidence are\nassigned with pseudo-labels and employed as the queries to retrieve related\nsamples from the source data. The pseudo-labels confirmed with the retrieved\nresults are regarded as supervised information for fine-tuning the pre-trained\ndeep model. To obtain a pixel-wise land-cover classification with the target\nimage, we rely on the fine-tuned CNN and develop a hybrid classification by\ncombining patch-wise classification and hierarchical segmentation. In addition,\nwe create a large-scale land-cover dataset containing 150 Gaofen-2 satellite\nimages for CNN pre-training. Experiments on multi-source HRRS images show\nencouraging results and demonstrate the applicability of the proposed scheme to\nland-cover classification.", "journal": "", "doi": "10.1016/j.rse.2019.111322", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1807.05713v3"}
{"entry_id": "http://arxiv.org/abs/2202.12939v2", "date": "2022-02-18", "title": "Automated Extraction of Energy Systems Information from Remotely Sensed Data: A Review and Analysis", "authors": "Simiao Ren, Wei Hu, Kyle Bradbury, Dylan Harrison-Atlas, Laura Malaguzzi Valeri, Brian Murray, Jordan M. Malof", "abstract": "High quality energy systems information is a crucial input to energy systems\nresearch, modeling, and decision-making. Unfortunately, actionable information\nabout energy systems is often of limited availability, incomplete, or only\naccessible for a substantial fee or through a non-disclosure agreement.\nRecently, remotely sensed data (e.g., satellite imagery, aerial photography)\nhave emerged as a potentially rich source of energy systems information.\nHowever, the use of these data is frequently challenged by its sheer volume and\ncomplexity, precluding manual analysis. Recent breakthroughs in machine\nlearning have enabled automated and rapid extraction of useful information from\nremotely sensed data, facilitating large-scale acquisition of critical energy\nsystem variables. Here we present a systematic review of the literature on this\nemerging topic, providing an in-depth survey and review of papers published\nwithin the past two decades. We first taxonomize the existing literature into\nten major areas, spanning the energy value chain. Within each research area, we\ndistill and critically discuss major features that are relevant to energy\nresearchers, including, for example, key challenges regarding the accessibility\nand reliability of the methods. We then synthesize our findings to identify\nlimitations and trends in the literature as a whole, and discuss opportunities\nfor innovation. These include the opportunity to extend the methods beyond\nelectricity to broader energy systems and wider geographic areas; and the\nability to expand the use of these methods in research and decision making as\nsatellite data become cheaper and easier to access. We also find that there are\npersistent challenges: limited standardization and rigor of performance\nassessments; limited sharing of code, which would improve replicability; and a\nlimited consideration of the ethics and privacy of data.", "journal": "Applied Energy, 326, 119876 (2022)", "doi": "10.1016/j.apenergy.2022.119876", "primary_category": "eess.SP", "categories": ["eess.SP", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2202.12939v2"}
{"entry_id": "http://arxiv.org/abs/2207.03860v2", "date": "2022-07-08", "title": "Consecutive Pretraining: A Knowledge Transfer Learning Strategy with Relevant Unlabeled Data for Remote Sensing Domain", "authors": "Tong Zhang, Peng Gao, Hao Dong, Yin Zhuang, Guanqun Wang, Wei Zhang, He Chen", "abstract": "Currently, under supervised learning, a model pretrained by a large-scale\nnature scene dataset and then fine-tuned on a few specific task labeling data\nis the paradigm that has dominated the knowledge transfer learning. It has\nreached the status of consensus solution for task-aware model training in\nremote sensing domain (RSD). Unfortunately, due to different categories of\nimaging data and stiff challenges of data annotation, there is not a large\nenough and uniform remote sensing dataset to support large-scale pretraining in\nRSD. Moreover, pretraining models on large-scale nature scene datasets by\nsupervised learning and then directly fine-tuning on diverse downstream tasks\nseems to be a crude method, which is easily affected by inevitable labeling\nnoise, severe domain gaps and task-aware discrepancies. Thus, in this paper,\nconsidering the self-supervised pretraining and powerful vision transformer\n(ViT) architecture, a concise and effective knowledge transfer learning\nstrategy called ConSecutive PreTraining (CSPT) is proposed based on the idea of\nnot stopping pretraining in natural language processing (NLP), which can\ngradually bridge the domain gap and transfer knowledge from the nature scene\ndomain to the RSD. The proposed CSPT also can release the huge potential of\nunlabeled data for task-aware model training. Finally, extensive experiments\nare carried out on twelve datasets in RSD involving three types of downstream\ntasks (e.g., scene classification, object detection and land cover\nclassification) and two types of imaging data (e.g., optical and SAR). The\nresults show that by utilizing the proposed CSPT for task-aware model training,\nalmost all downstream tasks in RSD can outperform the previous method of\nsupervised pretraining-then-fine-tuning and even surpass the state-of-the-art\n(SOTA) performance without any expensive labeling consumption and careful model\ndesign.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2207.03860v2"}
{"entry_id": "http://arxiv.org/abs/2208.02613v2", "date": "2022-08-04", "title": "Semantic Interleaving Global Channel Attention for Multilabel Remote Sensing Image Classification", "authors": "Yongkun Liu, Kesong Ni, Yuhan Zhang, Lijian Zhou, Kun Zhao", "abstract": "Multi-Label Remote Sensing Image Classification (MLRSIC) has received\nincreasing research interest. Taking the cooccurrence relationship of multiple\nlabels as additional information helps to improve the performance of this task.\nCurrent methods focus on using it to constrain the final feature output of a\nConvolutional Neural Network (CNN). On the one hand, these methods do not make\nfull use of label correlation to form feature representation. On the other\nhand, they increase the label noise sensitivity of the system, resulting in\npoor robustness. In this paper, a novel method called Semantic Interleaving\nGlobal Channel Attention (SIGNA) is proposed for MLRSIC. First, the label\nco-occurrence graph is obtained according to the statistical information of the\ndata set. The label co-occurrence graph is used as the input of the Graph\nNeural Network (GNN) to generate optimal feature representations. Then, the\nsemantic features and visual features are interleaved, to guide the feature\nexpression of the image from the original feature space to the semantic feature\nspace with embedded label relations. SIGNA triggers global attention of feature\nmaps channels in a new semantic feature space to extract more important visual\nfeatures. Multihead SIGNA based feature adaptive weighting networks are\nproposed to act on any layer of CNN in a plug-and-play manner. For remote\nsensing images, better classification performance can be achieved by inserting\nCNN into the shallow layer. We conduct extensive experimental comparisons on\nthree data sets: UCM data set, AID data set, and DFC15 data set. Experimental\nresults demonstrate that the proposed SIGNA achieves superior classification\nperformance compared to state-of-the-art (SOTA) methods. It is worth mentioning\nthat the codes of this paper will be open to the community for reproducibility\nresearch. Our codes are available at https://github.com/kyle-one/SIGNA.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2208.02613v2"}
{"entry_id": "http://arxiv.org/abs/2301.04581v1", "date": "2023-01-11", "title": "Elevation Estimation-Driven Building 3D Reconstruction from Single-View Remote Sensing Imagery", "authors": "Yongqiang Mao, Kaiqiang Chen, Liangjin Zhao, Wei Chen, Deke Tang, Wenjie Liu, Zhirui Wang, Wenhui Diao, Xian Sun, Kun Fu", "abstract": "Building 3D reconstruction from remote sensing images has a wide range of\napplications in smart cities, photogrammetry and other fields. Methods for\nautomatic 3D urban building modeling typically employ multi-view images as\ninput to algorithms to recover point clouds and 3D models of buildings.\nHowever, such models rely heavily on multi-view images of buildings, which are\ntime-intensive and limit the applicability and practicality of the models. To\nsolve these issues, we focus on designing an efficient DSM estimation-driven\nreconstruction framework (Building3D), which aims to reconstruct 3D building\nmodels from the input single-view remote sensing image. First, we propose a\nSemantic Flow Field-guided DSM Estimation (SFFDE) network, which utilizes the\nproposed concept of elevation semantic flow to achieve the registration of\nlocal and global features. Specifically, in order to make the network semantics\nglobally aware, we propose an Elevation Semantic Globalization (ESG) module to\nrealize the semantic globalization of instances. Further, in order to alleviate\nthe semantic span of global features and original local features, we propose a\nLocal-to-Global Elevation Semantic Registration (L2G-ESR) module based on\nelevation semantic flow. Our Building3D is rooted in the SFFDE network for\nbuilding elevation prediction, synchronized with a building extraction network\nfor building masks, and then sequentially performs point cloud reconstruction,\nsurface reconstruction (or CityGML model reconstruction). On this basis, our\nBuilding3D can optionally generate CityGML models or surface mesh models of the\nbuildings. Extensive experiments on ISPRS Vaihingen and DFC2019 datasets on the\nDSM estimation task show that our SFFDE significantly improves upon\nstate-of-the-arts. Furthermore, our Building3D achieves impressive results in\nthe 3D point cloud and 3D model reconstruction process.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.04581v1"}
{"entry_id": "http://arxiv.org/abs/1709.00308v2", "date": "2017-09-01", "title": "A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community", "authors": "John E. Ball, Derek T. Anderson, Chee Seng Chan", "abstract": "In recent years, deep learning (DL), a re-branding of neural networks (NNs),\nhas risen to the top in numerous areas, namely computer vision (CV), speech\nrecognition, natural language processing, etc. Whereas remote sensing (RS)\npossesses a number of unique challenges, primarily related to sensors and\napplications, inevitably RS draws from many of the same theories as CV; e.g.,\nstatistics, fusion, and machine learning, to name a few. This means that the RS\ncommunity should be aware of, if not at the leading edge of, of advancements\nlike DL. Herein, we provide the most comprehensive survey of state-of-the-art\nRS DL research. We also review recent new developments in the DL field that can\nbe used in DL for RS. Namely, we focus on theories, tools and challenges for\nthe RS community. Specifically, we focus on unsolved challenges and\nopportunities as it relates to (i) inadequate data sets, (ii)\nhuman-understandable solutions for modelling physical phenomena, (iii) Big\nData, (iv) non-traditional heterogeneous data sources, (v) DL architectures and\nlearning algorithms for spectral, spatial and temporal data, (vi) transfer\nlearning, (vii) an improved theoretical understanding of DL systems, (viii)\nhigh barriers to entry, and (ix) training and optimizing the DL.", "journal": "J. Appl. Remote Sens. 11(4) (2017) 042609", "doi": "10.1117/1.JRS.11.042609", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1709.00308v2"}
{"entry_id": "http://arxiv.org/abs/1902.06148v3", "date": "2019-02-16", "title": "BigEarthNet: A Large-Scale Benchmark Archive For Remote Sensing Image Understanding", "authors": "Gencer Sumbul, Marcela Charfuelan, Beg\u00fcm Demir, Volker Markl", "abstract": "This paper presents the BigEarthNet that is a new large-scale multi-label\nSentinel-2 benchmark archive. The BigEarthNet consists of 590,326 Sentinel-2\nimage patches, each of which is a section of i) 120x120 pixels for 10m bands;\nii) 60x60 pixels for 20m bands; and iii) 20x20 pixels for 60m bands. Unlike\nmost of the existing archives, each image patch is annotated by multiple\nland-cover classes (i.e., multi-labels) that are provided from the CORINE Land\nCover database of the year 2018 (CLC 2018). The BigEarthNet is significantly\nlarger than the existing archives in remote sensing (RS) and thus is much more\nconvenient to be used as a training source in the context of deep learning.\nThis paper first addresses the limitations of the existing archives and then\ndescribes the properties of the BigEarthNet. Experimental results obtained in\nthe framework of RS image scene classification problems show that a shallow\nConvolutional Neural Network (CNN) architecture trained on the BigEarthNet\nprovides much higher accuracy compared to a state-of-the-art CNN model\npre-trained on the ImageNet (which is a very popular large-scale benchmark\narchive in computer vision). The BigEarthNet opens up promising directions to\nadvance operational RS applications and research in massive Sentinel-2 image\narchives.", "journal": "", "doi": "10.1109/IGARSS.2019.8900532", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1902.06148v3"}
{"entry_id": "http://arxiv.org/abs/1902.11274v3", "date": "2019-02-28", "title": "A Novel Multi-Attention Driven System For Multi-Label Remote Sensing Image Classification", "authors": "Gencer Sumbul, Beg\u00fcm Demir", "abstract": "This paper presents a novel multi-attention driven system that jointly\nexploits Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN)\nin the context of multi-label remote sensing (RS) image classification. The\nproposed system consists of four main modules. The first module aims to extract\npreliminary local descriptors of RS image bands that can be associated to\ndifferent spatial resolutions. To this end, we introduce a K-Branch CNN, in\nwhich each branch extracts descriptors of image bands that have the same\nspatial resolution. The second module aims to model spatial relationship among\nlocal descriptors. This is achieved by a bidirectional RNN architecture, in\nwhich Long Short-Term Memory nodes enrich local descriptors by considering\nspatial relationships of local areas (image patches). The third module aims to\ndefine multiple attention scores for local descriptors. This is achieved by a\nnovel patch-based multi-attention mechanism that takes into account the joint\noccurrence of multiple land-cover classes and provides the attention-based\nlocal descriptors. The last module exploits these descriptors for multi-label\nRS image classification. Experimental results obtained on the BigEarthNet that\nis a large-scale Sentinel-2 benchmark archive show the effectiveness of the\nproposed method compared to a state of the art method.", "journal": "", "doi": "10.1109/IGARSS.2019.8898188", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1902.11274v3"}
{"entry_id": "http://arxiv.org/abs/1904.01258v3", "date": "2019-04-02", "title": "Metric-Learning based Deep Hashing Network for Content Based Retrieval of Remote Sensing Images", "authors": "Subhankar Roy, Enver Sangineto, Beg\u00fcm Demir, Nicu Sebe", "abstract": "Hashing methods have been recently found very effective in retrieval of\nremote sensing (RS) images due to their computational efficiency and fast\nsearch speed. The traditional hashing methods in RS usually exploit\nhand-crafted features to learn hash functions to obtain binary codes, which can\nbe insufficient to optimally represent the information content of RS images. To\novercome this problem, in this paper we introduce a metric-learning based\nhashing network, which learns: 1) a semantic-based metric space for effective\nfeature representation; and 2) compact binary hash codes for fast archive\nsearch. Our network considers an interplay of multiple loss functions that\nallows to jointly learn a metric based semantic space facilitating similar\nimages to be clustered together in that target space and at the same time\nproducing compact final activations that lose negligible information when\nbinarized. Experiments carried out on two benchmark RS archives point out that\nthe proposed network significantly improves the retrieval performance under the\nsame retrieval time when compared to the state-of-the-art hashing methods in\nRS.", "journal": "", "doi": "10.1109/LGRS.2020.2974629", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1904.01258v3"}
{"entry_id": "http://arxiv.org/abs/1912.06552v1", "date": "2019-12-13", "title": "Active emulation of computer codes with Gaussian processes -- Application to remote sensing", "authors": "Daniel Heestermans Svendsen, Luca Martino, Gustau Camps-Valls", "abstract": "Many fields of science and engineering rely on running simulations with\ncomplex and computationally expensive models to understand the involved\nprocesses in the system of interest. Nevertheless, the high cost involved\nhamper reliable and exhaustive simulations. Very often such codes incorporate\nheuristics that ironically make them less tractable and transparent. This paper\nintroduces an active learning methodology for adaptively constructing surrogate\nmodels, i.e. emulators, of such costly computer codes in a multi-output\nsetting. The proposed technique is sequential and adaptive, and is based on the\noptimization of a suitable acquisition function. It aims to achieve accurate\napproximations, model tractability, as well as compact and expressive simulated\ndatasets. In order to achieve this, the proposed Active Multi-Output Gaussian\nProcess Emulator (AMOGAPE) combines the predictive capacity of Gaussian\nProcesses (GPs) with the design of an acquisition function that favors sampling\nin low density and fluctuating regions of the approximation functions.\nComparing different acquisition functions, we illustrate the promising\nperformance of the method for the construction of emulators with toy examples,\nas well as for a widely used remote sensing transfer code.", "journal": "Pattern Recognition (2019): 107103", "doi": "10.1016/j.patcog.2019.107103", "primary_category": "cs.LG", "categories": ["cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1912.06552v1"}
{"entry_id": "http://arxiv.org/abs/2006.11529v2", "date": "2020-06-20", "title": "Remote Sensing Image Scene Classification with Deep Neural Networks in JPEG 2000 Compressed Domain", "authors": "Akshara Preethy Byju, Gencer Sumbul, Beg\u00fcm Demir, Lorenzo Bruzzone", "abstract": "To reduce the storage requirements, remote sensing (RS) images are usually\nstored in compressed format. Existing scene classification approaches using\ndeep neural networks (DNNs) require to fully decompress the images, which is a\ncomputationally demanding task in operational applications. To address this\nissue, in this paper we propose a novel approach to achieve scene\nclassification in JPEG 2000 compressed RS images. The proposed approach\nconsists of two main steps: i) approximation of the finer resolution sub-bands\nof reversible biorthogonal wavelet filters used in JPEG 2000; and ii)\ncharacterization of the high-level semantic content of approximated wavelet\nsub-bands and scene classification based on the learnt descriptors. This is\nachieved by taking codestreams associated with the coarsest resolution wavelet\nsub-band as input to approximate finer resolution sub-bands using a number of\ntransposed convolutional layers. Then, a series of convolutional layers models\nthe high-level semantic content of the approximated wavelet sub-band. Thus, the\nproposed approach models the multiresolution paradigm given in the JPEG 2000\ncompression algorithm in an end-to-end trainable unified neural network. In the\nclassification stage, the proposed approach takes only the coarsest resolution\nwavelet sub-bands as input, thereby reducing the time required to apply\ndecoding. Experimental results performed on two benchmark aerial image archives\ndemonstrate that the proposed approach significantly reduces the computational\ntime with similar classification accuracies when compared to traditional RS\nscene classification approaches (which requires full image decompression).", "journal": "", "doi": "10.1109/TGRS.2020.3007523", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2006.11529v2"}
{"entry_id": "http://arxiv.org/abs/2112.01932v1", "date": "2021-12-02", "title": "Multi-Content Complementation Network for Salient Object Detection in Optical Remote Sensing Images", "authors": "Gongyang Li, Zhi Liu, Weisi Lin, Haibin Ling", "abstract": "In the computer vision community, great progresses have been achieved in\nsalient object detection from natural scene images (NSI-SOD); by contrast,\nsalient object detection in optical remote sensing images (RSI-SOD) remains to\nbe a challenging emerging topic. The unique characteristics of optical RSIs,\nsuch as scales, illuminations and imaging orientations, bring significant\ndifferences between NSI-SOD and RSI-SOD. In this paper, we propose a novel\nMulti-Content Complementation Network (MCCNet) to explore the complementarity\nof multiple content for RSI-SOD. Specifically, MCCNet is based on the general\nencoder-decoder architecture, and contains a novel key component named\nMulti-Content Complementation Module (MCCM), which bridges the encoder and the\ndecoder. In MCCM, we consider multiple types of features that are critical to\nRSI-SOD, including foreground features, edge features, background features, and\nglobal image-level features, and exploit the content complementarity between\nthem to highlight salient regions over various scales in RSI features through\nthe attention mechanism. Besides, we comprehensively introduce pixel-level,\nmap-level and metric-aware losses in the training phase. Extensive experiments\non two popular datasets demonstrate that the proposed MCCNet outperforms 23\nstate-of-the-art methods, including both NSI-SOD and RSI-SOD methods. The code\nand results of our method are available at https://github.com/MathLee/MCCNet.", "journal": "", "doi": "10.1109/TGRS.2021.3131221", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2112.01932v1"}
{"entry_id": "http://arxiv.org/abs/2201.06459v2", "date": "2022-01-17", "title": "A Novel Framework to Jointly Compress and Index Remote Sensing Images for Efficient Content-Based Retrieval", "authors": "Gencer Sumbul, Jun Xiang, Nimisha Thekke Madam, Beg\u00fcm Demir", "abstract": "Remote sensing (RS) images are usually stored in compressed format to reduce\nthe storage size of the archives. Thus, existing content-based image retrieval\n(CBIR) systems in RS require decoding images before applying CBIR (which is\ncomputationally demanding in the case of large-scale CBIR problems). To address\nthis problem, in this paper, we present a joint framework that simultaneously\nlearns RS image compression and indexing. Thus, it eliminates the need for\ndecoding RS images before applying CBIR. The proposed framework is made up of\ntwo modules. The first module compresses RS images based on an auto-encoder\narchitecture. The second module produces hash codes with a high discrimination\ncapability by employing soft pairwise, bit-balancing and classification loss\nfunctions. We also introduce a two stage learning strategy with gradient\nmanipulation techniques to obtain image representations that are compatible\nwith both RS image indexing and compression. Experimental results show the\nefficacy of the proposed framework when compared to widely used approaches in\nRS. The code of the proposed framework is available at\nhttps://git.tu-berlin.de/rsim/RS-JCIF.", "journal": "", "doi": "10.1109/IGARSS46834.2022.9884146", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2201.06459v2"}
{"entry_id": "http://arxiv.org/abs/2201.08049v1", "date": "2022-01-20", "title": "Lightweight Salient Object Detection in Optical Remote Sensing Images via Feature Correlation", "authors": "Gongyang Li, Zhi Liu, Zhen Bai, Weisi Lin, and Haibin Ling", "abstract": "Salient object detection in optical remote sensing images (ORSI-SOD) has been\nwidely explored for understanding ORSIs. However, previous methods focus mainly\non improving the detection accuracy while neglecting the cost in memory and\ncomputation, which may hinder their real-world applications. In this paper, we\npropose a novel lightweight ORSI-SOD solution, named CorrNet, to address these\nissues. In CorrNet, we first lighten the backbone (VGG-16) and build a\nlightweight subnet for feature extraction. Then, following the coarse-to-fine\nstrategy, we generate an initial coarse saliency map from high-level semantic\nfeatures in a Correlation Module (CorrM). The coarse saliency map serves as the\nlocation guidance for low-level features. In CorrM, we mine the object location\ninformation between high-level semantic features through the cross-layer\ncorrelation operation. Finally, based on low-level detailed features, we refine\nthe coarse saliency map in the refinement subnet equipped with Dense\nLightweight Refinement Blocks, and produce the final fine saliency map. By\nreducing the parameters and computations of each component, CorrNet ends up\nhaving only 4.09M parameters and running with 21.09G FLOPs. Experimental\nresults on two public datasets demonstrate that our lightweight CorrNet\nachieves competitive or even better performance compared with 26\nstate-of-the-art methods (including 16 large CNN-based methods and 2\nlightweight methods), and meanwhile enjoys the clear memory and run time\nefficiency. The code and results of our method are available at\nhttps://github.com/MathLee/CorrNet.", "journal": "", "doi": "10.1109/TGRS.2022.3145483", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2201.08049v1"}
{"entry_id": "http://arxiv.org/abs/2210.02071v3", "date": "2022-10-05", "title": "Advanced Deep Learning Architectures for Accurate Detection of Subsurface Tile Drainage Pipes from Remote Sensing Images", "authors": "Tom-Lukas Breitkopf, Leonard W. Hackel, Mahdyar Ravanbakhsh, Anne-Karin Cooke, Sandra Willkommen, Stefan Broda, Beg\u00fcm Demir", "abstract": "Subsurface tile drainage pipes provide agronomic, economic and environmental\nbenefits. By lowering the water table of wet soils, they improve the aeration\nof plant roots and ultimately increase the productivity of farmland. They do\nhowever also provide an entryway of agrochemicals into subsurface water bodies\nand increase nutrition loss in soils. For maintenance and infrastructural\ndevelopment, accurate maps of tile drainage pipe locations and drained\nagricultural land are needed. However, these maps are often outdated or not\npresent. Different remote sensing (RS) image processing techniques have been\napplied over the years with varying degrees of success to overcome these\nrestrictions. Recent developments in deep learning (DL) techniques improve upon\nthe conventional techniques with machine learning segmentation models. In this\nstudy, we introduce two DL-based models: i) improved U-Net architecture; and\nii) Visual Transformer-based encoder-decoder in the framework of tile drainage\npipe detection. Experimental results confirm the effectiveness of both models\nin terms of detection accuracy when compared to a basic U-Net architecture. Our\ncode and models are publicly available at\nhttps://git.tu-berlin.de/rsim/drainage-pipes-detection.", "journal": "", "doi": "10.1117/12.2636263", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2210.02071v3"}
{"entry_id": "http://arxiv.org/abs/2211.06918v1", "date": "2022-11-13", "title": "Towards a Dynamic Composability Approach for using Heterogeneous Systems in Remote Sensing", "authors": "Ilkay Altintas, Ismael Perez, Dmitry Mishin, Adrien Trouillaud, Christopher Irving, John Graham, Mahidhar Tatineni, Thomas DeFanti, Shawn Strande, Larry Smarr, Michael L. Norman", "abstract": "Influenced by the advances in data and computing, the scientific practice\nincreasingly involves machine learning and artificial intelligence driven\nmethods which requires specialized capabilities at the system-, science- and\nservice-level in addition to the conventional large-capacity supercomputing\napproaches. The latest distributed architectures built around the composability\nof data-centric applications led to the emergence of a new ecosystem for\ncontainer coordination and integration. However, there is still a divide\nbetween the application development pipelines of existing supercomputing\nenvironments, and these new dynamic environments that disaggregate fluid\nresource pools through accessible, portable and re-programmable interfaces. New\napproaches for dynamic composability of heterogeneous systems are needed to\nfurther advance the data-driven scientific practice for the purpose of more\nefficient computing and usable tools for specific scientific domains. In this\npaper, we present a novel approach for using composable systems in the\nintersection between scientific computing, artificial intelligence (AI), and\nremote sensing domain. We describe the architecture of a first working example\nof a composable infrastructure that federates Expanse, an NSF-funded\nsupercomputer, with Nautilus, a Kubernetes-based GPU geo-distributed cluster.\nWe also summarize a case study in wildfire modeling, that demonstrates the\napplication of this new infrastructure in scientific workflows: a composed\nsystem that bridges the insights from edge sensing, AI and computing\ncapabilities with a physics-driven simulation.", "journal": "", "doi": null, "primary_category": "cs.DC", "categories": ["cs.DC", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2211.06918v1"}
{"entry_id": "http://arxiv.org/abs/2301.02778v1", "date": "2023-01-07", "title": "Lightweight Salient Object Detection in Optical Remote Sensing Images via Semantic Matching and Edge Alignment", "authors": "Gongyang Li, Zhi Liu, Xinpeng Zhang, Weisi Lin", "abstract": "Recently, relying on convolutional neural networks (CNNs), many methods for\nsalient object detection in optical remote sensing images (ORSI-SOD) are\nproposed. However, most methods ignore the huge parameters and computational\ncost brought by CNNs, and only a few pay attention to the portability and\nmobility. To facilitate practical applications, in this paper, we propose a\nnovel lightweight network for ORSI-SOD based on semantic matching and edge\nalignment, termed SeaNet. Specifically, SeaNet includes a lightweight\nMobileNet-V2 for feature extraction, a dynamic semantic matching module (DSMM)\nfor high-level features, an edge self-alignment module (ESAM) for low-level\nfeatures, and a portable decoder for inference. First, the high-level features\nare compressed into semantic kernels. Then, semantic kernels are used to\nactivate salient object locations in two groups of high-level features through\ndynamic convolution operations in DSMM. Meanwhile, in ESAM, cross-scale edge\ninformation extracted from two groups of low-level features is self-aligned\nthrough L2 loss and used for detail enhancement. Finally, starting from the\nhighest-level features, the decoder infers salient objects based on the\naccurate locations and fine details contained in the outputs of the two\nmodules. Extensive experiments on two public datasets demonstrate that our\nlightweight SeaNet not only outperforms most state-of-the-art lightweight\nmethods but also yields comparable accuracy with state-of-the-art conventional\nmethods, while having only 2.76M parameters and running with 1.7G FLOPs for\n288x288 inputs. Our code and results are available at\nhttps://github.com/MathLee/SeaNet.", "journal": "", "doi": "10.1109/TGRS.2023.3235717", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.02778v1"}
{"entry_id": "http://arxiv.org/abs/cond-mat/0312552v1", "date": "2003-12-20", "title": "Novel sensing media based on ferromagnetic microwires for application to the remote imaging of the stress distribution", "authors": "L. Panina, S. Sandacci, D. Makhnovskiy", "abstract": "In this research project we propose a new composite medium, which can\nvisualise the mechanical stress at any stage: before and after damage. The main\nfeature of the proposed stress-tuneable composite is its permittivity\n(dielectric constant), which depends on the mechanical stress. This kind of\ncomposite material can be characterised as a \"sensing medium\" that opens up new\npossibilities for remote monitoring of stress with the use of microwave\ntransceiving techniques. The composite material can be made as a bulk medium or\nas thin cover to image the mechanical stress distribution inside construction\nor on its surface.", "journal": "", "doi": null, "primary_category": "cond-mat.mtrl-sci", "categories": ["cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/cond-mat/0312552v1"}
{"entry_id": "http://arxiv.org/abs/1608.06245v1", "date": "2016-08-22", "title": "The Remote Observatories of the Southeastern Association for Research in Astronomy (SARA)", "authors": "William C. Keel, Terry Oswalt, Peter Mack, Gary Henson, Todd Hillwig, Daniel Batcheldor, Robert Berrington, Chris De Pree, Dieter Hartmann, Martha Leake, Javier Licandro, Brian Murphy, James Webb, Matt A. Wood", "abstract": "We describe the remote facilities operated by the Southeastern Association\nfor Research in Astronomy (SARA), a consortium of colleges and universities in\nthe US partnered with Lowell Observatory, the Chilean National Telescope\nAllocation Committee, and the Instituto de Astrofisica de Canarias. SARA\nobservatories comprise a 0.96m telescope at Kitt Peak, Arizona; a 0.6m\ninstrument on Cerro Tololo, Chile; and the 1m Jacobus Kapteyn Telescope at the\nRoque de los Muchachos, La Palma, Spain. All are operated using standard VNC or\nRadmin protocols communicating with on-site PCs. Remote operation offers\nconsiderable flexibility in scheduling, allowing long-term observational\ncadences difficult to achieve with classical observing at remote facilities, as\nwell as obvious travel savings. Multiple observers at different locations can\nshare a telescope for training, educational use, or collaborative research\nprograms. Each telescope has a CCD system for optical imaging, using\nthermoelectric cooling to avoid the need for frequent local service, and a\nsecond CCD for offset guiding. The Arizona and Chile instruments also have\nfiber-fed echelle spectrographs. Switching between imaging and spectroscopy is\nvery rapid, so a night can easily accommodate mixed observing modes. We present\nsome sample observational programs. For the benefit of other groups organizing\nsimilar consortia, we describe the operating structure and principles of SARA,\nas well as some lessons learned from almost 20 years of remote operations.", "journal": "", "doi": "10.1088/1538-3873/129/971/015002", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1608.06245v1"}
{"entry_id": "http://arxiv.org/abs/2108.03727v2", "date": "2021-08-08", "title": "Nanofibers coated with Rare-Earth complexes", "authors": "Ori Ezrah Mor, Tal Ohana, Adrien Borne, Yael Diskin Posner, Maor Asher, Omer Yaffe, Abraham Shanzer, Barak Dayan", "abstract": "Crystals and fibers doped with Rare Earth (RE) ions provide the basis to most\nof today's solid-state optical systems, from lasers and telecom devices to\nemerging potential quantum applications such as quantum memories and optical to\nmicrowave conversion. The two platforms, doped crystals and doped fibers, seem\nmutually exclusive, each having its own strengths and limitations- the former\nproviding high homogeneity and coherence, and the latter offering the\nadvantages of robust optical waveguides. Here we present a hybrid platform that\ndoes not rely on doping but rather on coating the waveguide - a tapered silica\noptical fiber - with a monolayer of complexes, each containing a single RE ion.\nThe complexes offer an identical, tailored environment to each ion, thus\nminimizing inhomogeneity and allowing tuning of their properties to the desired\napplication. Specifically, we use highly luminescent\nYb$^{+3}$[Zn(II)$_{MC}$(QXA)] complexes, which isolate the RE ion from the\nenvironment and suppress non-radiative decay channels. We demonstrate that the\nbeneficial optical transitions of the Yb$^{+3}$ are retained after deposition\non the tapered fiber, and observe an excited-state lifetime of over 0.9 ms, on\npar with state-of-the-art Yb doped inorganic crystals.", "journal": "", "doi": null, "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/2108.03727v2"}
{"entry_id": "http://arxiv.org/abs/hep-ph/0105067v2", "date": "2001-05-08", "title": "Observability of Earth-skimming Ultra-high Energy Neutrinos", "authors": "Jonathan L. Feng, Peter Fisher, Frank Wilczek, Terri M. Yu", "abstract": "Neutrinos with energies above 10^8 GeV are expected from cosmic ray\ninteractions with the microwave background and are predicted in many\nspeculative models. Such energetic neutrinos are difficult to detect, as they\nare shadowed by the Earth, but rarely interact in the atmosphere. Here we\npropose a novel detection strategy: Earth-skimming neutrinos convert to charged\nleptons that escape the Earth, and these leptons are detected in ground level\nfluorescence detectors. With the existing HiRes detector, neutrinos from some\nproposed sources are marginally detectable, and improvements of two orders of\nmagnitude are possible at the proposed Telescope Array.", "journal": "Phys.Rev.Lett. 88 (2002) 161102", "doi": "10.1103/PhysRevLett.88.161102", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph"], "pdf_url": "http://arxiv.org/pdf/hep-ph/0105067v2"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0410487v1", "date": "2004-10-20", "title": "The Earth's Gamma-ray Albedo as observed by EGRET", "authors": "Dirk Petry", "abstract": "The Earth's high energy gamma-ray emission is caused by cosmic ray\ninteractions with the atmosphere. The EGRET detector on-board the CGRO\nsatellite is only the second experiment (after SAS-2) to provide a suitable\ndataset for the comprehensive study of this emission. Approximately 60% of the\nEGRET dataset consist of gamma photons from the Earth. This conference\ncontribution presents the first results from the first analysis project to\ntackle this large dataset. Ultimate purpose is to develop an analytical model\nof the Earth's emission for use in the GLAST project. The results obtained so\nfar confirm the earlier results from SAS-2 and extend them in terms of\nstatistical precision and angular resolution.", "journal": "", "doi": "10.1063/1.1878488", "primary_category": "astro-ph", "categories": ["astro-ph", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0410487v1"}
{"entry_id": "http://arxiv.org/abs/2006.13024v2", "date": "2020-06-23", "title": "Equilibrium current vortices in rare-earth-doped simple metals", "authors": "Adam B. Cahaya, Alejandro O. Leon, Mojtaba Rahimi Aliabad, Gerrit E. W. Bauer", "abstract": "Dilute alloys of rare earths have played a vital role in understanding\nmagnetic phenomena. Here, we model the ground state of dilute 4f rare-earth\nimpurities in light metals. When the 4f subshells are open (but not\nhalf-filled), the spin-orbit coupling imprints a rotational charge current of\nconduction electrons around rare-earth atoms. The sign and amplitude of the\ncurrent oscillate similar to the RKKY spin polarization. We compute the\nobservable effect, namely the Oersted field generated by the current vortices\nand the Knight shift.", "journal": "Phys. Rev. B 103, 064433 (2021)", "doi": "10.1103/PhysRevB.103.064433", "primary_category": "cond-mat.mes-hall", "categories": ["cond-mat.mes-hall"], "pdf_url": "http://arxiv.org/pdf/2006.13024v2"}
{"entry_id": "http://arxiv.org/abs/0712.3250v1", "date": "2007-12-19", "title": "Jupiter and Super-Earth embedded in a gaseous disc", "authors": "E. Podlewska, E. Szuszkiewicz", "abstract": "In this paper we investigate the evolution of a pair of interacting planets -\na Jupiter mass planet and a Super-Earth with the 5.5 Earth masses - orbiting a\nSolar type star and embedded in a gaseous protoplanetary disc. We focus on the\neffects of type I and II orbital migrations, caused by the planet-disc\ninteraction, leading to the Super-Earth capture in first order mean motion\nresonances by the Jupiter. The stability of the resulting resonant system in\nwhich the Super-Earth is on the internal orbit relatively to the Jupiter has\nbeen studied numerically by means of full 2D hydrodynamical simulations. Our\nmain motivation is to determine the Super-Earth behaviour in the presence of\nthe gas giant in the system. It has been found that the Jupiter captures the\nSuper-Earth into the interior 3:2 or 4:3 mean motion resonances and the\nstability of such configurations depends on the initial planet positions and\neccentricity evolution. If the initial separation of planet orbits is larger or\nclose to that required for the exact resonance than the final outcome is the\nmigration of the pair of planets with the rate similar to that of the gas giant\nat least for time of our simulations. Otherwise we observe a scattering of the\nSuper-Earth from the disc. The evolution of planets immersed in the gaseous\ndisc has been compared with their behaviour in the case of the classical\nthree-body problem when the disc is absent.", "journal": "", "doi": "10.1111/j.1365-2966.2008.12871.x", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0712.3250v1"}
{"entry_id": "http://arxiv.org/abs/hep-ph/0406001v1", "date": "2004-05-31", "title": "Imaging the Earth's Interior: the Angular Distribution of Terrestrial Neutrinos", "authors": "Brian D. Fields, Kathrin A. Hochmuth", "abstract": "Decays of radionuclides throughout the Earth's interior produce geothermal\nheat, but also are a source of antineutrinos. The (angle-integrated)\ngeoneutrino flux places an integral constraint on the terrestrial radionuclide\ndistribution. In this paper, we calculate the angular distribution of\ngeoneutrinos, which opens a window on the differential radionuclide\ndistribution. We develop the general formalism for the neutrino angular\ndistribution, and we present the inverse transformation which recovers the\nterrestrial radioisotope distribution given a measurement of the neutrino\nangular distribution. Thus, geoneutrinos not only allow a means to image the\nEarth's interior, but offering a direct measure of the radioactive Earth, both\n(1) revealing the Earth's inner structure as probed by radionuclides, and (2)\nallowing for a complete determination of the radioactive heat generation as a\nfunction of radius. We present the geoneutrino angular distribution for the\nfavored Earth model which has been used to calculate geoneutrino flux. In this\nmodel the neutrino generation is dominated by decays in the Earth's mantle and\ncrust; this leads to a very ``peripheral'' angular distribution, in which 2/3\nof the neutrinos come from angles > 60 degrees away from the downward vertical.\nWe note the possibility of that the Earth's core contains potassium; different\ngeophysical predictions lead to strongly varying, and hence distinguishable,\ncentral intensities (< 30 degrees from the downward vertical). Other\nuncertainties in the models, and prospects for observation of the geoneutrino\nangular distribution, are briefly discussed. We conclude by urging the\ndevelopment and construction of antineutrino experiments with angular\nsensitivity. (Abstract abridged.)", "journal": "Earth Moon Planets 99:155-181,2006", "doi": "10.1007/s11038-006-9132-4", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph", "nucl-ex", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/hep-ph/0406001v1"}
{"entry_id": "http://arxiv.org/abs/1306.5567v1", "date": "2013-06-24", "title": "The Formation and Dynamics of Super-Earth Planets", "authors": "Nader Haghighipour", "abstract": "Super-Earths, objects slightly larger than Earth and slightly smaller than\nUranus, have found a special place in exoplanetary science. As a new class of\nplanetary bodies, these objects have challenged models of planet formation at\nboth ends of the spectrum and have triggered a great deal of research on the\ncomposition and interior dynamics of rocky planets in connection to their\nmasses and radii. Being relatively easier to detect than an Earth-sized planet\nat 1 AU around a G star, super-Earths have become the focus of worldwide\nobservational campaigns to search for habitable planets. With a range of masses\nthat allows these objects to retain moderate atmospheres and perhaps even plate\ntectonics, super-Earths may be habitable if they maintain long-term orbits in\nthe habitable zones of their host stars. Given that in the past two years a few\nsuch potentially habitable super-Earths have in fact been discovered, it is\nnecessary to develop a deep understanding of the formation and dynamical\nevolution of these objects. This article reviews the current state of research\non the formation of super-Earths and discusses different models of their\nformation and dynamical evolution.", "journal": "Annual Review of Earth and Planetary Sciences, Volume 41, pages\n  469-495 (2013)", "doi": "10.1146/annurev-earth-042711-105340", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1306.5567v1"}
{"entry_id": "http://arxiv.org/abs/2103.11131v2", "date": "2021-03-20", "title": "A subgradient algorithm for data-rate optimization in the remote state estimation problem", "authors": "Christoph Kawan, Sigurdur Hafstein, Peter Giesl", "abstract": "In the remote state estimation problem, an observer tries to reconstruct the\nstate of a dynamical system at a remote location, where no direct sensor\nmeasurements are available. The observer only has access to information sent\nthrough a digital communication channel with a finite capacity. The recently\nintroduced notion of restoration entropy provides a way to determine the\nsmallest channel capacity above which an observer can be designed that observes\nthe system without a degradation of the initial observation quality. In this\npaper, we propose a subgradient algorithm to estimate the restoration entropy\nvia the computation of an appropriate Riemannian metric on the state space,\nwhich allows to determine the approximate value of the entropy from the\ntime-one map (in the discrete-time case) or the generating vector field (for\nODE systems), respectively.", "journal": "", "doi": null, "primary_category": "math.OC", "categories": ["math.OC", "math.DS", "93B07, 93B53, 93B70"], "pdf_url": "http://arxiv.org/pdf/2103.11131v2"}
{"entry_id": "http://arxiv.org/abs/2104.12137v6", "date": "2021-04-25", "title": "A Novel Transformer Based Semantic Segmentation Scheme for Fine-Resolution Remote Sensing Images", "authors": "Libo Wang, Rui Li, Chenxi Duan, Ce Zhang, Xiaoliang Meng, Shenghui Fang", "abstract": "The fully convolutional network (FCN) with an encoder-decoder architecture\nhas been the standard paradigm for semantic segmentation. The encoder-decoder\narchitecture utilizes an encoder to capture multilevel feature maps, which are\nincorporated into the final prediction by a decoder. As the context is crucial\nfor precise segmentation, tremendous effort has been made to extract such\ninformation in an intelligent fashion, including employing dilated/atrous\nconvolutions or inserting attention modules. However, these endeavors are all\nbased on the FCN architecture with ResNet or other backbones, which cannot\nfully exploit the context from the theoretical concept. By contrast, we\nintroduce the Swin Transformer as the backbone to extract the context\ninformation and design a novel decoder of densely connected feature aggregation\nmodule (DCFAM) to restore the resolution and produce the segmentation map. The\nexperimental results on two remotely sensed semantic segmentation datasets\ndemonstrate the effectiveness of the proposed scheme.Code is available at\nhttps://github.com/WangLibo1995/GeoSeg", "journal": "", "doi": "10.1109/LGRS.2022.3143368", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2104.12137v6"}
{"entry_id": "http://arxiv.org/abs/2012.07337v1", "date": "2020-12-14", "title": "Lava Worlds: From Early Earth to Exoplanets", "authors": "Keng-Hsien Chao, Rebecca deGraffenried, Mackenzie Lach, William Nelson, Kelly Truax, Eric Gaidos", "abstract": "The magma ocean concept was first conceived to explain the geology of the\nMoon, but hemispherical or global oceans of silicate melt could be a widespread\n\"lava world\" phase of rocky planet accretion, and could persist on planets on\nshort-period orbits around other stars. The formation and crystallization of\nmagma oceans could be a defining stage in the assembly of a core, origin of a\ncrust, initiation of tectonics, and formation of an atmosphere. The last decade\nhas seen significant advances in our understanding of this phenomenon through\nanalysis of terrestrial and extraterrestrial samples, planetary missions, and\nastronomical observations of exoplanets. This review describes the energetic\nbasis of magma oceans and lava worlds and the lava lake analogs available for\nstudy on Earth and Io. It provides an overview of evidence for magma oceans\nthroughout the Solar System and considers the factors that control the rocks\nthese magma oceans leave behind. It describes research on theoretical and\nobserved exoplanets that could host extant magma oceans and summarizes efforts\nto detect and characterize them. It reviews modeling of the evolution of magma\noceans as a result of crystallization and evaporation, the interaction with the\nunderlying solid mantle, and the effects of planetary rotation. The review also\nconsiders theoretical investigations on the formation of an atmosphere in\nconcert with the magma ocean and in response to irradiation from the host star,\nand possible end-states. Finally, it describes needs and gaps in our knowledge\nand points to future opportunities with new planetary missions and space\ntelescopes to identify and better characterize lava worlds around nearby stars.", "journal": "", "doi": "10.1016/j.chemer.2020.125735", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2012.07337v1"}
{"entry_id": "http://arxiv.org/abs/2010.09766v1", "date": "2020-10-19", "title": "Which Stars can see Earth as a Transiting Exoplanet?", "authors": "L. Kaltenegger, J. Pepper", "abstract": "Transit observations have found the majority of exoplanets to date.\nSpectroscopic observations of transits and eclipses are the most commonly used\ntool to characterize exoplanet atmospheres and will be used in the search for\nlife. However, an exoplanet's orbit must be aligned with our line of sight to\nobserve a transit. Here we ask, from which stellar vantage points would a\ndistant observer be able to search for life on Earth in the same way?\n  We use the TESS Input Catalog and data from Gaia DR2 to identify the closest\nstars that could see Earth as a transiting exoplanet: We identify 1,004 Main\nSequence stars within 100 parsecs, of which 508 guarantee a minimum 10-hour\nlong observation of Earth's transit. Our star list consists of about 77%\nM-type, 12% K-type, 6% G-type, 4% F-type stars, and 1% A-type stars close to\nthe ecliptic. SETI searches like the Breakthrough Listen Initiative are already\nfocusing on this part of the sky. Our catalog now provides a target list for\nthis search. As part of the extended mission, NASA's TESS will also search for\ntransiting planets in the ecliptic to find planets that could detect life on\nour transiting Earth as well.", "journal": "", "doi": "10.1093/mnrasl/slaa161", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2010.09766v1"}
{"entry_id": "http://arxiv.org/abs/2108.03522v2", "date": "2021-08-07", "title": "Space-based weather observatory at Earth-Moon Lagrange point L1 to monitor earth's magnetotail effects on the Moon", "authors": "Saurabh Gore, Manuel Ntumba", "abstract": "Lunar hematite is formed by the oxidation of iron on the surface of the Moon\nby oxygen from the Earth's upper atmosphere. The Moon's surface is continuously\naffected by solar particles from the sun. However, Earth's magnetic tail blocks\n99 % of the solar wind and provides windows of opportunity to transport oxygen\nfrom Earth's upper atmosphere to the Moon through magnetotail when it is in its\nfull moon phase. Here, we propose to place a space weather observatory at the\nEarth-Moon L1 Lagrange point carrying a crucial payload onboard to study how\nEarth's magnetotail causes the Moon's surface to rust. The space weather\nobservatory monitors the effect of Earth's magnetic field on the Moon using\nadvanced spectroscopic sensors from Lagrange-based stations. Earth-moon L1\nLagrange point is the key location for space-weather observation as spacecraft\nnear this point obtains a nearly unobstructed view of the moon. Numerical\nmethods needed for a high-order analytical approximation have been implemented\nfor more accurate predictions.", "journal": "", "doi": "10.13140/RG.2.2.12897.84322", "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM", "astro-ph.EP", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2108.03522v2"}
{"entry_id": "http://arxiv.org/abs/1502.01097v2", "date": "2015-02-04", "title": "Dense v.s. Sparse: A Comparative Study of Sampling Analysis in Scene Classification of High-Resolution Remote Sensing Imagery", "authors": "Jingwen Hu, Gui-Song Xia, Fan Hu, Liangpei Zhang", "abstract": "Scene classification is a key problem in the interpretation of\nhigh-resolution remote sensing imagery. Many state-of-the-art methods, e.g.\nbag-of-visual-words model and its variants, the topic models as well as deep\nlearning-based approaches, share similar procedures: patch sampling, feature\ndescription/learning and classification. Patch sampling is the first and a key\nprocedure which has a great influence on the results. In the literature, many\ndifferent sampling strategies have been used, {e.g. dense sampling, random\nsampling, keypoint-based sampling and saliency-based sampling, etc. However, it\nis still not clear which sampling strategy is suitable for the scene\nclassification of high-resolution remote sensing images. In this paper, we\ncomparatively study the effects of different sampling strategies under the\nscenario of scene classification of high-resolution remote sensing images. We\ndivide the existing sampling methods into two types: dense sampling and sparse\nsampling, the later of which includes random sampling, keypoint-based sampling\nand various saliency-based sampling proposed recently. In order to compare\ntheir performances, we rely on a standard bag-of-visual-words model to\nconstruct our testing scheme, owing to their simplicity, robustness and\nefficiency. The experimental results on two commonly used datasets show that\ndense sampling has the best performance among all the strategies but with high\nspatial and computational complexity, random sampling gives better or\ncomparable results than other sparse sampling methods, like the sophisticated\nmulti-scale key-point operators and the saliency-based methods which are\nintensively studied and commonly used recently.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1502.01097v2"}
{"entry_id": "http://arxiv.org/abs/1711.00594v1", "date": "2017-11-02", "title": "Formation of Super-Earths by Tidally-Forced Turbulence", "authors": "Cong Yu", "abstract": "The Kepler observations indicate that many exoplanets are super-Earths, which\nbrings about a puzzle for the core-accretion scenario. Since observed\nsuper-Earths are in the range of critical mass, they would accrete gas\nefficiently and become gas giants. Theoretically, super-Earths are predicted to\nbe rare in the core-accretion framework. To resolve this contradiction, we\npropose that the tidally-forced turbulent diffusion may affect the heat\ntransport inside the planet. Thermal feedback induced by turbulent diffusion is\ninvestigated. We find that the tidally-forced turbulence would generate\npseudo-adiabatic regions within radiative zones, which pushes the\nradiative-convective boundaries (RCBs) inwards. This would decrease the cooling\nluminosity and enhance the Kelvin-Helmholtz (KH) timescale. For a given\nlifetime of protoplanetary disks (PPDs), there exists a critical threshold for\nthe turbulent diffusivity, $\\nu_{\\rm critical}$. If $\\nu_{\\rm turb}>\\nu_{\\rm\ncritical} $, the KH timescale is longer than the disk lifetime and the planet\nwould become a super-Earth rather than a gas giant. We find that even a small\nvalue of turbulent diffusion has influential effects on evolutions of\nsuper-Earths. $\\nu_{\\rm critical}$ increases with the core mass. We further\nascertain that, within the minimum mass extrasolar nebula (MMEN), $\\nu_{\\rm\ncritical}$ increases with the semi-major axis. This may explain the feature\nthat super-Earths are common in inner PPD regions, while gas giants are common\nin the outer PPD regions. The predicted envelope mass fraction (EMF) is not\nfully consistent with observations. We discuss physical processes, such as late\ncore assembly and mass loss mechanisms, that may be operating during\nsuper-Earth formation.", "journal": "", "doi": "10.3847/1538-4357/aa9849", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1711.00594v1"}
{"entry_id": "http://arxiv.org/abs/1603.00776v2", "date": "2016-02-29", "title": "The Search for Extraterrestrial Intelligence in Earth's Solar Transit Zone", "authors": "Ren\u00e9 Heller, Ralph E. Pudritz", "abstract": "Over the past few years, astronomers have detected thousands of planets and\ncandidate planets by observing their periodic transits in front of their host\nstars. Related methods might soon allow studies of the chemical imprints of\nlife in extrasolar planetary atmospheres. Here, we address the reciprocal\nquestion, namely, from where is Earth detectable by extrasolar observers using\nsimilar methods. We explore Earth's transit zone (ETZ), the projection of a\nband around Earth's ecliptic onto the celestial plane, where observers can\ndetect Earth transits across the Sun. The ETZ is between $0.520^\\circ$ and\n$0.537^\\circ$ wide due to the non-circular Earth orbit. The restricted ETZ\n(rETZ), where Earth transits the Sun less than 0.5 solar radii from its center,\nis ~$0.262^\\circ$ wide. We first compile a target list of 45 K and 37 G dwarf\nstars inside the rETZ and within 1 kiloparsec (3260 lightyears) using the\nHipparcos catalog. We then greatly enlarge the number of potential targets by\nconstructing an analytic galactic disk model and find that ~$10^5$ K and G\ndwarf stars should reside within the rETZ. The ongoing GAIA space mission can\npotentially discover all G dwarfs among them (several $10^4$) within the next\nfive years. Many more potentially habitable planets orbit dim, unknown M stars\nin the ETZ and other stars that traversed the ETZ long time ago. If any of\nthese planets host intelligent observers, they could have identified Earth as a\nhabitable, or even as a living, world, and we could be receiving their\nbroadcasts today. The K2 mission, the Allen Telescope Array, the upcoming\nSquare Kilometer Array, or the Green Bank Telescope might detect such\ndeliberate extraterrestrial messages. Ultimately, the ETZ would be an ideal\nregion to monitor by the Breakthrough Listen Initiatives, an upcoming survey\nthat will constitute the most comprehensive search for extraterrestrial\nintelligence so far.", "journal": "", "doi": "10.1089/ast.2015.1358", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1603.00776v2"}
{"entry_id": "http://arxiv.org/abs/1604.01080v2", "date": "2016-04-04", "title": "Capabilities of Earth-based radar facilities for near-Earth asteroid observations", "authors": "Shantanu. P. Naidu, Lance. A. M. Benner, Jean-Luc Margot, Michael. W. Busch, Patrick. A. Taylor", "abstract": "We evaluated the planetary radar capabilities at Arecibo, the Goldstone 70-m\nDSS-14 and 34-m DSS-13 antennas, the 70-m DSS-43 antenna at Canberra, the Green\nBank Telescope, and the Parkes Radio Telescope in terms of their relative\nsensitivities and the number of known near-Earth asteroids (NEAs) detectable\nper year in monostatic and bistatic configurations. In the 2015 calendar year,\nmonostatic observations with Arecibo and DSS-14 were capable of detecting 253\nand 131 NEAs respectively, with signal-to-noise ratios (SNRs) greater than\n30/track. Combined, the two observatories were capable of detecting 276 NEAs.\nOf these, Arecibo detected 77 and Goldstone detected 32, or 30% and 24% the\nnumbers that were possible. The two observatories detected an additional 18 and\n7 NEAs respectively, with SNRs of less than 30/track. This indicates that a\nsubstantial number of potential targets are not being observed. The bistatic\nconfiguration with DSS-14 transmitting and the Green Bank Telescope receiving\nwas capable of detecting about 195 NEAs, or ~50% more than with monostatic\nobservations at DSS-14. Most of the detectable asteroids were targets of\nopportunity that were discovered less than 15 days before the end of their\nobserving windows. About 50% of the detectable asteroids have absolute\nmagnitudes > 25, which corresponds diameters < ~30 m.", "journal": "", "doi": "10.3847/0004-6256/152/4/99", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/1604.01080v2"}
{"entry_id": "http://arxiv.org/abs/2006.05198v1", "date": "2020-06-09", "title": "The cloudbow of planet Earth observed in polarisation", "authors": "Michael F. Sterzik, Stefano Bagnulo, Claudia Emde, Mihail Manev", "abstract": "Scattering processes in the atmospheres of planets cause characteristic\nfeatures that can be particularly well observed in polarisation. For planet\nEarth, both molecular and scattering by small particles imprint specific\nsignatures in its phase curve. An unequivocal prediction of a\nliquid-water-loaded atmosphere is the existence of a rainbow feature at a\nscattering angle of around 138-144deg. Earthshine allows us to observe the\nprimary rainbow in linear polarisation. We observed polarisation spectra of\nEarthshine using FORS2 at the Very Large Telescope for phase angles from 33deg\nto 65deg (Sun--Earth--Moon angle). The spectra were used to derive the degree\nof polarisation in the B, V, R, and I passbands and the phase curve from 33deg\nto 136deg . The new observations extend to the smallest phases that can be\nobserved from the ground. The degree of polarisation of planet Earth is\nincreasing for decreasing phase angles downwards of 45deg. From comparison of\nthe phase curve observed with models of an Earth-type atmosphere we are able to\ndetermine the refractive index of water and to constrain the mean water droplet\nsizes to 6-7 mum. Furthermore, we can retrieve the mean cloud fraction of\nliquid water clouds to 0.3, and the mean optical depth of the water clouds to\nvalues between 10 and 20. Our observations allow us to discern two\nfundamentally different scattering mechanisms of the atmosphere of planet\nEarth: molecular and particle scattering. The physical and chemical properties\ncan be retrieved with high fidelity through suitable inversion of the phase\ncurve. Observations of polarimetric phase curves of planets beyond the Solar\nSystem shall be extremely valuable for a thorough characterisation of their\natmospheres.", "journal": "A&A 639, A89 (2020)", "doi": "10.1051/0004-6361/202038270", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2006.05198v1"}
{"entry_id": "http://arxiv.org/abs/1405.4780v1", "date": "2014-05-19", "title": "High resolution transmission spectrum of the Earth's atmosphere -- Seeing Earth as an exoplanet using a lunar eclipse", "authors": "Fei Yan, Robert A. E. Fosbury, Monika G. Petr-Gotzens, Gang Zhao, Wei Wang, Liang Wang, Yujuan Liu, Enric Pall\u00e9", "abstract": "With the rapid developments in the exoplanet field, more and more terrestrial\nexoplanets are being detected. Characterising their atmospheres using transit\nobservations will become a key datum in the quest for detecting an Earth-like\nexoplanet. The atmospheric transmission spectrum of our Earth will be an ideal\ntemplate for comparison with future exo-Earth candidates. By observing a lunar\neclipse, which offers a similar configuration to that of an exoplanet transit,\nwe have obtained a high resolution and high signal-to-noise ratio transmission\nspectrum of the Earth's atmosphere. This observation was performed with the\nHigh Resolution Spectrograph at Xinglong Station, China during the total lunar\neclipse in December 2011. We compare the observed transmission spectrum with\nour atmospheric model, and determine the characteristics of the various\natmospheric species in detail. In the transmission spectrum, O2, O3, O2-O2, NO2\nand H2O are detected, and their column densities are measured and compared with\nthe satellites data. The visible Chappuis band of ozone produces the most\nprominent absorption feature, which suggests that ozone is a promising molecule\nfor the future exo-Earth characterization. The individual O2 lines are resolved\nand O2 isotopes are clearly detected. Our new observations do not confirm the\nabsorption features of Ca II or Na I which have been reported in previous lunar\neclipse observations. However, features in these and some other strong\nFraunhofer line positions do occur in the observed spectrum. We propose that\nthese are due to a Raman-scattered component in the forward-scattered sunlight\nappearing in the lunar umbral spectrum. Water vapour absorption is found to be\nrather weak in our spectrum because the atmosphere we probed is relatively dry,\nwhich prompts us to discuss the detectability of water vapour in Earth-like\nexoplanet atmospheres.", "journal": "", "doi": "10.1017/S1473550414000172", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1405.4780v1"}
{"entry_id": "http://arxiv.org/abs/1909.01075v2", "date": "2019-07-07", "title": "High obliquity, high Angular Momentum Earth as Moon origin revisited by Advanced Kinematic Model of Earth-Moon System", "authors": "Bijay Kumar Sharma", "abstract": "Matija Cuk et.al (2016) have proposed a new model for the birth and tidal\nevolution of our natural satellite Moon, born from impact generated terrestrial\ndebris in the equatorial plane of high obliquity, high angular momentum Earth.\nThis paper examines their findings critically in the light of advanced\nkinematic model (AKM) which includes Earth's obliquity (\\phi), Moon's orbital\nplane inclination (\\alpha) , Moon's obliquity (\\beta) and lunar's orbit\neccentricity (e). For the real Earth-Moon (E-M) system, the history of\nevolution of \\phi, \\alpha, \\beta, e and (length of month)/(length of day) or\nLOM/LOD is traced from 45R_{E} to 60.33R_{E} where R_{E} is Earth Radius. It is\nshown that AKM's valid range of application is from 45R_{E} to 60.33R_{E} . The\nevolution of {\\alpha}, \\beta, e is in correspondence with the simulation\nresults of Matija Cuk et.al (2016) but evolution of Earth's obliquity has a\nbreak at 45R_{E} . According to AKM , earlier than 45RE Earth should achieve\nzero degree obliquity in order to achieve the modern value of 23.44{\\deg}\nobliquity. Cuk et al (2016) do not explain how this can be achieved.AKM stands\nvindicated because using protocol exchange algorithm (described in S6 SOM), AKM\nhas successfully given precise theoretical formalism of Observed LOD curve for\nthe last 1.2Gy time span opening the way for early warning and forecasting\nmethods for Earth-quake and sudden volcanic eruptions(See S7 of SOM).", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1909.01075v2"}
{"entry_id": "http://arxiv.org/abs/hep-ph/9903302v1", "date": "1999-03-09", "title": "Remarks on parametric resonance of neutrino oscillations in the earth", "authors": "E. Kh. Akhmedov", "abstract": "Neutrino oscillations in matter can exhibit a specific resonance enhancement\n-- parametric resonance, which is different from the MSW resonance. Recently it\nhas been shown that the oscillations of atmospheric and solar neutrinos inside\nthe earth can undergo parametric enhancement when neutrino trajectories cross\nthe core of the earth. In this paper we continue the study of the parametric\nresonance of neutrino oscillations in the earth. The following issues are\ndiscussed: stability of the resonance with respect to the variations of the\nzenith angle of the neutrino source; higher-order resonances; prospects of the\nexperimental observation of the parametric resonance of neutrino oscillations.\nWe also comment on a recent controversy regarding the physical nature of the\nresonance enhancement of the oscillations of the core crossing neutrinos in the\nearth.", "journal": "", "doi": "10.1007/s12043-000-0006-4", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph", "hep-ex"], "pdf_url": "http://arxiv.org/pdf/hep-ph/9903302v1"}
{"entry_id": "http://arxiv.org/abs/2004.02692v1", "date": "2020-04-06", "title": "A novel change point approach for the detection of gas emission sources using remotely contained concentration data", "authors": "Idris Eckley, Claudia Kirch, Silke Weber", "abstract": "Motivated by an example from remote sensing of gas emission sources, we\nderive two novel change point procedures for multivariate time series where, in\ncontrast to classical change point literature, the changes are not required to\nbe aligned in the different components of the time series. Instead the change\npoints are described by a functional relationship where the precise shape\ndepends on unknown parameters of interest such as the source of the gas\nemission in the above example. Two different types of tests and the\ncorresponding estimators for the unknown parameters describing the change\nlocations are proposed. We derive the null asymptotics for both tests under\nweak assumptions on the error time series and show asymptotic consistency under\nalternatives. Furthermore, we prove consistency for the corresponding\nestimators of the parameters of interest. The small sample behavior of the\nmethodology is assessed by means of a simulation study and the above remote\nsensing example analyzed in detail.", "journal": "", "doi": null, "primary_category": "stat.ME", "categories": ["stat.ME", "stat.AP", "62H12, 62M10, 62G20"], "pdf_url": "http://arxiv.org/pdf/2004.02692v1"}
{"entry_id": "http://arxiv.org/abs/1608.04290v1", "date": "2016-08-15", "title": "Robust Volume Minimization-Based Matrix Factorization for Remote Sensing and Document Clustering", "authors": "Xiao Fu, Kejun Huang, Bo Yang, Wing-Kin Ma, Nicholas D. Sidiropoulos", "abstract": "This paper considers \\emph{volume minimization} (VolMin)-based structured\nmatrix factorization (SMF). VolMin is a factorization criterion that decomposes\na given data matrix into a basis matrix times a structured coefficient matrix\nvia finding the minimum-volume simplex that encloses all the columns of the\ndata matrix. Recent work showed that VolMin guarantees the identifiability of\nthe factor matrices under mild conditions that are realistic in a wide variety\nof applications. This paper focuses on both theoretical and practical aspects\nof VolMin. On the theory side, exact equivalence of two independently developed\nsufficient conditions for VolMin identifiability is proven here, thereby\nproviding a more comprehensive understanding of this aspect of VolMin. On the\nalgorithm side, computational complexity and sensitivity to outliers are two\nkey challenges associated with real-world applications of VolMin. These are\naddressed here via a new VolMin algorithm that handles volume regularization in\na computationally simple way, and automatically detects and {iteratively\ndownweights} outliers, simultaneously. Simulations and real-data experiments\nusing a remotely sensed hyperspectral image and the Reuters document corpus are\nemployed to showcase the effectiveness of the proposed algorithm.", "journal": "", "doi": "10.1109/TSP.2016.2602800", "primary_category": "stat.ML", "categories": ["stat.ML"], "pdf_url": "http://arxiv.org/pdf/1608.04290v1"}
{"entry_id": "http://arxiv.org/abs/1910.06041v1", "date": "2019-10-14", "title": "Encoder-Decoder based CNN and Fully Connected CRFs for Remote Sensed Image Segmentation", "authors": "Vikas Agaradahalli Gurumurthy", "abstract": "With the advancement of remote-sensed imaging large volumes of very high\nresolution land cover images can now be obtained. Automation of object\nrecognition in these 2D images, however, is still a key issue. High intra-class\nvariance and low inter-class variance in Very High Resolution (VHR) images\nhamper the accuracy of prediction in object recognition tasks. Most successful\ntechniques in various computer vision tasks recently are based on deep\nsupervised learning. In this work, a deep Convolutional Neural Network (CNN)\nbased on symmetric encoder-decoder architecture with skip connections is\nemployed for the 2D semantic segmentation of most common land cover object\nclasses - impervious surface, buildings, low vegetation, trees and cars. Atrous\nconvolutions are employed to have large receptive field in the proposed CNN\nmodel. Further, the CNN outputs are post-processed using Fully Connected\nConditional Random Field (FCRF) model to refine the CNN pixel label\npredictions. The proposed CNN-FCRF model achieves an overall accuracy of 90.5%\non the ISPRS Vaihingen Dataset.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/1910.06041v1"}
{"entry_id": "http://arxiv.org/abs/2006.00836v1", "date": "2020-06-01", "title": "Multi-scale Cloud Detection in Remote Sensing Images using a Dual Convolutional Neural Network", "authors": "Markku Luotamo, Sari Mets\u00e4m\u00e4ki, Arto Klami", "abstract": "Semantic segmentation by convolutional neural networks (CNN) has advanced the\nstate of the art in pixel-level classification of remote sensing images.\nHowever, processing large images typically requires analyzing the image in\nsmall patches, and hence features that have large spatial extent still cause\nchallenges in tasks such as cloud masking. To support a wider scale of spatial\nfeatures while simultaneously reducing computational requirements for large\nsatellite images, we propose an architecture of two cascaded CNN model\ncomponents successively processing undersampled and full resolution images. The\nfirst component distinguishes between patches in the inner cloud area from\npatches at the cloud's boundary region. For the cloud-ambiguous edge patches\nrequiring further segmentation, the framework then delegates computation to a\nfine-grained model component. We apply the architecture to a cloud detection\ndataset of complete Sentinel-2 multispectral images, approximately annotated\nfor minimal false negatives in a land use application. On this specific task\nand data, we achieve a 16\\% relative improvement in pixel accuracy over a CNN\nbaseline based on patching.", "journal": "", "doi": "10.1109/TGRS.2020.3015272", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "cs.NE", "I.2.6; I.4.6"], "pdf_url": "http://arxiv.org/pdf/2006.00836v1"}
{"entry_id": "http://arxiv.org/abs/2008.12447v1", "date": "2020-08-28", "title": "Fast Single-shot Ship Instance Segmentation Based on Polar Template Mask in Remote Sensing Images", "authors": "Zhenhang Huang, Shihao Sun, Ruirui Li", "abstract": "Object detection and instance segmentation in remote sensing images is a\nfundamental and challenging task, due to the complexity of scenes and targets.\nThe latest methods tried to take into account both the efficiency and the\naccuracy of instance segmentation. In order to improve both of them, in this\npaper, we propose a single-shot convolutional neural network structure, which\nis conceptually simple and straightforward, and meanwhile makes up for the\nproblem of low accuracy of single-shot networks. Our method, termed with\nSSS-Net, detects targets based on the location of the object's center and the\ndistances between the center and the points on the silhouette sampling with\nnon-uniform angle intervals, thereby achieving abalanced sampling of lines in\nmask generation. In addition, we propose a non-uniform polar template IoU based\non the contour template in polar coordinates. Experiments on both the Airbus\nShip Detection Challenge dataset and the ISAIDships dataset show that SSS-Net\nhas strong competitiveness in precision and speed for ship instance\nsegmentation.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.12447v1"}
{"entry_id": "http://arxiv.org/abs/2009.01616v1", "date": "2020-09-03", "title": "Few-shot Object Detection with Feature Attention Highlight Module in Remote Sensing Images", "authors": "Zixuan Xiao, Ping Zhong, Yuan Quan, Xuping Yin, Wei Xue", "abstract": "In recent years, there are many applications of object detection in remote\nsensing field, which demands a great number of labeled data. However, in many\ncases, data is extremely rare. In this paper, we proposed a few-shot object\ndetector which is designed for detecting novel objects based on only a few\nexamples. Through fully leveraging labeled base classes, our model that is\ncomposed of a feature-extractor, a feature attention highlight module as well\nas a two-stage detection backend can quickly adapt to novel classes. The\npre-trained feature extractor whose parameters are shared produces general\nfeatures. While the feature attention highlight module is designed to be\nlight-weighted and simple in order to fit the few-shot cases. Although it is\nsimple, the information provided by it in a serial way is helpful to make the\ngeneral features to be specific for few-shot objects. Then the object-specific\nfeatures are delivered to the two-stage detection backend for the detection\nresults. The experiments demonstrate the effectiveness of the proposed method\nfor few-shot cases.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2009.01616v1"}
{"entry_id": "http://arxiv.org/abs/2009.12596v1", "date": "2020-09-26", "title": "Few-shot Object Detection with Self-adaptive Attention Network for Remote Sensing Images", "authors": "Zixuan Xiao, Wei Xue, Ping Zhong", "abstract": "In remote sensing field, there are many applications of object detection in\nrecent years, which demands a great number of labeled data. However, we may be\nfaced with some cases where only limited data are available. In this paper, we\nproposed a few-shot object detector which is designed for detecting novel\nobjects provided with only a few examples. Particularly, in order to fit the\nobject detection settings, our proposed few-shot detector concentrates on the\nrelations that lie in the level of objects instead of the full image with the\nassistance of Self-Adaptive Attention Network (SAAN). The SAAN can fully\nleverage the object-level relations through a relation GRU unit and\nsimultaneously attach attention on object features in a self-adaptive way\naccording to the object-level relations to avoid some situations where the\nadditional attention is useless or even detrimental. Eventually, the detection\nresults are produced from the features that are added with attention and thus\nare able to be detected simply. The experiments demonstrate the effectiveness\nof the proposed method in few-shot scenes.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2009.12596v1"}
{"entry_id": "http://arxiv.org/abs/2011.14302v2", "date": "2020-11-29", "title": "Multi-stage Attention ResU-Net for Semantic Segmentation of Fine-Resolution Remote Sensing Images", "authors": "Rui Li, Shunyi Zheng, Chenxi Duan, Jianlin Su, Ce Zhang", "abstract": "The attention mechanism can refine the extracted feature maps and boost the\nclassification performance of the deep network, which has become an essential\ntechnique in computer vision and natural language processing. However, the\nmemory and computational costs of the dot-product attention mechanism increase\nquadratically with the spatio-temporal size of the input. Such growth hinders\nthe usage of attention mechanisms considerably in application scenarios with\nlarge-scale inputs. In this Letter, we propose a Linear Attention Mechanism\n(LAM) to address this issue, which is approximately equivalent to dot-product\nattention with computational efficiency. Such a design makes the incorporation\nbetween attention mechanisms and deep networks much more flexible and\nversatile. Based on the proposed LAM, we re-factor the skip connections in the\nraw U-Net and design a Multi-stage Attention ResU-Net (MAResU-Net) for semantic\nsegmentation from fine-resolution remote sensing images. Experiments conducted\non the Vaihingen dataset demonstrated the effectiveness and efficiency of our\nMAResU-Net. Open-source code is available at\nhttps://github.com/lironui/Multistage-Attention-ResU-Net.", "journal": "", "doi": "10.1109/LGRS.2021.3063381", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2011.14302v2"}
{"entry_id": "http://arxiv.org/abs/2106.05193v1", "date": "2021-06-06", "title": "A Hybrid APM-CPGSO Approach for Constraint Satisfaction Problem Solving: Application to Remote Sensing", "authors": "Zouhayra Ayadi, Wadii Boulila, Imed Riadh Farah", "abstract": "Constraint satisfaction problem (CSP) has been actively used for modeling and\nsolving a wide range of complex real-world problems. However, it has been\nproven that developing efficient methods for solving CSP, especially for large\nproblems, is very difficult and challenging. Existing complete methods for\nproblem-solving are in most cases unsuitable. Therefore, proposing hybrid\nCSP-based methods for problem-solving has been of increasing interest in the\nlast decades. This paper aims at proposing a novel approach that combines\nincomplete and complete CSP methods for problem-solving. The proposed approach\ntakes advantage of the group search algorithm (GSO) and the constraint\npropagation (CP) methods to solve problems related to the remote sensing field.\nTo the best of our knowledge, this paper represents the first study that\nproposes a hybridization between an improved version of GSO and CP in the\nresolution of complex constraint-based problems. Experiments have been\nconducted for the resolution of object recognition problems in satellite\nimages. Results show good performances in terms of convergence and running time\nof the proposed CSP-based method compared to existing state-of-the-art methods.", "journal": "", "doi": null, "primary_category": "cs.AI", "categories": ["cs.AI"], "pdf_url": "http://arxiv.org/pdf/2106.05193v1"}
{"entry_id": "http://arxiv.org/abs/2108.07955v1", "date": "2021-08-18", "title": "WRICNet:A Weighted Rich-scale Inception Coder Network for Multi-Resolution Remote Sensing Image Change Detection", "authors": "Yu Jiang, Lei Hu, Yongmei Zhang, Xin Yang", "abstract": "Majority models of remote sensing image changing detection can only get great\neffect in a specific resolution data set. With the purpose of improving change\ndetection effectiveness of the model in the multi-resolution data set, a\nweighted rich-scale inception coder network (WRICNet) is proposed in this\narticle, which can make a great fusion of shallow multi-scale features, and\ndeep multi-scale features. The weighted rich-scale inception module of the\nproposed can obtain shallow multi-scale features, the weighted rich-scale coder\nmodule can obtain deep multi-scale features. The weighted scale block assigns\nappropriate weights to features of different scales, which can strengthen\nexpressive ability of the edge of the changing area. The performance\nexperiments on the multi-resolution data set demonstrate that, compared to the\ncomparative methods, the proposed can further reduce the false alarm outside\nthe change area, and the missed alarm in the change area, besides, the edge of\nthe change area is more accurate. The ablation study of the proposed shows that\nthe training strategy, and improvements of this article can improve the\neffectiveness of change detection.", "journal": "", "doi": "10.1109/TGRS.2022.3145652", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2108.07955v1"}
{"entry_id": "http://arxiv.org/abs/2108.13902v1", "date": "2021-08-31", "title": "Estimation of Air Pollution with Remote Sensing Data: Revealing Greenhouse Gas Emissions from Space", "authors": "Linus Scheibenreif, Michael Mommert, Damian Borth", "abstract": "Air pollution is a major driver of climate change. Anthropogenic emissions\nfrom the burning of fossil fuels for transportation and power generation emit\nlarge amounts of problematic air pollutants, including Greenhouse Gases (GHGs).\nDespite the importance of limiting GHG emissions to mitigate climate change,\ndetailed information about the spatial and temporal distribution of GHG and\nother air pollutants is difficult to obtain. Existing models for surface-level\nair pollution rely on extensive land-use datasets which are often locally\nrestricted and temporally static. This work proposes a deep learning approach\nfor the prediction of ambient air pollution that only relies on remote sensing\ndata that is globally available and frequently updated. Combining optical\nsatellite imagery with satellite-based atmospheric column density air pollution\nmeasurements enables the scaling of air pollution estimates (in this case\nNO$_2$) to high spatial resolution (up to $\\sim$10m) at arbitrary locations and\nadds a temporal component to these estimates. The proposed model performs with\nhigh accuracy when evaluated against air quality measurements from ground\nstations (mean absolute error $<$6$~\\mu g/m^3$). Our results enable the\nidentification and temporal monitoring of major sources of air pollution and\nGHGs.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV", "I.4"], "pdf_url": "http://arxiv.org/pdf/2108.13902v1"}
{"entry_id": "http://arxiv.org/abs/2110.09515v1", "date": "2021-10-14", "title": "Spatial-temporal water area monitoring of Miyun Reservoir using remote sensing imagery from 1984 to 2020", "authors": "Chang Liu, Hairong Tang, Luyan Ji, Yongchao Zhao", "abstract": "Miyun Reservoir has produced huge benefits in flood control, agricultural\nirrigation, power generation, aquaculture, tourism, and urban water supply.\nAccurately water mapping is of great significance to the ecological environment\nmonitoring of the Miyun Reservoir and the management of the South-to-North\nWater Diversion Project. On the 60th anniversary of the completion of the Miyun\nReservoir, we took the Miyun Reservoir as the study area and collected all the\nLandsat-5 and Landsat-8 remote sensing images from 1984 to 2020 for water\nmapping. Based on the spectral, topographical and temporal-spatial\ncharacteristics of water, we proposed an automated method for long-term\nresearvoir mapping, which can solve the problems caused by cloud, shadow, ice\nand snow pixels. Moreover, it can also deal with 'the same objects with\ndifferent spectra' and spectral mixed problems. The overall accuracy is as high\nas 98.2% for the case with no cloud or snow/ice cover. The landscape division\nindex is introduced to analyze the morphological changes of Miyun Reservoir.\nBased on the mapping results, we analyzed the changes of Miyun Reservoir from\n1984 to 2020 and the driving factors of them.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2110.09515v1"}
{"entry_id": "http://arxiv.org/abs/2212.10236v1", "date": "2022-12-20", "title": "Self-Pair: Synthesizing Changes from Single Source for Object Change Detection in Remote Sensing Imagery", "authors": "Minseok Seo, Hakjin Lee, Yongjin Jeon, Junghoon Seo", "abstract": "For change detection in remote sensing, constructing a training dataset for\ndeep learning models is difficult due to the requirements of bi-temporal\nsupervision. To overcome this issue, single-temporal supervision which treats\nchange labels as the difference of two semantic masks has been proposed. This\nnovel method trains a change detector using two spatially unrelated images with\ncorresponding semantic labels such as building. However, training on unpaired\ndatasets could confuse the change detector in the case of pixels that are\nlabeled unchanged but are visually significantly different. In order to\nmaintain the visual similarity in unchanged area, in this paper, we emphasize\nthat the change originates from the source image and show that manipulating the\nsource image as an after-image is crucial to the performance of change\ndetection. Extensive experiments demonstrate the importance of maintaining\nvisual information between pre- and post-event images, and our method\noutperforms existing methods based on single-temporal supervision. code is\navailable at https://github.com/seominseok0429/Self-Pair-for-Change-Detection.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2212.10236v1"}
{"entry_id": "http://arxiv.org/abs/2208.07722v2", "date": "2022-08-16", "title": "Unsupervised domain adaptation semantic segmentation of high-resolution remote sensing imagery with invariant domain-level prototype memory", "authors": "Jingru Zhu, Ya Guo, Geng Sun, Libo Yang, Min Deng, Jie Chen", "abstract": "Semantic segmentation is a key technique involved in automatic interpretation\nof high-resolution remote sensing (HRS) imagery and has drawn much attention in\nthe remote sensing community. Deep convolutional neural networks (DCNNs) have\nbeen successfully applied to the HRS imagery semantic segmentation task due to\ntheir hierarchical representation ability. However, the heavy dependency on a\nlarge number of training data with dense annotation and the sensitiveness to\nthe variation of data distribution severely restrict the potential application\nof DCNNs for the semantic segmentation of HRS imagery. This study proposes a\nnovel unsupervised domain adaptation semantic segmentation network\n(MemoryAdaptNet) for the semantic segmentation of HRS imagery. MemoryAdaptNet\nconstructs an output space adversarial learning scheme to bridge the domain\ndistribution discrepancy between source domain and target domain and to narrow\nthe influence of domain shift. Specifically, we embed an invariant feature\nmemory module to store invariant domain-level context information because the\nfeatures obtained from adversarial learning only tend to represent the variant\nfeature of current limited inputs. This module is integrated by a category\nattention-driven invariant domain-level context aggregation module to current\npseudo invariant feature for further augmenting the pixel representations. An\nentropy-based pseudo label filtering strategy is used to update the memory\nmodule with high-confident pseudo invariant feature of current target images.\nExtensive experiments under three cross-domain tasks indicate that our proposed\nMemoryAdaptNet is remarkably superior to the state-of-the-art methods.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, 2023", "doi": "10.1109/TGRS.2023.3243042", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2208.07722v2"}
{"entry_id": "http://arxiv.org/abs/1901.07925v2", "date": "2019-01-23", "title": "ORSIm Detector: A Novel Object Detection Framework in Optical Remote Sensing Imagery Using Spatial-Frequency Channel Features", "authors": "Xin Wu, Danfeng Hong, Jiaojiao Tian, Jocelyn Chanussot, Wei Li, Ran Tao", "abstract": "With the rapid development of spaceborne imaging techniques, object detection\nin optical remote sensing imagery has drawn much attention in recent decades.\nWhile many advanced works have been developed with powerful learning\nalgorithms, the incomplete feature representation still cannot meet the demand\nfor effectively and efficiently handling image deformations, particularly\nobjective scaling and rotation. To this end, we propose a novel object\ndetection framework, called optical remote sensing imagery detector (ORSIm\ndetector), integrating diverse channel features extraction, feature learning,\nfast image pyramid matching, and boosting strategy. ORSIm detector adopts a\nnovel spatial-frequency channel feature (SFCF) by jointly considering the\nrotation-invariant channel features constructed in frequency domain and the\noriginal spatial channel features (e.g., color channel, gradient magnitude).\nSubsequently, we refine SFCF using learning-based strategy in order to obtain\nthe high-level or semantically meaningful features. In the test phase, we\nachieve a fast and coarsely-scaled channel computation by mathematically\nestimating a scaling factor in the image domain. Extensive experimental results\nconducted on the two different airborne datasets are performed to demonstrate\nthe superiority and effectiveness in comparison with previous state-of-the-art\nmethods.", "journal": "IEEE Transactions on Geoscience and Remote Sensing, 2019, 57(7):\n  5146-5158", "doi": "10.1109/TGRS.2019.2897139", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1901.07925v2"}
{"entry_id": "http://arxiv.org/abs/1307.6821v1", "date": "2013-07-25", "title": "The Earth's Equilibrium Climate Sensitivity and Thermal Inertia", "authors": "B. S. H. Royce, S. H. Lam", "abstract": "The Earth's equilibrium climate sensitivity has received much attention\nbecause of its relevance and importance for global warming policymaking. This\npaper focuses on the Earth's \\emph{thermal inertia time scale} which has\nreceived relatively little attention. The difference between the observed\ntransient climate sensitivity and the equilibrium climate sensitivity is shown\nto be proportional to the thermal inertia time scale, and the numerical value\nof the proportionality factor is determined using recent observational data.\n  Many useful policymaking insights can be extracted from the resulting\nempirical quantitative relation.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/1307.6821v1"}
{"entry_id": "http://arxiv.org/abs/2210.04510v1", "date": "2022-10-10", "title": "Multi-Modal Fusion Transformer for Visual Question Answering in Remote Sensing", "authors": "Tim Siebert, Kai Norman Clasen, Mahdyar Ravanbakhsh, Beg\u00fcm Demir", "abstract": "With the new generation of satellite technologies, the archives of remote\nsensing (RS) images are growing very fast. To make the intrinsic information of\neach RS image easily accessible, visual question answering (VQA) has been\nintroduced in RS. VQA allows a user to formulate a free-form question\nconcerning the content of RS images to extract generic information. It has been\nshown that the fusion of the input modalities (i.e., image and text) is crucial\nfor the performance of VQA systems. Most of the current fusion approaches use\nmodality-specific representations in their fusion modules instead of joint\nrepresentation learning. However, to discover the underlying relation between\nboth the image and question modality, the model is required to learn the joint\nrepresentation instead of simply combining (e.g., concatenating, adding, or\nmultiplying) the modality-specific representations. We propose a multi-modal\ntransformer-based architecture to overcome this issue. Our proposed\narchitecture consists of three main modules: i) the feature extraction module\nfor extracting the modality-specific features; ii) the fusion module, which\nleverages a user-defined number of multi-modal transformer layers of the\nVisualBERT model (VB); and iii) the classification module to obtain the answer.\nExperimental results obtained on the RSVQAxBEN and RSVQA-LR datasets (which are\nmade up of RGB bands of Sentinel-2 images) demonstrate the effectiveness of\nVBFusion for VQA tasks in RS. To analyze the importance of using other spectral\nbands for the description of the complex content of RS images in the framework\nof VQA, we extend the RSVQAxBEN dataset to include all the spectral bands of\nSentinel-2 images with 10m and 20m spatial resolution.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2210.04510v1"}
{"entry_id": "http://arxiv.org/abs/1610.08213v3", "date": "2016-10-26", "title": "Quantum correlations responsible for remote state creation: strong and weak control parameters", "authors": "S. I. Doronin, A. I. Zenchuk", "abstract": "We study the quantum correlations between the two remote qubits (sender and\nreceiver) connected by the transmission line (homogeneous spin-1/2 chain)\ndepending on the parameters of the sender's and receiver's initial states\n(control parameters).\n  We consider two different measures of quantum correlations: the entanglement\n(a traditional measure) and the informational correlation (based on the\nparameter exchange between the sender and receiver).\n  We find the domain in the control parameter space yielding (i) zero\nentanglement between the sender and receiver during the whole evolution period\nand (ii) non-vanishing informational correlation between the sender and\nreceiver, thus showing that the informational correlation is responsible for\nthe remote state creation. Among the control parameters, there are the strong\nparameters (which strongly effect the values of studied measures) and the weak\nones (whose effect is negligible), therewith the eigenvalues of the initial\nstate are given a privileged role. We also show that the problem of small\nentanglement (concurrence) in quantum information processing is similar (in\ncertain sense) to the problem of small determinants in linear algebra. A\nparticular model of 40-node spin-1/2 communication line is presented.", "journal": "Quantum Inf. Process. v.16(3), 69 (2017)", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/1610.08213v3"}
{"entry_id": "http://arxiv.org/abs/1910.03517v2", "date": "2019-10-08", "title": "Real-time processing of high-resolution video and 3D model-based tracking for remote towers", "authors": "Oliver J. D. Barrowclough, Sverre Briseid, Georg Muntingh, Torbj\u00f8rn Viksand", "abstract": "High quality video data is a core component in emerging remote tower\noperations as it inherently contains a huge amount of information on which an\nair traffic controller can base decisions. Various digital technologies also\nhave the potential to exploit this data to bring enhancements, including\ntracking ground movements by relating events in the video view to their\npositions in 3D space. The total resolution of remote tower setups with\nmultiple cameras often exceeds 25 million RGB pixels and is captured at 30\nframes per second or more. It is thus a challenge to efficiently process all\nthe data in such a way as to provide relevant real-time enhancements to the\ncontroller. In this paper we discuss how a number of improvements can be\nimplemented efficiently on a single workstation by decoupling processes and\nutilizing hardware for parallel computing. We also highlight how decoupling the\nprocesses in this way increases resilience of the software solution in the\nsense that failure of a single component does not impair the function of the\nother components.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1910.03517v2"}
{"entry_id": "http://arxiv.org/abs/2103.14477v1", "date": "2021-03-26", "title": "On the Semi-Decidability of Remote State Estimation and Stabilization via Noisy Communication Channels", "authors": "Holger Boche, Yannik B\u00f6ck, Christian Deppe", "abstract": "We consider the task of remote state estimation and stabilization of\ndisturbed linear plants via noisy communication channels. In 2007 Matveev and\nSavkin established a surprising link between this problem and Shannon's theory\nof zero-error communication. By applying very recent results of computability\nof the channel reliability function and computability of the zero-error\ncapacity of noisy channels by Boche and Deppe, we analyze if, on the set of\nlinear time-invariant systems paired with a noisy communication channel, it is\nuniformly decidable by means of a Turing machine whether remote state\nestimation and stabilization is possible. The answer to this question largely\ndepends on whether the plant is disturbed by random noise or not. Our analysis\nincorporates scenarios both with and without channel feedback, as well as a\nweakened form of state estimation and stabilization. In the broadest sense, our\nresults yield a fundamental limit to the capabilities of computer-aided design\nand autonomous systems, assuming they are based on real-world digital\ncomputers.", "journal": "", "doi": null, "primary_category": "math.OC", "categories": ["math.OC", "cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2103.14477v1"}
{"entry_id": "http://arxiv.org/abs/2104.10085v1", "date": "2021-04-20", "title": "Predicting Medical Interventions from Vital Parameters: Towards a Decision Support System for Remote Patient Monitoring", "authors": "Kordian Gontarska, Weronika Wrazen, Jossekin Beilharz, Robert Schmid, Lauritz Thamsen, Andreas Polze", "abstract": "Cardiovascular diseases and heart failures in particular are the main cause\nof non-communicable disease mortality in the world. Constant patient monitoring\nenables better medical treatment as it allows practitioners to react on time\nand provide the appropriate treatment. Telemedicine can provide constant remote\nmonitoring so patients can stay in their homes, only requiring medical sensing\nequipment and network connections. A limiting factor for telemedical centers is\nthe amount of patients that can be monitored simultaneously. We aim to increase\nthis amount by implementing a decision support system. This paper investigates\na machine learning model to estimate a risk score based on patient vital\nparameters that allows sorting all cases every day to help practitioners focus\ntheir limited capacities on the most severe cases. The model we propose reaches\nan AUCROC of 0.84, whereas the baseline rule-based model reaches an AUCROC of\n0.73. Our results indicate that the usage of deep learning to improve the\nefficiency of telemedical centers is feasible. This way more patients could\nbenefit from better health-care through remote monitoring.", "journal": "", "doi": null, "primary_category": "cs.AI", "categories": ["cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2104.10085v1"}
{"entry_id": "http://arxiv.org/abs/2109.03016v1", "date": "2021-09-07", "title": "SpatialViewer: A Remote Work Sharing Tool that Considers Intimacy Among Workers", "authors": "Sicheng Li, Yudai Makioka, Kyousuke Kobayashi, Haoran Xie, Kentaro Takashima", "abstract": "Due to the influence of the new coronavirus disease (COVID-19), teleworking\nhas been expanding rapidly. Although existing interactive remote working\nsystems are convenient, they do not allow users to adjust their spatial\ndistance to team members at will, %\"Arbitrarily\" is probably not the best word\nhere. It means without apparent reason. A better expression might be \"at will.\"\nand they ignore the discomfort caused by different levels of intimacy. To solve\nthis issue, we propose a telework support system using spatial augmented\nreality technology. This system calibrates the space in which videos are\nprojected with real space and adjusts the spatial distance between users by\nchanging the position of projections. Users can switch the projection position\nof the video using hand-wave gestures. We also synchronize audio according to\ndistance to further emphasize the sense of space within the remote interaction:\nthe distance between projection position and user is inversely proportional to\nthe audio volume. We conducted a telework experiment and a questionnaire survey\nto evaluate our system. The results show that the system enables users to\nadjust distance according to intimacy and thus improve the users' comfort.", "journal": "", "doi": "10.1007/978-3-030-77599-5_5", "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/2109.03016v1"}
{"entry_id": "http://arxiv.org/abs/2208.12999v1", "date": "2022-08-27", "title": "Remote Water-to-air Eavesdropping through Phase-Engineered Impedance Matching Metasurfaces", "authors": "Jing-jing Liu, Zheng-wei Li, Bin Liang, Jian-chun Cheng, Andrea Alu", "abstract": "Efficiently receiving underwater sound remotely from air is a long-standing\nchallenge in acoustics hindered by the large impedance mismatch at the\nwater-air interface. Here we introduce and experimentally demonstrate a\ntechnique for remote and efficient water-to-air eavesdropping through\nphase-engineered impedance matching metasurfaces. By judiciously engineering an\nultrathin mechanically-rigid boundary, we make the water-air interface\nacoustically transparent and at the same time we are able to pattern the\ntransmitted wavefront, enabling efficient control over the effective spatial\nlocation of a distant airborne sensor such that it can measure underwater\nsignals with large signal-to-noise ratio as if placed close to the physical\nunderwater source. Such airborne eavesdropping of underwater sound is\nexperimentally demonstrated with a measured sensitivity enhancement exceeding\n38 dB at 8 kHz. We further demonstrate opportunities for\norbital-angular-momentum-multiplexed communications and underwater acoustic\ncommunications. Our metasurface opens new avenues for communication and\nsensing, which may be translated to nano-optics and radio-frequencies.", "journal": "", "doi": null, "primary_category": "physics.app-ph", "categories": ["physics.app-ph", "physics.class-ph"], "pdf_url": "http://arxiv.org/pdf/2208.12999v1"}
{"entry_id": "http://arxiv.org/abs/2303.02546v1", "date": "2023-03-05", "title": "An Avatar Robot Overlaid with the 3D Human Model of a Remote Operator", "authors": "Ravi Tejwani, Chengyuan Ma, Paolo Bonato, H. Harry Asada", "abstract": "Although telepresence assistive robots have made significant progress, they\nstill lack the sense of realism and physical presence of the remote operator.\nThis results in a lack of trust and adoption of such robots. In this paper, we\nintroduce an Avatar Robot System which is a mixed real/virtual robotic system\nthat physically interacts with a person in proximity of the robot. The robot\nstructure is overlaid with the 3D model of the remote caregiver and visualized\nthrough Augmented Reality (AR). In this way, the person receives haptic\nfeedback as the robot touches him/her. We further present an Optimal\nNon-Iterative Alignment solver that solves for the optimally aligned pose of 3D\nHuman model to the robot (shoulder to the wrist non-iteratively). The proposed\nalignment solver is stateless, achieves optimal alignment and faster than the\nbaseline solvers (demonstrated in our evaluations). We also propose an\nevaluation framework that quantifies the alignment quality of the solvers\nthrough multifaceted metrics. We show that our solver can consistently produce\nposes with similar or superior alignments as IK-based baselines without their\npotential drawbacks.", "journal": "", "doi": null, "primary_category": "cs.RO", "categories": ["cs.RO"], "pdf_url": "http://arxiv.org/pdf/2303.02546v1"}
{"entry_id": "http://arxiv.org/abs/1405.3798v1", "date": "2014-05-15", "title": "The Albedos of Kepler's Close-in super-Earths", "authors": "Brice-Olivier Demory", "abstract": "Exoplanet research focusing on the characterization of super-Earths is\ncurrently limited to those handful targets orbiting bright stars that are\namenable to detailed study. This Letter proposes to look at alternative avenues\nto probe the surface and atmospheric properties of this category of planets,\nknown to be ubiquitous in our galaxy. I conduct Markov Chain Monte Carlo\nlightcurve analyses for 97 Kepler close-in $R_P \\lesssim 2.0 R_{\\oplus}$\nsuper-Earth candidates with the aim to detect their occultations at visible\nwavelengths. Brightness temperatures and geometric albedos in the Kepler\nbandpass are constrained for 27 super-Earth candidates. A hierarchical Bayesian\nmodeling approach is then employed to characterize the population-level\nreflective properties of these close-in super-Earths. I find median geometric\nalbedos $A_g$ in the Kepler bandpass ranging between 0.16 and 0.30, once\ndecontaminated from thermal emission. These super-Earths geometric albedos are\nstatistically larger than for hot Jupiters, which have medians $A_g$ ranging\nbetween 0.06 and 0.11. A subset of objects, including Kepler-10b, exhibit\nsignificantly larger albedos ($A_g\\gtrsim$0.4). I argue that a better\nunderstanding of the incidence of stellar irradiation on planetary surface and\natmospheric processes is key to explain the diversity in albedos observed for\nclose-in super-Earths.", "journal": "", "doi": "10.1088/2041-8205/789/1/L20", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1405.3798v1"}
{"entry_id": "http://arxiv.org/abs/0901.4394v1", "date": "2009-01-28", "title": "The NASA-UC Eta-Earth Program: I. A Super-Earth Orbiting HD 7924", "authors": "Andrew W. Howard, John A. Johnson, Geoffrey W. Marcy, Debra A. Fischer, Jason T. Wright, Gregory W. Henry, Matthew J. Giguere, Howard Isaacson, Jeff A. Valenti, Jay Anderson, Nikolai E. Piskunov", "abstract": "We report the discovery of the first low-mass planet to emerge from the\nNASA-UC Eta-Earth Program, a super-Earth orbiting the K0 dwarf HD 7924.\nKeplerian modeling of precise Doppler radial velocities reveals a planet with\nminimum mass M_P sin i = 9.26 M_Earth in a P = 5.398 d orbit. Based on\nKeck-HIRES measurements from 2001 to 2008, the planet is robustly detected with\nan estimated false alarm probability of less than 0.001. Photometric\nobservations using the Automated Photometric Telescopes at Fairborn Observatory\nshow that HD 7924 is photometrically constant over the radial velocity period\nto 0.19 mmag, supporting the existence of the planetary companion. No transits\nwere detected down to a photometric limit of ~0.5 mmag, eliminating transiting\nplanets with a variety of compositions. HD 7924b is one of only eight planets\nknown with M_P sin i < 10 M_Earth and as such is a member of an emerging family\nof low-mass planets that together constrain theories of planet formation.", "journal": "Astrophys.J.696:75-83,2009", "doi": "10.1088/0004-637X/696/1/75", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0901.4394v1"}
{"entry_id": "http://arxiv.org/abs/1504.06629v1", "date": "2015-04-24", "title": "Three Super-Earths Orbiting HD 7924", "authors": "Benjamin J. Fulton, Lauren M. Weiss, Evan Sinukoff, Howard Isaacson, Andrew W. Howard, Geoffrey W. Marcy, Gregory W. Henry, Bradford P. Holden, Robert I. Kibrick", "abstract": "We report the discovery of two super-Earth mass planets orbiting the nearby\nK0.5 dwarf HD 7924 which was previously known to host one small planet. The new\ncompanions have masses of 7.9 and 6.4 M$_\\oplus$, and orbital periods of 15.3\nand 24.5 days. We perform a joint analysis of high-precision radial velocity\ndata from Keck/HIRES and the new Automated Planet Finder Telescope (APF) to\nrobustly detect three total planets in the system. We refine the ephemeris of\nthe previously known planet using five years of new Keck data and high-cadence\nobservations over the last 1.3 years with the APF. With this new ephemeris, we\nshow that a previous transit search for the inner-most planet would have\ncovered 70% of the predicted ingress or egress times. Photometric data\ncollected over the last eight years using the Automated Photometric Telescope\nshows no evidence for transits of any of the planets, which would be detectable\nif the planets transit and their compositions are hydrogen-dominated. We detect\na long-period signal that we interpret as the stellar magnetic activity cycle\nsince it is strongly correlated with the Ca II H and K activity index. We also\ndetect two additional short-period signals that we attribute to\nrotationally-modulated starspots and a one month alias. The high-cadence APF\ndata help to distinguish between the true orbital periods and aliases caused by\nthe window function of the Keck data. The planets orbiting HD 7924 are a local\nexample of the compact, multi-planet systems that the Kepler Mission found in\ngreat abundance.", "journal": "", "doi": "10.1088/0004-637X/805/2/175", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1504.06629v1"}
{"entry_id": "http://arxiv.org/abs/1404.5248v1", "date": "2014-04-21", "title": "Intelligent Remote Control for TV Program based on Emotion in Arabic Speech", "authors": "M. Meddeb, H. Karray, Adel M. Alimi", "abstract": "Recommender systems for TV program have been studied for the realization of\npersonalized TV Electronic Program Guides. In this paper, we propose automatic\nemotion Arabic speech recognition in order to achieve an intelligent remote\ncontrol. In addition, the TV can estimate our interests and preferences by\nobserving our behavior to watch and have a conversation on topics that might be\ninteresting to us.", "journal": "International Journal of Scientific Research & Engineering\n  Technology (IJSET), ISSN: (2277-1581) volume 1, 2014", "doi": null, "primary_category": "cs.HC", "categories": ["cs.HC"], "pdf_url": "http://arxiv.org/pdf/1404.5248v1"}
{"entry_id": "http://arxiv.org/abs/1007.0008v1", "date": "2010-06-30", "title": "The Earth as an extrasolar transiting planet: Earth's atmospheric composition and thickness revealed by Lunar eclipse observations", "authors": "Alfred Vidal-Madjar, Luc Arnold, David Ehrenreich, Roger Ferlet, Alain Lecavelier des Etangs, Fran\u00e7ois Bouchy, Damien Segransan, Isabelle Boisse, Guillaume H\u00e9brard, Claire Moutou, Jean-Michel D\u00e9sert, David K. Sing, R\u00e9my Cabanac, Christian Nitschelm, Xavier Bonfils, Xavier Delfosse, Morgan Desort, Rodrigo F. D\u00edaz, Anne Eggenberger, Thierry Forveille, Anne-Marie Lagrange, Christophe Lovis, Francesco Pepe, Christian Perrier, Fr\u00e9d\u00e9ric Pont, Nuno C. Santos, St\u00e9phane Udry", "abstract": "An important goal within the quest for detecting an Earth-like extrasolar\nplanet, will be to identify atmospheric gaseous bio-signatures. Observations of\nthe light transmitted through the Earth's atmosphere, as for an extrasolar\nplanet, will be the first step for future comparisons. We have completed\nobservations of the Earth during a Lunar eclipse, a unique situation similar to\nthat of a transiting planet. We aim at showing what species could be detected\nin its atmosphere at optical wavelengths, where a lot of photons are available\nin the masked stellar light. We present observations of the 2008 August 16 Moon\neclipse performed with the SOPHIE spectrograph at the Observatoire de\nHaute-Provence. Locating the spectrograph fibers in the penumbra of the\neclipse, the Moon irradiance is then a mix of direct, unabsorbed Sun light and\nsolar light that has passed through the Earth's limb. This mixture essentially\nreproduces what is recorded during the transit of an extrasolar planet. We\nreport here the clear detection of several Earth atmospheric compounds in the\ntransmission spectra, such as ozone, molecular oxygen, and neutral sodium as\nwell as molecular nitrogen and oxygen through the Rayleigh signature. Moreover,\nwe present a method that allows us to derive the thickness of the atmosphere\nversus the wavelength for penumbra eclipse observations. We quantitatively\nevaluate the altitude at which the atmosphere becomes transparent for important\nspecies like molecular oxygen and ozone, two species thought to be tightly\nlinked to the presence of life. The molecular detections presented here are an\nencouraging first attempt, necessary to better prepare for the future of\nextremely-large telescopes and transiting Earth-like planets. Instruments like\nSOPHIE will be mandatory when characterizing the atmospheres of transiting\nEarth-like planets from the ground and searching for bio-marker signatures.", "journal": "", "doi": "10.1051/0004-6361/201014751", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1007.0008v1"}
{"entry_id": "http://arxiv.org/abs/1801.07101v2", "date": "2018-01-22", "title": "Earth Similarity Index and Habitability Studies of Exoplanets", "authors": "Madhu Kashyap Jagadeesh", "abstract": "Study of exoplanets has been of considerable interest for Astronomers,\nPlanetary Scientists and Astrobiologists. Analysis of huge planetary data from\nspace missions such as CoRoT and Kepler is directed ultimately at finding a\nplanet similar to Earth- the Earth's twin, and looking for potential\nhabitability. The Earth Similarity Index (ESI) is defined to find the\nsimilarity with Earth, which ranges from 1 (Earth) to 0 (totally dissimilar to\nEarth). ESI can be computed using four physical parameters of a planet, namely\nradius, density, escape velocity and surface temperature. The surface\ntemperature entering surface ESI is a non-observable quantity and what we know\nis only equilibrium temperature of exoplanets. We have established a relation\nbetween surface and equilibrium temperatures using the data available for the\nsolar system objects to address the difficulty in determining surface\ntemperature. From the ESI analysis, we have found 20 Earth-like exoplanets with\nESI value above 0.8, which is set as the threshold. We are also interested in\nMars-like planets to search for planets that may host the extreme life For\nexample, methane-specific extremophile life form metabolism, for which a new\napproach, called Mars Similarity Index (MSI) is introduced. MSI is defined in\nthe range between 1 (present Mars) and 0 (dissimilar to present Mars) and uses\nthe same physical parameters as that of ESI. We introduced another new approach\nto study the potential habitability of exoplanets based on Cobb-Douglas\nFunction, multi-parametric function. This did not yield any encouraging\nresults.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1801.07101v2"}
{"entry_id": "http://arxiv.org/abs/0902.4086v1", "date": "2009-02-24", "title": "Formation and tidal evolution of hot super-Earths in multiple planetary systems", "authors": "Ji-Lin Zhou", "abstract": "Hot super-Earths are exoplanets with masses < 10 Earth masses and orbital\nperiods < 20 days. Around 8 hot super-Earths have been discovered in the\nneighborhood of solar system. In this lecture, we review the mechanisms for the\nformation of hot super-Earths, dynamical effects that play important roles in\nsculpting the architecture of the multiple planetary systems. Two example\nsystems (HD 40307 and GJ 436) are presented to show the formation and evolution\nof hot super-Earths or Neptunes.", "journal": "", "doi": "10.1051/eas/1042027", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0902.4086v1"}
{"entry_id": "http://arxiv.org/abs/1510.08855v2", "date": "2015-10-29", "title": "Breeding Super-Earths and Birthing Super-Puffs in Transitional Disks", "authors": "Eve J. Lee, Eugene Chiang", "abstract": "The riddle posed by super-Earths (1-4$R_\\oplus$, 2-20$M_\\oplus$) is that they\nare not Jupiters: their core masses are large enough to trigger runaway gas\naccretion, yet somehow super-Earths accreted atmospheres that weigh only a few\npercent of their total mass. We show that this puzzle is solved if super-Earths\nformed late, as the last vestiges of their parent gas disks were about to\nclear. This scenario would seem to present fine-tuning problems, but we show\nthat there are none. Ambient gas densities can span many (up to 9) orders of\nmagnitude, and super-Earths can still robustly emerge after $\\sim$0.1-1 Myr\nwith percent-by-weight atmospheres. Super-Earth cores are naturally bred in\ngas-poor environments where gas dynamical friction has weakened sufficiently to\nallow constituent protocores to merge. So little gas is present at the time of\ncore assembly that cores hardly migrate by disk torques: formation of\nsuper-Earths can be in situ. The picture --- that close-in super-Earths form in\na gas-poor (but not gas-empty) inner disk, fed continuously by gas that bleeds\ninward from a more massive outer disk --- recalls the largely evacuated but\nstill accreting inner cavities of transitional protoplanetary disks. We also\naddress the inverse problem presented by super-puffs: an uncommon class of\nshort-period planets seemingly too voluminous for their small masses\n(4-10$R_\\oplus$, 2-6$M_\\oplus$). Super-puffs easily acquire their thick\natmospheres as dust-free, rapidly cooling worlds outside $\\sim$1 AU where\nnebular gas is colder, less dense, and therefore less opaque. Unlike\nsuper-Earths which can form in situ, super-puffs migrated in to their current\norbits; they are expected to form the outer links of mean-motion resonant\nchains, and to exhibit greater water content. We close by confronting\nobservations and itemizing remaining questions.", "journal": "", "doi": "10.3847/0004-637X/817/2/90", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1510.08855v2"}
{"entry_id": "http://arxiv.org/abs/2108.01945v2", "date": "2021-08-04", "title": "System Modelling of Very Low Earth Orbit Satellites for Earth Observation", "authors": "N. H. Crisp, P. C. E. Roberts, K. L. Smith, V. T. A. Oiko, V. Sulliotti-Linner, V. Hanessian, G. H. Herdrich, Daniel Garc\u00eda-Almi\u00f1ana, D. Kataria, S. Seminari", "abstract": "The operation of satellites in very low Earth orbit (VLEO) has been linked to\na variety of benefits to both the spacecraft platform and mission design.\nCritically, for Earth observation (EO) missions a reduction in altitude can\nenable smaller and less powerful payloads to achieve the same performance as\nlarger instruments or sensors at higher altitude, with significant benefits to\nthe spacecraft design. As a result, renewed interest in the exploitation of\nthese orbits has spurred the development of new technologies that have the\npotential to enable sustainable operations in this lower altitude range. In\nthis paper, system models are developed for (i) novel materials that improve\naerodynamic performance enabling reduced drag or increased lift production and\nresistance to atomic oxygen erosion and (ii) atmosphere-breathing electric\npropulsion (ABEP) for sustained drag compensation or mitigation in VLEO.\nAttitude and orbit control methods that can take advantage of the aerodynamic\nforces and torques in VLEO are also discussed. These system models are\nintegrated into a framework for concept-level satellite design and this\napproach is used to explore the system-level trade-offs for future EO\nspacecraft enabled by these new technologies. A case-study presented for an\noptical very-high resolution spacecraft demonstrates the significant potential\nof reducing orbital altitude using these technologies and indicates possible\nsavings of up to 75% in system mass and over 50% in development and\nmanufacturing costs in comparison to current state-of-the-art missions. For a\nsynthetic aperture radar (SAR) satellite, the reduction in mass and cost with\naltitude were shown to be smaller, though it was noted that currently available\ncost models do not capture recent commercial advancements in this segment...", "journal": "Acta Astronautica, vol. 187 (2021)", "doi": "10.1016/j.actaastro.2021.07.004", "primary_category": "physics.space-ph", "categories": ["physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2108.01945v2"}
{"entry_id": "http://arxiv.org/abs/2101.01493v2", "date": "2021-01-05", "title": "Fast Quasi-Geostrophic Magneto-Coriolis Modes in the Earth's core", "authors": "Felix Gerick, Dominique Jault, Jerome Noir", "abstract": "Fast changes of Earth's magnetic field could be explained by inviscid and\ndiffusion-less quasi-geostrophic (QG) Magneto-Coriolis modes. We present a\nhybrid QG model with columnar flows and three-dimensional magnetic fields and\nfind modes with periods of a few years at parameters relevant to Earth's core.\nFor the simple poloidal magnetic field that we consider here they show a\nlocalization of kinetic and magnetic energy in the equatorial region. This\nconcentration of energy near the equator and the high frequency make them a\nplausible mechanism to explain similar features observed in recent geomagnetic\nfield observations. Our model potentially opens a way to probe the otherwise\ninaccessible magnetic field structure in the Earth's outer core.", "journal": "", "doi": "10.1029/2020GL090803", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph", "physics.flu-dyn"], "pdf_url": "http://arxiv.org/pdf/2101.01493v2"}
{"entry_id": "http://arxiv.org/abs/2210.05414v2", "date": "2022-10-11", "title": "Earth as an Exoplanet: II. Earth's Time-Variable Thermal Emission and its Atmospheric Seasonality of Bio-Indicators", "authors": "Jean-Noel Mettler, Sascha P. Quanz, Ravit Helled, Stephanie L. Olson, Edward W. Schwieterman", "abstract": "We assess the dependence of Earth's disk-integrated mid-infrared thermal\nemission spectrum on observation geometries and investigate which and how\nspectral features are impacted by seasonality on Earth. We compiled an\nexclusive dataset containing 2690 disk-integrated thermal emission spectra for\nfour different full-disk observing geometries (North & South Pole centered and\nAfrica & Pacific centred equatorial views) over four consecutive years. The\nspectra were derived from 2378 spectral channels in the wavelength range from\n3.75 to 15.4 micron (nominal resolution $\\approx$ 1200) and were recorded by\nthe Atmospheric Infrared Sounder aboard the Aqua satellite. We learned that\nthere is significant seasonal variability in Earth's thermal emission spectrum,\nand the strength of spectral features of bio-indicators, such as N2O, CH4, O3\nand CO2 depends strongly on both season and viewing geometry. In addition, we\nfound a strong spectral degeneracy with respect to the latter two indicating\nthat multi-epoch measurements and time-dependent signals may be required in\norder to fully characterize planetary environments. Even for Earth and\nespecially for equatorial views, the variations in flux and strength of\nabsorption features in the disk-integrated data are small and typically $\\leq$\n10%. Disentangling these variations from the noise in future exoplanet\nobservations will be a challenge. However, irrespectively of when the planet\nwill be measured (i.e., day or night or season) the results from mid-infrared\nobservations will remain the same to the zeroth order which is an advantage\nover reflected light observations.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/2210.05414v2"}
{"entry_id": "http://arxiv.org/abs/2106.08378v1", "date": "2021-06-15", "title": "Low-energy spin dynamics in rare-earth perovskite oxides", "authors": "A. Podlesnyak, S. Nikitin, G. Ehlers", "abstract": "We review recent studies of spin dynamics in rare-earth orthorhombic\nperovskite oxides of the type $RM$O$_3$, where $R$ is a rare-earth ion and $M$\nis a transition-metal ion, using single-crystal inelastic neutron scattering\n(INS). After a short introduction to the magnetic INS technique in general, the\nresults of INS experiments on both transition-metal and rare-earth subsystems\nfor four selected compounds (YbFeO$_3$, TmFeO$_3$, YFeO$_3$, YbAlO$_3$) are\npresented. We show that the spectrum of magnetic excitations consists of two\ntypes of collective modes that are well separated in energy: gapped magnons\nwith a typical bandwidth of $<$70 meV, associated with the\nantiferromagnetically (AFM) ordered transition-metal subsystem, and AFM\nfluctuations of $<$5 meV within the rare-earth subsystem, with no hybridization\nof those modes. We discuss the high-energy conventional magnon excitations of\nthe 3$d$ subsystem only briefly, and focus in more detail on the spectacular\ndynamics of the rare-earth sublattice in these materials. We observe that the\nnature of the ground state and the low-energy excitation strongly depends on\nthe identity of the rare-earth ion. In the case of non-Kramers ions, the\nlow-symmetry crystal field completely eliminates the degeneracy of the\nmultiplet state, creating a rich magnetic field-temperature phase diagram. In\nthe case of Kramers ions, the resulting ground state is at least a doublet,\nwhich can be viewed as an effective quantum spin-1/2. Equally important is the\nfact that in Yb-based materials the nearest-neighbor exchange interaction\ndominates in one direction, despite the three-dimensional nature of the\northoperovskite crystal structure. The observation of a fractional spinon\ncontinuum and quantum criticality in YbAlO$_3$ demonstrates that Kramers\nrare-earth based magnets can provide realizations of various aspects of quantum\nlow-dimensional physics.", "journal": "J. Phys.: Condens. Matter 33 403001 (2021)", "doi": "10.1088/1361-648X/ac1367", "primary_category": "cond-mat.str-el", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/2106.08378v1"}
{"entry_id": "http://arxiv.org/abs/2102.09639v1", "date": "2021-02-18", "title": "Non-Maxwellianity of electron distributions near Earth's magnetopause", "authors": "D. B. Graham, Yu. V. Khotyaintsev, M. Andr\u00e9, A. Vaivads, A. Chasapis, W. H. Matthaeus, A. Retino, F. Valentini, D. J. Gershman", "abstract": "Plasmas in Earth's outer magnetosphere, magnetosheath, and solar wind are\nessentially collisionless. This means particle distributions are not typically\nin thermodynamic equilibrium and deviate significantly from Maxwellian\ndistributions. The deviations of these distributions can be further enhanced by\nplasma processes, such as shocks, turbulence, and magnetic reconnection. Such\ndistributions can be unstable to a wide variety of kinetic plasma\ninstabilities, which in turn modify the electron distributions. In this paper\nthe deviations of the observed electron distributions from a bi-Maxwellian\ndistribution function is calculated and quantified using data from the\nMagnetospheric Multiscale (MMS) spacecraft. A statistical study from tens of\nmillions of electron distributions shows that the primary source of the\nobserved non-Maxwellianity are electron distributions consisting of distinct\nhot and cold components in Earth's low-density magnetosphere. This results in\nlarge non-Maxwellianities in at low densities. However, after performing a\nstastical study we find regions where large non-Maxwellianities are observed\nfor a given density. Highly non-Maxwellian distributions are routinely found\nare Earth's bowshock, in Earth's outer magnetosphere, and in the electron\ndiffusion regions of magnetic reconnection. Enhanced non-Maxwellianities are\nobserved in the turbulent magnetosheath, but are intermittent and are not\ncorrelated with local processes. The causes of enhanced non-Maxwellianities are\ninvestigated.", "journal": "", "doi": "10.1029/2021JA029260", "primary_category": "physics.plasm-ph", "categories": ["physics.plasm-ph", "physics.space-ph"], "pdf_url": "http://arxiv.org/pdf/2102.09639v1"}
{"entry_id": "http://arxiv.org/abs/1609.08110v2", "date": "2016-09-26", "title": "Dynamically hot Super-Earths from outer giant planet scattering", "authors": "Chelsea X. Huang, Cristobal Petrovich, Emily Deibert", "abstract": "The hundreds of multiple planetary systems discovered by the \\textit{Kepler}\nmission are typically observed to reside in close-in ($\\lesssim0.5$ AU),\nlow-eccentricity, and low-inclination orbits. We run N-body experiments to\nstudy the effect that unstable outer ($\\gtrsim1$ AU) giant planets, whose end\norbital configurations resemble those in the Radial Velocity population, have\non these close-in multiple super-Earth systems. Our experiments show that the\ngiant planets greatly reduce the multiplicity of the inner super-Earths and the\nsurviving population can have large eccentricities ($e\\gtrsim0.3$) and\ninclinations ($i\\gtrsim20^\\circ$) at levels that anti-correlate with\nmultiplicity. Consequently, this model predicts the existence of a population\nof dynamically hot single-transiting planets with typical eccentricities and\ninclinations %in the ranges of $\\sim 0.1-0.5$ and $\\sim 10^\\circ-40^\\circ$. We\nshow that these results can explain the following observations: (i) the recent\neccentricity measurements of \\textit{Kepler} super-Earths from transit\ndurations; (ii) the tentative observation that single-transiting systems have a\nwider distribution of stellar obliquity angles compared to the\nmultiple-transiting systems; (iii) the architecture of some eccentric\nsuper-Earths discovered by Radial Velocity surveys such as HD\\,125612c. Future\nobservations from \\textit{TESS} will reveal many more dynamically hot single\ntransiting planets, for which follow up Radial Velocity studies will be able to\ntest our models and see whether they have outer giant planets.", "journal": "", "doi": "10.3847/1538-3881/aa67fb", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1609.08110v2"}
{"entry_id": "http://arxiv.org/abs/1510.05637v1", "date": "2015-10-19", "title": "Observing Near-Earth Objects with the James Webb Space Telescope", "authors": "Cristina A. Thomas, Paul Abell, Julie Castillo-Rogez, Nicholas Moskovitz, Michael Mueller, Vishnu Reddy, Andrew Rivkin, Erin Ryan, John Stansberry", "abstract": "The James Webb Space Telescope (JWST) has the potential to enhance our\nunderstanding of near-Earth objects (NEOs). We present results of\ninvestigations into the observability of NEOs given the nominal observing\nrequirements of JWST on elongation (85-135 degrees) and non-sidereal rates\n($<$30mas/s). We find that approximately 75% of NEOs can be observed in a given\nyear. However, observers will need to wait for appropriate observing windows.\nWe find that JWST can easily execute photometric observations of meter-sized\nNEOs which will enhance our understanding of the small NEO population.", "journal": "", "doi": "10.1088/1538-3873/128/959/018002", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1510.05637v1"}
{"entry_id": "http://arxiv.org/abs/2012.10964v1", "date": "2020-12-20", "title": "GRACE -- gravity data for understanding the deep Earth's interior", "authors": "Mioara Mandea, V\u00e9ronique Dehant, Anny Cazenave", "abstract": "While the main causes of the temporal gravity variations observed by the\nGRACE space mission result from water mass redistributions occurring at the\nsurface of the Earth in response to climatic and anthropogenic forcings (e.g.,\nchanges in land hydrology, in ocean mass, in mass of glaciers and ice sheets),\nsolid Earth's mass redistributions are also recorded by these observations.\nThis is the case, in particular, for the Glacial Isostatic Adjustment (GIA) or\nthe viscous response of the mantle to the last deglaciation. However, it is\nonly recently showed that the gravity data also contain the signature of flows\ninside the outer core and their effects on the core-mantle boundary (CMB).\nDetecting deep Earth's processes in GRACE observations offers an exciting\nopportunity to provide additional insight on the dynamics of the core-mantle\ninterface. Here, we present one aspect of the GRACEFUL (GRavimetry, mAgnetism\nand CorE Flow) project, i.e. the possibility to use the gravity field data for\nunderstanding the dynamic processes inside the fluid core and core-mantle\nboundary of the Earth, beside that offered by the geomagnetic field variations.", "journal": "", "doi": null, "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2012.10964v1"}
{"entry_id": "http://arxiv.org/abs/2103.12760v2", "date": "2021-03-23", "title": "Two Bright M Dwarfs Hosting Ultra-Short-Period Super-Earths with Earth-like Compositions", "authors": "Teruyuki Hirano, John H. Livingston, Akihiko Fukui, Norio Narita, Hiroki Harakawa, Hiroyuki Tako Ishikawa, Kohei Miyakawa, Tadahiro Kimura, Akifumi Nakayama, Naho Fujita, Yasunori Hori, Keivan G. Stassun, Allyson Bieryla, Charles Cadieux, David R. Ciardi, Karen A. Collins, Masahiro Ikoma, Andrew Vanderburg, Thomas Barclay, C. E. Brasseur, Jerome P. de Leon, John P. Doty, Ren\u00e9 Doyon, Emma Esparza-Borges, Gilbert A. Esquerdo, Elise Furlan, Eric Gaidos, Erica J. Gonzales, Klaus Hodapp, Nobuhiko Kusakabe, Masayuki Kuzuhara, David Lafreni\u00e8re, David W. Latham, Bob Massey, Mayuko Mori, Felipe Murgas, Jun Nishikawa, Taku Nishiumi, Masashi Omiya, Martin Paegert, Enric Palle, Hannu Parviainen, Samuel N. Quinn, Steve B. Howell, Keisuke Isogai, Shane Jacobson, Jon M. Jenkins, Eric L. N. Jensen, Kiyoe Kawauchi, Takayuki Kotani, Tomoyuki Kudo, Seiya Kurita, Takashi Kurokawa, George R. Ricker, Richard P. Schwarz, Sara Seager, Peter Tenenbaum, Yuka Terada, Roland K. Vanderspek, Noriharu Watanabe, Joshua N. Winn", "abstract": "We present observations of two bright M dwarfs (TOI-1634 and TOI-1685:\n$J=9.5-9.6$) hosting ultra-short period (USP) planets, identified by the TESS\nmission. The two stars are similar in temperature, mass, and radius\n($T_\\mathrm{eff}\\,\\approx\\,3500$ K, $M_\\star\\,\\approx\\,0.45-0.46\\,M_\\odot$, and\n$R_\\star\\approx 0.45-0.46\\,R_\\odot$), and the planets are both\nsuper-Earth-sized ($1.25\\,R_\\oplus<R_p<2.0\\,R_\\oplus$). For both systems, light\ncurves from the ground-based photometry exhibit planetary transits, whose\ndepths are consistent with those by the TESS photometry. We also refine the\ntransit ephemerides based on the ground-based photometry, finding the orbital\nperiods of $P=0.9893436\\pm0.0000020$ day and $P=0.6691416\\pm0.0000019$ day for\nTOI-1634b and TOI-1685b, respectively. Through intensive radial velocity (RV)\nobservations using IRD on the Subaru 8.2m telescope, we confirm the planetary\nnature of the TOIs, and measure their masses: $10.14\\pm0.95\\,M_\\oplus$ and\n$3.43\\pm0.93\\,M_\\oplus$ for TOI-1634b and TOI-1685b, respectively, when the\nobserved RVs are fitted with a single-planet circular-orbit model. Combining\nthose with the planet radii of $R_p=1.749\\pm 0.079\\,R_\\oplus$ (TOI-1634b) and\n$1.459\\pm0.065\\,R_\\oplus$ (TOI-1685b), we find that both USP planets have mean\ndensities consistent with an Earth-like internal composition, which is typical\nfor small USP planets. TOI-1634b is currently the most massive USP planet in\nthis category, and it resides near the radius valley, which makes it a\nbenchmark planet in the context of discussing the size limit of rocky planet\ncores as well as testing the formation scenarios for USP planets. Excess\nscatter in the RV residuals for TOI-1685 suggests the presence of a possible\nsecondary planet or unknown activity/instrumental noise in the RV data, but\nfurther observations are required to check those possibilities.", "journal": "", "doi": "10.3847/1538-3881/ac0fdc", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2103.12760v2"}
{"entry_id": "http://arxiv.org/abs/1510.01846v1", "date": "2015-10-07", "title": "A Full Study on the Sun-Earth Connection of an Earth-Directed CME Magnetic Flux Rope", "authors": "P. Vemareddy, W. Mishra", "abstract": "We present an investigation of an eruption event of coronal mass ejection\n(CME) magnetic flux rope (MFR) from source active region (AR) NOAA 11719 on 11\nApril 2013 utilizing observations from SDO, STEREO, SOHO, and WIND spacecraft.\nThe source AR consists of pre-existing sigmoidal structure stacked over a\nfilament channel which is regarded as MFR system. EUV observations of low\ncorona suggest a further development of this MFR system by added axial flux\nthrough tether-cutting reconnection of loops at the middle of sigmoid under the\ninfluence of continuous slow flux motions during past two days. Our study\nimplies that the MFR system in the AR is initiated to upward motion by\nkink-instability and further driven by torus-instability. The CME morphology,\ncaptured in simultaneous three-point coronagraph observations, is fitted with\nGraduated Cylindrical Shell (GCS) model and discerns an MFR topology with\norientation aligning with magnetic neutral line in the source AR. This MFR\nexpands self-similarly and is found to have source AR twist signatures in the\nassociated near Earth magnetic cloud (MC). We further derived kinematics of\nthis CME propagation by employing a plethora of stereoscopic as well as single\nspacecraft reconstruction techniques. While stereoscopic methods perform\nrelatively poorly compared to other methods, fitting methods worked best in\nestimating the arrival time of the CME compared to in-situ measurements.\nSupplied with values of constrained solar wind velocity, drag parameter and 3D\nkinematics from GCS fit, we construct CME kinematics from the drag based model\nconsistent with in-situ MC arrival.", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/1510.01846v1"}
{"entry_id": "http://arxiv.org/abs/2104.02845v4", "date": "2021-04-07", "title": "A General Destriping Framework for Remote Sensing Images Using Flatness Constraint", "authors": "Kazuki Naganuma, Shunsuke Ono", "abstract": "Removing stripe noise, i.e., destriping, from remote sensing images is an\nessential task in terms of visual quality and subsequent processing. Most\nexisting destriping methods are designed by combining a particular image\nregularization with a stripe noise characterization that cooperates with the\nregularization, which precludes us to examine and activate different\nregularizations to adapt to various target images. To resolve this, two\nrequirements need to be considered: a general framework that can handle a\nvariety of image regularizations in destriping, and a strong stripe noise\ncharacterization that can consistently capture the nature of stripe noise,\nregardless of the choice of image regularization. To this end, this paper\nproposes a general destriping framework using a newly-introduced stripe noise\ncharacterization, named flatness constraint, where we can handle various\nregularization functions in a unified manner. Specifically, we formulate the\ndestriping problem as a nonsmooth convex optimization problem involving a\ngeneral form of image regularization and the flatness constraint. The\nconstraint mathematically models that the intensity of each stripe is constant\nalong one direction, resulting in a strong characterization of stripe noise.\nFor solving the optimization problem, we also develop an efficient algorithm\nbased on a diagonally preconditioned primal-dual splitting algorithm (DP-PDS),\nwhich can automatically adjust the stepsizes. The effectiveness of our\nframework is demonstrated through destriping experiments, where we\ncomprehensively compare combinations of a variety of image regularizations and\nstripe noise characterizations using hyperspectral images (HSI) and infrared\n(IR) videos.", "journal": "", "doi": "10.1109/TGRS.2022.3153995", "primary_category": "eess.IV", "categories": ["eess.IV"], "pdf_url": "http://arxiv.org/pdf/2104.02845v4"}
{"entry_id": "http://arxiv.org/abs/2109.03682v2", "date": "2021-09-08", "title": "Remote state preparation by multiple observers using a single copy of a two-qubit entangled state", "authors": "Shounak Datta, Shiladitya Mal, Arun K. Pati, A. S. Majumdar", "abstract": "We consider a scenario of remote state preparation of qubits where a single\ncopy of an entangled state is shared between Alice on one side, and several\nBobs on the other, who sequentially perform unsharp single-particle\nmeasurements. In the given scenario, we first determine the classical bound of\nfidelity for the preparation of remote states by the Bobs. We then show that\nthere can be at most 6 number of Bobs who can sequentially and independently\nprepare the remote qubit in Alice's lab with fidelity exceeding the classical\nbound in the presence of shared quantum correlations. The upper bound is\nachieved when the singlet state is initially shared between Alice and the first\nBob and every Bob prepares a state chosen from the equatorial circle of the\nBloch sphere. The maximum number of Bobs starts to decrease from 6 when either\nthe choice of remote states is shifted from the equatorial circle towards the\npoles of the Bloch sphere, or when the initial state shifts towards\nnon-maximally entangled pure and mixed states.", "journal": "", "doi": null, "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/2109.03682v2"}
{"entry_id": "http://arxiv.org/abs/2103.08840v2", "date": "2021-03-16", "title": "Remote Monitoring of Patient Respiration with Mask Attachment -- A Pragmatic Solution for Medical Facilities", "authors": "Vivian Ci Ai Koh, Yi Yang Ang, Wee Ser, Rex Xiao Tan", "abstract": "Remote monitoring of vital signs in infectious patients minimizes the risks\nof viral transmissions to healthcare professionals. Evidence indicates that\ndonning face masks reduces the risk of viral transmissions and is now the norm\nin medical facilities. We propose attaching an acoustic-sensing device onto\nface masks to assist medical facilities in monitoring patients' respiration\nremotely. Usability and functionality studies of the modified face mask were\nevaluated on 16 healthy participants, who were blindfolded throughout the data\ncollection. Around half of the participants noticed the difference between the\nmodified and unmodified masks but they also reported there was no discomfort in\nusing the modified mask. Respiratory rates of the participants were evaluated\nfor one minute and the mean error of respiratory rate was found to be 2.0 +/-\n1.3 breath per minute. As all participants were healthy, the wheeze detection\nalgorithm was assessed by playing 176 wheezes and 176 normal breaths through a\nfoam mannequin. The recordings were played at three different times to account\nfor varying environmental noise. The overall accuracy of the wheeze detection\nalgorithm was 91.9%. The current findings support and suggest the use of the\nmask attachment in medical facilities.", "journal": "Inventions 6 (2021) no. 4:81", "doi": "10.3390/inventions6040081", "primary_category": "eess.SP", "categories": ["eess.SP", "eess.AS"], "pdf_url": "http://arxiv.org/pdf/2103.08840v2"}
{"entry_id": "http://arxiv.org/abs/2209.06915v1", "date": "2022-09-14", "title": "Predictive Closed-Loop Remote Control over Wireless Two-Way Split Koopman Autoencoder", "authors": "Abanoub M. Girgis, Hyowoon Seo, Jihong Park, Mehdi Bennis, Jinho Choi", "abstract": "Real-time remote control over wireless is an important-yet-challenging\napplication in 5G and beyond due to its mission-critical nature under limited\ncommunication resources. Current solutions hinge on not only utilizing\nultra-reliable and low-latency communication (URLLC) links but also predicting\nfuture states, which may consume enormous communication resources and struggle\nwith a short prediction time horizon. To fill this void, in this article we\npropose a novel two-way Koopman autoencoder (AE) approach wherein: 1) a sensing\nKoopman AE learns to understand the temporal state dynamics and predicts\nmissing packets from a sensor to its remote controller; and 2) a controlling\nKoopman AE learns to understand the temporal action dynamics and predicts\nmissing packets from the controller to an actuator co-located with the sensor.\nSpecifically, each Koopman AE aims to learn the Koopman operator in the hidden\nlayers while the encoder of the AE aims to project the non-linear dynamics onto\na lifted subspace, which is reverted into the original non-linear dynamics by\nthe decoder of the AE. The Koopman operator describes the linearized temporal\ndynamics, enabling long-term future prediction and coping with missing packets\nand closed-form optimal control in the lifted subspace. Simulation results\ncorroborate that the proposed approach achieves a 38x lower mean squared\ncontrol error at 0 dBm signal-to-noise ratio (SNR) than the non-predictive\nbaseline.", "journal": "", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2209.06915v1"}
{"entry_id": "http://arxiv.org/abs/2206.11451v1", "date": "2022-06-23", "title": "RACS2: A Framework of Remote Autonomous Control System for Telescope Observation and its application", "authors": "Zhi-yue Wang, Guang-yu Zhang, Jian Wang, Qian Zhang, Zhe Genga, Ze-yu Zhu, Jia-Yao Gu, Zhen-hao Zheng, Lu-cheng Zhu, Kun Ge, Hong-fei Zhang", "abstract": "As the demand of astronomical observation rising, the telescope systems are\nbecoming more and more complex. Thus, the observatory control software needs to\nbe more intelligent, they have to control each instrument inside the\nobservatory, finish the observation tasks autonomously, and report the\ninformation to users if needed. We developed a distributed autonomous\nobservatory control framework named Remote Autonomous Control System 2nd, RACS2\nto meet these requirements. The RACS2 framework uses decentralized distributed\narchitecture, instrument control software and system service such as\nobservation control service are implemented as different components. The\ncommunication between components is implemented based on a high-performance\nserialization library and a light-weighted messaging library.The interfaces\ntowards python and Experimental Physics and Industrial Control System (EPICS)\nare implemented, so the RACS2 framework can communicate with EPICS based device\ncontrol software and python-based software. Several system components including\nlog, executor, scheduler and other modules are developed to help observation.\nObservation tasks can be programmed with python language, and the plans are\nscheduled by the scheduler component to achieve autonomous observation.A set of\nweb service is implemented based on the FastAPI framework, with which user can\ncontrol and manage the framework remotely.Based on the RACS2 framework, we have\nimplemented the DATs telescope's observation system and the space object\nobservation system.We performed remote autonomous observation and received many\ndata with these systems.", "journal": "", "doi": null, "primary_category": "astro-ph.IM", "categories": ["astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2206.11451v1"}
{"entry_id": "http://arxiv.org/abs/0810.2702v1", "date": "2008-10-15", "title": "The Detectability of Exo-Earths and Super-Earths Via Resonant Signatures in Exozodiacal Clouds", "authors": "Christopher C. Stark, Marc J. Kuchner", "abstract": "Directly imaging extrasolar terrestrial planets necessarily means contending\nwith the astrophysical noise of exozodiacal dust and the resonant structures\ncreated by these planets in exozodiacal clouds. Using a custom tailored hybrid\nsymplectic integrator we have constructed 120 models of resonant structures\ncreated by exo-Earths and super-Earths on circular orbits interacting with\ncollisionless steady-state dust clouds around a Sun-like star. Our models\ninclude enough particles to overcome the limitations of previous simulations\nthat were often dominated by a handful of long-lived particles, allowing us to\nquantitatively study the contrast of the resulting ring structures. We found\nthat in the case of a planet on a circular orbit, for a given star and dust\nsource distribution, the morphology and contrast of the resonant structures\ndepend on only two parameters: planet mass and $\\sqrt{a_{\\rm p}}/\\beta$, where\n$a_{\\rm p}$ is the planet's semi-major axis and $\\beta$ is the ratio of\nradiation pressure force to gravitational force on a grain. We constructed\nmultiple-grain-size models of 25,000 particles each and showed that in a\ncollisionless cloud, a Dohnanyi crushing law yields a resonant ring whose\noptical depth is dominated by the largest grains in the distribution, not the\nsmallest. We used these models to estimate the mass of the lowest-mass planet\nthat can be detected through observations of a resonant ring for a variety of\nassumptions about the dust cloud and the planet's orbit. Our simulations\nsuggest that planets with mass as small as a few times Mar's mass may produce\ndetectable signatures in debris disks for semi-major axes greater than 10 AU.", "journal": "Astrophys.J.686:637-648,2008", "doi": "10.1086/591442", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0810.2702v1"}
{"entry_id": "http://arxiv.org/abs/1708.00767v1", "date": "2017-08-02", "title": "Reduced gas accretion on super-Earths and ice giants", "authors": "Michiel Lambrechts, Elena Lega", "abstract": "A large fraction of giant planets have gaseous envelopes that are limited to\nabout 10 % of their total mass budget. Such planets are present in the Solar\nSystem (Uranus, Neptune) and are frequently observed in short periods around\nother stars (the so-called Super-Earths). In contrast to these observations,\ntheoretical calculations based on the evolution of hydrostatic envelopes argue\nthat such low mass envelopes cannot be maintained around cores exceeding five\nEarth masses. Instead, under nominal disc conditions, these planets would\nacquire massive envelopes through runaway gas accretion within the lifetime of\nthe protoplanetary disc. In this work, we show that planetary envelopes are not\nin hydrostatic balance, which slows down envelope growth. A series of\n3-dimensional, global, radiative hydrodynamical simulations reveal a steady\nstate gas flow, which enters through the poles and exits in the disc midplane.\nGas is pushed through the outer envelope in about 10 orbital timescales. In\nregions of the disc that are not significantly dust-depleted, envelope\naccretion onto cores of about five Earth masses can get stalled as the gas flow\nenters the deep interior. Accreted solids sublimate deep in the convective\ninterior, but small opacity-providing grains are trapped in the flow and do not\nsettle, which further prevents rapid envelope accretion. The transition to\nrunaway gas accretion can however be reached when cores grow larger than\ntypical Super-Earths, beyond 15 Earth masses, and preferably when disc\nopacities are below kappa=1 cm^2/g. These findings offer an explanation for the\ntypical low-mass envelopes around the cores of Super-Earths.", "journal": "A&A 606, A146 (2017)", "doi": "10.1051/0004-6361/201731014", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1708.00767v1"}
{"entry_id": "http://arxiv.org/abs/2202.10445v2", "date": "2022-02-21", "title": "A Grounded Theory of Coordination in Remote-First and Hybrid Software Teams", "authors": "Ronnie E. de Souza Santos, Paul Ralph", "abstract": "While the long-term effects of the COVID-19 pandemic on software\nprofessionals and organizations are difficult to predict, it seems likely that\nworking from home, remote-first teams, distributed teams, and hybrid\n(part-remote/part-office) teams will be more common. It is therefore important\nto investigate the challenges that software teams and organizations face with\nnew remote and hybrid work. Consequently, this paper reports a year-long,\nparticipant-observation, constructivist grounded theory study investigating the\nimpact of working from home on software development. This study resulted in a\ntheory of software team coordination. Briefly, shifting from in-office to\nat-home work fundamentally altered coordination within software teams. While\ngroup cohesion and more effective communication appear protective, coordination\nis undermined by distrust, parenting and communication bricolage. Poor\ncoordination leads to numerous problems including misunderstandings, help\nrequests, lower job satisfaction among team members, and more ill-defined\ntasks. These problems, in turn, reduce overall project success and prompt\nprofessionals to alter their software development processes (in this case, from\nScrum to Kanban). Our findings suggest that software organizations with many\nremote employees can improve performance by encouraging greater engagement\nwithin teams and supporting employees with family and childcare\nresponsibilities.", "journal": "", "doi": null, "primary_category": "cs.SE", "categories": ["cs.SE"], "pdf_url": "http://arxiv.org/pdf/2202.10445v2"}
{"entry_id": "http://arxiv.org/abs/1506.07892v1", "date": "2015-06-25", "title": "Remote Key Establishment by Mode Mixing in Multimode Fibres and Optical Reciprocity", "authors": "Yaron Bromberg, Brandon Redding, Sebastien M. Popoff, Hui Cao", "abstract": "Disorder and scattering in photonic systems have long been considered a\nnuisance that should be circumvented. Recently, disorder has been harnessed for\na rapidly growing number of applications, including imaging, sensing and\nspectroscopy. The chaotic dynamics and extreme sensitivity to external\nperturbations make random media particularly well-suited for optical\ncryptography. However, using random media for distribution of secret keys\nbetween remote users still remains challenging, since it requires the users\nhave access to the same scattering system. Here we utilize random mode mixing\nin multimode fibres to generate and distribute keys simultaneously. Fast\nfluctuations in the fibre mode mixing provide the source of randomness for the\nkey generation, and optical reciprocity guarantees that the keys at the two\nends of the fibre are identical. We experimentally demonstrate the scheme using\nclassical light and off-the-shelf components, opening the door for cost\neffective key establishment at the physical-layer of fibre-optic networks.", "journal": "Optical Engineering, 58(1), 016105 (2019)", "doi": "10.1117/1.OE.58.1.016105", "primary_category": "physics.optics", "categories": ["physics.optics", "quant-ph"], "pdf_url": "http://arxiv.org/pdf/1506.07892v1"}
{"entry_id": "http://arxiv.org/abs/1610.02902v1", "date": "2016-10-10", "title": "Content Based Image Retrieval (CBIR) in Remote Clinical Diagnosis and Healthcare", "authors": "Albany E. Herrmann, Vania Vieira Estrela", "abstract": "Content-Based Image Retrieval (CBIR) locates, retrieves and displays images\nalike to one given as a query, using a set of features. It demands accessible\ndata in medical archives and from medical equipment, to infer meaning after\nsome processing. A problem similar in some sense to the target image can aid\nclinicians. CBIR complements text-based retrieval and improves evidence-based\ndiagnosis, administration, teaching, and research in healthcare. It facilitates\nvisual/automatic diagnosis and decision-making in real-time remote\nconsultation/screening, store-and-forward tests, home care assistance and\noverall patient surveillance. Metrics help comparing visual data and improve\ndiagnostic. Specially designed architectures can benefit from the application\nscenario. CBIR use calls for file storage standardization, querying procedures,\nefficient image transmission, realistic databases, global availability, access\nsimplicity, and Internet-based structures. This chapter recommends important\nand complex aspects required to handle visual content in healthcare.", "journal": "Encyclopedia of E-Health and Telemedicine. IGI Global, 2016.\n  495-520. Web. 10 Oct. 2016", "doi": "10.4018/978-1-4666-9978-6.ch039", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1610.02902v1"}
{"entry_id": "http://arxiv.org/abs/2208.05566v2", "date": "2022-08-10", "title": "Remote non-invasive Fabry-Perot cavity spectroscopy for label-free sensing", "authors": "Abeer Al Ghamdi, Benjamin Dawson, Gin Jose, Almut Beige", "abstract": "One way of optically monitoring molecule concentrations is to utilise the\nhigh sensitivity of the transmission and reflection rates of Fabry-Perot\ncavities to changes of their optical properties. Up to now, intrinsic and\nextrinsic Fabry-Perot cavity sensors have been considered with analytes either\nbeing placed inside the resonator or coupled to evanescent fields on the\noutside. Here we show that Fabry-Perot cavities can also be used to monitor\nmolecule concentrations non-invasively and remotely, since the reflection of\nlight from the target molecules back into the Fabry-Perot cavity adds upwards\npeaks to the minima of its overall reflection rate. Detecting the amplitude of\nthese peaks reveals information about molecule concentrations. By using an\narray of optical cavities, a wide range of frequencies can be probed at once\nand a unique optical fingerprint can be obtained.", "journal": "Sensors 23, 385 (2023)", "doi": null, "primary_category": "physics.optics", "categories": ["physics.optics", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/2208.05566v2"}
{"entry_id": "http://arxiv.org/abs/1101.3594v2", "date": "2011-01-19", "title": "Classification under Data Contamination with Application to Remote Sensing Image Mis-registration", "authors": "Donghui Yan, Peng Gong, Aiyou Chen, Liheng Zhong", "abstract": "This work is motivated by the problem of image mis-registration in remote\nsensing and we are interested in determining the resulting loss in the accuracy\nof pattern classification. A statistical formulation is given where we propose\nto use data contamination to model and understand the phenomenon of image\nmis-registration. This model is widely applicable to many other types of errors\nas well, for example, measurement errors and gross errors etc. The impact of\ndata contamination on classification is studied under a statistical learning\ntheoretical framework. A closed-form asymptotic bound is established for the\nresulting loss in classification accuracy, which is less than\n$\\epsilon/(1-\\epsilon)$ for data contamination of an amount of $\\epsilon$. Our\nbound is sharper than similar bounds in the domain adaptation literature and,\nunlike such bounds, it applies to classifiers with an infinite\nVapnik-Chervonekis (VC) dimension. Extensive simulations have been conducted on\nboth synthetic and real datasets under various types of data contamination,\nincluding label flipping, feature swapping and the replacement of feature\nvalues with data generated from a random source such as a Gaussian or Cauchy\ndistribution. Our simulation results show that the bound we derive is fairly\ntight.", "journal": "", "doi": null, "primary_category": "stat.ME", "categories": ["stat.ME", "cs.LG", "stat.ML", "I.2.6; I.5.1; I.5.2"], "pdf_url": "http://arxiv.org/pdf/1101.3594v2"}
{"entry_id": "http://arxiv.org/abs/1903.07745v3", "date": "2019-03-18", "title": "Learning with Sets in Multiple Instance Regression Applied to Remote Sensing", "authors": "Thomas Uriot", "abstract": "In this paper, we propose a novel approach to tackle the multiple instance\nregression (MIR) problem. This problem arises when the data is a collection of\nbags, where each bag is made of multiple instances corresponding to the same\nunique real-valued label. Our goal is to train a regression model which maps\nthe instances of an unseen bag to its unique label. This MIR setting is common\nto remote sensing applications where there is high variability in the\nmeasurements and low geographical variability in the quantity being estimated.\nOur approach, in contrast to most competing methods, does not make the\nassumption that there exists a prime instance responsible for the label in each\nbag. Instead, we treat each bag as a set (i.e, an unordered sequence) of\ninstances and learn to map each bag to its unique label by using all the\ninstances in each bag. This is done by implementing an order-invariant\noperation characterized by a particular type of attention mechanism. This\nmethod is very flexible as it does not require domain knowledge nor does it\nmake any assumptions about the distribution of the instances within each bag.\nWe test our algorithm on five real world datasets and outperform previous\nstate-of-the-art on three of the datasets. In addition, we augment our feature\nspace by adding the moments of each feature for each bag, as extra features,\nand show that while the first moments lead to higher accuracy, there is a\ndiminishing return.", "journal": "", "doi": null, "primary_category": "stat.ML", "categories": ["stat.ML", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/1903.07745v3"}
{"entry_id": "http://arxiv.org/abs/1906.08462v1", "date": "2019-06-20", "title": "Nested Network with Two-Stream Pyramid for Salient Object Detection in Optical Remote Sensing Images", "authors": "Chongyi Li, Runmin Cong, Junhui Hou, Sanyi Zhang, Yue Qian, Sam Kwong", "abstract": "Arising from the various object types and scales, diverse imaging\norientations, and cluttered backgrounds in optical remote sensing image (RSI),\nit is difficult to directly extend the success of salient object detection for\nnature scene image to the optical RSI. In this paper, we propose an end-to-end\ndeep network called LV-Net based on the shape of network architecture, which\ndetects salient objects from optical RSIs in a purely data-driven fashion. The\nproposed LV-Net consists of two key modules, i.e., a two-stream pyramid module\n(L-shaped module) and an encoder-decoder module with nested connections\n(V-shaped module). Specifically, the L-shaped module extracts a set of\ncomplementary information hierarchically by using a two-stream pyramid\nstructure, which is beneficial to perceiving the diverse scales and local\ndetails of salient objects. The V-shaped module gradually integrates encoder\ndetail features with decoder semantic features through nested connections,\nwhich aims at suppressing the cluttered backgrounds and highlighting the\nsalient objects. In addition, we construct the first publicly available optical\nRSI dataset for salient object detection, including 800 images with varying\nspatial resolutions, diverse saliency types, and pixel-wise ground truth.\nExperiments on this benchmark dataset demonstrate that the proposed method\noutperforms the state-of-the-art salient object detection methods both\nqualitatively and quantitatively.", "journal": "", "doi": "10.1109/TGRS.2019.2925070", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1906.08462v1"}
{"entry_id": "http://arxiv.org/abs/2001.06372v3", "date": "2020-01-17", "title": "BigEarthNet Dataset with A New Class-Nomenclature for Remote Sensing Image Understanding", "authors": "Gencer Sumbul, Jian Kang, Tristan Kreuziger, Filipe Marcelino, Hugo Costa, Pedro Benevides, Mario Caetano, Beg\u00fcm Demir", "abstract": "This paper presents BigEarthNet that is a large-scale Sentinel-2\nmultispectral image dataset with a new class nomenclature to advance deep\nlearning (DL) studies in remote sensing (RS). BigEarthNet is made up of 590,326\nimage patches annotated with multi-labels provided by the CORINE Land Cover\n(CLC) map of 2018 based on its most thematic detailed Level-3 class\nnomenclature. Initial research demonstrates that some CLC classes are\nchallenging to be accurately described by considering only Sentinel-2 images.\nTo increase the effectiveness of BigEarthNet, in this paper we introduce an\nalternative class-nomenclature to allow DL models for better learning and\ndescribing the complex spatial and spectral information content of the\nSentinel-2 images. This is achieved by interpreting and arranging the CLC\nLevel-3 nomenclature based on the properties of Sentinel-2 images in a new\nnomenclature of 19 classes. Then, the new class-nomenclature of BigEarthNet is\nused within state-of-the-art DL models in the context of multi-label\nclassification. Results show that the models trained from scratch on\nBigEarthNet outperform those pre-trained on ImageNet, especially in relation to\nsome complex classes including agriculture, other vegetated and natural\nenvironments. All DL models are made publicly available at\nhttp://bigearth.net/#downloads, offering an important resource to guide future\nprogress on RS image analysis.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2001.06372v3"}
{"entry_id": "http://arxiv.org/abs/2009.08420v1", "date": "2020-09-17", "title": "Utilizing remote sensing data in forest inventory sampling via Bayesian optimization", "authors": "Jonne Pohjankukka, Sakari Tuominen, Jukka Heikkonen", "abstract": "In large-area forest inventories a trade-off between the amount of data to be\nsampled and the costs of collecting the data is necessary. It is not always\npossible to have a very large data sample when dealing with sampling-based\ninventories. It is therefore necessary to optimize the sampling design in order\nto achieve optimal population parameter estimation. On the contrary, the\navailability of remote sensing (RS) data correlated with the forest inventory\nvariables is usually much higher. The combination of RS and the sampled field\nmeasurement data is often used for improving the forest inventory parameter\nestimation. In addition, it is also reasonable to study the utilization of RS\ndata in inventory sampling, which can further improve the estimation of forest\nvariables. In this study, we propose a data sampling method based on Bayesian\noptimization which uses RS data in forest inventory sample selection. The\npresented method applies the learned functional relationship between the RS and\ninventory data in new sampling decisions. We evaluate our method by conducting\nsimulated sampling experiments with both synthetic data and measured data from\nthe Aland region in Finland. The proposed method is benchmarked against two\nbaseline methods: simple random sampling and the local pivotal method. The\nresults of the simulated experiments show the best results in terms of MSE\nvalues for the proposed method when the functional relationship between RS and\ninventory data is correctly learned from the available training data.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2009.08420v1"}
{"entry_id": "http://arxiv.org/abs/2009.10226v1", "date": "2020-09-21", "title": "Improving Maximal Safe Brain Tumor Resection with Photoacoustic Remote Sensing Microscopy", "authors": "Benjamin R. Ecclestone, Kevan Bell, Saad Abbasi, Deepak Dinakaran, Frank K. H. van Landeghem, John R. Mackey, Paul Fieguth, Parsin Haji Reza", "abstract": "Malignant brain tumors are among the deadliest neoplasms with the lowest\nsurvival rates of any cancer type. In considering surgical tumor resection,\nsuboptimal extent of resection is linked to poor clinical outcomes and lower\noverall survival rates. Currently available tools for intraoperative\nhistopathological assessment require an average of 20 minutes processing and\nare of limited diagnostic quality for guiding surgeries. Consequently, there is\nan unaddressed need for a rapid imaging technique to guide maximal resection of\nbrain tumors. Working towards this goal, presented here is an all optical\nnon-contact label-free reflection mode photoacoustic remote sensing (PARS)\nmicroscope. By using a tunable excitation laser, PARS takes advantage of the\nendogenous optical absorption peaks of DNA and cytoplasm to achieve virtual\ncontrast analogous to standard hematoxylin and eosin (H and E) staining. In\nconjunction, a fast 266 nm excitation is used to generate large grossing scans\nand rapidly assess small fields in real-time with hematoxylin-like contrast.\nImages obtained using this technique show comparable quality and contrast to\nthe current standard for histopathological assessment of brain tissues. Using\nthe proposed method, rapid, high-throughput, histological-like imaging was\nachieved in unstained brain tissues, indicating PARS utility for intraoperative\nguidance to improve extent of surgical resection.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "q-bio.TO"], "pdf_url": "http://arxiv.org/pdf/2009.10226v1"}
{"entry_id": "http://arxiv.org/abs/2102.08041v1", "date": "2021-02-16", "title": "A Multiscale Graph Convolutional Network for Change Detection in Homogeneous and Heterogeneous Remote Sensing Images", "authors": "Junzheng Wu, Biao Li, Yao Qin, Weiping Ni, Han Zhang, Yuli Sun", "abstract": "Change detection (CD) in remote sensing images has been an ever-expanding\narea of research. To date, although many methods have been proposed using\nvarious techniques, accurately identifying changes is still a great challenge,\nespecially in the high resolution or heterogeneous situations, due to the\ndifficulties in effectively modeling the features from ground objects with\ndifferent patterns. In this paper, a novel CD method based on the graph\nconvolutional network (GCN) and multiscale object-based technique is proposed\nfor both homogeneous and heterogeneous images. First, the object-wise high\nlevel features are obtained through a pre-trained U-net and the multiscale\nsegmentations. Treating each parcel as a node, the graph representations can be\nformed and then, fed into the proposed multiscale graph convolutional network\nwith each channel corresponding to one scale. The multiscale GCN propagates the\nlabel information from a small number of labeled nodes to the other ones which\nare unlabeled. Further, to comprehensively incorporate the information from the\noutput channels of multiscale GCN, a fusion strategy is designed using the\nfather-child relationships between scales. Extensive Experiments on optical,\nSAR and heterogeneous optical/SAR data sets demonstrate that the proposed\nmethod outperforms some state-of the-art methods in both qualitative and\nquantitative evaluations. Besides, the Influences of some factors are also\ndiscussed.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.IT", "eess.IV", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2102.08041v1"}
{"entry_id": "http://arxiv.org/abs/2102.10273v1", "date": "2021-02-20", "title": "Remote vibrometry recognition of nonlinear eigen-states for object coverage of randomly large size", "authors": "Michael C. Kobold, Michael McKinley", "abstract": "For objects of \"large\" vibration size such as waves on the sea surface, the\nchoice of measurement method can create different understandings of system\nbehavior. In one case, laser vibrometry measurements of a vibrating bar in a\ncontrolled laboratory setting, variation in probe spot size can omit or uncover\ncrucial structural vibration mode coupling data. In another case, a finite\nelement simulation of laser vibrometry measures a nonlinearly clattering armor\nplate system of a ground vehicle. The simulation shows that sensing the system\ndynamics simultaneously over the entire structure reveals more vibration data\nthan point measurements using a small diameter laser beam spot, regardless of\nthe variation of footprint (coverage) boundaries. Furthermore, a simulation\nmethod described herein allows calculation of transition probabilities between\nmodes (change-of-state). Wideband results of both cases demonstrate the 1/$f$\ntrend explained within -- that the energy of discrete structural vibration\nmodes tends to decrease with increasing mode number (and frequency), and why.\nThese results quantify the use of less expensive non-imaging classification\nsystems for vehicle identification using the remote sensing of surface\nvibrations \\emph{while mitigating spectral response distortion due to coverage\nvariation on the order of the structural wavelength} (spectral reduction or\nelimination).", "journal": "Journal of Vibroengineering 22, no. 3 (2020): 611-639", "doi": "10.21595/jve.2019.20501", "primary_category": "physics.ins-det", "categories": ["physics.ins-det", "nlin.CD"], "pdf_url": "http://arxiv.org/pdf/2102.10273v1"}
{"entry_id": "http://arxiv.org/abs/2106.14804v1", "date": "2021-06-28", "title": "Hyperspectral Remote Sensing Image Classification Based on Multi-scale Cross Graphic Convolution", "authors": "Yunsong Zhao, Yin Li, Zhihan Chen, Tianchong Qiu, Guojin Liu", "abstract": "The mining and utilization of features directly affect the classification\nperformance of models used in the classification and recognition of\nhyperspectral remote sensing images. Traditional models usually conduct feature\nmining from a single perspective, with the features mined being limited and the\ninternal relationships between them being ignored. Consequently, useful\nfeatures are lost and classification results are unsatisfactory. To fully mine\nand utilize image features, a new multi-scale feature-mining learning algorithm\n(MGRNet) is proposed. The model uses principal component analysis to reduce the\ndimensionality of the original hyperspectral image (HSI) to retain 99.99% of\nits semantic information and extract dimensionality reduction features. Using a\nmulti-scale convolution algorithm, the input dimensionality reduction features\nwere mined to obtain shallow features, which then served as inputs into a\nmulti-scale graph convolution algorithm to construct the internal relationships\nbetween eigenvalues at different scales. We then carried out cross fusion of\nmulti-scale information obtained by graph convolution, before inputting the new\ninformation obtained into the residual network algorithm for deep feature\nmining. Finally, a flexible maximum transfer function classifier was used to\npredict the final features and complete the classification. Experiments on\nthree common hyperspectral datasets showed the MGRNet algorithm proposed in\nthis paper to be superior to traditional methods in recognition accuracy.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2106.14804v1"}
{"entry_id": "http://arxiv.org/abs/2107.08465v1", "date": "2021-07-18", "title": "Compressed particle methods for expensive models with application in Astronomy and Remote Sensing", "authors": "Luca Martino, V\u00edctor Elvira, Javier L\u00f3pez-Santiago, Gustau Camps-Valls", "abstract": "In many inference problems, the evaluation of complex and costly models is\noften required. In this context, Bayesian methods have become very popular in\nseveral fields over the last years, in order to obtain parameter inversion,\nmodel selection or uncertainty quantification. Bayesian inference requires the\napproximation of complicated integrals involving (often costly) posterior\ndistributions. Generally, this approximation is obtained by means of Monte\nCarlo (MC) methods. In order to reduce the computational cost of the\ncorresponding technique, surrogate models (also called emulators) are often\nemployed. Another alternative approach is the so-called Approximate Bayesian\nComputation (ABC) scheme. ABC does not require the evaluation of the costly\nmodel but the ability to simulate artificial data according to that model.\nMoreover, in ABC, the choice of a suitable distance between real and artificial\ndata is also required. In this work, we introduce a novel approach where the\nexpensive model is evaluated only in some well-chosen samples. The selection of\nthese nodes is based on the so-called compressed Monte Carlo (CMC) scheme. We\nprovide theoretical results supporting the novel algorithms and give empirical\nevidence of the performance of the proposed method in several numerical\nexperiments. Two of them are real-world applications in astronomy and satellite\nremote sensing.", "journal": "", "doi": "10.1109/TAES.2021.3061791", "primary_category": "cs.CE", "categories": ["cs.CE", "stat.CO", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2107.08465v1"}
{"entry_id": "http://arxiv.org/abs/2107.11758v1", "date": "2021-07-25", "title": "Semantic Attention and Scale Complementary Network for Instance Segmentation in Remote Sensing Images", "authors": "Tianyang Zhang, Xiangrong Zhang, Peng Zhu, Xu Tang, Chen Li, Licheng Jiao, Huiyu Zhou", "abstract": "In this paper, we focus on the challenging multicategory instance\nsegmentation problem in remote sensing images (RSIs), which aims at predicting\nthe categories of all instances and localizing them with pixel-level masks.\nAlthough many landmark frameworks have demonstrated promising performance in\ninstance segmentation, the complexity in the background and scale variability\ninstances still remain challenging for instance segmentation of RSIs. To\naddress the above problems, we propose an end-to-end multi-category instance\nsegmentation model, namely Semantic Attention and Scale Complementary Network,\nwhich mainly consists of a Semantic Attention (SEA) module and a Scale\nComplementary Mask Branch (SCMB). The SEA module contains a simple fully\nconvolutional semantic segmentation branch with extra supervision to strengthen\nthe activation of interest instances on the feature map and reduce the\nbackground noise's interference. To handle the under-segmentation of geospatial\ninstances with large varying scales, we design the SCMB that extends the\noriginal single mask branch to trident mask branches and introduces\ncomplementary mask supervision at different scales to sufficiently leverage the\nmulti-scale information. We conduct comprehensive experiments to evaluate the\neffectiveness of our proposed method on the iSAID dataset and the NWPU Instance\nSegmentation dataset and achieve promising performance.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2107.11758v1"}
{"entry_id": "http://arxiv.org/abs/2109.09148v2", "date": "2021-09-19", "title": "RSI-Net: Two-Stream Deep Neural Network for Remote Sensing Imagesbased Semantic Segmentation", "authors": "Shuang He, Xia Lu, Jason Gu, Haitong Tang, Qin Yu, Kaiyue Liu, Haozhou Ding, Chunqi Chang, Nizhuan Wang", "abstract": "For semantic segmentation of remote sensing images (RSI), trade-off between\nrepresentation power and location accuracy is quite important. How to get the\ntrade-off effectively is an open question,where current approaches of utilizing\nvery deep models result in complex models with large memory consumption. In\ncontrast to previous work that utilizes dilated convolutions or deep models, we\npropose a novel two-stream deep neural network for semantic segmentation of RSI\n(RSI-Net) to obtain improved performance through modeling and propagating\nspatial contextual structure effectively and a decoding scheme with image-level\nand graph-level combination. The first component explicitly models correlations\nbetween adjacent land covers and conduct flexible convolution on arbitrarily\nirregular image regions by using graph convolutional network, while densely\nconnected atrous convolution network (DenseAtrousCNet) with multi-scale atrous\nconvolution can expand the receptive fields and obtain image global\ninformation. Extensive experiments are implemented on the Vaihingen, Potsdam\nand Gaofen RSI datasets, where the comparison results demonstrate the superior\nperformance of RSI-Net in terms of overall accuracy (91.83%, 93.31% and 93.67%\non three datasets, respectively), F1 score (90.3%, 91.49% and 89.35% on three\ndatasets, respectively) and kappa coefficient (89.46%, 90.46% and 90.37% on\nthree datasets, respectively) when compared with six state-of-the-art RSI\nsemantic segmentation methods.", "journal": "IEEE Access,2022,10:1-14", "doi": "10.1109/ACCESS.2022.3163535", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2109.09148v2"}
{"entry_id": "http://arxiv.org/abs/2109.09737v1", "date": "2021-09-19", "title": "Label-free virtual Hematoxylin and Eosin (H&E) staining using second generation Photoacoustic Remote Sensing (PARS)", "authors": "Benjamin R. Ecclestone, Kevan Bell, Sarah Sparkes, Deepak Dinakaran, John R. Mackey, Parsin Haji Reza", "abstract": "In the past decades, absorption modalities have emerged as powerful tools for\nlabel-free functional and structural imaging of cells and tissues. Many\nbiomolecules present unique absorption spectra providing chromophore-specific\ninformation on properties such as chemical bonding, and sample composition. As\nchromophores absorb photons the absorbed energy is emitted as photons\n(radiative relaxation) or converted to heat and under specific conditions\npressure (non-radiative relaxation). Modalities like fluorescence microscopy\nmay capture radiative relaxation to provide contrast, while modalities like\nphotoacoustic microscopy may leverage non-radiative heat and pressures. Here we\nshow an all-optical non-contact total-absorption photoacoustic remote sensing\n(TA-PARS) microscope, which can capture both radiative and non-radiative\nabsorption effects in a single acquisition. The TA-PARS yields an absorption\nmetric proposed as the quantum efficiency ratio (QER), which visualizes a\nbiomolecules proportional radiative and non-radiative absorption response. The\nTA-PARS provides label-free visualization of a range of biomolecules enabling\nconvincing analogues to traditional histochemical staining of tissues,\neffectively providing label-free Hematoxylin and Eosin (H&E)-like\nvisualizations. These findings represent the establishment of an effective\nall-optical non-contact total-absorption microscope for label-free inspection\nof biological media.", "journal": "", "doi": null, "primary_category": "physics.med-ph", "categories": ["physics.med-ph", "eess.IV", "physics.ins-det", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/2109.09737v1"}
{"entry_id": "http://arxiv.org/abs/2110.08733v6", "date": "2021-10-17", "title": "LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic Segmentation", "authors": "Junjue Wang, Zhuo Zheng, Ailong Ma, Xiaoyan Lu, Yanfei Zhong", "abstract": "Deep learning approaches have shown promising results in remote sensing high\nspatial resolution (HSR) land-cover mapping. However, urban and rural scenes\ncan show completely different geographical landscapes, and the inadequate\ngeneralizability of these algorithms hinders city-level or national-level\nmapping. Most of the existing HSR land-cover datasets mainly promote the\nresearch of learning semantic representation, thereby ignoring the model\ntransferability. In this paper, we introduce the Land-cOVEr Domain Adaptive\nsemantic segmentation (LoveDA) dataset to advance semantic and transferable\nlearning. The LoveDA dataset contains 5987 HSR images with 166768 annotated\nobjects from three different cities. Compared to the existing datasets, the\nLoveDA dataset encompasses two domains (urban and rural), which brings\nconsiderable challenges due to the: 1) multi-scale objects; 2) complex\nbackground samples; and 3) inconsistent class distributions. The LoveDA dataset\nis suitable for both land-cover semantic segmentation and unsupervised domain\nadaptation (UDA) tasks. Accordingly, we benchmarked the LoveDA dataset on\neleven semantic segmentation methods and eight UDA methods. Some exploratory\nstudies including multi-scale architectures and strategies, additional\nbackground supervision, and pseudo-label analysis were also carried out to\naddress these challenges. The code and data are available at\nhttps://github.com/Junjue-Wang/LoveDA.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2110.08733v6"}
{"entry_id": "http://arxiv.org/abs/2112.01715v1", "date": "2021-12-03", "title": "Self-Supervised Material and Texture Representation Learning for Remote Sensing Tasks", "authors": "Peri Akiva, Matthew Purri, Matthew Leotta", "abstract": "Self-supervised learning aims to learn image feature representations without\nthe usage of manually annotated labels. It is often used as a precursor step to\nobtain useful initial network weights which contribute to faster convergence\nand superior performance of downstream tasks. While self-supervision allows one\nto reduce the domain gap between supervised and unsupervised learning without\nthe usage of labels, the self-supervised objective still requires a strong\ninductive bias to downstream tasks for effective transfer learning. In this\nwork, we present our material and texture based self-supervision method named\nMATTER (MATerial and TExture Representation Learning), which is inspired by\nclassical material and texture methods. Material and texture can effectively\ndescribe any surface, including its tactile properties, color, and specularity.\nBy extension, effective representation of material and texture can describe\nother semantic classes strongly associated with said material and texture.\nMATTER leverages multi-temporal, spatially aligned remote sensing imagery over\nunchanged regions to learn invariance to illumination and viewing angle as a\nmechanism to achieve consistency of material and texture representation. We\nshow that our self-supervision pre-training method allows for up to 24.22% and\n6.33% performance increase in unsupervised and fine-tuned setups, and up to 76%\nfaster convergence on change detection, land cover classification, and semantic\nsegmentation tasks.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2112.01715v1"}
{"entry_id": "http://arxiv.org/abs/2112.03456v1", "date": "2021-12-07", "title": "RSBNet: One-Shot Neural Architecture Search for A Backbone Network in Remote Sensing Image Recognition", "authors": "Cheng Peng, Yangyang Li, Ronghua Shang, Licheng Jiao", "abstract": "Recently, a massive number of deep learning based approaches have been\nsuccessfully applied to various remote sensing image (RSI) recognition tasks.\nHowever, most existing advances of deep learning methods in the RSI field\nheavily rely on the features extracted by the manually designed backbone\nnetwork, which severely hinders the potential of deep learning models due the\ncomplexity of RSI and the limitation of prior knowledge. In this paper, we\nresearch a new design paradigm for the backbone architecture in RSI recognition\ntasks, including scene classification, land-cover classification and object\ndetection. A novel one-shot architecture search framework based on\nweight-sharing strategy and evolutionary algorithm is proposed, called RSBNet,\nwhich consists of three stages: Firstly, a supernet constructed in a layer-wise\nsearch space is pretrained on a self-assembled large-scale RSI dataset based on\nan ensemble single-path training strategy. Next, the pre-trained supernet is\nequipped with different recognition heads through the switchable recognition\nmodule and respectively fine-tuned on the target dataset to obtain\ntask-specific supernet. Finally, we search the optimal backbone architecture\nfor different recognition tasks based on the evolutionary algorithm without any\nnetwork training. Extensive experiments have been conducted on five benchmark\ndatasets for different recognition tasks, the results show the effectiveness of\nthe proposed search paradigm and demonstrate that the searched backbone is able\nto flexibly adapt different RSI recognition tasks and achieve impressive\nperformance.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2112.03456v1"}
{"entry_id": "http://arxiv.org/abs/2112.05220v1", "date": "2021-12-09", "title": "Hidden Path Selection Network for Semantic Segmentation of Remote Sensing Images", "authors": "Kunping Yang, Xin-Yi Tong, Gui-Song Xia, Weiming Shen, Liangpei Zhang", "abstract": "Targeting at depicting land covers with pixel-wise semantic categories,\nsemantic segmentation in remote sensing images needs to portray diverse\ndistributions over vast geographical locations, which is difficult to be\nachieved by the homogeneous pixel-wise forward paths in the architectures of\nexisting deep models. Although several algorithms have been designed to select\npixel-wise adaptive forward paths for natural image analysis, it still lacks\ntheoretical supports on how to obtain optimal selections. In this paper, we\nprovide mathematical analyses in terms of the parameter optimization, which\nguides us to design a method called Hidden Path Selection Network (HPS-Net).\nWith the help of hidden variables derived from an extra mini-branch, HPS-Net is\nable to tackle the inherent problem about inaccessible global optimums by\nadjusting the direct relationships between feature maps and pixel-wise path\nselections in existing algorithms, which we call hidden path selection. For the\nbetter training and evaluation, we further refine and expand the 5-class Gaofen\nImage Dataset (GID-5) to a new one with 15 land-cover categories, i.e., GID-15.\nThe experimental results on both GID-5 and GID-15 demonstrate that the proposed\nmodules can stably improve the performance of different deep structures, which\nvalidates the proposed mathematical analyses.", "journal": "", "doi": "10.1109/TGRS.2022.3197334", "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2112.05220v1"}
{"entry_id": "http://arxiv.org/abs/2201.06750v1", "date": "2022-01-18", "title": "DDU-Net: Dual-Decoder-U-Net for Road Extraction Using High-Resolution Remote Sensing Images", "authors": "Ying Wang, Yuexing Peng, Xinran Liu, Wei Li, George C. Alexandropoulos, Junchuan Yu, Daqing Ge, Wei Xiang", "abstract": "Extracting roads from high-resolution remote sensing images (HRSIs) is vital\nin a wide variety of applications, such as autonomous driving, path planning,\nand road navigation. Due to the long and thin shape as well as the shades\ninduced by vegetation and buildings, small-sized roads are more difficult to\ndiscern. In order to improve the reliability and accuracy of small-sized road\nextraction when roads of multiple sizes coexist in an HRSI, an enhanced deep\nneural network model termed Dual-Decoder-U-Net (DDU-Net) is proposed in this\npaper. Motivated by the U-Net model, a small decoder is added to form a\ndual-decoder structure for more detailed features. In addition, we introduce\nthe dilated convolution attention module (DCAM) between the encoder and\ndecoders to increase the receptive field as well as to distill multi-scale\nfeatures through cascading dilated convolution and global average pooling. The\nconvolutional block attention module (CBAM) is also embedded in the parallel\ndilated convolution and pooling branches to capture more attention-aware\nfeatures. Extensive experiments are conducted on the Massachusetts Roads\ndataset with experimental results showing that the proposed model outperforms\nthe state-of-the-art DenseUNet, DeepLabv3+ and D-LinkNet by 6.5%, 3.3%, and\n2.1% in the mean Intersection over Union (mIoU), and by 4%, 4.8%, and 3.1% in\nthe F1 score, respectively. Both ablation and heatmap analyses are presented to\nvalidate the effectiveness of the proposed model.", "journal": "", "doi": "10.1109/TGRS.2022.3197546", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2201.06750v1"}
{"entry_id": "http://arxiv.org/abs/2201.11523v2", "date": "2022-01-27", "title": "ResiDualGAN: Resize-Residual DualGAN for Cross-Domain Remote Sensing Images Semantic Segmentation", "authors": "Yang Zhao, Peng Guo, Zihao Sun, Xiuwan Chen, Han Gao", "abstract": "The performance of a semantic segmentation model for remote sensing (RS)\nimages pretrained on an annotated dataset would greatly decrease when testing\non another unannotated dataset because of the domain gap. Adversarial\ngenerative methods, e.g., DualGAN, are utilized for unpaired image-to-image\ntranslation to minimize the pixel-level domain gap, which is one of the common\napproaches for unsupervised domain adaptation (UDA). However, the existing\nimage translation methods are facing two problems when performing RS images\ntranslation: 1) ignoring the scale discrepancy between two RS datasets which\ngreatly affects the accuracy performance of scale-invariant objects, 2)\nignoring the characteristic of real-to-real translation of RS images which\nbrings an unstable factor for the training of the models. In this paper,\nResiDualGAN is proposed for RS images translation, where an in-network resizer\nmodule is used for addressing the scale discrepancy of RS datasets, and a\nresidual connection is used for strengthening the stability of real-to-real\nimages translation and improving the performance in cross-domain semantic\nsegmentation tasks. Combined with an output space adaptation method, the\nproposed method greatly improves the accuracy performance on common benchmarks,\nwhich demonstrates the superiority and reliability of ResiDuanGAN. At the end\nof the paper, a thorough discussion is also conducted to give a reasonable\nexplanation for the improvement of ResiDualGAN. Our source code is available at\nhttps://github.com/miemieyanga/ResiDualGAN-DRDG.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2201.11523v2"}
{"entry_id": "http://arxiv.org/abs/2202.11429v2", "date": "2022-02-23", "title": "A Novel Self-Supervised Cross-Modal Image Retrieval Method In Remote Sensing", "authors": "Gencer Sumbul, Markus M\u00fcller, Beg\u00fcm Demir", "abstract": "Due to the availability of multi-modal remote sensing (RS) image archives,\none of the most important research topics is the development of cross-modal RS\nimage retrieval (CM-RSIR) methods that search semantically similar images\nacross different modalities. Existing CM-RSIR methods require the availability\nof a high quality and quantity of annotated training images. The collection of\na sufficient number of reliable labeled images is time consuming, complex and\ncostly in operational scenarios, and can significantly affect the final\naccuracy of CM-RSIR. In this paper, we introduce a novel self-supervised\nCM-RSIR method that aims to: i) model mutual-information between different\nmodalities in a self-supervised manner; ii) retain the distributions of\nmodal-specific feature spaces similar to each other; and iii) define the most\nsimilar images within each modality without requiring any annotated training\nimage. To this end, we propose a novel objective including three loss functions\nthat simultaneously: i) maximize mutual information of different modalities for\ninter-modal similarity preservation; ii) minimize the angular distance of\nmulti-modal image tuples for the elimination of inter-modal discrepancies; and\niii) increase cosine similarity of the most similar images within each modality\nfor the characterization of intra-modal similarities. Experimental results show\nthe effectiveness of the proposed method compared to state-of-the-art methods.\nThe code of the proposed method is publicly available at\nhttps://git.tu-berlin.de/rsim/SS-CM-RSIR.", "journal": "", "doi": "10.1109/ICIP46576.2022.9897475", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2202.11429v2"}
{"entry_id": "http://arxiv.org/abs/2203.13664v1", "date": "2022-03-25", "title": "Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images", "authors": "Gongyang Li, Zhi Liu, Dan Zeng, Weisi Lin, Haibin Ling", "abstract": "Salient object detection (SOD) in optical remote sensing images (RSIs), or\nRSI-SOD, is an emerging topic in understanding optical RSIs. However, due to\nthe difference between optical RSIs and natural scene images (NSIs), directly\napplying NSI-SOD methods to optical RSIs fails to achieve satisfactory results.\nIn this paper, we propose a novel Adjacent Context Coordination Network\n(ACCoNet) to explore the coordination of adjacent features in an\nencoder-decoder architecture for RSI-SOD. Specifically, ACCoNet consists of\nthree parts: an encoder, Adjacent Context Coordination Modules (ACCoMs), and a\ndecoder. As the key component of ACCoNet, ACCoM activates the salient regions\nof output features of the encoder and transmits them to the decoder. ACCoM\ncontains a local branch and two adjacent branches to coordinate the multi-level\nfeatures simultaneously. The local branch highlights the salient regions in an\nadaptive way, while the adjacent branches introduce global information of\nadjacent levels to enhance salient regions. Additionally, to extend the\ncapabilities of the classic decoder block (i.e., several cascaded convolutional\nlayers), we extend it with two bifurcations and propose a\nBifurcation-Aggregation Block to capture the contextual information in the\ndecoder. Extensive experiments on two benchmark datasets demonstrate that the\nproposed ACCoNet outperforms 22 state-of-the-art methods under nine evaluation\nmetrics, and runs up to 81 fps on a single NVIDIA Titan X GPU. The code and\nresults of our method are available at https://github.com/MathLee/ACCoNet.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2203.13664v1"}
{"entry_id": "http://arxiv.org/abs/2205.09250v2", "date": "2022-05-19", "title": "Bayesian Convolutional Neural Networks for Limited Data Hyperspectral Remote Sensing Image Classification", "authors": "Mohammad Joshaghani, Amirabbas Davari, Faezeh Nejati Hatamian, Andreas Maier, Christian Riess", "abstract": "Employing deep neural networks for Hyperspectral remote sensing (HSRS) image\nclassification is a challenging task. HSRS images have high dimensionality and\na large number of channels with substantial redundancy between channels. In\naddition, the training data for classifying HSRS images is limited and the\namount of available training data is much smaller compared to other\nclassification tasks. These factors complicate the training process of deep\nneural networks with many parameters and cause them to not perform well even\ncompared to conventional models. Moreover, convolutional neural networks\nproduce over-confident predictions, which is highly undesirable considering the\naforementioned problem.\n  In this work, we use for HSRS image classification a special class of deep\nneural networks, namely a Bayesian neural network (BNN). To the extent of our\nknowledge, this is the first time that BNNs are used in HSRS image\nclassification. BNNs inherently provide a measure for uncertainty. We perform\nextensive experiments on the Pavia Centre, Salinas, and Botswana datasets. We\nshow that a BNN outperforms a standard convolutional neural network (CNN) and\nan off-the-shelf Random Forest (RF). Further experiments underline that the BNN\nis more stable and robust to model pruning, and that the uncertainty is higher\nfor samples with higher expected prediction error.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2205.09250v2"}
{"entry_id": "http://arxiv.org/abs/2210.03829v1", "date": "2022-10-07", "title": "Early Detection of Bark Beetle Attack Using Remote Sensing and Machine Learning: A Review", "authors": "Seyed Mojtaba Marvasti-Zadeh, Devin Goodsman, Nilanjan Ray, Nadir Erbilgin", "abstract": "Bark beetle outbreaks can result in a devastating impact on forest ecosystem\nprocesses, biodiversity, forest structure and function, and economies. Accurate\nand timely detection of bark beetle infestations is crucial to mitigate further\ndamage, develop proactive forest management activities, and minimize economic\nlosses. Incorporating remote sensing (RS) data with machine learning (ML) (or\ndeep learning (DL)) can provide a great alternative to the current approaches\nthat rely on aerial surveys and field surveys, which are impractical over vast\ngeographical regions. This paper provides a comprehensive review of past and\ncurrent advances in the early detection of bark beetle-induced tree mortality\nfrom three key perspectives: bark beetle & host interactions, RS, and ML/DL. We\nparse recent literature according to bark beetle species & attack phases, host\ntrees, study regions, imagery platforms & sensors, spectral/spatial/temporal\nresolutions, spectral signatures, spectral vegetation indices (SVIs), ML\napproaches, learning schemes, task categories, models, algorithms,\nclasses/clusters, features, and DL networks & architectures. This review\nfocuses on challenging early detection, discussing current challenges and\npotential solutions. Our literature survey suggests that the performance of\ncurrent ML methods is limited (less than 80%) and depends on various factors,\nincluding imagery sensors & resolutions, acquisition dates, and employed\nfeatures & algorithms/networks. A more promising result from DL networks and\nthen the random forest (RF) algorithm highlighted the potential to detect\nsubtle changes in visible, thermal, and short-wave infrared (SWIR) spectral\nregions.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.03829v1"}
{"entry_id": "http://arxiv.org/abs/2211.13286v1", "date": "2022-11-23", "title": "Corn Yield Prediction based on Remotely Sensed Variables Using Variational Autoencoder and Multiple Instance Regression", "authors": "Zeyu Cao, Yuchi Ma, Zhou Zhang", "abstract": "In the U.S., corn is the most produced crop and has been an essential part of\nthe American diet. To meet the demand for supply chain management and regional\nfood security, accurate and timely large-scale corn yield prediction is\nattracting more attention in precision agriculture. Recently, remote sensing\ntechnology and machine learning methods have been widely explored for crop\nyield prediction. Currently, most county-level yield prediction models use\ncounty-level mean variables for prediction, ignoring much detailed information.\nMoreover, inconsistent spatial resolution between crop area and satellite\nsensors results in mixed pixels, which may decrease the prediction accuracy.\nOnly a few works have addressed the mixed pixels problem in large-scale crop\nyield prediction. To address the information loss and mixed pixels problem, we\ndeveloped a variational autoencoder (VAE) based multiple instance regression\n(MIR) model for large-scaled corn yield prediction. We use all unlabeled data\nto train a VAE and the well-trained VAE for anomaly detection. As a preprocess\nmethod, anomaly detection can help MIR find a better representation of every\nbag than traditional MIR methods, thus better performing in large-scale corn\nyield prediction. Our experiments showed that variational autoencoder based\nmultiple instance regression (VAEMIR) outperformed all baseline methods in\nlarge-scale corn yield prediction. Though a suitable meta parameter is\nrequired, VAEMIR shows excellent potential in feature learning and extraction\nfor large-scale corn yield prediction.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2211.13286v1"}
{"entry_id": "http://arxiv.org/abs/1308.1864v1", "date": "2013-08-08", "title": "Remote sensing of seawater and drifting ice in Svalbard fjords by compact Raman LIDAR", "authors": "Alexey F. Bunkin, Vladimir K. Klinkov, Vasily N. Lednev, Dmitry L. Lushnikov, Aleksey V. Marchenko, Eugene G. Morozov, Sergey M. Pershin, Renat N. Yulmetov", "abstract": "A compact Raman LIDAR system for remote sensing of sea and drifting ice was\ndeveloped at the Wave Research Center at the Prokhorov General Physics\nInstitute of the RAS. The developed system is based on a diode pumped solid\nstate YVO4:Nd laser combined with compact spectrograph equipped with gated\ndetector. The system exhibits high sensitivity and can be used for mapping or\ndepth profiling of different parameters within many oceanographic problems.\nLight weight (~20 kg) and low power consumption (300 W) make possible to\ninstall the device on any vehicle including unmanned aircraft or submarine\nsystem. The Raman LIDAR presented was used for Svalbard fjords study and\nanalysis of different influence of the open sea and glaciers on the water\nproperties. Temperature, phytoplankton, and dissolved organic matter\ndistributions in the seawater were studied in the Ice Fjord, Van Mijen Fjord\nand Rinders Fjord. Drifting ice and seawater in the Rinders Fjord were\ncharacterized by the Raman spectroscopy and fluorescence. It was found that the\nPaula Glacier strongly influences the water temperature and chlorophyll\ndistributions in the Van Mijen Fjord and Rinders Fjord. Possible applications\nof compact LIDAR systems for express monitoring of seawater in the places with\nhigh concentration of floating ice or near cold streams in the Arctic Ocean are\ndiscussed", "journal": "Applied optics, 2012", "doi": null, "primary_category": "physics.optics", "categories": ["physics.optics", "physics.ao-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/1308.1864v1"}
{"entry_id": "http://arxiv.org/abs/1510.00098v2", "date": "2015-10-01", "title": "Transfer Learning from Deep Features for Remote Sensing and Poverty Mapping", "authors": "Michael Xie, Neal Jean, Marshall Burke, David Lobell, Stefano Ermon", "abstract": "The lack of reliable data in developing countries is a major obstacle to\nsustainable development, food security, and disaster relief. Poverty data, for\nexample, is typically scarce, sparse in coverage, and labor-intensive to\nobtain. Remote sensing data such as high-resolution satellite imagery, on the\nother hand, is becoming increasingly available and inexpensive. Unfortunately,\nsuch data is highly unstructured and currently no techniques exist to\nautomatically extract useful insights to inform policy decisions and help\ndirect humanitarian efforts. We propose a novel machine learning approach to\nextract large-scale socioeconomic indicators from high-resolution satellite\nimagery. The main challenge is that training data is very scarce, making it\ndifficult to apply modern techniques such as Convolutional Neural Networks\n(CNN). We therefore propose a transfer learning approach where nighttime light\nintensities are used as a data-rich proxy. We train a fully convolutional CNN\nmodel to predict nighttime lights from daytime imagery, simultaneously learning\nfeatures that are useful for poverty prediction. The model learns filters\nidentifying different terrains and man-made structures, including roads,\nbuildings, and farmlands, without any supervision beyond nighttime lights. We\ndemonstrate that these learned features are highly informative for poverty\nmapping, even approaching the predictive performance of survey data collected\nin the field.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.CY"], "pdf_url": "http://arxiv.org/pdf/1510.00098v2"}
{"entry_id": "http://arxiv.org/abs/1805.03371v4", "date": "2018-05-09", "title": "PSGAN: A Generative Adversarial Network for Remote Sensing Image Pan-Sharpening", "authors": "Qingjie Liu, Huanyu Zhou, Qizhi Xu, Xiangyu Liu, Yunhong Wang", "abstract": "This paper addresses the problem of remote sensing image pan-sharpening from\nthe perspective of generative adversarial learning. We propose a novel deep\nneural network based method named PSGAN. To the best of our knowledge, this is\none of the first attempts at producing high-quality pan-sharpened images with\nGANs. The PSGAN consists of two components: a generative network (i.e.,\ngenerator) and a discriminative network (i.e., discriminator). The generator is\ndesigned to accept panchromatic (PAN) and multispectral (MS) images as inputs\nand maps them to the desired high-resolution (HR) MS images and the\ndiscriminator implements the adversarial training strategy for generating\nhigher fidelity pan-sharpened images. In this paper, we evaluate several\narchitectures and designs, namely two-stream input, stacking input, batch\nnormalization layer, and attention mechanism to find the optimal solution for\npan-sharpening. Extensive experiments on QuickBird, GaoFen-2, and WorldView-2\nsatellite images demonstrate that the proposed PSGANs not only are effective in\ngenerating high-quality HR MS images and superior to state-of-the-art methods\nand also generalize well to full-scale images.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/1805.03371v4"}
{"entry_id": "http://arxiv.org/abs/1912.02305v2", "date": "2019-12-04", "title": "HABNet: Machine Learning, Remote Sensing Based Detection and Prediction of Harmful Algal Blooms", "authors": "P. R. Hill, A. Kumar, M. Temimi, D. R. Bull", "abstract": "This paper describes the application of machine learning techniques to\ndevelop a state-of-the-art detection and prediction system for spatiotemporal\nevents found within remote sensing data; specifically, Harmful Algal Bloom\nevents (HABs). We propose an HAB detection system based on: a ground truth\nhistorical record of HAB events, a novel spatiotemporal datacube representation\nof each event (from MODIS and GEBCO bathymetry data) and a variety of machine\nlearning architectures utilising state-of-the-art spatial and temporal analysis\nmethods based on Convolutional Neural Networks (CNNs), Long Short-Term Memory\n(LSTM) components together with Random Forest and Support Vector Machine (SVM)\nclassification methods.\n  This work has focused specifically on the case study of the detection of\nKarenia Brevis Algae (K. brevis) HAB events within the coastal waters of\nFlorida (over 2850 events from 2003 to 2018; an order of magnitude larger than\nany previous machine learning detection study into HAB events).\n  The development of multimodal spatiotemporal datacube data structures and\nassociated novel machine learning methods give a unique architecture for the\nautomatic detection of environmental events. Specifically, when applied to the\ndetection of HAB events it gives a maximum detection accuracy of 91% and a\nKappa coefficient of 0.81 for the Florida data considered.\n  A HAB forecast system was also developed where a temporal subset of each\ndatacube was used to predict the presence of a HAB in the future. This system\nwas not significantly less accurate than the detection system being able to\npredict with 86% accuracy up to 8 days in the future.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "eess.SP"], "pdf_url": "http://arxiv.org/pdf/1912.02305v2"}
{"entry_id": "http://arxiv.org/abs/2008.04021v1", "date": "2020-08-10", "title": "Road Segmentation for Remote Sensing Images using Adversarial Spatial Pyramid Networks", "authors": "Pourya Shamsolmoali, Masoumeh Zareapoor, Huiyu Zhou, Ruili Wang, Jie Yang", "abstract": "Road extraction in remote sensing images is of great importance for a wide\nrange of applications. Because of the complex background, and high density,\nmost of the existing methods fail to accurately extract a road network that\nappears correct and complete. Moreover, they suffer from either insufficient\ntraining data or high costs of manual annotation. To address these problems, we\nintroduce a new model to apply structured domain adaption for synthetic image\ngeneration and road segmentation. We incorporate a feature pyramid network into\ngenerative adversarial networks to minimize the difference between the source\nand target domains. A generator is learned to produce quality synthetic images,\nand the discriminator attempts to distinguish them. We also propose a feature\npyramid network that improves the performance of the proposed model by\nextracting effective features from all the layers of the network for describing\ndifferent scales objects. Indeed, a novel scale-wise architecture is introduced\nto learn from the multi-level feature maps and improve the semantics of the\nfeatures. For optimization, the model is trained by a joint reconstruction loss\nfunction, which minimizes the difference between the fake images and the real\nones. A wide range of experiments on three datasets prove the superior\nperformance of the proposed approach in terms of accuracy and efficiency. In\nparticular, our model achieves state-of-the-art 78.86 IOU on the Massachusetts\ndataset with 14.89M parameters and 86.78B FLOPs, with 4x fewer FLOPs but higher\naccuracy (+3.47% IOU) than the top performer among state-of-the-art approaches\nused in the evaluation.", "journal": "", "doi": "10.1109/TGRS.2020.3016086", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2008.04021v1"}
{"entry_id": "http://arxiv.org/abs/2010.07626v3", "date": "2020-10-15", "title": "Minimization of Age-of-Information in Remote Sensing with Energy Harvesting", "authors": "Akanksha Jaiswal, Arpan Chattopadhyay", "abstract": "In this paper, the minimization of time-averaged age-of-information (AoI) in\nan energy harvesting (EH) source-equipped remote sensing setting is considered.\nThe EH source opportunistically samples one or multiple processes over discrete\ntime instants and sends the status updates to a sink node over a time-varying\nwireless link. At any discrete-time instant, the EH node decides whether to\nprobe the link quality using its stored energy and further decides whether to\nsample a process and communicate the data based on the channel probe outcome.\nThe trade-off is between the freshness of information available at the sink\nnode and the available energy at the energy buffer of the source node. To this\nend, an infinite horizon Markov decision process theory is used to formulate\nthe problem of minimization of time-averaged expected AoI for a single energy\nharvesting source node. The following two scenarios are considered: (i) single\nprocess with channel state information at the transmitter (CSIT), (ii) multiple\nprocesses with CSIT. In each scenario, for probed channel state, the optimal\nsource node sampling policy is shown to be a threshold policy involving the\ninstantaneous age of the process(es), the available energy in the buffer, and\nthe instantaneous channel quality as the decision variables. Finally, numerical\nresults are provided to demonstrate the policy structures and trade-offs.", "journal": "https://arxiv.org/abs/2010.07626v1", "doi": null, "primary_category": "cs.IT", "categories": ["cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2010.07626v3"}
{"entry_id": "http://arxiv.org/abs/2011.13144v1", "date": "2020-11-26", "title": "Dense Attention Fluid Network for Salient Object Detection in Optical Remote Sensing Images", "authors": "Qijian Zhang, Runmin Cong, Chongyi Li, Ming-Ming Cheng, Yuming Fang, Xiaochun Cao, Yao Zhao, Sam Kwong", "abstract": "Despite the remarkable advances in visual saliency analysis for natural scene\nimages (NSIs), salient object detection (SOD) for optical remote sensing images\n(RSIs) still remains an open and challenging problem. In this paper, we propose\nan end-to-end Dense Attention Fluid Network (DAFNet) for SOD in optical RSIs. A\nGlobal Context-aware Attention (GCA) module is proposed to adaptively capture\nlong-range semantic context relationships, and is further embedded in a Dense\nAttention Fluid (DAF) structure that enables shallow attention cues flow into\ndeep layers to guide the generation of high-level feature attention maps.\nSpecifically, the GCA module is composed of two key components, where the\nglobal feature aggregation module achieves mutual reinforcement of salient\nfeature embeddings from any two spatial locations, and the cascaded pyramid\nattention module tackles the scale variation issue by building up a cascaded\npyramid framework to progressively refine the attention map in a coarse-to-fine\nmanner. In addition, we construct a new and challenging optical RSI dataset for\nSOD that contains 2,000 images with pixel-wise saliency annotations, which is\ncurrently the largest publicly available benchmark. Extensive experiments\ndemonstrate that our proposed DAFNet significantly outperforms the existing\nstate-of-the-art SOD competitors. https://github.com/rmcong/DAFNet_TIP20", "journal": "", "doi": "10.1109/TIP.2020.3042084", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2011.13144v1"}
{"entry_id": "http://arxiv.org/abs/2012.14569v1", "date": "2020-12-29", "title": "MGML: Multi-Granularity Multi-Level Feature Ensemble Network for Remote Sensing Scene Classification", "authors": "Qi Zhao, Shuchang Lyu, Yuewen Li, Yujing Ma, Lijiang Chen", "abstract": "Remote sensing (RS) scene classification is a challenging task to predict\nscene categories of RS images. RS images have two main characters: large\nintra-class variance caused by large resolution variance and confusing\ninformation from large geographic covering area. To ease the negative influence\nfrom the above two characters. We propose a Multi-granularity Multi-Level\nFeature Ensemble Network (MGML-FENet) to efficiently tackle RS scene\nclassification task in this paper. Specifically, we propose Multi-granularity\nMulti-Level Feature Fusion Branch (MGML-FFB) to extract multi-granularity\nfeatures in different levels of network by channel-separate feature generator\n(CS-FG). To avoid the interference from confusing information, we propose\nMulti-granularity Multi-Level Feature Ensemble Module (MGML-FEM) which can\nprovide diverse predictions by full-channel feature generator (FC-FG). Compared\nto previous methods, our proposed networks have ability to use structure\ninformation and abundant fine-grained features. Furthermore, through ensemble\nlearning method, our proposed MGML-FENets can obtain more convincing final\npredictions. Extensive classification experiments on multiple RS datasets (AID,\nNWPU-RESISC45, UC-Merced and VGoogle) demonstrate that our proposed networks\nachieve better performance than previous state-of-the-art (SOTA) networks. The\nvisualization analysis also shows the good interpretability of MGML-FENet.", "journal": "", "doi": "10.1109/TNNLS.2021.3106391", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2012.14569v1"}
{"entry_id": "http://arxiv.org/abs/2102.10225v1", "date": "2021-02-20", "title": "Single Acquisition Label-free Histology-like Imaging with Dual Contrast Photoacoustic Remote Sensing Microscopy", "authors": "Benjamin Ecclestone, Deepak Dinakaran, Parsin Haji Reza", "abstract": "Significance: Histopathological analysis of tissues is an essential tool for\ngrading, staging, diagnosing and resecting cancers and other malignancies.\nCurrent histopathological techniques require substantial sample processing\nprior to staining with hematoxylin and eosin (H&E) dyes, to highlight nuclear\nand cellular morphology. Sample preparation and staining is resource-intensive\nand introduces potential for variability during sample preparation.\n  Aim: We present a novel method for direct label-free histopathological\nassessment of formalin fixed paraffin embedded tissue blocks and thin tissue\nsections using a dual contrast photoacoustic remote sensing (PARS) microscopy\nsystem.\n  Approach: To emulate the nuclear and cellular contrast of H&E staining, we\nleverage unique properties of the PARS system. Here the ultraviolet excitation\nof the PAARS microscope takes advantage of DNA's unique optical absorption to\nprovide nuclear contrast analogous to hematoxylin staining of cell nucelli.\nConcurrently, the optical scattering contrast of the PARS detection system is\nleveraged to provide bulk tissue contrast analogous to eosin staining of cell\nmembranes.\n  Results: We demonstrate the efficacy of this technique by imaging human\nbreast tissue and human skin tissues in formalin fixed paraffin embedded tissue\nblocks and frozen sections respectively. Salient nuclear and extra-nuclear\nfeatures such as cancerous cells, glands and ducts, adipocytes, and stromal\nstructures such as collagen.\n  Conclusions. The presented dual contrast PARS microscope enables label-free\nvisualizations of tissue with contrast and quality analogous to the current\ngold standard for histopathological analysis. Thus, the proposed system is well\npositioned to augment existing histopathological workflows, providing\nhistological imaging directly on unstained tissue blocks and sections.", "journal": "", "doi": "10.1117/1.JBO.26.5.056007", "primary_category": "physics.med-ph", "categories": ["physics.med-ph", "eess.IV", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/2102.10225v1"}
{"entry_id": "http://arxiv.org/abs/2103.01449v1", "date": "2021-03-02", "title": "Interpretable Hyperspectral AI: When Non-Convex Modeling meets Hyperspectral Remote Sensing", "authors": "Danfeng Hong, Wei He, Naoto Yokoya, Jing Yao, Lianru Gao, Liangpei Zhang, Jocelyn Chanussot, Xiao Xiang Zhu", "abstract": "Hyperspectral imaging, also known as image spectrometry, is a landmark\ntechnique in geoscience and remote sensing (RS). In the past decade, enormous\nefforts have been made to process and analyze these hyperspectral (HS) products\nmainly by means of seasoned experts. However, with the ever-growing volume of\ndata, the bulk of costs in manpower and material resources poses new challenges\non reducing the burden of manual labor and improving efficiency. For this\nreason, it is, therefore, urgent to develop more intelligent and automatic\napproaches for various HS RS applications. Machine learning (ML) tools with\nconvex optimization have successfully undertaken the tasks of numerous\nartificial intelligence (AI)-related applications. However, their ability in\nhandling complex practical problems remains limited, particularly for HS data,\ndue to the effects of various spectral variabilities in the process of HS\nimaging and the complexity and redundancy of higher dimensional HS signals.\nCompared to the convex models, non-convex modeling, which is capable of\ncharacterizing more complex real scenes and providing the model\ninterpretability technically and theoretically, has been proven to be a\nfeasible solution to reduce the gap between challenging HS vision tasks and\ncurrently advanced intelligent data processing models.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2103.01449v1"}
{"entry_id": "http://arxiv.org/abs/2104.00222v1", "date": "2021-04-01", "title": "Embedded Self-Distillation in Compact Multi-Branch Ensemble Network for Remote Sensing Scene Classification", "authors": "Qi Zhao, Yujing Ma, Shuchang Lyu, Lijiang Chen", "abstract": "Remote sensing (RS) image scene classification task faces many challenges due\nto the interference from different characteristics of different geographical\nelements. To solve this problem, we propose a multi-branch ensemble network to\nenhance the feature representation ability by fusing features in final output\nlogits and intermediate feature maps. However, simply adding branches will\nincrease the complexity of models and decline the inference efficiency. On this\nissue, we embed self-distillation (SD) method to transfer knowledge from\nensemble network to main-branch in it. Through optimizing with SD, main-branch\nwill have close performance as ensemble network. During inference, we can cut\nother branches to simplify the whole model. In this paper, we first design\ncompact multi-branch ensemble network, which can be trained in an end-to-end\nmanner. Then, we insert SD method on output logits and feature maps. Compared\nto previous methods, our proposed architecture (ESD-MBENet) performs strongly\non classification accuracy with compact design. Extensive experiments are\napplied on three benchmark RS datasets AID, NWPU-RESISC45 and UC-Merced with\nthree classic baseline models, VGG16, ResNet50 and DenseNet121. Results prove\nthat our proposed ESD-MBENet can achieve better accuracy than previous\nstate-of-the-art (SOTA) complex models. Moreover, abundant visualization\nanalysis make our method more convincing and interpretable.", "journal": "", "doi": "10.1109/TGRS.2021.3126770", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2104.00222v1"}
{"entry_id": "http://arxiv.org/abs/2105.05496v2", "date": "2021-05-12", "title": "A Consensual Collaborative Learning Method for Remote Sensing Image Classification Under Noisy Multi-Labels", "authors": "Ahmet Kerem Aksoy, Mahdyar Ravanbakhsh, Tristan Kreuziger, Begum Demir", "abstract": "Collecting a large number of reliable training images annotated by multiple\nland-cover class labels in the framework of multi-label classification is\ntime-consuming and costly in remote sensing (RS). To address this problem,\npublicly available thematic products are often used for annotating RS images\nwith zero-labeling-cost. However, such an approach may result in constructing a\ntraining set with noisy multi-labels, distorting the learning process. To\naddress this problem, we propose a Consensual Collaborative Multi-Label\nLearning (CCML) method. The proposed CCML identifies, ranks and corrects\ntraining images with noisy multi-labels through four main modules: 1)\ndiscrepancy module; 2) group lasso module; 3) flipping module; and 4) swap\nmodule. The discrepancy module ensures that the two networks learn diverse\nfeatures, while obtaining the same predictions. The group lasso module detects\nthe potentially noisy labels by estimating the label uncertainty based on the\naggregation of two collaborative networks. The flipping module corrects the\nidentified noisy labels, whereas the swap module exchanges the ranking\ninformation between the two networks. The experimental results confirm the\nsuccess of the proposed CCML under high (synthetically added) multi-label noise\nrates. The code of the proposed method is publicly available at\nhttps://noisy-labels-in-rs.org", "journal": "", "doi": "10.1109/ICIP42928.2021.9506236", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2105.05496v2"}
{"entry_id": "http://arxiv.org/abs/2106.13323v2", "date": "2021-06-24", "title": "Domain-guided Machine Learning for Remotely Sensed In-Season Crop Growth Estimation", "authors": "George Worrall, Anand Rangarajan, Jasmeet Judge", "abstract": "Advanced machine learning techniques have been used in remote sensing (RS)\napplications such as crop mapping and yield prediction, but remain\nunder-utilized for tracking crop progress. In this study, we demonstrate the\nuse of agronomic knowledge of crop growth drivers in a Long Short-Term\nMemory-based, domain-guided neural network (DgNN) for in-season crop progress\nestimation. The DgNN uses a branched structure and attention to separate\nindependent crop growth drivers and capture their varying importance throughout\nthe growing season. The DgNN is implemented for corn, using RS data in Iowa for\nthe period 2003-2019, with USDA crop progress reports used as ground truth.\nState-wide DgNN performance shows significant improvement over sequential and\ndense-only NN structures, and a widely-used Hidden Markov Model method. The\nDgNN had a 4.0% higher Nash-Sutfliffe efficiency over all growth stages and 39%\nmore weeks with highest cosine similarity than the next best NN during test\nyears. The DgNN and Sequential NN were more robust during periods of abnormal\ncrop progress, though estimating the Silking-Grainfill transition was difficult\nfor all methods. Finally, Uniform Manifold Approximation and Projection\nvisualizations of layer activations showed how LSTM-based NNs separate crop\ngrowth time-series differently from a dense-only structure. Results from this\nstudy exhibit both the viability of NNs in crop growth stage estimation (CGSE)\nand the benefits of using domain knowledge. The DgNN methodology presented here\ncan be extended to provide near-real time CGSE of other crops.", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2106.13323v2"}
{"entry_id": "http://arxiv.org/abs/2210.07751v1", "date": "2022-10-14", "title": "Blind Super-Resolution for Remote Sensing Images via Conditional Stochastic Normalizing Flows", "authors": "Hanlin Wu, Ning Ni, Shan Wang, Libao Zhang", "abstract": "Remote sensing images (RSIs) in real scenes may be disturbed by multiple\nfactors such as optical blur, undersampling, and additional noise, resulting in\ncomplex and diverse degradation models. At present, the mainstream SR\nalgorithms only consider a single and fixed degradation (such as bicubic\ninterpolation) and cannot flexibly handle complex degradations in real scenes.\nTherefore, designing a super-resolution (SR) model that can cope with various\ndegradations is gradually attracting the attention of researchers. Some studies\nfirst estimate the degradation kernels and then perform degradation-adaptive SR\nbut face the problems of estimation error amplification and insufficient\nhigh-frequency details in the results. Although blind SR algorithms based on\ngenerative adversarial networks (GAN) have greatly improved visual quality,\nthey still suffer from pseudo-texture, mode collapse, and poor training\nstability. In this article, we propose a novel blind SR framework based on the\nstochastic normalizing flow (BlindSRSNF) to address the above problems.\nBlindSRSNF learns the conditional probability distribution over the\nhigh-resolution image space given a low-resolution (LR) image by explicitly\noptimizing the variational bound on the likelihood. BlindSRSNF is easy to train\nand can generate photo-realistic SR results that outperform GAN-based models.\nBesides, we introduce a degradation representation strategy based on\ncontrastive learning to avoid the error amplification problem caused by the\nexplicit degradation estimation. Comprehensive experiments show that the\nproposed algorithm can obtain SR results with excellent visual perception\nquality on both simulated LR and real-world RSIs.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.07751v1"}
{"entry_id": "http://arxiv.org/abs/2210.15972v1", "date": "2022-10-28", "title": "Contextual Learning in Fourier Complex Field for VHR Remote Sensing Images", "authors": "Yan Zhang, Xiyuan Gao, Qingyan Duan, Jiaxu Leng, Xiao Pu, Xinbo Gao", "abstract": "Very high-resolution (VHR) remote sensing (RS) image classification is the\nfundamental task for RS image analysis and understanding. Recently,\ntransformer-based models demonstrated outstanding potential for learning\nhigh-order contextual relationships from natural images with general resolution\n(224x224 pixels) and achieved remarkable results on general image\nclassification tasks. However, the complexity of the naive transformer grows\nquadratically with the increase in image size, which prevents transformer-based\nmodels from VHR RS image (500x500 pixels) classification and other\ncomputationally expensive downstream tasks. To this end, we propose to\ndecompose the expensive self-attention (SA) into real and imaginary parts via\ndiscrete Fourier transform (DFT) and therefore propose an efficient complex\nself-attention (CSA) mechanism. Benefiting from the conjugated symmetric\nproperty of DFT, CSA is capable to model the high-order contextual information\nwith less than half computations of naive SA. To overcome the gradient\nexplosion in Fourier complex field, we replace the Softmax function with the\ncarefully designed Logmax function to normalize the attention map of CSA and\nstabilize the gradient propagation. By stacking various layers of CSA blocks,\nwe propose the Fourier Complex Transformer (FCT) model to learn global\ncontextual information from VHR aerial images following the hierarchical\nmanners. Universal experiments conducted on commonly used RS classification\ndata sets demonstrate the effectiveness and efficiency of FCT, especially on\nvery high-resolution RS images.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2210.15972v1"}
{"entry_id": "http://arxiv.org/abs/2212.07623v1", "date": "2022-12-15", "title": "SBSS: Stacking-Based Semantic Segmentation Framework for Very High Resolution Remote Sensing Image", "authors": "Yuanzhi Cai, Lei Fan, Yuan Fang", "abstract": "Semantic segmentation of Very High Resolution (VHR) remote sensing images is\na fundamental task for many applications. However, large variations in the\nscales of objects in those VHR images pose a challenge for performing accurate\nsemantic segmentation. Existing semantic segmentation networks are able to\nanalyse an input image at up to four resizing scales, but this may be\ninsufficient given the diversity of object scales. Therefore, Multi Scale (MS)\ntest-time data augmentation is often used in practice to obtain more accurate\nsegmentation results, which makes equal use of the segmentation results\nobtained at the different resizing scales. However, it was found in this study\nthat different classes of objects had their preferred resizing scale for more\naccurate semantic segmentation. Based on this behaviour, a Stacking-Based\nSemantic Segmentation (SBSS) framework is proposed to improve the segmentation\nresults by learning this behaviour, which contains a learnable Error Correction\nModule (ECM) for segmentation result fusion and an Error Correction Scheme\n(ECS) for computational complexity control. Two ECS, i.e., ECS-MS and ECS-SS,\nare proposed and investigated in this study. The Floating-point operations\n(Flops) required for ECS-MS and ECS-SS are similar to the commonly used MS test\nand the Single-Scale (SS) test, respectively. Extensive experiments on four\ndatasets (i.e., Cityscapes, UAVid, LoveDA and Potsdam) show that SBSS is an\neffective and flexible framework. It achieved higher accuracy than MS when\nusing ECS-MS, and similar accuracy as SS with a quarter of the memory footprint\nwhen using ECS-SS.", "journal": "", "doi": "10.1109/TGRS.2023.3234549", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2212.07623v1"}
{"entry_id": "http://arxiv.org/abs/2302.06060v1", "date": "2023-02-13", "title": "Threatening Patch Attacks on Object Detection in Optical Remote Sensing Images", "authors": "Xuxiang Sun, Gong Cheng, Lei Pei, Hongda Li, Junwei Han", "abstract": "Advanced Patch Attacks (PAs) on object detection in natural images have\npointed out the great safety vulnerability in methods based on deep neural\nnetworks. However, little attention has been paid to this topic in Optical\nRemote Sensing Images (O-RSIs). To this end, we focus on this research, i.e.,\nPAs on object detection in O-RSIs, and propose a more Threatening PA without\nthe scarification of the visual quality, dubbed TPA. Specifically, to address\nthe problem of inconsistency between local and global landscapes in existing\npatch selection schemes, we propose leveraging the First-Order Difference (FOD)\nof the objective function before and after masking to select the sub-patches to\nbe attacked. Further, considering the problem of gradient inundation when\napplying existing coordinate-based loss to PAs directly, we design an IoU-based\nobjective function specific for PAs, dubbed Bounding box Drifting Loss (BDL),\nwhich pushes the detected bounding boxes far from the initial ones until there\nare no intersections between them. Finally, on two widely used benchmarks,\ni.e., DIOR and DOTA, comprehensive evaluations of our TPA with four typical\ndetectors (Faster R-CNN, FCOS, RetinaNet, and YOLO-v4) witness its remarkable\neffectiveness. To the best of our knowledge, this is the first attempt to study\nthe PAs on object detection in O-RSIs, and we hope this work can get our\nreaders interested in studying this topic.", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2302.06060v1"}
{"entry_id": "http://arxiv.org/abs/0903.2334v1", "date": "2009-03-13", "title": "Habitable Zones for Earth-mass Planets in Multiple Planetary Systems", "authors": "Ji Jianghui, Liu Lin, H. Kinoshita, Li Guangyu", "abstract": "We perform numerical simulations to study the Habitable zones (HZs) and\ndynamical structure for Earth-mass planets in multiple planetary systems. For\nexample, in the HD 69830 system, we extensively explore the planetary\nconfiguration of three Neptune-mass companions with one massive terrestrial\nplanet residing in 0.07 AU $\\leq a \\leq$ 1.20 AU, to examine the asteroid\nstructure in this system. We underline that there are stable zones of at least\n$10^5$ yr for low-mass terrestrial planets locating between 0.3 and 0.5 AU, and\n0.8 and 1.2 AU with final eccentricities of $e < 0.20$. Moreover, we also find\nthat the accumulation or depletion of the asteroid belt are also shaped by\norbital resonances of the outer planets, for example, the asteroidal gaps at\n2:1 and 3:2 mean motion resonances (MMRs) with Planet C, and 5:2 and 1:2 MMRs\nwith Planet D. In a dynamical sense, the proper candidate regions for the\nexistence of the potential terrestrial planets or HZs are 0.35 AU $< a < $ 0.50\nAU, and 0.80 AU $< a < $ 1.00 AU for relatively low eccentricities, which makes\nsense to have the possible asteroidal structure in this system.", "journal": "IAU Symposium 249. Cambridge: Cambridge University Press, 2008,\n  pp.499-502", "doi": "10.1017/S174392130801702X", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0903.2334v1"}
{"entry_id": "http://arxiv.org/abs/physics/0211069v1", "date": "2002-11-15", "title": "An Fe-Si-Ni solidification model of the Earth's layering", "authors": "A. Aitta", "abstract": "The physical process creating layered structure in planetary rocky bodies is\nconsidered here to be multicomponent solidification. This is a unified\nalternative approach to the present interpretations where each layer is\nreasoned and matched individually. The Earth's solidification is modelled using\nthe ternary phase diagram Fe-Si-Ni. The four cotectic concentrations and the\nfour corresponding seismic discontinuity radii have been used to show that the\nsilicon concentration as a function of the distance R from the centre of the\nEarth can be modelled by C(Si) = G(R/Re)(R/Re) where G = 0.583, Re is the\nEarth's radius and the Ni/Fe ratio is 0.072. Earth would have up to 13\nchemically different layers. This model predicts that there are three to four\nchemically slightly different sublayers in the D\" layer and two boundaries in\nthe inner core at radii 870 km and 1050 km. The observed hemispheric asymmetry\nin the inner core could follow if the Ni-concentration slightly varies locally.\nAlthough this model can account for all the layers using only three elements it\ncan not, of course, match the full chemistry of the real Earth.", "journal": "", "doi": null, "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/physics/0211069v1"}
{"entry_id": "http://arxiv.org/abs/1108.4660v2", "date": "2011-08-23", "title": "Vaporization of the Earth: Application to Exoplanet Atmospheres", "authors": "Laura Schaefer, Katharina Lodders, Bruce Fegley Jr", "abstract": "Currently, there are about 3 dozen known super-Earth (M < 10 MEarth), of\nwhich 8 are transiting planets suitable for atmospheric follow-up observations.\nSome of the planets are exposed to extreme temperatures as they orbit close to\ntheir host stars, e.g., CoRot-7b, and all of these planets have equilibrium\ntemperatures significantly hotter than the Earth. Such planets can develop\natmospheres through (partial) vaporization of their crustal and/or mantle\nsilicates. We investigated the chemical equilibrium composition of such heated\nsystems from 500 - 4000 K and total pressures from 10-6 to 10+2 bars. The major\ngases are H2O and CO2 over broad temperature and pressure ranges, and Na, K,\nO2, SiO, and O at high temperatures and low pressures. We discuss the\ndifferences in atmospheric composition arising from vaporization of SiO2-rich\n(i.e., felsic) silicates (like Earth's continental crust) and MgO-, FeO-rich\n(i.e., mafic) silicates like the bulk silicate Earth. The computational results\nwill be useful in planning spectroscopic studies of the atmospheres of\nEarth-like exoplanets.", "journal": "", "doi": "10.1088/0004-637X/755/1/41", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1108.4660v2"}
{"entry_id": "http://arxiv.org/abs/1202.1758v1", "date": "2012-02-08", "title": "The Rare Earth Peak : An Overlooked r-Process Diagnostic", "authors": "M. Mumpower, G. McLaughlin, R. Surman", "abstract": "The astrophysical site or sites responsible for the r-process of\nnucleosynthesis still remains an enigma. Since the rare earth region is formed\nin the latter stages of the r-process it provides a unique probe of the\nastrophysical conditions during which the r-process takes place. We use\nfeatures of a successful rare earth region in the context of a high entropy\nr-process (S>100k_B) and discuss the types of astrophysical conditions that\nproduce abundance patterns that best match meteoritic and observational data.\nDespite uncertainties in nuclear physics input, this method effectively\nconstrains astrophysical conditions.", "journal": "", "doi": null, "primary_category": "astro-ph.SR", "categories": ["astro-ph.SR", "nucl-th"], "pdf_url": "http://arxiv.org/pdf/1202.1758v1"}
{"entry_id": "http://arxiv.org/abs/1511.06802v1", "date": "2015-11-21", "title": "Meridional Transport in the Atmospheres of Earth and Mars", "authors": "Alejandro Soto", "abstract": "As we continue to discover terrestrial exoplanets, many with orbital and\nplanetary characteristics drastically different from anything encountered in\nour solar system, we are likely to encounter 'exotic' atmospheric transport\nprocesses. As an example, we show an analysis of meridional transport from\nsimulations Mars. These simulations provide insight into the differences in\nmeridional transport between Earth and Mars, particularly through the role of a\ncondensation flow. The differences between Earth and Mars are a reminder that\nthere may be a wide variety of meridional transport processes at work across\nthe range of observed terrestrial planets.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1511.06802v1"}
{"entry_id": "http://arxiv.org/abs/1306.2111v1", "date": "2013-06-10", "title": "Visible Spectroscopic Observations of Near-Earth Object 2012 DA14", "authors": "Seitaro Urakawa, Mitsugu Fujii, Hidekazu Hanayama, Jun Takahashi, Tsuyoshi Terai, Osamu Oshima", "abstract": "We present visible spectroscopic observations of a near-earth object (NEO)\n2012 DA14. The asteroid 2012 DA14 came close to the surface of the Earth on\nFebruary 15, 2013 at a distance of 27,700 km. Its estimated diameter is around\n45 m. The physical properties of such a small asteroid have not yet been well\ndetermined. The close encounter is a good opportunity to conduct a variety of\nobservations. The purpose of this paper is to deduce the taxonomy of 2012 DA14\nby visible spectroscopic observations using the 0.4 m f/10 telescope at the\nFujii Kurosaki Observatory. We conclude that the taxonomy of 2012 DA14 is an\nL-type in the visible wavelength region. In addition, we refer to the\navailability of a small, accessible telescope for NEOs smaller than 100 m.", "journal": "", "doi": "10.1093/pasj/65.4.L9", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1306.2111v1"}
{"entry_id": "http://arxiv.org/abs/1905.05862v1", "date": "2019-05-14", "title": "Optimizing Ground-based Observations of O2 in Earth Analogs", "authors": "Mercedes Lopez-Morales, Sagi Ben-Ami, Gonzalo Gonzalez-Abad, Juliana Garcia-Mejia, Jeremy Dietrich, Andrew Szentgyorgyi", "abstract": "We present the result of calculations to optimize the search for molecular\noxygen (O2) in Earth analogs transiting around nearby, low-mass stars using\nground-based, high-resolution, Doppler shift techniques. We investigate a\nseries of parameters, namely spectral resolution, wavelength coverage of the\nobservations, and sky coordinates and systemic velocity of the exoplanetary\nsystems, to find the values that optimize detectability of O2. We find that\nincreasing the spectral resolution of observations to R = 300,000 - 400,000\nfrom the typical R ~ 100,000, more than doubles the average depth of O2 lines\nin planets with atmospheres similar to Earth's. Resolutions higher than about\n500,000 do not produce significant gains in the depths of the O2 lines. We\nconfirm that observations in the O2 A-band are the most efficient except for\nM9V host stars, for which observations in the O2 NIR-band are more efficient.\nCombining observations in the O2 A, B, and NIR -bands can reduce the number of\ntransits needed to produce a detection of O2 by about 1/3 in the case of white\nnoise limited observations. However, that advantage disappears in the presence\nof typical levels of red noise. Therefore, combining observations in more than\none band produces no significant gains versus observing only in the A-band,\nunless red-noise can be significantly reduced. Blending between the exoplanet's\nO2 lines and telluric O2 lines is a known problem. We find that problem can be\nalleviated by increasing the resolution of the observations, and by giving\npreference to targets near the ecliptic.", "journal": "", "doi": "10.3847/1538-3881/ab21d7", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1905.05862v1"}
{"entry_id": "http://arxiv.org/abs/2301.10348v2", "date": "2023-01-24", "title": "On the Need for a Near-Earth Object Characterization Constellation in Low-Earth Orbit", "authors": "Nathan Golovich", "abstract": "In 2005, the United States Congress passed a bill mandating the detection,\ntracking, cataloguing and characterization of 90\\% of the 140 meter and larger\nnear-Earth objects (NEOs) by 2020. At the deadline $\\sim$35\\% were detected,\ntracked and catalogued, but only a small fraction were characterized. At the\npresent rate, it will take 40 years to meet the detection mandate, and there\nare insufficient global facilities dedicated to NEO characterization to come\nclose to the characterization threshold. The major surveys focus mainly on\ndetection and initial orbit determination, which must be refined in order to\nfully be tracked and catalogued. Characterization requires observations\nspanning multiple wavelengths, cadences, and instruments, so it is challenging\nfor observers to acquire the requisite data in a timely manner for planetary\ndefense. Two upcoming surveys will easily meet the 90\\% threshold for\ndetection, but each will require separate facilities to tip and queue to refine\norbits and characterize new discoveries, and they will provide too many\ndiscoveries for ground and space-based assets to keep up with. Here, I argue\nfor a constellation of proliferating small satellites carrying visible and\ninfrared sensors that would offer the needed coverage and flexibility to follow\nup detections from current and upcoming surveys in a timely manner. Such a\nconstellation would enable NASA to move beyond the detection focused\ninvestments and fully meet the 2005 Congressional mandate.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2301.10348v2"}
{"entry_id": "http://arxiv.org/abs/1505.04829v2", "date": "2015-05-18", "title": "Fundamental limits of remote estimation of autoregressive Markov processes under communication constraints", "authors": "Jhelum Chakravorty, Aditya Mahajan", "abstract": "The fundamental limits of remote estimation of Markov processes under\ncommunication constraints are presented. The remote estimation system consists\nof a sensor and an estimator. The sensor observes a discrete-time Markov\nprocess, which is a symmetric countable state Markov source or a Gauss-Markov\nprocess. At each time, the sensor either transmits the current state of the\nMarkov process or does not transmit at all. Communication is noiseless but\ncostly. The estimator estimates the Markov process based on the transmitted\nobservations. In such a system, there is a trade-off between communication cost\nand estimation accuracy. Two fundamental limits of this trade-off are\ncharacterized for infinite horizon discounted cost and average cost setups.\nFirst, when each transmission is costly, we characterize the minimum achievable\ncost of communication plus estimation error. Second, when there is a constraint\non the average number of transmissions, we characterize the minimum achievable\nestimation error. Transmission and estimation strategies that achieve these\nfundamental limits are also identified.", "journal": "", "doi": null, "primary_category": "math.OC", "categories": ["math.OC", "cs.IT", "cs.SY", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1505.04829v2"}
{"entry_id": "http://arxiv.org/abs/1510.00064v1", "date": "2015-09-30", "title": "Optimal Sensor Scheduling and Remote Estimation over an Additive Noise Channel", "authors": "Xiaobin Gao, Emrah Akyol, Tamer Basar", "abstract": "We consider a sensor scheduling and remote estimation problem with one sensor\nand one estimator. At each time step, the sensor makes an observation on the\nstate of a source, and then decides whether to transmit its observation to the\nestimator or not. The sensor is charged a cost for each transmission. The\nremote estimator generates a real-time estimate on the state of the source\nbased on the messages received from the sensor. The estimator is charged for\nestimation error. As compared with previous works from the literature, we\nfurther assume that there is an additive communication channel noise. As a\nconsequence, the sensor needs to encode the message before transmitting it to\nthe estimator. For some specific distributions of the underlying random\nvariables, we obtain the optimal solution to the problem of minimizing the\nexpected value of the sum of communication cost and estimation cost over the\ntime horizon.", "journal": "", "doi": null, "primary_category": "cs.SY", "categories": ["cs.SY", "cs.IT", "math.IT"], "pdf_url": "http://arxiv.org/pdf/1510.00064v1"}
{"entry_id": "http://arxiv.org/abs/1310.4228v1", "date": "2013-10-15", "title": "Luminescence of cadmium fluoride doped with rare-earth ions", "authors": "Evgeny Radzhabov, Roman Shendrik", "abstract": "Absorption, excitation and emission spectra of cadmium fluoride crystals\ndoped with rare-earth ions were investigated. In contrast to alkaline-earth\nfluorides the absorption spectra due to 4f - 5d transitions of Ce$^{3+}$,\nPr$^{3+}$ and Tb$^{3+}$ ions are broadened. No 5d-4f emissions were observed.\nThese prove that 5d(e$_g$) levels of rare earth ions lie in conduction band of\nCdF$_2$ crystal. Emission spectra of Tb$^{3+}$ show the group of 4f-4f\n$^5$D$_4$-$^7$F$_j$ lines in contrast to other alkaline-earth fluorides where\nemission due to $^5$D$_3$-$^7$F$_j$ transitions is also observed. The absence\nof the emission is due to position of $^5$D$_3$ level within condution band.\n  Among the all measured crystals doped with impurity ions (Pr, Nd, Eu, Ho, Tb,\nTm, Yb, Ga, In or Mn), the CdF$_2$ doped with Pr$^{3+}$, Tb$^{3+}$, or\nMn$^{2+}$ ions have the highest light outputs under x-ray excitation.", "journal": "", "doi": "10.1109/TNS.2013.2284488", "primary_category": "cond-mat.mtrl-sci", "categories": ["cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/1310.4228v1"}
{"entry_id": "http://arxiv.org/abs/2105.00912v1", "date": "2021-05-03", "title": "Causal inference for process understanding in Earth sciences", "authors": "Adam Massmann, Pierre Gentine, Jakob Runge", "abstract": "There is growing interest in the study of causal methods in the Earth\nsciences. However, most applications have focused on causal discovery, i.e.\ninferring the causal relationships and causal structure from data. This paper\ninstead examines causality through the lens of causal inference and how\nexpert-defined causal graphs, a fundamental from causal theory, can be used to\nclarify assumptions, identify tractable problems, and aid interpretation of\nresults and their causality in Earth science research. We apply causal theory\nto generic graphs of the Earth system to identify where causal inference may be\nmost tractable and useful to address problems in Earth Science, and avoid\npotentially incorrect conclusions. Specifically, causal inference may be useful\nwhen: (1) the effect of interest is only causally affected by the observed\nportion of the state space; or: (2) the cause of interest can be assumed to be\nindependent of the evolution of the system's state; or: (3) the state space of\nthe system is reconstructable from lagged observations of the system. However,\nwe also highlight through examples how causal graphs can be used to explicitly\ndefine and communicate assumptions and hypotheses, and help to structure\nanalyses, even if causal inference is ultimately challenging given the data\navailability, limitations and uncertainties.", "journal": "", "doi": null, "primary_category": "physics.ao-ph", "categories": ["physics.ao-ph"], "pdf_url": "http://arxiv.org/pdf/2105.00912v1"}
{"entry_id": "http://arxiv.org/abs/1505.00269v2", "date": "2015-05-01", "title": "Variability in the super-Earth 55 Cnc e", "authors": "Brice-Olivier Demory, Michael Gillon, Nikku Madhusudhan, Didier Queloz", "abstract": "Considerable progress has been made in recent years in observations of\natmospheric signatures of giant exoplanets, but processes in rocky exoplanets\nremain largely unknown due to major challenges in observing small planets.\nNumerous efforts to observe spectra of super-Earths, exoplanets with masses of\n1-10 Earth masses, have thus far revealed only featureless spectra. In this\npaper we report a 4-$\\sigma$ detection of variability in the dayside thermal\nemission from the transiting super-Earth 55 Cancri e. Dedicated space-based\nmonitoring of the planet in the mid-infrared over eight eclipses revealed the\nthermal emission from its dayside atmosphere varying by a factor 3.7 between\n2012 and 2013. The amplitude and trend of the variability are not explained by\npotential influence of star spots or by local thermal or compositional changes\nin the atmosphere over the short span of the observations. The possibility of\nlarge scale surface activity due to strong tidal interactions possibly similar\nto Io, or the presence of circumstellar/circumplanetary material appear\nplausible and motivate future long-term monitoring of the planet.", "journal": "MNRAS (January 11, 2016) 455 (2): 2018-2027", "doi": "10.1093/mnras/stv2239", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1505.00269v2"}
{"entry_id": "http://arxiv.org/abs/1111.3046v2", "date": "2011-11-13", "title": "The Role of Kozai Cycles in Near-Earth Binary Asteroids", "authors": "Julia Fang, Jean-Luc Margot", "abstract": "We investigate the Kozai mechanism in the context of near-Earth binaries and\nthe Sun. The Kozai effect can lead to changes in eccentricity and inclination\nof the binary orbit, but it can be weakened or completely suppressed by other\nsources of pericenter precession, such as the oblateness of the primary body.\nThrough numerical integrations including primary oblateness and 3 bodies (the\ntwo binary components and the Sun), we show that Kozai cycles cannot occur for\nthe closely-separated near-Earth binaries in our sample. We demonstrate that\nthis is due to pericenter precession around the oblate primary, even for very\nsmall oblateness values. Since the majority of observed near-Earth binaries are\nnot well-separated, we predict that Kozai cycles do not play an important role\nin the orbital evolution of most near-Earth binaries. For a hypothetical wide\nbinary modeled after 1998 ST27, the separation is large at 16 primary radii and\nso the orbital effects of primary oblateness are lessened. For this wide\nbinary, we illustrate the possible excursions in eccentricity and inclination\ndue to Kozai cycles as well as depict stable orientations for the binary's\norbital plane. Unstable orientations lead to collisions between binary\ncomponents, and we suggest that the Kozai effect acting in wide binaries may be\na route to the formation of near-Earth contact binaries.", "journal": "", "doi": "10.1088/0004-6256/143/3/59", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1111.3046v2"}
{"entry_id": "http://arxiv.org/abs/2207.05833v2", "date": "2022-07-12", "title": "Earthformer: Exploring Space-Time Transformers for Earth System Forecasting", "authors": "Zhihan Gao, Xingjian Shi, Hao Wang, Yi Zhu, Yuyang Wang, Mu Li, Dit-Yan Yeung", "abstract": "Conventionally, Earth system (e.g., weather and climate) forecasting relies\non numerical simulation with complex physical models and are hence both\nexpensive in computation and demanding on domain expertise. With the explosive\ngrowth of the spatiotemporal Earth observation data in the past decade,\ndata-driven models that apply Deep Learning (DL) are demonstrating impressive\npotential for various Earth system forecasting tasks. The Transformer as an\nemerging DL architecture, despite its broad success in other domains, has\nlimited adoption in this area. In this paper, we propose Earthformer, a\nspace-time Transformer for Earth system forecasting. Earthformer is based on a\ngeneric, flexible and efficient space-time attention block, named Cuboid\nAttention. The idea is to decompose the data into cuboids and apply\ncuboid-level self-attention in parallel. These cuboids are further connected\nwith a collection of global vectors. We conduct experiments on the MovingMNIST\ndataset and a newly proposed chaotic N-body MNIST dataset to verify the\neffectiveness of cuboid attention and figure out the best design of\nEarthformer. Experiments on two real-world benchmarks about precipitation\nnowcasting and El Nino/Southern Oscillation (ENSO) forecasting show Earthformer\nachieves state-of-the-art performance. Code is available:\nhttps://github.com/amazon-science/earth-forecasting-transformer .", "journal": "", "doi": null, "primary_category": "cs.LG", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2207.05833v2"}
{"entry_id": "http://arxiv.org/abs/1805.07347v1", "date": "2018-05-18", "title": "Organic chemistry in a CO2 rich early Earth atmosphere", "authors": "Benjamin Fleury, Nathalie Carrasco, Maeva Millan, Ludovic Vettier, Cyril Szopa", "abstract": "The emergence of life on the Earth has required a prior organic chemistry\nleading to the formation of prebiotic molecules. The origin and the evolution\nof the organic matter on the early Earth is not yet firmly understood. Several\nhypothesis, possibly complementary, are considered. They can be divided in two\ncategories: endogenous and exogenous sources. In this work we investigate the\ncontribution of a specific endogenous source: the organic chemistry occurring\nin the ionosphere of the early Earth where the significant VUV contribution of\nthe young Sun involved an efficient formation of reactive species. We address\nthe issue whether this chemistry can lead to the formation of complex organic\ncompounds with CO2 as only source of carbon in an early atmosphere made of N2,\nCO2 and H2, by mimicking experimentally this type of chemistry using a low\npressure plasma reactor. By analyzing the gaseous phase composition, we\nstrictly identified the formation of H2O, NH3, N2O and C2N2. The formation of a\nsolid organic phase is also observed, confirming the possibility to trigger\norganic chemistry in the upper atmosphere of the early Earth. The\nidentification of Nitrogen-bearing chemical functions in the solid highlights\nthe possibility for an efficient ionospheric chemistry to provide prebiotic\nmaterial on the early Earth.", "journal": "Earth and Planetary Science Letters, Elsevier, 2017, 479, pp.34-42", "doi": "10.1016/j.epsl.2017.09.026", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1805.07347v1"}
{"entry_id": "http://arxiv.org/abs/2105.15026v2", "date": "2021-05-31", "title": "Evolution of Earth-like extended exospheres orbiting solar-like stars", "authors": "Ada Canet, Ana In\u00e9s G\u00f3mez de Castro", "abstract": "Recent observations of the Earth's exosphere revealed the presence of an\nextended hydrogenic component that could reach distances beyond 40 planetary\nradii. Detection of similar extended exospheres around Earth-like exoplanets\ncould reveal crucial facts in terms of habitability. The presence of these\nrarified hydrogen envelopes is extremely dependent of the planetary\nenvironment, dominated by the ionizing radiation and plasma winds coming from\nthe host star. Radiation and fast wind particles ionize the uppermost layers of\nplanetary atmospheres, especially for planets orbiting active, young stars. The\nsurvival of the produced ions in the exosphere of such these planets is subject\nto the action of the magnetized stellar winds, particularly for unmagnetized\nbodies. In order to address these star-planet interactions, we have carried out\nnumerical 2.5D ideal MHD simulations using the PLUTO code to study the\ndynamical evolution of tenuous, hydrogen-rich, Earth-like extended exospheres\nfor an unmagnetized planet, at different stellar evolutionary stages: from a\nvery young, solar-like star of 0.1 Gyr to a 5.0 Gyr star. For each star-planet\nconfiguration, we show that the morphology of extended Earth-like hydrogen\nexospheres is strongly dependent of the incident stellar winds and the produced\nions present in these gaseous envelopes, showing that the ionized component of\nEarth-like exospheres is quickly swept by the stellar winds of young stars,\nleading to large bow shock formation for later stellar ages.", "journal": "Monthly Notices of the Royal Astronomical Society, Volume 502,\n  Issue 4, 2021, pp.6170-6176", "doi": "10.1093/mnras/stab492", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/2105.15026v2"}
{"entry_id": "http://arxiv.org/abs/2206.09820v1", "date": "2022-06-20", "title": "Earth through the looking glass: how frequently are we detected by other civilisations through photometric microlensing?", "authors": "S. Suphapolthaworn, S. Awiphan, T. Chatchadanoraset, E. Kerins, D. Specht, N. Nakharutai, S. Komonjinda, A. C. Robin", "abstract": "Microlensing is proving to be one of the best techniques to detect distant,\nlow-mass planets around the most common stars in the Galaxy. In principle,\nEarth's microlensing signal could offer the chance for other technological\ncivilisations to find the Earth across Galactic distances. We consider the\nphotometric microlensing signal of Earth to other potential technological\ncivilisations and dub the regions of our Galaxy from which Earth's photometric\nmicrolensing signal is most readily observable as the \"Earth Microlensing Zone\"\n(EMZ). The EMZ can be thought of as the microlensing analogue of the Earth\nTransit Zone (ETZ) from where observers see Earth transit the Sun. Just as for\nthe ETZ, the EMZ could represent a game-theoretic Schelling point for targeted\nsearches for extra-terrestrial intelligence (SETI). To compute the EMZ, we use\nthe Gaia DR2 catalogue with magnitude G<20 to generate Earth microlensing\nprobability and detection rate maps to other observers. Whilst our Solar system\nis a multi-planet system, we show that Earth's photometric microlensing\nsignature is almost always well approximated by a binary lens assumption. We\nthen show that the Earth is in fact well-hidden to observers with technology\ncomparable to our own. Specifically, even if observers are located around every\nGaia DR2 star with G<20, we expect photometric microlensing signatures from the\nEarth to be observable on average only tens per year by any of them. In\naddition, the EMZs overlap with the ETZ near the Galactic centre which could be\nthe main areas for future SETI searches.", "journal": "", "doi": "10.1093/mnras/stac1855", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.GA", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2206.09820v1"}
{"entry_id": "http://arxiv.org/abs/1909.03001v2", "date": "2019-09-06", "title": "Hydrogen isotopic evidence for early oxidation of silicate Earth", "authors": "Kaveh Pahlevan, Laura Schaefer, Marc M. Hirschmann", "abstract": "The Moon-forming giant impact extensively melts and partially vaporizes the\nsilicate Earth and delivers a substantial mass of metal to Earth's core.\nSubsequent evolution of the magma ocean and overlying atmosphere has been\ndescribed by theoretical models but observable constraints on this epoch have\nproved elusive. Here, we report calculations of the primordial atmosphere\nduring the magma ocean and water ocean epochs and forge new links with\nobservations to gain insight into the behavior of volatiles on the early Earth.\nAs Earth's magma ocean crystallizes, it outgasses the bulk of the volatiles\ninto the primordial atmosphere. The redox state of the magma ocean controls\nboth the chemical composition of the outgassed volatiles and the hydrogen\nisotopic composition of water oceans that remain after hydrogen loss from the\nprimordial atmosphere. Whereas water condenses and is retained, molecular\nhydrogen does not condense and can escape, allowing large quantities (~10^2\nbars) of hydrogen - if present - to be lost from Earth in this epoch. Because\nthe escaping inventory of H can be comparable to the hydrogen inventory in the\nearly oceans, the corresponding deuterium enrichment can be large with a\nmagnitude that depends on the initial H2 inventory. By contrast, the common\nview that terrestrial water has a carbonaceous chondrite source requires the\noceans to preserve the isotopic composition of that source, undergoing minimal\nD-enrichment via H2 loss. Such minimal enrichment places upper limits on the\namount of primordial H2 in contact with early water oceans (pH2<20 bars),\nimplies oxidizing conditions for outgassing from the magma ocean, and suggests\nthat Earth's mantle supplied the oxidant for the chemical resorption of metals\nduring late accretion.", "journal": "", "doi": "10.1016/j.epsl.2019.115770", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1909.03001v2"}
{"entry_id": "http://arxiv.org/abs/2208.06297v1", "date": "2022-08-12", "title": "Greater climate sensitivity and variability on TRAPPIST-1e than Earth", "authors": "Assaf Hochman, Paolo De Luca, Thaddeus D. Komacek", "abstract": "The atmospheres of rocky exoplanets are close to being characterized by\nastronomical observations, in part due to the commissioning of the James Webb\nSpace Telescope. These observations compel us to understand exoplanetary\natmospheres, in the voyage to find habitable planets. With this aim, we\ninvestigate the effect that CO$_2$ partial pressure (pCO$_2$) has on\nexoplanets' climate variability, by analyzing results from ExoCAM model\nsimulations of the tidally locked TRAPPIST-1e exoplanet, an Earth-like\naqua-planet and Earth itself. First, we relate the differences between the\nplanets to their elementary parameters. Then, we compare the sensitivity of the\nEarth analogue and TRAPPIST-1e's surface temperature and precipitation to\npCO$_2$. Our simulations suggest that the climatology and extremes of\nTRAPPIST-1e's temperature are $\\sim$1.5 times more sensitive to pCO$_2$\nrelative to Earth. The precipitation sensitivity strongly depends on the\nspecific region analyzed. Indeed, the precipitation near mid-latitude and\nequatorial sub-stellar regions of TRAPPIST-1e is more sensitive to pCO$_2$, and\nthe precipitation sensitivity is $\\sim$2 times larger in TRAPPIST-1e. A\ndynamical systems perspective, which provides information about how the\natmosphere evolves in phase-space, provides additional insights. Notably, an\nincrease in pCO$_2$, results in an increase in atmospheric persistence on both\nplanets, and the persistence of TRAPPIST-1e is more sensitive to pCO$_2$ than\nEarth. We conclude that the climate of TRAPPIST-1e may be more sensitive to\npCO$_2$, particularly on its dayside. This study documents a new pathway for\nunderstanding the effect that varying planetary parameters have on the climate\nvariability of potentially habitable exoplanets and on Earth.", "journal": "The Astrophysical Journal, 938:114 (25pp), 2022 October 20", "doi": "10.3847/1538-4357/ac866f", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.ao-ph", "physics.flu-dyn"], "pdf_url": "http://arxiv.org/pdf/2208.06297v1"}
{"entry_id": "http://arxiv.org/abs/1402.5515v1", "date": "2014-02-22", "title": "Impulsive rotational Raman scattering of N2 by a remote \"air laser\" in femtosecond laser filament", "authors": "Jielei Ni, Wei Chu, Haisu Zhang, Bin Zeng, Jinping Yao, Guihua Li, Chenrui Jing, Hongqiang Xie, Huailiang Xu, Ya Cheng, Zhizhan Xu", "abstract": "We report on experimental realization of impulsive rotational Raman\nscattering from neutral nitrogen molecules in a femtosecond laser filament\nusing an intense self-induced white-light seeding \"air laser\" generated during\nthe filamentation of an 800 nm Ti: Sapphire laser in nitrogen gas. The\nimpulsive rotational Raman fingerprint signals are observed with a maximum\nconversion efficiency of ~0.8%. Our observation provides a promising way of\nremote identification and location of chemical species in atmosphere by\nrotational Raman scattering of molecules.", "journal": "", "doi": "10.1364/OL.39.002250", "primary_category": "physics.optics", "categories": ["physics.optics"], "pdf_url": "http://arxiv.org/pdf/1402.5515v1"}
{"entry_id": "http://arxiv.org/abs/hep-ph/0012354v4", "date": "2000-12-28", "title": "The Earth effects on the supernova neutrino spectra", "authors": "K. Takahashi, M. Watanabe, K. Sato", "abstract": "The Earth effects on the energy spectra of supernova neutrinos are studied.\nWe analyze numerically the time-integrated energy spectra of neutrino in a\nmantle-core-mantle step function model of the Earth's matter density profile.\nWe consider a realistic frame-work in which there are three active neutrinos\nwhose mass squared differences and mixings are constrained by the present\nunderstanding of solar and atmospheric neutrinos. We find that the energy\nspectra change for some allowed mixing parameters. Especially, the expected\nnumber of events at SNO shows characteristic behavior with respect to energy,\ni.e. a great dip and peak. We show that observations of the Earth effect allow\nus to identify the solar neutrino solution and to probe the mixing angle\n$\\theta_{2}$.", "journal": "Phys.Lett.B510:189-196,2001", "doi": "10.1016/S0370-2693(01)00610-4", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph"], "pdf_url": "http://arxiv.org/pdf/hep-ph/0012354v4"}
{"entry_id": "http://arxiv.org/abs/1608.07296v1", "date": "2016-08-25", "title": "Direct Detection of Dark Matter Bound to the Earth", "authors": "Riccardo Catena, Chris Kouvaris", "abstract": "We study the properties and direct detection prospects of an as of yet\nneglected population of dark matter (DM) particles moving in orbits\ngravitationally bound to the Earth. This DM population is expected to form via\nscattering by nuclei in the Earth's interior. We compute fluxes and nuclear\nrecoil energy spectra expected at direct detection experiments for the new DM\npopulation considering detectors with and without directional sensitivity, and\ndifferent types of target materials and DM-nucleon interactions. DM particles\nbound to the Earth manifest as a prominent rise in the low-energy part of the\nobserved nuclear recoil energy spectrum. Ultra-low threshold energies of about\n1 eV are needed to resolve this effect. Its shape is independent of the\nDM-nucleus scattering cross-section normalisation.", "journal": "Phys. Rev. D 96, 063012 (2017)", "doi": "10.1103/PhysRevD.96.063012", "primary_category": "astro-ph.CO", "categories": ["astro-ph.CO", "hep-ph"], "pdf_url": "http://arxiv.org/pdf/1608.07296v1"}
{"entry_id": "http://arxiv.org/abs/2104.02702v1", "date": "2021-04-06", "title": "Earth's carbon deficit caused by early loss through irreversible sublimation", "authors": "Jie Li, Edwin A. Bergin, Geoffrey A. Blake, Fred J. Ciesla, Marc M. Hirschmann", "abstract": "Carbon is an essential element for life but its behavior during Earth's\naccretion is not well understood. Carbonaceous grains in meteoritic and\ncometary materials suggest that irreversible sublimation, and not condensation,\ngoverns carbon acquisition by terrestrial worlds. Through astronomical\nobservations and modeling we show that the sublimation front of carbon carriers\nin the solar nebula, or the soot line, moved inward quickly so that carbon-rich\ningredients would be available for accretion at 1 au after the first million\nyears. On the other hand, geological constraints firmly establish a severe\ncarbon deficit in Earth, requiring the destruction of inherited carbonaceous\norganics in the majority of its building blocks. The carbon-poor nature of the\nEarth thus implies carbon loss in its precursor material through sublimation\nwithin the first million years.", "journal": "Science Advances published 02 Apr 2021: Vol. 7, no. 14, DOI:\n  10.1126/sciadv.abd3632", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2104.02702v1"}
{"entry_id": "http://arxiv.org/abs/0808.1071v1", "date": "2008-08-07", "title": "On the equilibrium rotation of Earth-like extra-solar planets", "authors": "Alexandre C. M. Correia, Benjamin Levrard, Jacques Laskar", "abstract": "The equilibrium rotation of tidally evolved \"Earth-like\" extra-solar planets\nis often assumed to be synchronous with their orbital mean motion. The same\nassumption persisted for Mercury and Venus until radar observations revealed\ntheir true spin rates. As many of these planets follow eccentric orbits and are\nbelieved to host dense atmospheres, we expect the equilibrium rotation to\ndiffer from the synchronous motion. Here we provide a general description of\nthe allowed final equilibrium rotation states of these planets, and apply this\nto already discovered cases in which the mass is lower than twelve\nEarth-masses. At low obliquity and moderate eccentricity, it is shown that\nthere are at most four distinct equilibrium possibilities, one of which can be\nretrograde. Because most presently known \"Earth-like\" planets present eccentric\norbits, their equilibrium rotation is unlikely to be synchronous.", "journal": "", "doi": "10.1051/0004-6361:200810388", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/0808.1071v1"}
{"entry_id": "http://arxiv.org/abs/2211.10903v1", "date": "2022-11-20", "title": "Proximity Operations about Apophis through its 2029 Earth Flyby", "authors": "Daniel J. Scheeres", "abstract": "The dynamics and control of a satellite in proximity to the asteroid Apophis\nacross its Earth close approach in 2029 is evaluated and investigated. First,\nthe feasibility of carrying out close proximity operations about Apophis when\nin its heliocentric orbit phase is evaluated and shown to be feasible. Then\nthree different types of close proximity motion relative to Apophis are\nanalyzed that will enable a spacecraft to take observations throughout the\nEarth close approach. These are maintaining a relative orbit that is somewhat\ndistant from Apophis, hovering along the Earth-Apophis line, or maintaining\norbit about Apophis through the flyby. Each of these are shown to be feasible,\nalbeit challenging, and some basic aspects of these operations are noted and\ndiscussed.", "journal": "", "doi": null, "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.IM"], "pdf_url": "http://arxiv.org/pdf/2211.10903v1"}
{"entry_id": "http://arxiv.org/abs/2104.07273v3", "date": "2021-04-15", "title": "Comparing weighted difference and earth mover's distance via Young diagrams", "authors": "William Q. Erickson", "abstract": "We consider two natural statistics on pairs of histograms, in which the $n$\nbins have weights $0, \\ldots, n-1$. The difference ($\\mathbf{D}$) between the\nweighted totals of the histograms is, in a sense, refined by the earth mover's\ndistance ($\\mathbf{EMD}$), which measures the amount of work required to\nequalize the histograms. We were recently surprised, however, by how little\n$\\mathbf{EMD}$ actually does refine $\\mathbf{D}$ in certain real-world\napplications, which led to the main problem in this paper: what is the\nprobability that $\\mathbf{EMD} = |\\mathbf{D}|$? We derive a formula for this\nprobability, as well as the expected value of $|\\mathbf{D}|$, via the\ncombinatorics of Young diagrams and plane partitions. We then generalize our\nresults to an arbitrary number of histograms, where we realize this\nhigher-dimensional $\\mathbf{D}$ as distance on the Type-A root lattice.", "journal": "", "doi": null, "primary_category": "math.CO", "categories": ["math.CO", "90C27 (Primary), 05E10 (Secondary)"], "pdf_url": "http://arxiv.org/pdf/2104.07273v3"}
{"entry_id": "http://arxiv.org/abs/1212.3863v2", "date": "2012-12-17", "title": "Geostationary Earth Orbit Satellite Model using Easy Java Simulation", "authors": "Loo Kang Wee, Giam Hwee Goh", "abstract": "We develop an Easy Java Simulation (EJS) model for students to visualize\ngeostationary orbits near Earth, modeled using Java 3D implementation of the\nEJS 3D library. The simplified physics model is described and simulated using\nsimple constant angular velocity equation. Four computer model design ideas\nsuch as 1) simple and realistic 3D view and associated learning to real world,\n2) comparative visualization of permanent geostationary satellite 3) examples\nof non-geostationary orbits of different 3-1) rotation sense, 3-2) periods,\n3-3) planes and 4) incorrect physics model for conceptual discourse are\ndiscussed. General feedback from the students has been relatively positive, and\nwe hope teachers will find the computer model useful in their own classes. 2015\nResources\nhttp://iwant2study.org/ospsg/index.php/interactive-resources/physics/02-newtonian-mechanics/08-gravity/62-gravity10", "journal": "Phys. Educ. 48 72 (2013)", "doi": "10.1088/0031-9120/48/1/72", "primary_category": "physics.ed-ph", "categories": ["physics.ed-ph", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/1212.3863v2"}
{"entry_id": "http://arxiv.org/abs/2012.04469v1", "date": "2020-12-07", "title": "Multi-temporal and multi-source remote sensing image classification by nonlinear relative normalization", "authors": "Devis Tuia, Diego Marcos, Gustau Camps-Valls", "abstract": "Remote sensing image classification exploiting multiple sensors is a very\nchallenging problem: data from different modalities are affected by spectral\ndistortions and mis-alignments of all kinds, and this hampers re-using models\nbuilt for one image to be used successfully in other scenes. In order to adapt\nand transfer models across image acquisitions, one must be able to cope with\ndatasets that are not co-registered, acquired under different illumination and\natmospheric conditions, by different sensors, and with scarce ground\nreferences. Traditionally, methods based on histogram matching have been used.\nHowever, they fail when densities have very different shapes or when there is\nno corresponding band to be matched between the images. An alternative builds\nupon \\emph{manifold alignment}. Manifold alignment performs a multidimensional\nrelative normalization of the data prior to product generation that can cope\nwith data of different dimensionality (e.g. different number of bands) and\npossibly unpaired examples. Aligning data distributions is an appealing\nstrategy, since it allows to provide data spaces that are more similar to each\nother, regardless of the subsequent use of the transformed data. In this paper,\nwe study a methodology that aligns data from different domains in a nonlinear\nway through {\\em kernelization}. We introduce the Kernel Manifold Alignment\n(KEMA) method, which provides a flexible and discriminative projection map,\nexploits only a few labeled samples (or semantic ties) in each domain, and\nreduces to solving a generalized eigenvalue problem. We successfully test KEMA\nin multi-temporal and multi-source very high resolution classification tasks,\nas well as on the task of making a model invariant to shadowing for\nhyperspectral imaging.", "journal": "ISPRS Journal of Photogrammetry and Remote Sensing 120, DOI:\n  10.1016/j.isprsjprs.2016.07.004", "doi": "10.1016/j.isprsjprs.2016.07.004", "primary_category": "eess.SP", "categories": ["eess.SP", "cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2012.04469v1"}
{"entry_id": "http://arxiv.org/abs/2105.03647v3", "date": "2021-05-08", "title": "Informative and Representative Triplet Selection for Multilabel Remote Sensing Image Retrieval", "authors": "Gencer Sumbul, Mahdyar Ravanbakhsh, Beg\u00fcm Demir", "abstract": "Learning the similarity between remote sensing (RS) images forms the\nfoundation for content-based RS image retrieval (CBIR). Recently, deep metric\nlearning approaches that map the semantic similarity of images into an\nembedding (metric) space have been found very popular in RS. A common approach\nfor learning the metric space relies on the selection of triplets of similar\n(positive) and dissimilar (negative) images to a reference image called as an\nanchor. Choosing triplets is a difficult task particularly for multi-label RS\nCBIR, where each training image is annotated by multiple class labels. To\naddress this problem, in this paper we propose a novel triplet sampling method\nin the framework of deep neural networks (DNNs) defined for multi-label RS CBIR\nproblems. The proposed method selects a small set of the most representative\nand informative triplets based on two main steps. In the first step, a set of\nanchors that are diverse to each other in the embedding space is selected from\nthe current mini-batch using an iterative algorithm. In the second step,\ndifferent sets of positive and negative images are chosen for each anchor by\nevaluating the relevancy, hardness and diversity of the images among each other\nbased on a novel strategy. Experimental results obtained on two multi-label\nbenchmark archives show that the selection of the most informative and\nrepresentative triplets in the context of DNNs results in: i) reducing the\ncomputational complexity of the training phase of the DNNs without any\nsignificant loss on the performance; and ii) an increase in learning speed\nsince informative triplets allow fast convergence. The code of the proposed\nmethod is publicly available at\nhttps://git.tu-berlin.de/rsim/image-retrieval-from-triplets.", "journal": "", "doi": "10.1109/TGRS.2021.3124326", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2105.03647v3"}
{"entry_id": "http://arxiv.org/abs/2207.13975v2", "date": "2022-07-28", "title": "On the Effects of Different Types of Label Noise in Multi-Label Remote Sensing Image Classification", "authors": "Tom Burgert, Mahdyar Ravanbakhsh, Beg\u00fcm Demir", "abstract": "The development of accurate methods for multi-label classification (MLC) of\nremote sensing (RS) images is one of the most important research topics in RS.\nTo address MLC problems, the use of deep neural networks that require a high\nnumber of reliable training images annotated by multiple land-cover class\nlabels (multi-labels) has been found popular in RS. However, collecting such\nannotations is time-consuming and costly. A common procedure to obtain\nannotations at zero labeling cost is to rely on thematic products or\ncrowdsourced labels. As a drawback, these procedures come with the risk of\nlabel noise that can distort the learning process of the MLC algorithms. In the\nliterature, most label noise robust methods are designed for single-label\nclassification (SLC) problems in computer vision (CV), where each image is\nannotated by a single label. Unlike SLC, label noise in MLC can be associated\nwith: 1) subtractive label-noise (a land cover class label is not assigned to\nan image while that class is present in the image); 2) additive label-noise (a\nland cover class label is assigned to an image although that class is not\npresent in the given image); and 3) mixed label-noise (a combination of both).\nIn this paper, we investigate three different noise robust CV SLC methods and\nadapt them to be robust for multi-label noise scenarios in RS. During\nexperiments, we study the effects of different types of multi-label noise and\nevaluate the adapted methods rigorously. To this end, we also introduce a\nsynthetic multi-label noise injection strategy that is more adequate to\nsimulate operational scenarios compared to the uniform label noise injection\nstrategy, in which the labels of absent and present classes are flipped at\nuniform probability. Further, we study the relevance of different evaluation\nmetrics in MLC problems under noisy multi-labels.", "journal": "", "doi": "10.1109/TGRS.2022.3226371", "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2207.13975v2"}
{"entry_id": "http://arxiv.org/abs/1810.01163v1", "date": "2018-10-02", "title": "An Entropic Optimal Transport Loss for Learning Deep Neural Networks under Label Noise in Remote Sensing Images", "authors": "Bharath Bhushan Damodaran, R\u00e9mi Flamary, Viven Seguy, Nicolas Courty", "abstract": "Deep neural networks have established as a powerful tool for large scale\nsupervised classification tasks. The state-of-the-art performances of deep\nneural networks are conditioned to the availability of large number of\naccurately labeled samples. In practice, collecting large scale accurately\nlabeled datasets is a challenging and tedious task in most scenarios of remote\nsensing image analysis, thus cheap surrogate procedures are employed to label\nthe dataset. Training deep neural networks on such datasets with inaccurate\nlabels easily overfits to the noisy training labels and degrades the\nperformance of the classification tasks drastically. To mitigate this effect,\nwe propose an original solution with entropic optimal transportation. It allows\nto learn in an end-to-end fashion deep neural networks that are, to some\nextent, robust to inaccurately labeled samples. We empirically demonstrate on\nseveral remote sensing datasets, where both scene and pixel-based hyperspectral\nimages are considered for classification. Our method proves to be highly\ntolerant to significant amounts of label noise and achieves favorable results\nagainst state-of-the-art methods.", "journal": "Computer Vision and Image Understanding, Volume 191, 2020, 102863,\n  ISSN 1077-3142", "doi": "10.1016/j.cviu.2019.102863", "primary_category": "cs.CV", "categories": ["cs.CV", "cs.LG", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/1810.01163v1"}
{"entry_id": "http://arxiv.org/abs/1903.03412v1", "date": "2019-03-08", "title": "Research on the pixel-based and object-oriented methods of urban feature extraction with GF-2 remote-sensing images", "authors": "Dong-dong Zhang, Lei Zhang, Vladimir Zaborovsky, Feng Xie, Yan-wen Wu, Ting-ting Lu", "abstract": "During the rapid urbanization construction of China, acquisition of urban\ngeographic information and timely data updating are important and fundamental\ntasks for the refined management of cities. With the development of domestic\nremote sensing technology, the application of Gaofen-2 (GF-2) high-resolution\nremote sensing images can greatly improve the accuracy of information\nextraction. This paper introduces an approach using object-oriented\nclassification methods for urban feature extraction based on GF-2 satellite\ndata. A combination of spectral, spatial attributes and membership functions\nwas employed for mapping the urban features of Qinhuai District, Nanjing. The\ndata preprocessing is carried out by ENVI software, and the subsequent data is\nexported into the eCognition software for object-oriented classification and\nextraction of urban feature information. Finally, the obtained raster image\nclassification results are vectorized using the ARCGIS software, and the vector\ngraphics are stored in the library, which can be used for further analysis and\nmodeling. Accuracy assessment was performed using ground truth data acquired by\nvisual interpretation and from other reliable secondary data sources. Compared\nwith the result of pixel-based supervised (neural net) classification, the\ndeveloped object-oriented method can significantly improve extraction accuracy,\nand after manual interpretation, an overall accuracy of 95.44% can be achieved,\nwith a Kappa coefficient of 0.9405, which objectively confirmed the superiority\nof the object-oriented method and the feasibility of the utilization of GF-2\nsatellite data.", "journal": "", "doi": null, "primary_category": "cs.OH", "categories": ["cs.OH", "cs.CV", "cs.LG", "physics.data-an"], "pdf_url": "http://arxiv.org/pdf/1903.03412v1"}
{"entry_id": "http://arxiv.org/abs/2301.05856v1", "date": "2023-01-14", "title": "EARL: An Elliptical Distribution aided Adaptive Rotation Label Assignment for Oriented Object Detection in Remote Sensing Images", "authors": "Jian Guan, Mingjie Xie, Youtian Lin, Guangjun He, Pengming Feng", "abstract": "Label assignment is often employed in recent convolutional neural network\n(CNN) based detectors to determine positive or negative samples during training\nprocess. However, we note that current label assignment strategies barely\nconsider the characteristics of targets in remote sensing images thoroughly,\nsuch as large variations in orientations, aspect ratios and scales, which lead\nto insufficient sampling. In this paper, an Elliptical Distribution aided\nAdaptive Rotation Label Assignment (EARL) is proposed to select positive\nsamples with higher quality in orientation detectors, and yields better\nperformance. Concretely, to avoid inadequate sampling of targets with extreme\nscales, an adaptive scale sampling (ADS) strategy is proposed to dynamically\nselect samples on different feature levels according to the scales of targets.\nTo enhance ADS, positive samples are selected following a dynamic elliptical\ndistribution (DED), which can further exploit the orientation and shape\nproperties of targets. Moreover, a spatial distance weighting (SDW) module is\nintroduced to mitigate the influence from low-quality samples on detection\nperformance. Extensive experiments on popular remote sensing datasets, such as\nDOTA and HRSC2016, demonstrate the effectiveness and the superiority of our\nproposed EARL, where without bells and whistles, it achieves 72.87 of mAP on\nDOTA dataset by being integrated with simple structure, which outperforms\ncurrent state-of-the-art anchor-free detectors and provides comparable\nperformance as anchor-based methods. The source code will be available at\nhttps://github.com/Justlovesmile/EARL", "journal": "", "doi": null, "primary_category": "cs.CV", "categories": ["cs.CV"], "pdf_url": "http://arxiv.org/pdf/2301.05856v1"}
{"entry_id": "http://arxiv.org/abs/2007.15417v1", "date": "2020-07-30", "title": "Very Deep Super-Resolution of Remotely Sensed Images with Mean Square Error and Var-norm Estimators as Loss Functions", "authors": "Antigoni Panagiotopoulou, Lazaros Grammatikopoulos, Eleni Charou, Emmanuel Bratsolis, Nicholas Madamopoulos, John Petrogonas", "abstract": "In this work, very deep super-resolution (VDSR) method is presented for\nimproving the spatial resolution of remotely sensed (RS) images for scale\nfactor 4. The VDSR net is re-trained with Sentinel-2 images and with drone aero\northophoto images, thus becomes RS-VDSR and Aero-VDSR, respectively. A novel\nloss function, the Var-norm estimator, is proposed in the regression layer of\nthe convolutional neural network during re-training and prediction. According\nto numerical and optical comparisons, the proposed nets RS-VDSR and Aero-VDSR\ncan outperform VDSR during prediction with RS images. RS-VDSR outperforms VDSR\nup to 3.16 dB in terms of PSNR in Sentinel-2 images.", "journal": "", "doi": null, "primary_category": "eess.IV", "categories": ["eess.IV", "cs.CV"], "pdf_url": "http://arxiv.org/pdf/2007.15417v1"}
{"entry_id": "http://arxiv.org/abs/2108.12279v1", "date": "2021-08-26", "title": "In vivo functional and structural retina imaging using multimodal photoacoustic remote sensing microscopy and optical coherence tomography", "authors": "Zohreh Hosseinaee, Nicholas Pellegrino, Nima Abbasi, Tara Amiri, James A. Tummon Simmons, Paul Fieguth, Parsin Haji Reza", "abstract": "We have developed a multimodal photoacoustic remote sensing (PARS) microscope\ncombined with swept source optical coherence tomography for in vivo,\nnon-contact retinal imaging. Building on the proven strength of multiwavelength\nPARS imaging, the system is applied for estimating retinal oxygen saturation in\nthe rat retina. The capability of the technology is demonstrated by imaging\nboth microanatomy and the microvasculature of the retina in vivo. To our\nknowledge this is the first time a non-contact photoacoustic imaging technique\nis employed for in vivo oxygen saturation measurement in the retina.", "journal": "", "doi": null, "primary_category": "physics.med-ph", "categories": ["physics.med-ph", "eess.IV", "physics.optics"], "pdf_url": "http://arxiv.org/pdf/2108.12279v1"}
{"entry_id": "http://arxiv.org/abs/1902.05858v3", "date": "2019-02-15", "title": "Limits on $f(R,T)$ Gravity from Earth's Atmosphere", "authors": "Taylor M. Ordines, Eric D. Carlson", "abstract": "We investigate changes in Earth's atmospheric models coming from the $f(R,T)$\nmodified theory of gravity, in which the gravitational Lagrangian is given by\nan arbitrary function of the Ricci scalar and the trace of the stress-energy\ntensor. We obtain a generic form for the gravitational field equations and\nderive the hydrostatic equation for Earth's atmosphere for leading order terms\n$f(R,T) = R + 2\\chi T.$ Based on the apparent accuracy of the 1976 U.S.\nStandard Atmosphere model, which varies no more than $10\\%$ from observations,\nwe find limits of $-1.6\\times 10^{-13} \\lesssim \\chi \\lesssim 1.8\\times\n10^{-13}$.", "journal": "Phys. Rev. D 99, 104052 (2019)", "doi": "10.1103/PhysRevD.99.104052", "primary_category": "gr-qc", "categories": ["gr-qc"], "pdf_url": "http://arxiv.org/pdf/1902.05858v3"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0702027v1", "date": "2007-02-01", "title": "Planning Near Earth Asteroid Observations on a 1m Class Telescope", "authors": "Ovidiu Vaduvescu, Mirel Birlan", "abstract": "The number of known Near Earth Asteroids (NEAs) and Potentially Hazardous\nAsteroids (PHAs) has continued to grow in the last decade. Follow-up and\nrecovery of newly discovered objects, as well as new astrometry at second or\nthird oppositions are necessary to improve their orbits and predict any\npotential collision with the Earth in the future. A project to follow-up and\nrecovery PHAs and NEAs is proposed, using 1m class telescopes in the next two\nyears. Two incoming runs will take place first at Pic du Midi Observatory\n(France) and SAAO (South Africa), both to use 1m telescopes. Other observing\nruns are sought in the future. Collaborators to extend this project are\nwelcomed.", "journal": "", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0702027v1"}
{"entry_id": "http://arxiv.org/abs/2110.08333v1", "date": "2021-10-15", "title": "Probing the Earth's Core using Atmospheric Neutrinos at INO", "authors": "Anil Kumar, Sanjib Kumar Agarwalla", "abstract": "The proposed 50 kt Iron Calorimeter (ICAL) detector at the India-based\nNeutrino Observatory (INO) aims to detect atmospheric muon neutrinos and\nantineutrinos separately in the multi-GeV range of energies and over a wide\nrange of path lengths. While passing through the Earth, the upward-going\nneutrinos experience a density-dependent matter effect, which can be utilized\nto extract information about the internal structure of Earth. Since the Earth's\nmatter effect modifies the neutrino oscillation patterns differently for\nneutrinos and antineutrinos, the capability of ICAL to distinguish $\\mu^-$ and\n$\\mu^+$ events plays an important role in observing this matter effect. Taking\nadvantage of good angular resolution, ICAL would be able to observe about 331\n$\\mu^-$ and 146 $\\mu^+$ events corresponding to the core-passing neutrinos and\nantineutrinos, respectively, in 10 years. We demonstrate for the first time\nthat ICAL would be able to validate the presence of Earth's core by ruling out\na two-layered profile consisting of only mantle and crust in fit with respect\nto the PREM profile in data with a median $\\Delta \\chi^2$ of 7.45 for normal\nmass ordering (NO) and 4.83 for inverted mass ordering (IO) using 500\nkt$\\cdot$yr exposure. If we do not use the charge identification capability of\nICAL, these sensitivities deteriorate to a $\\Delta\\chi^2$ of 3.76 for NO and\n1.59 for IO.", "journal": "", "doi": null, "primary_category": "hep-ph", "categories": ["hep-ph", "physics.ins-det"], "pdf_url": "http://arxiv.org/pdf/2110.08333v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0304314v2", "date": "2003-04-16", "title": "Resolving the Microlens Mass Degeneracy for Earth-Mass Planets", "authors": "Andrew Gould, B. Scott Gaudi, Cheongho Han", "abstract": "Of all planet-finding techniques, microlensing is potentially the most\nsensitive to Earth-mass planets. However, microlensing lightcurves generically\nyield only the planet-star mass ratio: the mass itself is uncertain to a factor\nof a few. To determine the planet mass, one must measure both the ``microlens\nparallax'' and source-lens relative proper motion. Here we present a new method\nto measure microlens masses for terrestrial planets. We show that, with only a\nmodest adjustment to the proposed orbit of the dedicated satellite that finds\nthe events, and combined with observations from a ground-based observing\nprogram, the planet mass can be measured routinely. The dedicated satellite\nthat finds the events will automatically measure the proper motion and one\nprojection of the ``vector microlens parallax.'' If the satellite is placed in\nan L2 orbit, or a highly elliptical orbit around the Earth, the Earth-satellite\nbaseline is sufficient to measure a second projection of the vector microlens\nparallax from the difference in the lightcurves as seen from the Earth and the\nsatellite as the source passes over the caustic structure induced by the\nplanet. This completes the mass measurement.", "journal": "Astrophys.J. 591 (2003) L53-L56", "doi": "10.1086/377071", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0304314v2"}
{"entry_id": "http://arxiv.org/abs/hep-ph/0308175v2", "date": "2003-08-18", "title": "Discriminating among Earth composition models using geo-antineutrinos", "authors": "H. Nunokawa, W. J. C. Teves, R. Zukanovich Funchal", "abstract": "It has been estimated that the entire Earth generates heat corresponding to\nabout 40 TW (equivalent to 10,000 nuclear power plants) which is considered to\noriginate mainly from the radioactive decay of elements like U, Th and K,\ndeposited in the crust and mantle of the Earth. Radioactivity of these elements\nproduce not only heat but also antineutrinos (called geo-antineutrinos) which\ncan be observed by terrestrial detectors. We investigate the possibility of\ndiscriminating among Earth composition models predicting different total\nradiogenic heat generation, by observing such geo-antineutrinos at Kamioka and\nGran Sasso, assuming KamLAND and Borexino (type) detectors, respectively, at\nthese places. By simulating the future geo-antineutrino data as well as reactor\nantineutrino background contributions, we try to establish to which extent we\ncan discriminate among Earth composition models for given exposures (in units\nof kt$\\cdot$ yr) at these two sites on our planet. We use also information on\nneutrino mixing parameters coming from solar neutrino data as well as KamLAND\nreactor antineutrino data, in order to estimate the number of geo-antineutrino\ninduced events.", "journal": "JHEP 0311 (2003) 020", "doi": "10.1088/1126-6708/2003/11/020", "primary_category": "hep-ph", "categories": ["hep-ph", "hep-ex", "nucl-ex", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/hep-ph/0308175v2"}
{"entry_id": "http://arxiv.org/abs/1207.5049v2", "date": "2012-07-20", "title": "(Down-to-)Earth matter effect in supernova neutrinos", "authors": "Enrico Borriello, Sovan Chakraborty, Alessandro Mirizzi, Pasquale Dario Serpico, Irene Tamborra", "abstract": "Neutrino oscillations in the Earth matter may introduce peculiar modulations\nin the supernova (SN) neutrino spectra. The detection of this effect has been\nproposed as diagnostic tool for the neutrino mass hierarchy at \"large\" 1-3\nleptonic mixing angle theta13. We perform an updated study on the observability\nof this effect at large next-generation underground detectors (i.e., 0.4 Mton\nwater Cherenkov, 50 kton scintillation and 100 kton liquid Argon detectors)\nbased on neutrino fluxes from state-of-the-art SN simulations and accounting\nfor statistical fluctuations via Montecarlo simulations. Since the average\nenergies predicted by recent simulations are lower than previously expected and\na tendency towards the equalization of the neutrino fluxes appears during the\nSN cooling phase, the detection of the Earth matter effect will be more\nchallenging than expected from previous studies. We find that none of the\nproposed detectors shall be able to detect the Earth modulation for the\nneutrino signal of a typical galactic SN at 10 kpc. It should be observable in\na 100 kton liquid Argon detector for a SN at few kpc and all three detectors\nwould clearly see the Earth signature for very close-by stars only (d ~ 0.2\nkpc). Finally, we show that adopting IceCube as co-detector together with a\nMton water Cherenkov detector is not a viable option either.", "journal": "Phys. Rev. D 86, 083004 (2012)", "doi": "10.1103/PhysRevD.86.083004", "primary_category": "hep-ph", "categories": ["hep-ph", "astro-ph.SR", "hep-ex"], "pdf_url": "http://arxiv.org/pdf/1207.5049v2"}
{"entry_id": "http://arxiv.org/abs/1609.04798v1", "date": "2016-09-15", "title": "Super-Earths as Failed Cores in Orbital Migration Traps", "authors": "Yasuhiro Hasegawa", "abstract": "We explore whether close-in super-Earths were formed as rocky bodies that\nfailed to grow fast enough to become the cores of gas giants before the natal\nprotostellar disk dispersed. We model the failed cores' inward orbital\nmigration in the low-mass or type I regime, to stopping points at distances\nwhere the tidal interaction with the protostellar disk applies zero net torque.\nThe three kinds of migration traps considered are those due to the dead zone's\nouter edge, the ice line, and the transition from accretion to starlight as the\ndisk's main heat source. As the disk disperses, the traps move toward final\npositions near or just outside 1~au. Planets at this location exceeding about\n3~M$_\\oplus$ open a gap, decouple from their host trap, and migrate inward in\nthe high-mass or type II regime to reach the vicinity of the star. We\nsynthesize the population of planets formed in this scenario, finding that some\nfraction of the observed super-Earths can be failed cores. Most super-Earths\nformed this way have more than 4~M$_\\oplus$, so their orbits when the disk\ndisperses are governed by type II migration. These planets have solid cores\nsurrounded by gaseous envelopes. Their subsequent photoevaporative mass loss is\nmost effective for masses originally below about 6 M$_\\oplus$. The failed core\nscenario suggests a division of the observed super-Earth mass-radius diagram\ninto five zones according to the inferred formation history.", "journal": "", "doi": "10.3847/0004-637X/832/1/83", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1609.04798v1"}
{"entry_id": "http://arxiv.org/abs/2201.00846v1", "date": "2022-01-03", "title": "Convectively driven decadal zonal accelerations in Earth's fluid core", "authors": "Colin More, Mathieu Dumberry", "abstract": "Azimuthal accelerations of cylindrical surfaces co-axial with the rotation\naxis have been inferred to exist in Earth's fluid core on the basis of magnetic\nfield observations and changes in the length-of-day. These accelerations have a\ntypical timescale of decades. However, the physical mechanism causing the\naccelerations is not well understood. Scaling arguments suggest that the\nleading order torque averaged over cylindrical surfaces should arise from the\nLorentz force. Decadal fluctuations in the magnetic field inside the core,\ndriven by convective flows, could then force decadal changes in the Lorentz\ntorque and generate zonal accelerations. We test this hypothesis by\nconstructing a quasi-geostrophic model of magnetoconvection, with\nthermally-driven flows perturbing a steady, imposed background magnetic field.\nWe show that when the Alfv\\'{e}n number in our model is similar to that in\nEarth's fluid core, temporal fluctuations in the torque balance are dominated\nby the Lorentz torque, with the latter generating mean zonal accelerations. Our\nmodel reproduces both fast, free Alfv\\'{e}n waves and slow, forced\naccelerations, with ratios of relative strength and relative timescale similar\nto those inferred for the Earth's core. The temporal changes in the magnetic\nfield which drive the time-varying Lorentz torque are produced by the\nunderlying convective flows, shearing and advecting the magnetic field on a\ntimescale associated with convective eddies. Our results support the hypothesis\nthat temporal changes in the magnetic field deep inside Earth's fluid core\ndrive the observed decadal zonal accelerations of cylindrical surfaces through\nthe Lorentz torque.", "journal": "Geophysical Journal International, 2018, vol 213, 434-446", "doi": "10.1093/gji/ggx548", "primary_category": "physics.geo-ph", "categories": ["physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2201.00846v1"}
{"entry_id": "http://arxiv.org/abs/2212.00819v1", "date": "2022-12-01", "title": "Magnetic and Electrical Properties of high-entropy rare-earth manganites", "authors": "Ashutosh Kumar, David B\u00e9rardan, Diana Dragoe, Eric Riviere, Tomohiro Takayama, Hidenori Takagi, Nita Dragoe", "abstract": "Detailed investigations of structural, magnetic and electronic transport\nproperties of hole-doped high-entropy rare-earth manganites are presented. The\nhigh-entropy samples (LaNdPrSmEu)$_{1-x}$Sr$_x$MnO$_3$\n(0$\\leq$\\textit{x}$\\leq$0.5), synthesized using the solid-state technique, show\na change in the crystal structure from \\textit{Pbnm} to \\textit{R-3c} with\nincreasing Sr substitution, attributed to the change in the tolerance factor.\nProminent ferromagnetic ordering is observed in the sample with a rhombohedral\nstructure (\\textit{x}$\\geq$0.3), originating from the dominant double exchange\nmechanism mediated by itinerant electrons. Further, the Curie temperature is\nsmaller for the high-entropy sample with \\textit{x}=0.3, as compared to\nLa$_{0.7}$Sr$_{0.3}$MnO$_3$, suggesting a strong relation between the Curie\ntemperature and the Mn-O-Mn bond angle associated with the reduced ionic radii\nat the rare-earth site. The electrical resistivity of the high-entropy samples\nis larger than those of La$_{1-x}$Sr$_x$MnO$_3$, which can be ascribed to the\nreduced bandwidth due to the enhanced structural distortion. A concomitant rise\nin magnetoresistance is observed for high-entropy samples with the increase in\nSr concentration. These findings considering the configurational complexity of\ndifferent rare-earths advance the understanding of high-entropy rare earth\nmanganites.", "journal": "Materials Today Physics 32 (2023) 101026", "doi": "10.1016/j.mtphys.2023.101026", "primary_category": "cond-mat.str-el", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf_url": "http://arxiv.org/pdf/2212.00819v1"}
{"entry_id": "http://arxiv.org/abs/0906.2958v1", "date": "2009-06-16", "title": "The transmission spectrum of Earth through lunar eclipse observations", "authors": "Enric Palle, Maria Rosa Zapatero Osorio, Pilar Montanes-Rodriguez, Rafael Barrena, Eduardo L. Martin", "abstract": "Of the 342 planets discovered so far orbiting other stars, 58 \"transit\" the\nstellar disk, meaning that they can be detected by a periodic decrease in the\nstarlight flux. The light from the star passes through the atmosphere of the\nplanet, and in a few cases the basic atmospheric composition of the planet can\nbe estimated. As we get closer to finding analogues of Earth, an important\nconsideration toward the characterization of exoplanetary atmospheres is what\nthe transmission spectrum of our planet looks like. Here we report the optical\nand near-infrared transmission spectrum of the Earth, obtained during a lunar\neclipse. Some biologically relevant atmospheric features that are weak in the\nreflected spectrum (such as ozone, molecular oxygen, water, carbon dioxide and\nmethane) are much stronger in the transmission spectrum, and indeed stronger\nthan predicted by modelling. We also find the fingerprints of the Earth's\nionosphere and of the major atmospheric constituent, diatomic nitrogen (N2),\nwhich are missing in the reflected spectrum.", "journal": "2009, Nature, 459, 814", "doi": "10.1038/nature08050", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP", "astro-ph.SR"], "pdf_url": "http://arxiv.org/pdf/0906.2958v1"}
{"entry_id": "http://arxiv.org/abs/1310.2980v1", "date": "2013-10-10", "title": "The Population of Tiny Near-Earth Objects Observed by NEOWISE", "authors": "A. Mainzer, J. Bauer, T. Grav, J. Masiero, R. M. Cutri, E. L. Wright, C. R. Nugent, R. Stevenson, E. Clyne, G. Cukrov, F. Masci", "abstract": "Only a very small fraction of the asteroid population at size scales\ncomparable to the object that exploded over Chelyabinsk, Russia has been\ndiscovered to date, and physical properties are poorly characterized. We\npresent previously unreported detections of 106 close approaching near-Earth\nobjects (NEOs) by the Wide-field Infrared Survey Explorer mission's NEOWISE\nproject. These infrared observations constrain physical properties such as\ndiameter and albedo for these objects, many of which are found to be smaller\nthan 100 m. Because these objects are intrinsically faint, they were detected\nby WISE during very close approaches to the Earth, often at large apparent\non-sky velocities. We observe a trend of increasing albedo with decreasing\nsize, but as this sample of NEOs was discovered by visible light surveys, it is\nlikely that selection biases against finding small, dark NEOs influence this\nfinding.", "journal": "", "doi": "10.1088/0004-637X/784/2/110", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/1310.2980v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/9912254v1", "date": "1999-12-13", "title": "Earth Trojan asteroids: A study in support of observational searches", "authors": "Paul Wiegert, Kimmo Innanen, Seppo Mikkola", "abstract": "Observational searches for asteroids orbiting near Earth's triangular\nLagrange points face unique obstacles. A population of such asteroids would\noccupy a large projected area on the sky (possibly hundreds of square degrees)\nand is not favorably placed with respect to the Sun. Here we examine the\nproperties of synthetic populations of Earth ``Trojans'' in order to aid in the\noptimization of observational searches for them. We find that the highest\non-sky projected number densities are not located at the positions of the L4\nand L5 points themselves, but rather a few degrees closer to the Sun. Also,\nasteroids on orbits about the L4 and L5 points typically brighten as the\ndifference between their ecliptic longitude and that of the Sun increases owing\nto phase effects, but their number density on the sky concurrently falls\nrapidly.", "journal": "", "doi": "10.1006/icar.2000.6339", "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/9912254v1"}
{"entry_id": "http://arxiv.org/abs/astro-ph/0308162v1", "date": "2003-08-10", "title": "Evolution of angular momenta and energy of the Earth-Moon system", "authors": "Arbab I. Arbab", "abstract": "We have developed a model for the evolution of the Earth-Moon angular\nmomenta, energy dissipation and tidal torque valid for the entire history of\nthe Earth-Moon system. The model is supported by present observational data.", "journal": "Acta Geod.Geophys.Hung. 40 (2005) 33-42", "doi": null, "primary_category": "astro-ph", "categories": ["astro-ph"], "pdf_url": "http://arxiv.org/pdf/astro-ph/0308162v1"}
{"entry_id": "http://arxiv.org/abs/quant-ph/0308127v1", "date": "2003-08-25", "title": "Remote preparation of a single-mode photonic qubit by measuring field quadrature noise", "authors": "S. A. Babichev, B. Brezger, A. I. Lvovsky", "abstract": "An electromagnetic field quadrature measurement, performed on one of the\nmodes of the nonlocal single-photon state $a|1,0>-b|0,1>$, collapses it into a\nsuperposition of the single-photon and vacuum states in the other mode. We use\nthis effect to implement remote preparation of arbitrary single-mode photonic\nqubits conditioned on observation of a preselected quadrature value. The\nquantum efficiency of the prepared qubit can be higher than that of the initial\nsingle photon.", "journal": "Physical Review Letters 92, 047903 (2004)", "doi": "10.1103/PhysRevLett.92.047903", "primary_category": "quant-ph", "categories": ["quant-ph"], "pdf_url": "http://arxiv.org/pdf/quant-ph/0308127v1"}
{"entry_id": "http://arxiv.org/abs/0907.3010v2", "date": "2009-07-17", "title": "Asymmetric impacts of near-Earth asteroids on the Moon", "authors": "Takashi Ito, Renu Malhotra", "abstract": "Recent lunar crater studies have revealed an asymmetric distribution of rayed\ncraters on the lunar surface. The asymmetry is related to the synchronous\nrotation of the Moon: there is a higher density of rayed craters on the leading\nhemisphere compared with the trailing hemisphere. Rayed craters represent\ngenerally the youngest impacts. The purpose of this paper is to test the\nhypotheses that (i) the population of Near-Earth asteroids (NEAs) is the source\nof the impactors that have made the rayed craters, and (ii) that impacts by\nthis projectile population account quantitatively for the observed asymmetry.\nWe carried out numerical simulations of the orbital evolution of a large number\nof test particles representing NEAs in order to determine directly their impact\nflux on the Moon. The simulations were done in two stages. In the first stage\nwe obtained encounter statistics of NEAs on the Earth's activity sphere. In the\nsecond stage we calculated the direct impact flux of the encountering particles\non the surface of the Moon; the latter calculations were confined within the\nactivity sphere of the Earth. A steady-state synthetic population of NEAs was\ngenerated from a debiased orbital distribution of the known NEAs. We find that\nthe near-Earth asteroids do have an asymmetry in their impact flux on the Moon:\napex-to-antapex ratio of 1.32 +/- 0.01. However, the observed rayed crater\ndistribution's asymmetry is significantly more pronounced: apex-to-antapex\nratio of 1.65 +/- 0.16. Our results suggest the existence of an undetected\npopulation of slower (low impact velocity) projectiles, such as a population of\nobjects nearly coorbiting with Earth; more observational study of young lunar\ncraters is needed to secure this conclusion.", "journal": "Astronomy & Astrophysics 519, A63 (2010)", "doi": "10.1051/0004-6361/200912901", "primary_category": "astro-ph.EP", "categories": ["astro-ph.EP"], "pdf_url": "http://arxiv.org/pdf/0907.3010v2"}
{"entry_id": "http://arxiv.org/abs/2103.16909v1", "date": "2021-03-31", "title": "Generating Multi-scale Maps from Remote Sensing Images via Series Generative Adversarial Networks", "authors": "Xu Chen, Bangguo Yin, Songqiang Chen, Haifeng Li, Tian Xu", "abstract": "Considering the success of generative adversarial networks (GANs) for\nimage-to-image translation, researchers have attempted to translate remote\nsensing images (RSIs) to maps (rs2map) through GAN for cartography. However,\nthese studies involved limited scales, which hinders multi-scale map creation.\nBy extending their method, multi-scale RSIs can be trivially translated to\nmulti-scale maps (multi-scale rs2map translation) through scale-wise rs2map\nmodels trained for certain scales (parallel strategy). However, this strategy\nhas two theoretical limitations. First, inconsistency between various spatial\nresolutions of multi-scale RSIs and object generalization on multi-scale maps\n(RS-m inconsistency) increasingly complicate the extraction of geographical\ninformation from RSIs for rs2map models with decreasing scale. Second, as\nrs2map translation is cross-domain, generators incur high computation costs to\ntransform the RSI pixel distribution to that on maps. Thus, we designed a\nseries strategy of generators for multi-scale rs2map translation to address\nthese limitations. In this strategy, high-resolution RSIs are inputted to an\nrs2map model to output large-scale maps, which are translated to multi-scale\nmaps through series multi-scale map translation models. The series strategy\navoids RS-m inconsistency as inputs are high-resolution large-scale RSIs, and\nreduces the distribution gap in multi-scale map generation through similar\npixel distributions among multi-scale maps. Our experimental results showed\nbetter quality multi-scale map generation with the series strategy, as shown by\naverage increases of 11.69%, 53.78%, 55.42%, and 72.34% in the structural\nsimilarity index, edge structural similarity index, intersection over union\n(road), and intersection over union (water) for data from Mexico City and Tokyo\nat zoom level 17-13.", "journal": "", "doi": "10.1109/LGRS.2021.3129285", "primary_category": "cs.CV", "categories": ["cs.CV", "eess.IV"], "pdf_url": "http://arxiv.org/pdf/2103.16909v1"}
